{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb491c47-7a4f-49d5-bc28-670f3f1b9a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import torch\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from data_prep.dataset import Dataset\n",
    "from data_prep.dataset_loader import LoadData\n",
    "from loguru import logger\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from utils.utils import excute_cmd, execute_cmd_realtime\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import mode\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "from networks.NetworkController import getNetwork\n",
    "from experiments.ClassifierController import getExperiment\n",
    "\n",
    "# Custom log format\n",
    "fmt = \"{message}\"\n",
    "config = {\n",
    "    \"handlers\": [\n",
    "        {\"sink\": sys.stderr, \"format\": fmt},\n",
    "    ],\n",
    "}\n",
    "logger.configure(**config)\n",
    "\n",
    "# To allow auto reload to this notebook after modifying any external file imported\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b972a00d-6922-4a6d-baf8-7a7d322f54c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading the data from ../datasets/challenge1/train\n",
      "Loading the data from ../datasets/challenge1/val\n"
     ]
    }
   ],
   "source": [
    "dataset_path_ch1_train = '../datasets/challenge1/train'\n",
    "dataset_path_ch1_valid = '../datasets/challenge1/val'\n",
    "\n",
    "train_dataset_df, train_images, train_labels, n_classes = LoadData(dataset_path_ch1_train, class_labels = {'nevus': 0, 'others': 1})\n",
    "valid_dataset_df, valid_images, valid_labels, n_classes = LoadData(dataset_path_ch1_valid, class_labels = {'nevus': 0, 'others': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12cb834a-8b42-4acf-9d0b-79fed26ebf1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<data_prep.dataset.Dataset at 0x7f1792b1e530>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataset = Dataset(\n",
    "        images_path=valid_images, labels=valid_labels, transform=True, split=\"val\", \n",
    "        input_size=(224, 224)\n",
    "        )\n",
    "val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64ae99cf-fc47-42cc-84a5-c64715015c69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7f1792b1e3e0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=32, shuffle=True)\n",
    "val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a85ed32-37f8-4084-a107-93cbf35e9f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15195 15195\n",
      "3796 3796\n"
     ]
    }
   ],
   "source": [
    "print(len(train_images), len(train_labels))\n",
    "print(len(valid_images), len(valid_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b16048b9-ba9d-498d-88a0-139a77ec64df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "0    7725\n",
       "1    7470\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset_df['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d59f77e8-d5ab-4d12-a149-a0e5d2fa443a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://chat.openai.com/share/a41b7798-5a48-4f8f-8603-4babcb68bb37"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c67f29c9-6188-4970-b77e-192656c15afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the training and validation datasets\n",
    "all_images = train_images + valid_images\n",
    "all_labels = train_labels + valid_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb0e5d9c-feda-47cd-81cb-2fc4f25181bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18991,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(all_images).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93ad32af-d1b9-45c0-93d9-4d6d2ac03845",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18991,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(all_labels).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e210e456-88b3-49ad-825b-cf260c3e413d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with all the data\n",
    "all_data_df = pd.concat([train_dataset_df, valid_dataset_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "48ca39a5-542f-43d2-aa5b-673a9d064c92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image_Path</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/mnt/c/Users/abdal/Documents/Master/EMJMD MAIA...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/mnt/c/Users/abdal/Documents/Master/EMJMD MAIA...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/mnt/c/Users/abdal/Documents/Master/EMJMD MAIA...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/mnt/c/Users/abdal/Documents/Master/EMJMD MAIA...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/mnt/c/Users/abdal/Documents/Master/EMJMD MAIA...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3791</th>\n",
       "      <td>/mnt/c/Users/abdal/Documents/Master/EMJMD MAIA...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3792</th>\n",
       "      <td>/mnt/c/Users/abdal/Documents/Master/EMJMD MAIA...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3793</th>\n",
       "      <td>/mnt/c/Users/abdal/Documents/Master/EMJMD MAIA...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3794</th>\n",
       "      <td>/mnt/c/Users/abdal/Documents/Master/EMJMD MAIA...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3795</th>\n",
       "      <td>/mnt/c/Users/abdal/Documents/Master/EMJMD MAIA...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18991 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Image_Path  Label\n",
       "0     /mnt/c/Users/abdal/Documents/Master/EMJMD MAIA...      0\n",
       "1     /mnt/c/Users/abdal/Documents/Master/EMJMD MAIA...      0\n",
       "2     /mnt/c/Users/abdal/Documents/Master/EMJMD MAIA...      0\n",
       "3     /mnt/c/Users/abdal/Documents/Master/EMJMD MAIA...      0\n",
       "4     /mnt/c/Users/abdal/Documents/Master/EMJMD MAIA...      0\n",
       "...                                                 ...    ...\n",
       "3791  /mnt/c/Users/abdal/Documents/Master/EMJMD MAIA...      1\n",
       "3792  /mnt/c/Users/abdal/Documents/Master/EMJMD MAIA...      1\n",
       "3793  /mnt/c/Users/abdal/Documents/Master/EMJMD MAIA...      1\n",
       "3794  /mnt/c/Users/abdal/Documents/Master/EMJMD MAIA...      1\n",
       "3795  /mnt/c/Users/abdal/Documents/Master/EMJMD MAIA...      1\n",
       "\n",
       "[18991 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b19ded94-2c8a-450b-9c3d-a9c3e702cfc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV 1/3]: Train index length 12660, Validation index length 6331...\n",
      "int64 [    0     1     3 ... 18986 18988 18990]\n",
      "6331\n",
      "\n",
      "[CV 2/3]: Train index length 12661, Validation index length 6330...\n",
      "int64 [    0     1     2 ... 18987 18988 18989]\n",
      "6330\n",
      "\n",
      "[CV 3/3]: Train index length 12661, Validation index length 6330...\n",
      "int64 [    2     4     5 ... 18987 18989 18990]\n",
      "6330\n"
     ]
    }
   ],
   "source": [
    "num_folds = 3\n",
    "\n",
    "# Create lists to store the split indices\n",
    "train_indices_list = []\n",
    "valid_indices_list = []\n",
    "\n",
    "# Assuming train_images and train_labels are numpy arrays or lists\n",
    "skf = StratifiedKFold(n_splits= num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "val_rows_list = []\n",
    "\n",
    "for fold, (train_index, val_index) in enumerate(skf.split(all_images, all_labels)):\n",
    "    print(f\"\\n[CV {fold + 1}/{num_folds}]: Train index length {len(train_index)}, Validation index length {len(val_index)}...\")\n",
    "    print(train_index.dtype, train_index)\n",
    "    print(len(val_index))\n",
    "    images_path = [all_images[i] for i in train_index]\n",
    "    labels_path = [all_images[i] for i in val_index]\n",
    "\n",
    "# for fold in range(num_folds):\n",
    "#     # Get the indices for the current split\n",
    "#     train_indices = train_indices_list[fold]\n",
    "#     valid_indices = valid_indices_list[fold]\n",
    "\n",
    "#     # Use the indices to create the training and validation datasets\n",
    "#     train_dataset = all_data_df.iloc[fold]\n",
    "#     valid_dataset = all_data_df.iloc[fold]\n",
    "\n",
    "#     # Separate the images and labels for training and validation\n",
    "#     train_images = all_images[fold]\n",
    "#     train_labels = all_labels[fold]\n",
    "\n",
    "#     valid_images = all_images[fold]\n",
    "#     valid_labels = all_labels[fold]\n",
    "\n",
    "\n",
    "    \n",
    "#     # Select rows based on the validation index\n",
    "#     train_rows = train_dataset_df.iloc[train_index]\n",
    "#     val_rows = train_dataset_df.iloc[val_index]\n",
    "\n",
    "#     # Append val_rows to the list\n",
    "#     val_rows_list.append(val_rows)\n",
    "\n",
    "#     # Perform value counts on train_dataset_df for the selected rows\n",
    "#     value_counts = val_rows['Label'].value_counts()\n",
    "#     print(value_counts)\n",
    "\n",
    "# # Check if all val_rows are the same\n",
    "# are_val_rows_same = all(val_rows.equals(val_rows_list[0]) for val_rows in val_rows_list[1:])\n",
    "\n",
    "# if are_val_rows_same:\n",
    "#     print(\"\\nValidation rows are the same in every fold.\")\n",
    "# else:\n",
    "#     print(\"\\nValidation rows differ across folds.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "66f7b892-ea3b-4dfa-b920-fcd6cd6ed971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV 1/7]: Train index length 16278, Validation index length 2713...\n",
      "16278\n",
      "2713\n",
      "\n",
      "[CV 2/7]: Train index length 16278, Validation index length 2713...\n",
      "16278\n",
      "2713\n",
      "\n",
      "[CV 3/7]: Train index length 16278, Validation index length 2713...\n",
      "16278\n",
      "2713\n",
      "\n",
      "[CV 4/7]: Train index length 16278, Validation index length 2713...\n",
      "16278\n",
      "2713\n",
      "\n",
      "[CV 5/7]: Train index length 16278, Validation index length 2713...\n",
      "16278\n",
      "2713\n",
      "\n",
      "[CV 6/7]: Train index length 16278, Validation index length 2713...\n",
      "16278\n",
      "2713\n",
      "\n",
      "[CV 7/7]: Train index length 16278, Validation index length 2713...\n",
      "16278\n",
      "2713\n"
     ]
    }
   ],
   "source": [
    "num_folds = 7\n",
    "\n",
    "# Create lists to store the split indices\n",
    "train_indices_list = []\n",
    "valid_indices_list = []\n",
    "\n",
    "# Assuming train_images and train_labels are numpy arrays or lists\n",
    "skf = StratifiedKFold(n_splits= num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "val_rows_list = []\n",
    "\n",
    "for fold, (train_index, val_index) in enumerate(skf.split(all_images, all_labels)):\n",
    "    print(f\"\\n[CV {fold + 1}/{num_folds}]: Train index length {len(train_index)}, Validation index length {len(val_index)}...\")\n",
    "    print(len(train_index))\n",
    "    print(len(val_index))\n",
    "    images_path = [all_images[i] for i in train_index]\n",
    "    labels_path = [all_images[i] for i in val_index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e694b47-4448-4452-87b9-1a9d6e66ee39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,     1,    10, ..., 18957, 18962, 18974])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "78fc50df-afb3-41ec-9630-33a3b884145b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excuting training pipeline with 1 epochs and 2 folds.\n",
      "Loading the data from ../datasets/challenge1/train\n",
      "Loading the data from ../datasets/challenge1/val\n",
      "Creating a classifier experiment using VGG16_BN_Attention network.\n",
      "Using VGG16_BN_Attention with configurations: num_classes='2', normalize_attn='False'\n",
      "[CV 1/2]: Epoch: 1, train batch 10, loss: 0.638522207736969, 3.4% complete\n",
      "[CV 1/2]: Epoch: 1, train batch 20, loss: 0.4631451964378357, 6.7% complete\n",
      "[CV 1/2]: Epoch: 1, train batch 30, loss: 0.49124935269355774, 10.1% complete\n",
      "[CV 1/2]: Epoch: 1, train batch 40, loss: 0.6418288946151733, 13.5% complete\n",
      "[CV 1/2]: Epoch: 1, train batch 50, loss: 0.5985834002494812, 16.8% complete\n",
      "[CV 1/2]: Epoch: 1, train batch 60, loss: 0.5354160070419312, 20.2% complete\n",
      "[CV 1/2]: Epoch: 1, train batch 70, loss: 0.3409406244754791, 23.6% complete\n",
      "[CV 1/2]: Epoch: 1, train batch 80, loss: 0.40570464730262756, 26.9% complete\n",
      "[CV 1/2]: Epoch: 1, train batch 90, loss: 0.5311029553413391, 30.3% complete\n",
      "[CV 1/2]: Epoch: 1, train batch 100, loss: 0.5910346508026123, 33.7% complete\n",
      "[CV 1/2]: Epoch: 1, train batch 110, loss: 0.40738439559936523, 37.0% complete\n",
      "[CV 1/2]: Epoch: 1, train batch 120, loss: 0.4142916202545166, 40.4% complete\n",
      "[CV 1/2]: Epoch: 1, train batch 130, loss: 0.5336112976074219, 43.8% complete\n",
      "[CV 1/2]: Epoch: 1, train batch 140, loss: 0.4894949495792389, 47.1% complete\n",
      "[CV 1/2]: Epoch: 1, train batch 150, loss: 0.5846906304359436, 50.5% complete\n",
      "[CV 1/2]: Epoch: 1, train batch 160, loss: 0.4080733358860016, 53.9% complete\n",
      "[CV 1/2]: Epoch: 1, train batch 170, loss: 0.5399501919746399, 57.2% complete\n",
      "[CV 1/2]: Epoch: 1, train batch 180, loss: 0.41700479388237, 60.6% complete\n",
      "[CV 1/2]: Epoch: 1, train batch 190, loss: 0.49283817410469055, 64.0% complete\n",
      "[CV 1/2]: Epoch: 1, train batch 200, loss: 0.5622982978820801, 67.3% complete\n",
      "[CV 1/2]: Epoch: 1, train batch 210, loss: 0.45800456404685974, 70.7% complete\n",
      "[CV 1/2]: Epoch: 1, train batch 220, loss: 0.45018497109413147, 74.1% complete\n",
      "[CV 1/2]: Epoch: 1, train batch 230, loss: 0.45155149698257446, 77.4% complete\n",
      "[CV 1/2]: Epoch: 1, train batch 240, loss: 0.5169567465782166, 80.8% complete\n",
      "[CV 1/2]: Epoch: 1, train batch 250, loss: 0.4836142361164093, 84.2% complete\n",
      "[CV 1/2]: Epoch: 1, train batch 260, loss: 0.45411697030067444, 87.5% complete\n",
      "[CV 1/2]: Epoch: 1, train batch 270, loss: 0.5948019027709961, 90.9% complete\n",
      "[CV 1/2]: Epoch: 1, train batch 280, loss: 0.5976235270500183, 94.3% complete\n",
      "[CV 1/2]: Epoch: 1, train batch 290, loss: 0.3459450900554657, 97.6% complete\n",
      "[CV 1/2]:Epoch: 1, valid batch 1, loss 0.3415718674659729\n",
      "[CV 1/2]:Epoch: 1, valid batch 2, loss 0.1698364019393921\n",
      "[CV 1/2]:Epoch: 1, valid batch 3, loss 0.6243555545806885\n",
      "[CV 1/2]:Epoch: 1, valid batch 4, loss 0.4672394394874573\n",
      "[CV 1/2]:Epoch: 1, valid batch 5, loss 0.35892629623413086\n",
      "[CV 1/2]:Epoch: 1, valid batch 6, loss 0.6149340271949768\n",
      "[CV 1/2]:Epoch: 1, valid batch 7, loss 0.5242539644241333\n",
      "[CV 1/2]:Epoch: 1, valid batch 8, loss 0.28884634375572205\n",
      "[CV 1/2]:Epoch: 1, valid batch 9, loss 0.39083611965179443\n",
      "[CV 1/2]:Epoch: 1, valid batch 10, loss 0.4054079055786133\n",
      "[CV 1/2]:Epoch: 1, valid batch 11, loss 0.40327197313308716\n",
      "[CV 1/2]:Epoch: 1, valid batch 12, loss 0.36710628867149353\n",
      "[CV 1/2]:Epoch: 1, valid batch 13, loss 0.4010208547115326\n",
      "[CV 1/2]:Epoch: 1, valid batch 14, loss 0.494968444108963\n",
      "[CV 1/2]:Epoch: 1, valid batch 15, loss 0.3349051773548126\n",
      "[CV 1/2]:Epoch: 1, valid batch 16, loss 0.6364736557006836\n",
      "[CV 1/2]:Epoch: 1, valid batch 17, loss 0.5647780299186707\n",
      "[CV 1/2]:Epoch: 1, valid batch 18, loss 0.38993993401527405\n",
      "[CV 1/2]:Epoch: 1, valid batch 19, loss 0.42642366886138916\n",
      "[CV 1/2]:Epoch: 1, valid batch 20, loss 0.4394567906856537\n",
      "[CV 1/2]:Epoch: 1, valid batch 21, loss 0.4225645959377289\n",
      "[CV 1/2]:Epoch: 1, valid batch 22, loss 0.6101760864257812\n",
      "[CV 1/2]:Epoch: 1, valid batch 23, loss 0.40668636560440063\n",
      "[CV 1/2]:Epoch: 1, valid batch 24, loss 0.36991629004478455\n",
      "[CV 1/2]:Epoch: 1, valid batch 25, loss 0.5056471824645996\n",
      "[CV 1/2]:Epoch: 1, valid batch 26, loss 0.42679619789123535\n",
      "[CV 1/2]:Epoch: 1, valid batch 27, loss 0.44964271783828735\n",
      "[CV 1/2]:Epoch: 1, valid batch 28, loss 0.4108135998249054\n",
      "[CV 1/2]:Epoch: 1, valid batch 29, loss 0.5419936776161194\n",
      "[CV 1/2]:Epoch: 1, valid batch 30, loss 0.30956006050109863\n",
      "[CV 1/2]:Epoch: 1, valid batch 31, loss 0.4487899839878082\n",
      "[CV 1/2]:Epoch: 1, valid batch 32, loss 0.5250670313835144\n",
      "[CV 1/2]:Epoch: 1, valid batch 33, loss 0.35948050022125244\n",
      "[CV 1/2]:Epoch: 1, valid batch 34, loss 0.6456142067909241\n",
      "[CV 1/2]:Epoch: 1, valid batch 35, loss 0.4490295648574829\n",
      "[CV 1/2]:Epoch: 1, valid batch 36, loss 0.3445051908493042\n",
      "[CV 1/2]:Epoch: 1, valid batch 37, loss 0.44894036650657654\n",
      "[CV 1/2]:Epoch: 1, valid batch 38, loss 0.45011505484580994\n",
      "[CV 1/2]:Epoch: 1, valid batch 39, loss 0.41249626874923706\n",
      "[CV 1/2]:Epoch: 1, valid batch 40, loss 0.6054214239120483\n",
      "[CV 1/2]:Epoch: 1, valid batch 41, loss 0.42602047324180603\n",
      "[CV 1/2]:Epoch: 1, valid batch 42, loss 0.24943748116493225\n",
      "[CV 1/2]:Epoch: 1, valid batch 43, loss 0.43085265159606934\n",
      "[CV 1/2]:Epoch: 1, valid batch 44, loss 0.4055182933807373\n",
      "[CV 1/2]:Epoch: 1, valid batch 45, loss 0.47160887718200684\n",
      "[CV 1/2]:Epoch: 1, valid batch 46, loss 0.47242969274520874\n",
      "[CV 1/2]:Epoch: 1, valid batch 47, loss 0.44063475728034973\n",
      "[CV 1/2]:Epoch: 1, valid batch 48, loss 0.5634974241256714\n",
      "[CV 1/2]:Epoch: 1, valid batch 49, loss 0.35692915320396423\n",
      "[CV 1/2]:Epoch: 1, valid batch 50, loss 0.24451830983161926\n",
      "[CV 1/2]:Epoch: 1, valid batch 51, loss 0.33518826961517334\n",
      "[CV 1/2]:Epoch: 1, valid batch 52, loss 0.22448314726352692\n",
      "[CV 1/2]:Epoch: 1, valid batch 53, loss 0.20086033642292023\n",
      "[CV 1/2]:Epoch: 1, valid batch 54, loss 0.4708655774593353\n",
      "[CV 1/2]:Epoch: 1, valid batch 55, loss 0.3437192738056183\n",
      "[CV 1/2]:Epoch: 1, valid batch 56, loss 0.48464059829711914\n",
      "[CV 1/2]:Epoch: 1, valid batch 57, loss 0.36120545864105225\n",
      "[CV 1/2]:Epoch: 1, valid batch 58, loss 0.46344155073165894\n",
      "[CV 1/2]:Epoch: 1, valid batch 59, loss 0.4817885756492615\n",
      "[CV 1/2]:Epoch: 1, valid batch 60, loss 0.43815186619758606\n",
      "[CV 1/2]:Epoch: 1, valid batch 61, loss 0.32180142402648926\n",
      "[CV 1/2]:Epoch: 1, valid batch 62, loss 0.2373320460319519\n",
      "[CV 1/2]:Epoch: 1, valid batch 63, loss 0.4769144654273987\n",
      "[CV 1/2]:Epoch: 1, valid batch 64, loss 0.48191872239112854\n",
      "[CV 1/2]:Epoch: 1, valid batch 65, loss 0.48622947931289673\n",
      "[CV 1/2]:Epoch: 1, valid batch 66, loss 0.43928131461143494\n",
      "[CV 1/2]:Epoch: 1, valid batch 67, loss 0.3843124806880951\n",
      "[CV 1/2]:Epoch: 1, valid batch 68, loss 0.5164136290550232\n",
      "[CV 1/2]:Epoch: 1, valid batch 69, loss 0.4512026906013489\n",
      "[CV 1/2]:Epoch: 1, valid batch 70, loss 0.5341830253601074\n",
      "[CV 1/2]:Epoch: 1, valid batch 71, loss 0.4933376908302307\n",
      "[CV 1/2]:Epoch: 1, valid batch 72, loss 0.33394986391067505\n",
      "[CV 1/2]:Epoch: 1, valid batch 73, loss 0.2480887919664383\n",
      "[CV 1/2]:Epoch: 1, valid batch 74, loss 0.29006490111351013\n",
      "[CV 1/2]:Epoch: 1, valid batch 75, loss 0.5658824443817139\n",
      "[CV 1/2]:Epoch: 1, valid batch 76, loss 0.2825702428817749\n",
      "[CV 1/2]:Epoch: 1, valid batch 77, loss 0.3391067683696747\n",
      "[CV 1/2]:Epoch: 1, valid batch 78, loss 0.7346426844596863\n",
      "[CV 1/2]:Epoch: 1, valid batch 79, loss 0.41474372148513794\n",
      "[CV 1/2]:Epoch: 1, valid batch 80, loss 0.4149855077266693\n",
      "[CV 1/2]:Epoch: 1, valid batch 81, loss 0.5154533386230469\n",
      "[CV 1/2]:Epoch: 1, valid batch 82, loss 0.4216409921646118\n",
      "[CV 1/2]:Epoch: 1, valid batch 83, loss 0.5827019214630127\n",
      "[CV 1/2]:Epoch: 1, valid batch 84, loss 0.27952510118484497\n",
      "[CV 1/2]:Epoch: 1, valid batch 85, loss 0.3201572000980377\n",
      "[CV 1/2]:Epoch: 1, valid batch 86, loss 0.40782031416893005\n",
      "[CV 1/2]:Epoch: 1, valid batch 87, loss 0.5490660667419434\n",
      "[CV 1/2]:Epoch: 1, valid batch 88, loss 0.5120927095413208\n",
      "[CV 1/2]:Epoch: 1, valid batch 89, loss 0.22777289152145386\n",
      "[CV 1/2]:Epoch: 1, valid batch 90, loss 0.3282002806663513\n",
      "[CV 1/2]:Epoch: 1, valid batch 91, loss 0.5031946301460266\n",
      "[CV 1/2]:Epoch: 1, valid batch 92, loss 0.43030795454978943\n",
      "[CV 1/2]:Epoch: 1, valid batch 93, loss 0.42298343777656555\n",
      "[CV 1/2]:Epoch: 1, valid batch 94, loss 0.3984171450138092\n",
      "[CV 1/2]:Epoch: 1, valid batch 95, loss 0.37301793694496155\n",
      "[CV 1/2]:Epoch: 1, valid batch 96, loss 0.28222352266311646\n",
      "[CV 1/2]:Epoch: 1, valid batch 97, loss 0.4012881815433502\n",
      "[CV 1/2]:Epoch: 1, valid batch 98, loss 0.2726452946662903\n",
      "[CV 1/2]:Epoch: 1, valid batch 99, loss 0.3855327367782593\n",
      "[CV 1/2]:Epoch: 1, valid batch 100, loss 0.34293437004089355\n",
      "[CV 1/2]:Epoch: 1, valid batch 101, loss 0.3656751215457916\n",
      "[CV 1/2]:Epoch: 1, valid batch 102, loss 0.3278956711292267\n",
      "[CV 1/2]:Epoch: 1, valid batch 103, loss 0.2791179120540619\n",
      "[CV 1/2]:Epoch: 1, valid batch 104, loss 0.39759838581085205\n",
      "[CV 1/2]:Epoch: 1, valid batch 105, loss 0.4985515773296356\n",
      "[CV 1/2]:Epoch: 1, valid batch 106, loss 0.35548174381256104\n",
      "[CV 1/2]:Epoch: 1, valid batch 107, loss 0.4928959608078003\n",
      "[CV 1/2]:Epoch: 1, valid batch 108, loss 0.3773530423641205\n",
      "[CV 1/2]:Epoch: 1, valid batch 109, loss 0.3383429944515228\n",
      "[CV 1/2]:Epoch: 1, valid batch 110, loss 0.32791250944137573\n",
      "[CV 1/2]:Epoch: 1, valid batch 111, loss 0.5497639179229736\n",
      "[CV 1/2]:Epoch: 1, valid batch 112, loss 0.35853126645088196\n",
      "[CV 1/2]:Epoch: 1, valid batch 113, loss 0.5576745271682739\n",
      "[CV 1/2]:Epoch: 1, valid batch 114, loss 0.4008070230484009\n",
      "[CV 1/2]:Epoch: 1, valid batch 115, loss 0.605739414691925\n",
      "[CV 1/2]:Epoch: 1, valid batch 116, loss 0.315858393907547\n",
      "[CV 1/2]:Epoch: 1, valid batch 117, loss 0.3979191482067108\n",
      "[CV 1/2]:Epoch: 1, valid batch 118, loss 0.5831209421157837\n",
      "[CV 1/2]:Epoch: 1, valid batch 119, loss 0.3578905165195465\n",
      "[CV 1/2]:Epoch: 1, valid batch 120, loss 0.4920835793018341\n",
      "[CV 1/2]:Epoch: 1, valid batch 121, loss 0.423617422580719\n",
      "[CV 1/2]:Epoch: 1, valid batch 122, loss 0.42188435792922974\n",
      "[CV 1/2]:Epoch: 1, valid batch 123, loss 0.45399704575538635\n",
      "[CV 1/2]:Epoch: 1, valid batch 124, loss 0.286727637052536\n",
      "[CV 1/2]:Epoch: 1, valid batch 125, loss 0.22509336471557617\n",
      "[CV 1/2]:Epoch: 1, valid batch 126, loss 0.48899897933006287\n",
      "[CV 1/2]:Epoch: 1, valid batch 127, loss 0.30871081352233887\n",
      "[CV 1/2]:Epoch: 1, valid batch 128, loss 0.44799670577049255\n",
      "[CV 1/2]:Epoch: 1, valid batch 129, loss 0.2865797281265259\n",
      "[CV 1/2]:Epoch: 1, valid batch 130, loss 0.3926984369754791\n",
      "[CV 1/2]:Epoch: 1, valid batch 131, loss 0.3381638526916504\n",
      "[CV 1/2]:Epoch: 1, valid batch 132, loss 0.4210955500602722\n",
      "[CV 1/2]:Epoch: 1, valid batch 133, loss 0.3002842664718628\n",
      "[CV 1/2]:Epoch: 1, valid batch 134, loss 0.45093294978141785\n",
      "[CV 1/2]:Epoch: 1, valid batch 135, loss 0.391864150762558\n",
      "[CV 1/2]:Epoch: 1, valid batch 136, loss 0.4121735692024231\n",
      "[CV 1/2]:Epoch: 1, valid batch 137, loss 0.34123706817626953\n",
      "[CV 1/2]:Epoch: 1, valid batch 138, loss 0.40763241052627563\n",
      "[CV 1/2]:Epoch: 1, valid batch 139, loss 0.3725561499595642\n",
      "[CV 1/2]:Epoch: 1, valid batch 140, loss 0.33073389530181885\n",
      "[CV 1/2]:Epoch: 1, valid batch 141, loss 0.25832557678222656\n",
      "[CV 1/2]:Epoch: 1, valid batch 142, loss 0.3914679288864136\n",
      "[CV 1/2]:Epoch: 1, valid batch 143, loss 0.362400621175766\n",
      "[CV 1/2]:Epoch: 1, valid batch 144, loss 0.3512076437473297\n",
      "[CV 1/2]:Epoch: 1, valid batch 145, loss 0.26912856101989746\n",
      "[CV 1/2]:Epoch: 1, valid batch 146, loss 0.37181785702705383\n",
      "[CV 1/2]:Epoch: 1, valid batch 147, loss 0.5794440507888794\n",
      "[CV 1/2]:Epoch: 1, valid batch 148, loss 0.43486106395721436\n",
      "[CV 1/2]:Epoch: 1, valid batch 149, loss 0.42301902174949646\n",
      "[CV 1/2]:Epoch: 1, valid batch 150, loss 0.34190434217453003\n",
      "[CV 1/2]:Epoch: 1, valid batch 151, loss 0.4512427747249603\n",
      "[CV 1/2]:Epoch: 1, valid batch 152, loss 0.3985964059829712\n",
      "[CV 1/2]:Epoch: 1, valid batch 153, loss 0.4225907623767853\n",
      "[CV 1/2]:Epoch: 1, valid batch 154, loss 0.34768038988113403\n",
      "[CV 1/2]:Epoch: 1, valid batch 155, loss 0.39150363206863403\n",
      "[CV 1/2]:Epoch: 1, valid batch 156, loss 0.492199569940567\n",
      "[CV 1/2]:Epoch: 1, valid batch 157, loss 0.4436483383178711\n",
      "[CV 1/2]:Epoch: 1, valid batch 158, loss 0.7153444886207581\n",
      "[CV 1/2]:Epoch: 1, valid batch 159, loss 0.363926500082016\n",
      "[CV 1/2]:Epoch: 1, valid batch 160, loss 0.36037492752075195\n",
      "[CV 1/2]:Epoch: 1, valid batch 161, loss 0.377315491437912\n",
      "[CV 1/2]:Epoch: 1, valid batch 162, loss 0.317771315574646\n",
      "[CV 1/2]:Epoch: 1, valid batch 163, loss 0.3840201795101166\n",
      "[CV 1/2]:Epoch: 1, valid batch 164, loss 0.49063950777053833\n",
      "[CV 1/2]:Epoch: 1, valid batch 165, loss 0.3079768717288971\n",
      "[CV 1/2]:Epoch: 1, valid batch 166, loss 0.422726035118103\n",
      "[CV 1/2]:Epoch: 1, valid batch 167, loss 0.4290565848350525\n",
      "[CV 1/2]:Epoch: 1, valid batch 168, loss 0.30432066321372986\n",
      "[CV 1/2]:Epoch: 1, valid batch 169, loss 0.6839704513549805\n",
      "[CV 1/2]:Epoch: 1, valid batch 170, loss 0.3130107522010803\n",
      "[CV 1/2]:Epoch: 1, valid batch 171, loss 0.5487232804298401\n",
      "[CV 1/2]:Epoch: 1, valid batch 172, loss 0.24808374047279358\n",
      "[CV 1/2]:Epoch: 1, valid batch 173, loss 0.6081544756889343\n",
      "[CV 1/2]:Epoch: 1, valid batch 174, loss 0.45439574122428894\n",
      "[CV 1/2]:Epoch: 1, valid batch 175, loss 0.39857468008995056\n",
      "[CV 1/2]:Epoch: 1, valid batch 176, loss 0.44044560194015503\n",
      "[CV 1/2]:Epoch: 1, valid batch 177, loss 0.370983749628067\n",
      "[CV 1/2]:Epoch: 1, valid batch 178, loss 0.4968198239803314\n",
      "[CV 1/2]:Epoch: 1, valid batch 179, loss 0.42190924286842346\n",
      "[CV 1/2]:Epoch: 1, valid batch 180, loss 0.3957318663597107\n",
      "[CV 1/2]:Epoch: 1, valid batch 181, loss 0.44340187311172485\n",
      "[CV 1/2]:Epoch: 1, valid batch 182, loss 0.4871285855770111\n",
      "[CV 1/2]:Epoch: 1, valid batch 183, loss 0.4156081974506378\n",
      "[CV 1/2]:Epoch: 1, valid batch 184, loss 0.5052851438522339\n",
      "[CV 1/2]:Epoch: 1, valid batch 185, loss 0.17046856880187988\n",
      "[CV 1/2]:Epoch: 1, valid batch 186, loss 0.2587831914424896\n",
      "[CV 1/2]:Epoch: 1, valid batch 187, loss 0.3611220121383667\n",
      "[CV 1/2]:Epoch: 1, valid batch 188, loss 0.4221290051937103\n",
      "[CV 1/2]:Epoch: 1, valid batch 189, loss 0.30978429317474365\n",
      "[CV 1/2]:Epoch: 1, valid batch 190, loss 0.4833996891975403\n",
      "[CV 1/2]:Epoch: 1, valid batch 191, loss 0.249227374792099\n",
      "[CV 1/2]:Epoch: 1, valid batch 192, loss 0.5072903037071228\n",
      "[CV 1/2]:Epoch: 1, valid batch 193, loss 0.4891042709350586\n",
      "[CV 1/2]:Epoch: 1, valid batch 194, loss 0.41024044156074524\n",
      "[CV 1/2]:Epoch: 1, valid batch 195, loss 0.5593276023864746\n",
      "[CV 1/2]:Epoch: 1, valid batch 196, loss 0.6264757513999939\n",
      "[CV 1/2]:Epoch: 1, valid batch 197, loss 0.22901727259159088\n",
      "[CV 1/2]:Epoch: 1, valid batch 198, loss 0.5989565253257751\n",
      "[CV 1/2]:Epoch: 1, valid batch 199, loss 0.601500391960144\n",
      "[CV 1/2]:Epoch: 1, valid batch 200, loss 0.47106215357780457\n",
      "[CV 1/2]:Epoch: 1, valid batch 201, loss 0.5444122552871704\n",
      "[CV 1/2]:Epoch: 1, valid batch 202, loss 0.4209849238395691\n",
      "[CV 1/2]:Epoch: 1, valid batch 203, loss 0.3068349361419678\n",
      "[CV 1/2]:Epoch: 1, valid batch 204, loss 0.5433681607246399\n",
      "[CV 1/2]:Epoch: 1, valid batch 205, loss 0.4447106122970581\n",
      "[CV 1/2]:Epoch: 1, valid batch 206, loss 0.4345754086971283\n",
      "[CV 1/2]:Epoch: 1, valid batch 207, loss 0.4582718014717102\n",
      "[CV 1/2]:Epoch: 1, valid batch 208, loss 0.44842010736465454\n",
      "[CV 1/2]:Epoch: 1, valid batch 209, loss 0.3985513746738434\n",
      "[CV 1/2]:Epoch: 1, valid batch 210, loss 0.43342673778533936\n",
      "[CV 1/2]:Epoch: 1, valid batch 211, loss 0.5666521787643433\n",
      "[CV 1/2]:Epoch: 1, valid batch 212, loss 0.4001404345035553\n",
      "[CV 1/2]:Epoch: 1, valid batch 213, loss 0.708248496055603\n",
      "[CV 1/2]:Epoch: 1, valid batch 214, loss 0.2910650372505188\n",
      "[CV 1/2]:Epoch: 1, valid batch 215, loss 0.5648277997970581\n",
      "[CV 1/2]:Epoch: 1, valid batch 216, loss 0.3422418236732483\n",
      "[CV 1/2]:Epoch: 1, valid batch 217, loss 0.42090970277786255\n",
      "[CV 1/2]:Epoch: 1, valid batch 218, loss 0.31599754095077515\n",
      "[CV 1/2]:Epoch: 1, valid batch 219, loss 0.4870088994503021\n",
      "[CV 1/2]:Epoch: 1, valid batch 220, loss 0.33231037855148315\n",
      "[CV 1/2]:Epoch: 1, valid batch 221, loss 0.5072179436683655\n",
      "[CV 1/2]:Epoch: 1, valid batch 222, loss 0.32232534885406494\n",
      "[CV 1/2]:Epoch: 1, valid batch 223, loss 0.3802788555622101\n",
      "[CV 1/2]:Epoch: 1, valid batch 224, loss 0.36264488101005554\n",
      "[CV 1/2]:Epoch: 1, valid batch 225, loss 0.4449019134044647\n",
      "[CV 1/2]:Epoch: 1, valid batch 226, loss 0.36386534571647644\n",
      "[CV 1/2]:Epoch: 1, valid batch 227, loss 0.3492668867111206\n",
      "[CV 1/2]:Epoch: 1, valid batch 228, loss 0.601280152797699\n",
      "[CV 1/2]:Epoch: 1, valid batch 229, loss 0.4358800947666168\n",
      "[CV 1/2]:Epoch: 1, valid batch 230, loss 0.533786952495575\n",
      "[CV 1/2]:Epoch: 1, valid batch 231, loss 0.3436790108680725\n",
      "[CV 1/2]:Epoch: 1, valid batch 232, loss 0.3701538145542145\n",
      "[CV 1/2]:Epoch: 1, valid batch 233, loss 0.33901292085647583\n",
      "[CV 1/2]:Epoch: 1, valid batch 234, loss 0.40325355529785156\n",
      "[CV 1/2]:Epoch: 1, valid batch 235, loss 0.4779796600341797\n",
      "[CV 1/2]:Epoch: 1, valid batch 236, loss 0.28349971771240234\n",
      "[CV 1/2]:Epoch: 1, valid batch 237, loss 0.2490212768316269\n",
      "[CV 1/2]:Epoch: 1, valid batch 238, loss 0.39582082629203796\n",
      "[CV 1/2]:Epoch: 1, valid batch 239, loss 0.38667041063308716\n",
      "[CV 1/2]:Epoch: 1, valid batch 240, loss 0.2687269151210785\n",
      "[CV 1/2]:Epoch: 1, valid batch 241, loss 0.3989032208919525\n",
      "[CV 1/2]:Epoch: 1, valid batch 242, loss 0.5081324577331543\n",
      "[CV 1/2]:Epoch: 1, valid batch 243, loss 0.32513630390167236\n",
      "[CV 1/2]:Epoch: 1, valid batch 244, loss 0.48142382502555847\n",
      "[CV 1/2]:Epoch: 1, valid batch 245, loss 0.4314799904823303\n",
      "[CV 1/2]:Epoch: 1, valid batch 246, loss 0.40493911504745483\n",
      "[CV 1/2]:Epoch: 1, valid batch 247, loss 0.39915308356285095\n",
      "[CV 1/2]:Epoch: 1, valid batch 248, loss 0.5855838656425476\n",
      "[CV 1/2]:Epoch: 1, valid batch 249, loss 0.4090586006641388\n",
      "[CV 1/2]:Epoch: 1, valid batch 250, loss 0.6462188959121704\n",
      "[CV 1/2]:Epoch: 1, valid batch 251, loss 0.3572777509689331\n",
      "[CV 1/2]:Epoch: 1, valid batch 252, loss 0.3490297496318817\n",
      "[CV 1/2]:Epoch: 1, valid batch 253, loss 0.47463259100914\n",
      "[CV 1/2]:Epoch: 1, valid batch 254, loss 0.3385942876338959\n",
      "[CV 1/2]:Epoch: 1, valid batch 255, loss 0.385322630405426\n",
      "[CV 1/2]:Epoch: 1, valid batch 256, loss 0.2288108766078949\n",
      "[CV 1/2]:Epoch: 1, valid batch 257, loss 0.4593166708946228\n",
      "[CV 1/2]:Epoch: 1, valid batch 258, loss 0.3740715980529785\n",
      "[CV 1/2]:Epoch: 1, valid batch 259, loss 0.41376256942749023\n",
      "[CV 1/2]:Epoch: 1, valid batch 260, loss 0.39197421073913574\n",
      "[CV 1/2]:Epoch: 1, valid batch 261, loss 0.34667742252349854\n",
      "[CV 1/2]:Epoch: 1, valid batch 262, loss 0.31581613421440125\n",
      "[CV 1/2]:Epoch: 1, valid batch 263, loss 0.30443936586380005\n",
      "[CV 1/2]:Epoch: 1, valid batch 264, loss 0.5027329921722412\n",
      "[CV 1/2]:Epoch: 1, valid batch 265, loss 0.339072585105896\n",
      "[CV 1/2]:Epoch: 1, valid batch 266, loss 0.46084854006767273\n",
      "[CV 1/2]:Epoch: 1, valid batch 267, loss 0.3097676634788513\n",
      "[CV 1/2]:Epoch: 1, valid batch 268, loss 0.40068233013153076\n",
      "[CV 1/2]:Epoch: 1, valid batch 269, loss 0.4242886006832123\n",
      "[CV 1/2]:Epoch: 1, valid batch 270, loss 0.46046268939971924\n",
      "[CV 1/2]:Epoch: 1, valid batch 271, loss 0.4811297059059143\n",
      "[CV 1/2]:Epoch: 1, valid batch 272, loss 0.43217289447784424\n",
      "[CV 1/2]:Epoch: 1, valid batch 273, loss 0.3149908781051636\n",
      "[CV 1/2]:Epoch: 1, valid batch 274, loss 0.37091130018234253\n",
      "[CV 1/2]:Epoch: 1, valid batch 275, loss 0.3655168414115906\n",
      "[CV 1/2]:Epoch: 1, valid batch 276, loss 0.5842955708503723\n",
      "[CV 1/2]:Epoch: 1, valid batch 277, loss 0.50193190574646\n",
      "[CV 1/2]:Epoch: 1, valid batch 278, loss 0.2657047212123871\n",
      "[CV 1/2]:Epoch: 1, valid batch 279, loss 0.30204206705093384\n",
      "[CV 1/2]:Epoch: 1, valid batch 280, loss 0.3018251359462738\n",
      "[CV 1/2]:Epoch: 1, valid batch 281, loss 0.5591819882392883\n",
      "[CV 1/2]:Epoch: 1, valid batch 282, loss 0.40357711911201477\n",
      "[CV 1/2]:Epoch: 1, valid batch 283, loss 0.2618505656719208\n",
      "[CV 1/2]:Epoch: 1, valid batch 284, loss 0.4852353632450104\n",
      "[CV 1/2]:Epoch: 1, valid batch 285, loss 0.525037944316864\n",
      "[CV 1/2]:Epoch: 1, valid batch 286, loss 0.3701130449771881\n",
      "[CV 1/2]:Epoch: 1, valid batch 287, loss 0.5677176117897034\n",
      "[CV 1/2]:Epoch: 1, valid batch 288, loss 0.4584440290927887\n",
      "[CV 1/2]:Epoch: 1, valid batch 289, loss 0.41100919246673584\n",
      "[CV 1/2]:Epoch: 1, valid batch 290, loss 0.41047269105911255\n",
      "[CV 1/2]:Epoch: 1, valid batch 291, loss 0.4079374372959137\n",
      "[CV 1/2]:Epoch: 1, valid batch 292, loss 0.4696992337703705\n",
      "[CV 1/2]:Epoch: 1, valid batch 293, loss 0.3462457060813904\n",
      "[CV 1/2]:Epoch: 1, valid batch 294, loss 0.3320748209953308\n",
      "[CV 1/2]:Epoch: 1, valid batch 295, loss 0.5110913515090942\n",
      "[CV 1/2]:Epoch: 1, valid batch 296, loss 0.5028852820396423\n",
      "[CV 1/2]:Epoch: 1, valid batch 297, loss 0.3823986351490021\n",
      "Valid loss improved from inf to 0.415356. Saving model ...\n",
      "[CV 1/2]: Epoch: 01/1 | epoch time: 16.0m 33.84s | lr: 1.00000e-04 | train/loss: 0.46744 | val/loss: 0.41536 | val/accuracy: 0.80750 | val/AUC: 0.80538 | val/Kappa: 0.61329\n",
      "[CV 1/2]: Run complete. Total time: 00:16:34\n",
      "[CV 1/2]: Testing...\n",
      "[CV 1/2]: Test Accuracy: 0.80750\n",
      "[CV 1/2]: Test AUC: 0.80538\n",
      "[CV 1/2]: Test Kappa: 0.61329\n",
      "[CV 1/2]: Target 0 - Precision: 0.75042, Recall: 0.93103, F-score: 0.83102, Sensitivity: 0.9310273405136703, Specificity: 0.6797343616109683, Support: 4828\n",
      "[CV 1/2]: Target 1 - Precision: 0.90502, Recall: 0.67973, F-score: 0.77636, Sensitivity: 0.6797343616109683, Specificity: 0.9310273405136703, Support: 4668\n",
      "[CV 1/2]: Testing complete.\n",
      "Creating a classifier experiment using VGG16_BN_Attention network.\n",
      "Using VGG16_BN_Attention with configurations: num_classes='2', normalize_attn='False'\n",
      "[CV 2/2]: Epoch: 1, train batch 10, loss: 0.6433772444725037, 3.4% complete\n",
      "[CV 2/2]: Epoch: 1, train batch 20, loss: 0.6118836402893066, 6.7% complete\n",
      "[CV 2/2]: Epoch: 1, train batch 30, loss: 0.5454500317573547, 10.1% complete\n",
      "[CV 2/2]: Epoch: 1, train batch 40, loss: 0.4694109559059143, 13.5% complete\n",
      "[CV 2/2]: Epoch: 1, train batch 50, loss: 0.5674379467964172, 16.8% complete\n",
      "[CV 2/2]: Epoch: 1, train batch 60, loss: 0.4464960992336273, 20.2% complete\n",
      "[CV 2/2]: Epoch: 1, train batch 70, loss: 0.45601680874824524, 23.6% complete\n",
      "[CV 2/2]: Epoch: 1, train batch 80, loss: 0.49947816133499146, 26.9% complete\n",
      "[CV 2/2]: Epoch: 1, train batch 90, loss: 0.5209165811538696, 30.3% complete\n",
      "[CV 2/2]: Epoch: 1, train batch 100, loss: 0.34332627058029175, 33.7% complete\n",
      "[CV 2/2]: Epoch: 1, train batch 110, loss: 0.5335863828659058, 37.0% complete\n",
      "[CV 2/2]: Epoch: 1, train batch 120, loss: 0.37344643473625183, 40.4% complete\n",
      "[CV 2/2]: Epoch: 1, train batch 130, loss: 0.35938939452171326, 43.8% complete\n",
      "[CV 2/2]: Epoch: 1, train batch 140, loss: 0.5479317307472229, 47.1% complete\n",
      "[CV 2/2]: Epoch: 1, train batch 150, loss: 0.5323773622512817, 50.5% complete\n",
      "[CV 2/2]: Epoch: 1, train batch 160, loss: 0.38293808698654175, 53.9% complete\n",
      "[CV 2/2]: Epoch: 1, train batch 170, loss: 0.4398955702781677, 57.2% complete\n",
      "[CV 2/2]: Epoch: 1, train batch 180, loss: 0.39336493611335754, 60.6% complete\n",
      "[CV 2/2]: Epoch: 1, train batch 190, loss: 0.5197528600692749, 64.0% complete\n",
      "[CV 2/2]: Epoch: 1, train batch 200, loss: 0.4325968027114868, 67.3% complete\n",
      "[CV 2/2]: Epoch: 1, train batch 210, loss: 0.35087522864341736, 70.7% complete\n",
      "[CV 2/2]: Epoch: 1, train batch 220, loss: 0.541599452495575, 74.1% complete\n",
      "[CV 2/2]: Epoch: 1, train batch 230, loss: 0.46693986654281616, 77.4% complete\n",
      "[CV 2/2]: Epoch: 1, train batch 240, loss: 0.5648764371871948, 80.8% complete\n",
      "[CV 2/2]: Epoch: 1, train batch 250, loss: 0.4157535135746002, 84.2% complete\n",
      "[CV 2/2]: Epoch: 1, train batch 260, loss: 0.42455601692199707, 87.5% complete\n",
      "[CV 2/2]: Epoch: 1, train batch 270, loss: 0.48908838629722595, 90.9% complete\n",
      "[CV 2/2]: Epoch: 1, train batch 280, loss: 0.43957117199897766, 94.3% complete\n",
      "[CV 2/2]: Epoch: 1, train batch 290, loss: 0.3955691456794739, 97.6% complete\n",
      "[CV 2/2]:Epoch: 1, valid batch 1, loss 0.44997864961624146\n",
      "[CV 2/2]:Epoch: 1, valid batch 2, loss 0.2652851939201355\n",
      "[CV 2/2]:Epoch: 1, valid batch 3, loss 0.4309934377670288\n",
      "[CV 2/2]:Epoch: 1, valid batch 4, loss 0.43954992294311523\n",
      "[CV 2/2]:Epoch: 1, valid batch 5, loss 0.32624974846839905\n",
      "[CV 2/2]:Epoch: 1, valid batch 6, loss 0.39746078848838806\n",
      "[CV 2/2]:Epoch: 1, valid batch 7, loss 0.32427170872688293\n",
      "[CV 2/2]:Epoch: 1, valid batch 8, loss 0.3567314147949219\n",
      "[CV 2/2]:Epoch: 1, valid batch 9, loss 0.45267245173454285\n",
      "[CV 2/2]:Epoch: 1, valid batch 10, loss 0.5594824552536011\n",
      "[CV 2/2]:Epoch: 1, valid batch 11, loss 0.3930699825286865\n",
      "[CV 2/2]:Epoch: 1, valid batch 12, loss 0.44045180082321167\n",
      "[CV 2/2]:Epoch: 1, valid batch 13, loss 0.4383402168750763\n",
      "[CV 2/2]:Epoch: 1, valid batch 14, loss 0.6160262823104858\n",
      "[CV 2/2]:Epoch: 1, valid batch 15, loss 0.5169379115104675\n",
      "[CV 2/2]:Epoch: 1, valid batch 16, loss 0.4984154999256134\n",
      "[CV 2/2]:Epoch: 1, valid batch 17, loss 0.4158768057823181\n",
      "[CV 2/2]:Epoch: 1, valid batch 18, loss 0.5005684494972229\n",
      "[CV 2/2]:Epoch: 1, valid batch 19, loss 0.5417830944061279\n",
      "[CV 2/2]:Epoch: 1, valid batch 20, loss 0.4510934054851532\n",
      "[CV 2/2]:Epoch: 1, valid batch 21, loss 0.3747667074203491\n",
      "[CV 2/2]:Epoch: 1, valid batch 22, loss 0.4446489214897156\n",
      "[CV 2/2]:Epoch: 1, valid batch 23, loss 0.40435710549354553\n",
      "[CV 2/2]:Epoch: 1, valid batch 24, loss 0.35842180252075195\n",
      "[CV 2/2]:Epoch: 1, valid batch 25, loss 0.4968017637729645\n",
      "[CV 2/2]:Epoch: 1, valid batch 26, loss 0.4155934154987335\n",
      "[CV 2/2]:Epoch: 1, valid batch 27, loss 0.32658258080482483\n",
      "[CV 2/2]:Epoch: 1, valid batch 28, loss 0.34501969814300537\n",
      "[CV 2/2]:Epoch: 1, valid batch 29, loss 0.46946996450424194\n",
      "[CV 2/2]:Epoch: 1, valid batch 30, loss 0.5617085099220276\n",
      "[CV 2/2]:Epoch: 1, valid batch 31, loss 0.4657624661922455\n",
      "[CV 2/2]:Epoch: 1, valid batch 32, loss 0.39868611097335815\n",
      "[CV 2/2]:Epoch: 1, valid batch 33, loss 0.3796535134315491\n",
      "[CV 2/2]:Epoch: 1, valid batch 34, loss 0.4263565242290497\n",
      "[CV 2/2]:Epoch: 1, valid batch 35, loss 0.3134365975856781\n",
      "[CV 2/2]:Epoch: 1, valid batch 36, loss 0.5402398109436035\n",
      "[CV 2/2]:Epoch: 1, valid batch 37, loss 0.4164310395717621\n",
      "[CV 2/2]:Epoch: 1, valid batch 38, loss 0.35101649165153503\n",
      "[CV 2/2]:Epoch: 1, valid batch 39, loss 0.35921505093574524\n",
      "[CV 2/2]:Epoch: 1, valid batch 40, loss 0.4078861176967621\n",
      "[CV 2/2]:Epoch: 1, valid batch 41, loss 0.25826215744018555\n",
      "[CV 2/2]:Epoch: 1, valid batch 42, loss 0.7124918699264526\n",
      "[CV 2/2]:Epoch: 1, valid batch 43, loss 0.35150185227394104\n",
      "[CV 2/2]:Epoch: 1, valid batch 44, loss 0.46812692284584045\n",
      "[CV 2/2]:Epoch: 1, valid batch 45, loss 0.4239589273929596\n",
      "[CV 2/2]:Epoch: 1, valid batch 46, loss 0.5021459460258484\n",
      "[CV 2/2]:Epoch: 1, valid batch 47, loss 0.40204334259033203\n",
      "[CV 2/2]:Epoch: 1, valid batch 48, loss 0.4085314869880676\n",
      "[CV 2/2]:Epoch: 1, valid batch 49, loss 0.301746666431427\n",
      "[CV 2/2]:Epoch: 1, valid batch 50, loss 0.4724220037460327\n",
      "[CV 2/2]:Epoch: 1, valid batch 51, loss 0.4912512004375458\n",
      "[CV 2/2]:Epoch: 1, valid batch 52, loss 0.33519792556762695\n",
      "[CV 2/2]:Epoch: 1, valid batch 53, loss 0.5140108466148376\n",
      "[CV 2/2]:Epoch: 1, valid batch 54, loss 0.43882960081100464\n",
      "[CV 2/2]:Epoch: 1, valid batch 55, loss 0.4653506278991699\n",
      "[CV 2/2]:Epoch: 1, valid batch 56, loss 0.3786618709564209\n",
      "[CV 2/2]:Epoch: 1, valid batch 57, loss 0.573544979095459\n",
      "[CV 2/2]:Epoch: 1, valid batch 58, loss 0.3666979968547821\n",
      "[CV 2/2]:Epoch: 1, valid batch 59, loss 0.4145016372203827\n",
      "[CV 2/2]:Epoch: 1, valid batch 60, loss 0.351527601480484\n",
      "[CV 2/2]:Epoch: 1, valid batch 61, loss 0.4891173243522644\n",
      "[CV 2/2]:Epoch: 1, valid batch 62, loss 0.5110451579093933\n",
      "[CV 2/2]:Epoch: 1, valid batch 63, loss 0.3591665029525757\n",
      "[CV 2/2]:Epoch: 1, valid batch 64, loss 0.38930144906044006\n",
      "[CV 2/2]:Epoch: 1, valid batch 65, loss 0.4456222951412201\n",
      "[CV 2/2]:Epoch: 1, valid batch 66, loss 0.5249161124229431\n",
      "[CV 2/2]:Epoch: 1, valid batch 67, loss 0.4011564254760742\n",
      "[CV 2/2]:Epoch: 1, valid batch 68, loss 0.7356665134429932\n",
      "[CV 2/2]:Epoch: 1, valid batch 69, loss 0.36823853850364685\n",
      "[CV 2/2]:Epoch: 1, valid batch 70, loss 0.29057392477989197\n",
      "[CV 2/2]:Epoch: 1, valid batch 71, loss 0.3874964118003845\n",
      "[CV 2/2]:Epoch: 1, valid batch 72, loss 0.318134069442749\n",
      "[CV 2/2]:Epoch: 1, valid batch 73, loss 0.35565251111984253\n",
      "[CV 2/2]:Epoch: 1, valid batch 74, loss 0.498660683631897\n",
      "[CV 2/2]:Epoch: 1, valid batch 75, loss 0.4889368414878845\n",
      "[CV 2/2]:Epoch: 1, valid batch 76, loss 0.23079822957515717\n",
      "[CV 2/2]:Epoch: 1, valid batch 77, loss 0.49697214365005493\n",
      "[CV 2/2]:Epoch: 1, valid batch 78, loss 0.3218976855278015\n",
      "[CV 2/2]:Epoch: 1, valid batch 79, loss 0.6832588911056519\n",
      "[CV 2/2]:Epoch: 1, valid batch 80, loss 0.6248524785041809\n",
      "[CV 2/2]:Epoch: 1, valid batch 81, loss 0.4106733798980713\n",
      "[CV 2/2]:Epoch: 1, valid batch 82, loss 0.4993933439254761\n",
      "[CV 2/2]:Epoch: 1, valid batch 83, loss 0.39861559867858887\n",
      "[CV 2/2]:Epoch: 1, valid batch 84, loss 0.4218657910823822\n",
      "[CV 2/2]:Epoch: 1, valid batch 85, loss 0.35433313250541687\n",
      "[CV 2/2]:Epoch: 1, valid batch 86, loss 0.4706101417541504\n",
      "[CV 2/2]:Epoch: 1, valid batch 87, loss 0.5755100846290588\n",
      "[CV 2/2]:Epoch: 1, valid batch 88, loss 0.5045586824417114\n",
      "[CV 2/2]:Epoch: 1, valid batch 89, loss 0.5791873931884766\n",
      "[CV 2/2]:Epoch: 1, valid batch 90, loss 0.24084310233592987\n",
      "[CV 2/2]:Epoch: 1, valid batch 91, loss 0.38652557134628296\n",
      "[CV 2/2]:Epoch: 1, valid batch 92, loss 0.47195732593536377\n",
      "[CV 2/2]:Epoch: 1, valid batch 93, loss 0.5171993374824524\n",
      "[CV 2/2]:Epoch: 1, valid batch 94, loss 0.4776105582714081\n",
      "[CV 2/2]:Epoch: 1, valid batch 95, loss 0.39615797996520996\n",
      "[CV 2/2]:Epoch: 1, valid batch 96, loss 0.4879872500896454\n",
      "[CV 2/2]:Epoch: 1, valid batch 97, loss 0.35432884097099304\n",
      "[CV 2/2]:Epoch: 1, valid batch 98, loss 0.41691482067108154\n",
      "[CV 2/2]:Epoch: 1, valid batch 99, loss 0.4609557092189789\n",
      "[CV 2/2]:Epoch: 1, valid batch 100, loss 0.5417130589485168\n",
      "[CV 2/2]:Epoch: 1, valid batch 101, loss 0.4845462143421173\n",
      "[CV 2/2]:Epoch: 1, valid batch 102, loss 0.31680506467819214\n",
      "[CV 2/2]:Epoch: 1, valid batch 103, loss 0.2277268022298813\n",
      "[CV 2/2]:Epoch: 1, valid batch 104, loss 0.4746209383010864\n",
      "[CV 2/2]:Epoch: 1, valid batch 105, loss 0.42464563250541687\n",
      "[CV 2/2]:Epoch: 1, valid batch 106, loss 0.47527745366096497\n",
      "[CV 2/2]:Epoch: 1, valid batch 107, loss 0.5316945910453796\n",
      "[CV 2/2]:Epoch: 1, valid batch 108, loss 0.3143736720085144\n",
      "[CV 2/2]:Epoch: 1, valid batch 109, loss 0.31510162353515625\n",
      "[CV 2/2]:Epoch: 1, valid batch 110, loss 0.3820725381374359\n",
      "[CV 2/2]:Epoch: 1, valid batch 111, loss 0.45700106024742126\n",
      "[CV 2/2]:Epoch: 1, valid batch 112, loss 0.46161526441574097\n",
      "[CV 2/2]:Epoch: 1, valid batch 113, loss 0.48170027136802673\n",
      "[CV 2/2]:Epoch: 1, valid batch 114, loss 0.39415812492370605\n",
      "[CV 2/2]:Epoch: 1, valid batch 115, loss 0.3858320116996765\n",
      "[CV 2/2]:Epoch: 1, valid batch 116, loss 0.39007532596588135\n",
      "[CV 2/2]:Epoch: 1, valid batch 117, loss 0.37464937567710876\n",
      "[CV 2/2]:Epoch: 1, valid batch 118, loss 0.5553280711174011\n",
      "[CV 2/2]:Epoch: 1, valid batch 119, loss 0.44530558586120605\n",
      "[CV 2/2]:Epoch: 1, valid batch 120, loss 0.666070282459259\n",
      "[CV 2/2]:Epoch: 1, valid batch 121, loss 0.5031459927558899\n",
      "[CV 2/2]:Epoch: 1, valid batch 122, loss 0.5660912990570068\n",
      "[CV 2/2]:Epoch: 1, valid batch 123, loss 0.3935660123825073\n",
      "[CV 2/2]:Epoch: 1, valid batch 124, loss 0.48115697503089905\n",
      "[CV 2/2]:Epoch: 1, valid batch 125, loss 0.5270974040031433\n",
      "[CV 2/2]:Epoch: 1, valid batch 126, loss 0.4559117257595062\n",
      "[CV 2/2]:Epoch: 1, valid batch 127, loss 0.48940593004226685\n",
      "[CV 2/2]:Epoch: 1, valid batch 128, loss 0.3954116702079773\n",
      "[CV 2/2]:Epoch: 1, valid batch 129, loss 0.5801414847373962\n",
      "[CV 2/2]:Epoch: 1, valid batch 130, loss 0.6473363041877747\n",
      "[CV 2/2]:Epoch: 1, valid batch 131, loss 0.6569588780403137\n",
      "[CV 2/2]:Epoch: 1, valid batch 132, loss 0.4404439330101013\n",
      "[CV 2/2]:Epoch: 1, valid batch 133, loss 0.4745565950870514\n",
      "[CV 2/2]:Epoch: 1, valid batch 134, loss 0.36508721113204956\n",
      "[CV 2/2]:Epoch: 1, valid batch 135, loss 0.4588666558265686\n",
      "[CV 2/2]:Epoch: 1, valid batch 136, loss 0.37826287746429443\n",
      "[CV 2/2]:Epoch: 1, valid batch 137, loss 0.566015362739563\n",
      "[CV 2/2]:Epoch: 1, valid batch 138, loss 0.41265714168548584\n",
      "[CV 2/2]:Epoch: 1, valid batch 139, loss 0.5641714930534363\n",
      "[CV 2/2]:Epoch: 1, valid batch 140, loss 0.2724341154098511\n",
      "[CV 2/2]:Epoch: 1, valid batch 141, loss 0.3320084810256958\n",
      "[CV 2/2]:Epoch: 1, valid batch 142, loss 0.40915647149086\n",
      "[CV 2/2]:Epoch: 1, valid batch 143, loss 0.3544013798236847\n",
      "[CV 2/2]:Epoch: 1, valid batch 144, loss 0.21227186918258667\n",
      "[CV 2/2]:Epoch: 1, valid batch 145, loss 0.7378154397010803\n",
      "[CV 2/2]:Epoch: 1, valid batch 146, loss 0.34329545497894287\n",
      "[CV 2/2]:Epoch: 1, valid batch 147, loss 0.45996931195259094\n",
      "[CV 2/2]:Epoch: 1, valid batch 148, loss 0.5217654705047607\n",
      "[CV 2/2]:Epoch: 1, valid batch 149, loss 0.24046550691127777\n",
      "[CV 2/2]:Epoch: 1, valid batch 150, loss 0.3340010344982147\n",
      "[CV 2/2]:Epoch: 1, valid batch 151, loss 0.4851363003253937\n",
      "[CV 2/2]:Epoch: 1, valid batch 152, loss 0.41518571972846985\n",
      "[CV 2/2]:Epoch: 1, valid batch 153, loss 0.31385454535484314\n",
      "[CV 2/2]:Epoch: 1, valid batch 154, loss 0.48500290513038635\n",
      "[CV 2/2]:Epoch: 1, valid batch 155, loss 0.3851487636566162\n",
      "[CV 2/2]:Epoch: 1, valid batch 156, loss 0.6171361804008484\n",
      "[CV 2/2]:Epoch: 1, valid batch 157, loss 0.45255592465400696\n",
      "[CV 2/2]:Epoch: 1, valid batch 158, loss 0.5376853942871094\n",
      "[CV 2/2]:Epoch: 1, valid batch 159, loss 0.6028772592544556\n",
      "[CV 2/2]:Epoch: 1, valid batch 160, loss 0.3380352556705475\n",
      "[CV 2/2]:Epoch: 1, valid batch 161, loss 0.22972437739372253\n",
      "[CV 2/2]:Epoch: 1, valid batch 162, loss 0.33577731251716614\n",
      "[CV 2/2]:Epoch: 1, valid batch 163, loss 0.36445116996765137\n",
      "[CV 2/2]:Epoch: 1, valid batch 164, loss 0.3169718086719513\n",
      "[CV 2/2]:Epoch: 1, valid batch 165, loss 0.5403497815132141\n",
      "[CV 2/2]:Epoch: 1, valid batch 166, loss 0.32380175590515137\n",
      "[CV 2/2]:Epoch: 1, valid batch 167, loss 0.4124689996242523\n",
      "[CV 2/2]:Epoch: 1, valid batch 168, loss 0.6058788299560547\n",
      "[CV 2/2]:Epoch: 1, valid batch 169, loss 0.3540554642677307\n",
      "[CV 2/2]:Epoch: 1, valid batch 170, loss 0.399988055229187\n",
      "[CV 2/2]:Epoch: 1, valid batch 171, loss 0.4672694802284241\n",
      "[CV 2/2]:Epoch: 1, valid batch 172, loss 0.29471373558044434\n",
      "[CV 2/2]:Epoch: 1, valid batch 173, loss 0.38174059987068176\n",
      "[CV 2/2]:Epoch: 1, valid batch 174, loss 0.38761335611343384\n",
      "[CV 2/2]:Epoch: 1, valid batch 175, loss 0.2577868402004242\n",
      "[CV 2/2]:Epoch: 1, valid batch 176, loss 0.2078026980161667\n",
      "[CV 2/2]:Epoch: 1, valid batch 177, loss 0.4140583574771881\n",
      "[CV 2/2]:Epoch: 1, valid batch 178, loss 0.31005656719207764\n",
      "[CV 2/2]:Epoch: 1, valid batch 179, loss 0.2308417558670044\n",
      "[CV 2/2]:Epoch: 1, valid batch 180, loss 0.3296475112438202\n",
      "[CV 2/2]:Epoch: 1, valid batch 181, loss 0.52298903465271\n",
      "[CV 2/2]:Epoch: 1, valid batch 182, loss 0.38369956612586975\n",
      "[CV 2/2]:Epoch: 1, valid batch 183, loss 0.34015095233917236\n",
      "[CV 2/2]:Epoch: 1, valid batch 184, loss 0.33264705538749695\n",
      "[CV 2/2]:Epoch: 1, valid batch 185, loss 0.33914148807525635\n",
      "[CV 2/2]:Epoch: 1, valid batch 186, loss 0.35068240761756897\n",
      "[CV 2/2]:Epoch: 1, valid batch 187, loss 0.4798916280269623\n",
      "[CV 2/2]:Epoch: 1, valid batch 188, loss 0.3608875274658203\n",
      "[CV 2/2]:Epoch: 1, valid batch 189, loss 0.4900739789009094\n",
      "[CV 2/2]:Epoch: 1, valid batch 190, loss 0.24481754004955292\n",
      "[CV 2/2]:Epoch: 1, valid batch 191, loss 0.3679679334163666\n",
      "[CV 2/2]:Epoch: 1, valid batch 192, loss 0.47428178787231445\n",
      "[CV 2/2]:Epoch: 1, valid batch 193, loss 0.32849159836769104\n",
      "[CV 2/2]:Epoch: 1, valid batch 194, loss 0.4452354609966278\n",
      "[CV 2/2]:Epoch: 1, valid batch 195, loss 0.36749568581581116\n",
      "[CV 2/2]:Epoch: 1, valid batch 196, loss 0.36793947219848633\n",
      "[CV 2/2]:Epoch: 1, valid batch 197, loss 0.3575206995010376\n",
      "[CV 2/2]:Epoch: 1, valid batch 198, loss 0.41144394874572754\n",
      "[CV 2/2]:Epoch: 1, valid batch 199, loss 0.40616199374198914\n",
      "[CV 2/2]:Epoch: 1, valid batch 200, loss 0.43589454889297485\n",
      "[CV 2/2]:Epoch: 1, valid batch 201, loss 0.3689713180065155\n",
      "[CV 2/2]:Epoch: 1, valid batch 202, loss 0.3885953426361084\n",
      "[CV 2/2]:Epoch: 1, valid batch 203, loss 0.3624389171600342\n",
      "[CV 2/2]:Epoch: 1, valid batch 204, loss 0.42762401700019836\n",
      "[CV 2/2]:Epoch: 1, valid batch 205, loss 0.5264369249343872\n",
      "[CV 2/2]:Epoch: 1, valid batch 206, loss 0.42893415689468384\n",
      "[CV 2/2]:Epoch: 1, valid batch 207, loss 0.48042505979537964\n",
      "[CV 2/2]:Epoch: 1, valid batch 208, loss 0.3671627640724182\n",
      "[CV 2/2]:Epoch: 1, valid batch 209, loss 0.3066517114639282\n",
      "[CV 2/2]:Epoch: 1, valid batch 210, loss 0.3375296890735626\n",
      "[CV 2/2]:Epoch: 1, valid batch 211, loss 0.3336922526359558\n",
      "[CV 2/2]:Epoch: 1, valid batch 212, loss 0.43950894474983215\n",
      "[CV 2/2]:Epoch: 1, valid batch 213, loss 0.3646584153175354\n",
      "[CV 2/2]:Epoch: 1, valid batch 214, loss 0.3030432164669037\n",
      "[CV 2/2]:Epoch: 1, valid batch 215, loss 0.306706041097641\n",
      "[CV 2/2]:Epoch: 1, valid batch 216, loss 0.4818156063556671\n",
      "[CV 2/2]:Epoch: 1, valid batch 217, loss 0.35214951634407043\n",
      "[CV 2/2]:Epoch: 1, valid batch 218, loss 0.37306323647499084\n",
      "[CV 2/2]:Epoch: 1, valid batch 219, loss 0.43378961086273193\n",
      "[CV 2/2]:Epoch: 1, valid batch 220, loss 0.5209200382232666\n",
      "[CV 2/2]:Epoch: 1, valid batch 221, loss 0.4708094596862793\n",
      "[CV 2/2]:Epoch: 1, valid batch 222, loss 0.49531590938568115\n",
      "[CV 2/2]:Epoch: 1, valid batch 223, loss 0.19114382565021515\n",
      "[CV 2/2]:Epoch: 1, valid batch 224, loss 0.36108121275901794\n",
      "[CV 2/2]:Epoch: 1, valid batch 225, loss 0.38418614864349365\n",
      "[CV 2/2]:Epoch: 1, valid batch 226, loss 0.38807064294815063\n",
      "[CV 2/2]:Epoch: 1, valid batch 227, loss 0.42904162406921387\n",
      "[CV 2/2]:Epoch: 1, valid batch 228, loss 0.5185970664024353\n",
      "[CV 2/2]:Epoch: 1, valid batch 229, loss 0.3834660053253174\n",
      "[CV 2/2]:Epoch: 1, valid batch 230, loss 0.5132995843887329\n",
      "[CV 2/2]:Epoch: 1, valid batch 231, loss 0.43497613072395325\n",
      "[CV 2/2]:Epoch: 1, valid batch 232, loss 0.36036014556884766\n",
      "[CV 2/2]:Epoch: 1, valid batch 233, loss 0.42188912630081177\n",
      "[CV 2/2]:Epoch: 1, valid batch 234, loss 0.46397748589515686\n",
      "[CV 2/2]:Epoch: 1, valid batch 235, loss 0.2954873740673065\n",
      "[CV 2/2]:Epoch: 1, valid batch 236, loss 0.35106080770492554\n",
      "[CV 2/2]:Epoch: 1, valid batch 237, loss 0.44104018807411194\n",
      "[CV 2/2]:Epoch: 1, valid batch 238, loss 0.399436891078949\n",
      "[CV 2/2]:Epoch: 1, valid batch 239, loss 0.3230167627334595\n",
      "[CV 2/2]:Epoch: 1, valid batch 240, loss 0.32789796590805054\n",
      "[CV 2/2]:Epoch: 1, valid batch 241, loss 0.4372917115688324\n",
      "[CV 2/2]:Epoch: 1, valid batch 242, loss 0.2997402846813202\n",
      "[CV 2/2]:Epoch: 1, valid batch 243, loss 0.384980708360672\n",
      "[CV 2/2]:Epoch: 1, valid batch 244, loss 0.4026690125465393\n",
      "[CV 2/2]:Epoch: 1, valid batch 245, loss 0.4084766209125519\n",
      "[CV 2/2]:Epoch: 1, valid batch 246, loss 0.32878589630126953\n",
      "[CV 2/2]:Epoch: 1, valid batch 247, loss 0.377940833568573\n",
      "[CV 2/2]:Epoch: 1, valid batch 248, loss 0.36759689450263977\n",
      "[CV 2/2]:Epoch: 1, valid batch 249, loss 0.28470730781555176\n",
      "[CV 2/2]:Epoch: 1, valid batch 250, loss 0.47573259472846985\n",
      "[CV 2/2]:Epoch: 1, valid batch 251, loss 0.29428011178970337\n",
      "[CV 2/2]:Epoch: 1, valid batch 252, loss 0.6521633267402649\n",
      "[CV 2/2]:Epoch: 1, valid batch 253, loss 0.6177126169204712\n",
      "[CV 2/2]:Epoch: 1, valid batch 254, loss 0.3982967734336853\n",
      "[CV 2/2]:Epoch: 1, valid batch 255, loss 0.4493404030799866\n",
      "[CV 2/2]:Epoch: 1, valid batch 256, loss 0.2860243320465088\n",
      "[CV 2/2]:Epoch: 1, valid batch 257, loss 0.3701373338699341\n",
      "[CV 2/2]:Epoch: 1, valid batch 258, loss 0.4592188000679016\n",
      "[CV 2/2]:Epoch: 1, valid batch 259, loss 0.33524686098098755\n",
      "[CV 2/2]:Epoch: 1, valid batch 260, loss 0.507159411907196\n",
      "[CV 2/2]:Epoch: 1, valid batch 261, loss 0.3129459321498871\n",
      "[CV 2/2]:Epoch: 1, valid batch 262, loss 0.4262101948261261\n",
      "[CV 2/2]:Epoch: 1, valid batch 263, loss 0.34324315190315247\n",
      "[CV 2/2]:Epoch: 1, valid batch 264, loss 0.6010614633560181\n",
      "[CV 2/2]:Epoch: 1, valid batch 265, loss 0.4365607798099518\n",
      "[CV 2/2]:Epoch: 1, valid batch 266, loss 0.4604555666446686\n",
      "[CV 2/2]:Epoch: 1, valid batch 267, loss 0.5702863931655884\n",
      "[CV 2/2]:Epoch: 1, valid batch 268, loss 0.35134366154670715\n",
      "[CV 2/2]:Epoch: 1, valid batch 269, loss 0.4721960425376892\n",
      "[CV 2/2]:Epoch: 1, valid batch 270, loss 0.32131868600845337\n",
      "[CV 2/2]:Epoch: 1, valid batch 271, loss 0.38123586773872375\n",
      "[CV 2/2]:Epoch: 1, valid batch 272, loss 0.5554192066192627\n",
      "[CV 2/2]:Epoch: 1, valid batch 273, loss 0.3249276280403137\n",
      "[CV 2/2]:Epoch: 1, valid batch 274, loss 0.19142718613147736\n",
      "[CV 2/2]:Epoch: 1, valid batch 275, loss 0.37094080448150635\n",
      "[CV 2/2]:Epoch: 1, valid batch 276, loss 0.5425084829330444\n",
      "[CV 2/2]:Epoch: 1, valid batch 277, loss 0.5137141346931458\n",
      "[CV 2/2]:Epoch: 1, valid batch 278, loss 0.5260244607925415\n",
      "[CV 2/2]:Epoch: 1, valid batch 279, loss 0.4293130934238434\n",
      "[CV 2/2]:Epoch: 1, valid batch 280, loss 0.4654906690120697\n",
      "[CV 2/2]:Epoch: 1, valid batch 281, loss 0.299091100692749\n",
      "[CV 2/2]:Epoch: 1, valid batch 282, loss 0.5051431059837341\n",
      "[CV 2/2]:Epoch: 1, valid batch 283, loss 0.44584646821022034\n",
      "[CV 2/2]:Epoch: 1, valid batch 284, loss 0.4466608762741089\n",
      "[CV 2/2]:Epoch: 1, valid batch 285, loss 0.3951248824596405\n",
      "[CV 2/2]:Epoch: 1, valid batch 286, loss 0.5282827615737915\n",
      "[CV 2/2]:Epoch: 1, valid batch 287, loss 0.5817415714263916\n",
      "[CV 2/2]:Epoch: 1, valid batch 288, loss 0.4423027038574219\n",
      "[CV 2/2]:Epoch: 1, valid batch 289, loss 0.3442789912223816\n",
      "[CV 2/2]:Epoch: 1, valid batch 290, loss 0.39752501249313354\n",
      "[CV 2/2]:Epoch: 1, valid batch 291, loss 0.394166499376297\n",
      "[CV 2/2]:Epoch: 1, valid batch 292, loss 0.48655641078948975\n",
      "[CV 2/2]:Epoch: 1, valid batch 293, loss 0.4792798161506653\n",
      "[CV 2/2]:Epoch: 1, valid batch 294, loss 0.3985161781311035\n",
      "[CV 2/2]:Epoch: 1, valid batch 295, loss 0.35665151476860046\n",
      "[CV 2/2]:Epoch: 1, valid batch 296, loss 0.42517438530921936\n",
      "[CV 2/2]:Epoch: 1, valid batch 297, loss 0.5314931273460388\n",
      "Valid loss improved from inf to 0.422149. Saving model ...\n",
      "[CV 2/2]: Epoch: 01/1 | epoch time: 16.0m 0.1223s | lr: 1.00000e-04 | train/loss: 0.46913 | val/loss: 0.42215 | val/accuracy: 0.79926 | val/AUC: 0.79678 | val/Kappa: 0.59645\n",
      "[CV 2/2]: Run complete. Total time: 00:16:00\n",
      "[CV 2/2]: Testing...\n",
      "[CV 2/2]: Test Accuracy: 0.79926\n",
      "[CV 2/2]: Test AUC: 0.79678\n",
      "[CV 2/2]: Test Kappa: 0.59645\n",
      "[CV 2/2]: Target 0 - Precision: 0.73610, Recall: 0.94345, F-score: 0.82698, Sensitivity: 0.9434548467274234, Specificity: 0.6500964216841654, Support: 4828\n",
      "[CV 2/2]: Target 1 - Precision: 0.91745, Recall: 0.65010, F-score: 0.76097, Sensitivity: 0.6500964216841654, Specificity: 0.9434548467274234, Support: 4667\n",
      "[CV 2/2]: Testing complete.\n",
      "Average accuracy: 0.80338. Average AUC: 0.80108. Average Kappa: 0.60487\n",
      "An error occurred: 'str' object has no attribute 'parent'\n"
     ]
    }
   ],
   "source": [
    "# command = 'python ../train_cv.py --train_path \"../datasets/challenge1/train\" \\\n",
    "#                         --valid_path \"../datasets/challenge1/val\" \\\n",
    "#                         --experiment_name \"ClassifierExperimentCV\" \\\n",
    "#                         --network_name \"VGG16_BN_Attention\" \\\n",
    "#                         --max_epochs \"1\" \\\n",
    "#                         --num_folds \"2\" \\\n",
    "#                         --batch_size \"32\" \\\n",
    "#                         --verbose \"2\"'\n",
    "\n",
    "# # run the function to excute the command\n",
    "# _ = execute_cmd_realtime(command, log=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf453304-f157-4652-91b9-8566e035978d",
   "metadata": {},
   "source": [
    "Inference is below.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f34f618-fc89-4d69-8228-f606a9844286",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "networks.VGG16.VGG16_BN_Attention"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network = getNetwork('VGG16_BN_Attention')\n",
    "network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a1439b0-4050-4712-b8ca-f97e7323e456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = network(num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8777e28-a6b1-43b5-9bf6-3caabeef38f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fold_1', 'fold_2', 'fold_3', 'fold_4', 'fold_5']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_path = 'outputs/ClassifierExperimentCV_224_epo20_bs32_lr0.0001_s42/2023-12-03_2157_VGG16_BN_Attention'\n",
    "\n",
    "os.listdir(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8688a459-d4e4-45f7-80be-9f7189c2c314",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['outputs/ClassifierExperimentCV_224_epo20_bs32_lr0.0001_s42/2023-12-03_2157_VGG16_BN_Attention/fold_1/ClassifierExperimentCV_224_VGG16_BN_Attention_epo20_bs32_lr0.0001_seed42_fold1.pth',\n",
       " 'outputs/ClassifierExperimentCV_224_epo20_bs32_lr0.0001_s42/2023-12-03_2157_VGG16_BN_Attention/fold_2/ClassifierExperimentCV_224_VGG16_BN_Attention_epo20_bs32_lr0.0001_seed42_fold2.pth',\n",
       " 'outputs/ClassifierExperimentCV_224_epo20_bs32_lr0.0001_s42/2023-12-03_2157_VGG16_BN_Attention/fold_3/ClassifierExperimentCV_224_VGG16_BN_Attention_epo20_bs32_lr0.0001_seed42_fold3.pth',\n",
       " 'outputs/ClassifierExperimentCV_224_epo20_bs32_lr0.0001_s42/2023-12-03_2157_VGG16_BN_Attention/fold_4/ClassifierExperimentCV_224_VGG16_BN_Attention_epo20_bs32_lr0.0001_seed42_fold4.pth',\n",
       " 'outputs/ClassifierExperimentCV_224_epo20_bs32_lr0.0001_s42/2023-12-03_2157_VGG16_BN_Attention/fold_5/ClassifierExperimentCV_224_VGG16_BN_Attention_epo20_bs32_lr0.0001_seed42_fold5.pth']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_paths = sorted(glob(os.path.join(output_path, \"***\", \"*.pth\"), recursive=True))\n",
    "models_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ede19910-55f8-499b-a400-f5e675307f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming your 'network' class has a 'load_state_dict' method\n",
    "def load_model(model, path):\n",
    "    checkpoint = torch.load(path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d6a8c8de-12b8-4312-85f7-ebc084d02c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using VGG16_BN_Attention with configurations: num_classes='2', normalize_attn='False'\n",
      "Using VGG16_BN_Attention with configurations: num_classes='2', normalize_attn='False'\n",
      "Using VGG16_BN_Attention with configurations: num_classes='2', normalize_attn='False'\n",
      "Using VGG16_BN_Attention with configurations: num_classes='2', normalize_attn='False'\n",
      "Using VGG16_BN_Attention with configurations: num_classes='2', normalize_attn='False'\n"
     ]
    }
   ],
   "source": [
    "# Load all models\n",
    "models = [network(num_classes=2) for _ in range(len(models_paths))]\n",
    "for i, path in enumerate(models_paths):\n",
    "    load_model(models[i], path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1f6fce41-09f6-438f-9c49-35c814f2d269",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[], [], [], [], []]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predictions for each model\n",
    "all_predictions = [[] for _ in range(len(models))]\n",
    "all_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8c84ed07-774e-4c86-b12a-9130087905d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ed7bb8e7-1257-4885-83e6-87574025ed26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 119/119 [34:07<00:00, 17.20s/it]\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for images, labels in tqdm(val_loader):\n",
    "        for i, model in enumerate(models):\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            all_predictions[i].extend(predicted.cpu().numpy())\n",
    "        \n",
    "        validation_labels.extend(labels.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bfda7f1f-4bec-4fcc-b891-5058e1a9f02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_labels = np.array(validation_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7c9e1136-3c31-4714-901e-83cb63997d04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3796,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cc6d7aeb-c43a-4071-a4c0-86bc9506292b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predictions = np.array(all_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e1c600d8-350b-47b6-a8ff-0202fa697aae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 3796)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a4130ccc-9d91-460e-9864-0ea92a3bf57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_predictions, _ = mode(all_predictions, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "51eba0cb-f805-40ed-8da3-48b177ce83f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3796,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "51fdb139-a5dd-49bf-84f7-9e539f40f823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Accuracy: 0.9230769230769231\n",
      "Ensemble Cohen's Kappa: 0.8459548756987352\n",
      "Ensemble AUC: 0.9225588430892604\n"
     ]
    }
   ],
   "source": [
    "# Calculate metrics using scikit-learn\n",
    "accuracy = accuracy_score(validation_labels, ensemble_predictions)\n",
    "kappa = cohen_kappa_score(validation_labels, ensemble_predictions)\n",
    "auc = roc_auc_score(validation_labels, ensemble_predictions)\n",
    "\n",
    "print(f\"Ensemble Accuracy: {accuracy}\")\n",
    "print(f\"Ensemble Cohen's Kappa: {kappa}\")\n",
    "print(f\"Ensemble AUC: {auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b0259e-2c2f-41ca-9184-7c6268ddec42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a714014-a96b-4047-ad68-7d5c472ff885",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
