{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from utils.utils import excute_cmd, execute_cmd_realtime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# To allow auto reload to this notebook after modifying any external file imported\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training a single using the train masks, lower lr, and more epochs using `ClassifierSegExperiment`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excuting training pipeline with 50 epochs...\n",
      "Loading data with 3 class labels...\n",
      "Loading the data from ../datasets/challenge2/train\n",
      "Loading the data from ../datasets/challenge2/val\n",
      "Using segmentation masks for training...\n",
      "train_images: 5082, train_masks: 5082, train_labels: 5082\n",
      "Class weights: [0.62440103 0.84997491 4.50531915]\n",
      "Creating a classifier experiment using VGG16_BN_Attention network.\n",
      "Using VGG16_BN_Attention with configurations: num_classes='3', normalize_attn='False'\n",
      "Using focal loss.\n",
      "Experiment started.\n",
      "Epoch: 1 Train batch 10 loss: 0.4747427701950073, 6.3% complete\n",
      "Epoch: 1 Train batch 20 loss: 0.44776538014411926, 12.6% complete\n",
      "Epoch: 1 Train batch 30 loss: 0.43278053402900696, 18.9% complete\n",
      "Epoch: 1 Train batch 40 loss: 0.4322032928466797, 25.2% complete\n",
      "Epoch: 1 Train batch 50 loss: 0.42653924226760864, 31.4% complete\n",
      "Epoch: 1 Train batch 60 loss: 0.4082804024219513, 37.7% complete\n",
      "Epoch: 1 Train batch 70 loss: 0.3972669243812561, 44.0% complete\n",
      "Epoch: 1 Train batch 80 loss: 0.389247864484787, 50.3% complete\n",
      "Epoch: 1 Train batch 90 loss: 0.34983113408088684, 56.6% complete\n",
      "Epoch: 1 Train batch 100 loss: 0.3667583465576172, 62.9% complete\n",
      "Epoch: 1 Train batch 110 loss: 0.30558013916015625, 69.2% complete\n",
      "Epoch: 1 Train batch 120 loss: 0.35588204860687256, 75.5% complete\n",
      "Epoch: 1 Train batch 130 loss: 0.31048497557640076, 81.8% complete\n",
      "Epoch: 1 Train batch 140 loss: 0.3045996427536011, 88.1% complete\n",
      "Epoch: 1 Train batch 150 loss: 0.3046036958694458, 94.3% complete\n",
      "Batch 1. Data shape torch.Size([32, 3, 224, 224]) Loss 0.28956541419029236\n",
      "Batch 2. Data shape torch.Size([32, 3, 224, 224]) Loss 0.26625683903694153\n",
      "Batch 3. Data shape torch.Size([32, 3, 224, 224]) Loss 0.2209746539592743\n",
      "Batch 4. Data shape torch.Size([32, 3, 224, 224]) Loss 0.2725856304168701\n",
      "Batch 5. Data shape torch.Size([32, 3, 224, 224]) Loss 0.41197043657302856\n",
      "Batch 6. Data shape torch.Size([32, 3, 224, 224]) Loss 0.3744330406188965\n",
      "Batch 7. Data shape torch.Size([32, 3, 224, 224]) Loss 0.30339956283569336\n",
      "Batch 8. Data shape torch.Size([32, 3, 224, 224]) Loss 0.33512192964553833\n",
      "Batch 9. Data shape torch.Size([32, 3, 224, 224]) Loss 0.2317788302898407\n",
      "Batch 10. Data shape torch.Size([32, 3, 224, 224]) Loss 0.2666257619857788\n",
      "Batch 11. Data shape torch.Size([32, 3, 224, 224]) Loss 0.3275596499443054\n",
      "Batch 12. Data shape torch.Size([32, 3, 224, 224]) Loss 0.31041282415390015\n",
      "Batch 13. Data shape torch.Size([32, 3, 224, 224]) Loss 0.32137978076934814\n",
      "Batch 14. Data shape torch.Size([32, 3, 224, 224]) Loss 0.372474730014801\n",
      "Batch 15. Data shape torch.Size([32, 3, 224, 224]) Loss 0.31153053045272827\n",
      "Batch 16. Data shape torch.Size([32, 3, 224, 224]) Loss 0.3111312985420227\n",
      "Batch 17. Data shape torch.Size([32, 3, 224, 224]) Loss 0.2510441541671753\n",
      "Batch 18. Data shape torch.Size([32, 3, 224, 224]) Loss 0.34684479236602783\n",
      "Batch 19. Data shape torch.Size([32, 3, 224, 224]) Loss 0.34048253297805786\n",
      "Batch 20. Data shape torch.Size([32, 3, 224, 224]) Loss 0.24896490573883057\n",
      "Batch 21. Data shape torch.Size([32, 3, 224, 224]) Loss 0.30690664052963257\n",
      "Batch 22. Data shape torch.Size([32, 3, 224, 224]) Loss 0.2860327959060669\n",
      "Batch 23. Data shape torch.Size([32, 3, 224, 224]) Loss 0.23603925108909607\n",
      "Batch 24. Data shape torch.Size([32, 3, 224, 224]) Loss 0.3018466830253601\n",
      "Batch 25. Data shape torch.Size([32, 3, 224, 224]) Loss 0.3431797921657562\n",
      "Batch 26. Data shape torch.Size([32, 3, 224, 224]) Loss 0.30726948380470276\n",
      "Batch 27. Data shape torch.Size([32, 3, 224, 224]) Loss 0.3244352340698242\n",
      "Batch 28. Data shape torch.Size([32, 3, 224, 224]) Loss 0.33763188123703003\n",
      "Batch 29. Data shape torch.Size([32, 3, 224, 224]) Loss 0.2848794460296631\n",
      "Batch 30. Data shape torch.Size([32, 3, 224, 224]) Loss 0.3580501675605774\n",
      "Batch 31. Data shape torch.Size([32, 3, 224, 224]) Loss 0.3066674470901489\n",
      "Batch 32. Data shape torch.Size([32, 3, 224, 224]) Loss 0.28362593054771423\n",
      "Batch 33. Data shape torch.Size([32, 3, 224, 224]) Loss 0.2948925793170929\n",
      "Batch 34. Data shape torch.Size([32, 3, 224, 224]) Loss 0.3131217062473297\n",
      "Batch 35. Data shape torch.Size([32, 3, 224, 224]) Loss 0.28753000497817993\n",
      "Batch 36. Data shape torch.Size([32, 3, 224, 224]) Loss 0.28926384449005127\n",
      "Batch 37. Data shape torch.Size([32, 3, 224, 224]) Loss 0.32255107164382935\n",
      "Batch 38. Data shape torch.Size([32, 3, 224, 224]) Loss 0.33095261454582214\n",
      "Batch 39. Data shape torch.Size([32, 3, 224, 224]) Loss 0.32447904348373413\n",
      "Batch 40. Data shape torch.Size([22, 3, 224, 224]) Loss 0.2848292589187622\n",
      "Valid loss improved from inf to 0.305968. Saving model ...\n",
      "Epoch: 01/50 | time: 9.0m 9.621s | lr: 1.0000e-05 | train/loss: 0.37816 | val/loss: 0.30597 | val/accuracy: 0.74173 | val/AUC: 0.82861 | val/Kappa: 0.52856\n",
      "Epoch: 2 Train batch 10 loss: 0.2643885314464569, 6.3% complete\n",
      "Epoch: 2 Train batch 20 loss: 0.27110782265663147, 12.6% complete\n",
      "Epoch: 2 Train batch 30 loss: 0.25981655716896057, 18.9% complete\n",
      "Epoch: 2 Train batch 40 loss: 0.26526665687561035, 25.2% complete\n",
      "Epoch: 2 Train batch 50 loss: 0.31779223680496216, 31.4% complete\n",
      "Epoch: 2 Train batch 60 loss: 0.23215442895889282, 37.7% complete\n",
      "Epoch: 2 Train batch 70 loss: 0.25210875272750854, 44.0% complete\n",
      "Epoch: 2 Train batch 80 loss: 0.24646726250648499, 50.3% complete\n",
      "Epoch: 2 Train batch 90 loss: 0.23425154387950897, 56.6% complete\n",
      "Epoch: 2 Train batch 100 loss: 0.2634647786617279, 62.9% complete\n",
      "Epoch: 2 Train batch 110 loss: 0.316121906042099, 69.2% complete\n",
      "Epoch: 2 Train batch 120 loss: 0.27651146054267883, 75.5% complete\n",
      "Epoch: 2 Train batch 130 loss: 0.20150449872016907, 81.8% complete\n",
      "Epoch: 2 Train batch 140 loss: 0.23371434211730957, 88.1% complete\n",
      "Epoch: 2 Train batch 150 loss: 0.20296156406402588, 94.3% complete\n",
      "Batch 1. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1637316346168518\n",
      "Batch 2. Data shape torch.Size([32, 3, 224, 224]) Loss 0.22018754482269287\n",
      "Batch 3. Data shape torch.Size([32, 3, 224, 224]) Loss 0.31699874997138977\n",
      "Batch 4. Data shape torch.Size([32, 3, 224, 224]) Loss 0.2629956007003784\n",
      "Batch 5. Data shape torch.Size([32, 3, 224, 224]) Loss 0.2152668535709381\n",
      "Batch 6. Data shape torch.Size([32, 3, 224, 224]) Loss 0.19502070546150208\n",
      "Batch 7. Data shape torch.Size([32, 3, 224, 224]) Loss 0.20281052589416504\n",
      "Batch 8. Data shape torch.Size([32, 3, 224, 224]) Loss 0.23704513907432556\n",
      "Batch 9. Data shape torch.Size([32, 3, 224, 224]) Loss 0.2897416949272156\n",
      "Batch 10. Data shape torch.Size([32, 3, 224, 224]) Loss 0.11595101654529572\n",
      "Batch 11. Data shape torch.Size([32, 3, 224, 224]) Loss 0.12571850419044495\n",
      "Batch 12. Data shape torch.Size([32, 3, 224, 224]) Loss 0.22558435797691345\n",
      "Batch 13. Data shape torch.Size([32, 3, 224, 224]) Loss 0.2564653754234314\n",
      "Batch 14. Data shape torch.Size([32, 3, 224, 224]) Loss 0.26702815294265747\n",
      "Batch 15. Data shape torch.Size([32, 3, 224, 224]) Loss 0.3035951256752014\n",
      "Batch 16. Data shape torch.Size([32, 3, 224, 224]) Loss 0.2299651801586151\n",
      "Batch 17. Data shape torch.Size([32, 3, 224, 224]) Loss 0.32780778408050537\n",
      "Batch 18. Data shape torch.Size([32, 3, 224, 224]) Loss 0.2681390941143036\n",
      "Batch 19. Data shape torch.Size([32, 3, 224, 224]) Loss 0.23096422851085663\n",
      "Batch 20. Data shape torch.Size([32, 3, 224, 224]) Loss 0.23969632387161255\n",
      "Batch 21. Data shape torch.Size([32, 3, 224, 224]) Loss 0.20611734688282013\n",
      "Batch 22. Data shape torch.Size([32, 3, 224, 224]) Loss 0.25649118423461914\n",
      "Batch 23. Data shape torch.Size([32, 3, 224, 224]) Loss 0.17219316959381104\n",
      "Batch 24. Data shape torch.Size([32, 3, 224, 224]) Loss 0.19917738437652588\n",
      "Batch 25. Data shape torch.Size([32, 3, 224, 224]) Loss 0.2210574448108673\n",
      "Batch 26. Data shape torch.Size([32, 3, 224, 224]) Loss 0.2589747905731201\n",
      "Batch 27. Data shape torch.Size([32, 3, 224, 224]) Loss 0.26392024755477905\n",
      "Batch 28. Data shape torch.Size([32, 3, 224, 224]) Loss 0.19160819053649902\n",
      "Batch 29. Data shape torch.Size([32, 3, 224, 224]) Loss 0.17403152585029602\n",
      "Batch 30. Data shape torch.Size([32, 3, 224, 224]) Loss 0.2303890436887741\n",
      "Batch 31. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1930938959121704\n",
      "Batch 32. Data shape torch.Size([32, 3, 224, 224]) Loss 0.24728091061115265\n",
      "Batch 33. Data shape torch.Size([32, 3, 224, 224]) Loss 0.21849235892295837\n",
      "Batch 34. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1839577704668045\n",
      "Batch 35. Data shape torch.Size([32, 3, 224, 224]) Loss 0.19743473827838898\n",
      "Batch 36. Data shape torch.Size([32, 3, 224, 224]) Loss 0.17082145810127258\n",
      "Batch 37. Data shape torch.Size([32, 3, 224, 224]) Loss 0.2274375557899475\n",
      "Batch 38. Data shape torch.Size([32, 3, 224, 224]) Loss 0.21734878420829773\n",
      "Batch 39. Data shape torch.Size([32, 3, 224, 224]) Loss 0.3246040344238281\n",
      "Batch 40. Data shape torch.Size([22, 3, 224, 224]) Loss 0.1764986515045166\n",
      "Valid loss improved from 0.305968 to 0.225641. Saving model ...\n",
      "Epoch: 02/50 | time: 7.0m 22.71s | lr: 1.0000e-05 | train/loss: 0.26031 | val/loss: 0.22564 | val/accuracy: 0.78976 | val/AUC: 0.88246 | val/Kappa: 0.61149\n",
      "Epoch: 3 Train batch 10 loss: 0.22896872460842133, 6.3% complete\n",
      "Epoch: 3 Train batch 20 loss: 0.2602343261241913, 12.6% complete\n",
      "Epoch: 3 Train batch 30 loss: 0.2213907688856125, 18.9% complete\n",
      "Epoch: 3 Train batch 40 loss: 0.149368017911911, 25.2% complete\n",
      "Epoch: 3 Train batch 50 loss: 0.2838113009929657, 31.4% complete\n",
      "Epoch: 3 Train batch 60 loss: 0.23510147631168365, 37.7% complete\n",
      "Epoch: 3 Train batch 70 loss: 0.17704525589942932, 44.0% complete\n",
      "Epoch: 3 Train batch 80 loss: 0.3080478012561798, 50.3% complete\n",
      "Epoch: 3 Train batch 90 loss: 0.19616833329200745, 56.6% complete\n",
      "Epoch: 3 Train batch 100 loss: 0.25931766629219055, 62.9% complete\n",
      "Epoch: 3 Train batch 110 loss: 0.1634911298751831, 69.2% complete\n",
      "Epoch: 3 Train batch 120 loss: 0.24525484442710876, 75.5% complete\n",
      "Epoch: 3 Train batch 130 loss: 0.14974717795848846, 81.8% complete\n",
      "Epoch: 3 Train batch 140 loss: 0.231379896402359, 88.1% complete\n",
      "Epoch: 3 Train batch 150 loss: 0.1659672111272812, 94.3% complete\n",
      "Batch 1. Data shape torch.Size([32, 3, 224, 224]) Loss 0.20806573331356049\n",
      "Batch 2. Data shape torch.Size([32, 3, 224, 224]) Loss 0.23780113458633423\n",
      "Batch 3. Data shape torch.Size([32, 3, 224, 224]) Loss 0.27861487865448\n",
      "Batch 4. Data shape torch.Size([32, 3, 224, 224]) Loss 0.14235860109329224\n",
      "Batch 5. Data shape torch.Size([32, 3, 224, 224]) Loss 0.20064350962638855\n",
      "Batch 6. Data shape torch.Size([32, 3, 224, 224]) Loss 0.14100320637226105\n",
      "Batch 7. Data shape torch.Size([32, 3, 224, 224]) Loss 0.17462094128131866\n",
      "Batch 8. Data shape torch.Size([32, 3, 224, 224]) Loss 0.18177828192710876\n",
      "Batch 9. Data shape torch.Size([32, 3, 224, 224]) Loss 0.21503415703773499\n",
      "Batch 10. Data shape torch.Size([32, 3, 224, 224]) Loss 0.18911488354206085\n",
      "Batch 11. Data shape torch.Size([32, 3, 224, 224]) Loss 0.24091166257858276\n",
      "Batch 12. Data shape torch.Size([32, 3, 224, 224]) Loss 0.16809576749801636\n",
      "Batch 13. Data shape torch.Size([32, 3, 224, 224]) Loss 0.21153950691223145\n",
      "Batch 14. Data shape torch.Size([32, 3, 224, 224]) Loss 0.21770916879177094\n",
      "Batch 15. Data shape torch.Size([32, 3, 224, 224]) Loss 0.16855981945991516\n",
      "Batch 16. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1454310417175293\n",
      "Batch 17. Data shape torch.Size([32, 3, 224, 224]) Loss 0.19698305428028107\n",
      "Batch 18. Data shape torch.Size([32, 3, 224, 224]) Loss 0.11520086228847504\n",
      "Batch 19. Data shape torch.Size([32, 3, 224, 224]) Loss 0.2531922459602356\n",
      "Batch 20. Data shape torch.Size([32, 3, 224, 224]) Loss 0.14354659616947174\n",
      "Batch 21. Data shape torch.Size([32, 3, 224, 224]) Loss 0.20891302824020386\n",
      "Batch 22. Data shape torch.Size([32, 3, 224, 224]) Loss 0.19078989326953888\n",
      "Batch 23. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08556919544935226\n",
      "Batch 24. Data shape torch.Size([32, 3, 224, 224]) Loss 0.24219727516174316\n",
      "Batch 25. Data shape torch.Size([32, 3, 224, 224]) Loss 0.15261103212833405\n",
      "Batch 26. Data shape torch.Size([32, 3, 224, 224]) Loss 0.2703304588794708\n",
      "Batch 27. Data shape torch.Size([32, 3, 224, 224]) Loss 0.23466333746910095\n",
      "Batch 28. Data shape torch.Size([32, 3, 224, 224]) Loss 0.19915194809436798\n",
      "Batch 29. Data shape torch.Size([32, 3, 224, 224]) Loss 0.22609826922416687\n",
      "Batch 30. Data shape torch.Size([32, 3, 224, 224]) Loss 0.17689943313598633\n",
      "Batch 31. Data shape torch.Size([32, 3, 224, 224]) Loss 0.11005917936563492\n",
      "Batch 32. Data shape torch.Size([32, 3, 224, 224]) Loss 0.21967117488384247\n",
      "Batch 33. Data shape torch.Size([32, 3, 224, 224]) Loss 0.11967338621616364\n",
      "Batch 34. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1993589997291565\n",
      "Batch 35. Data shape torch.Size([32, 3, 224, 224]) Loss 0.21324241161346436\n",
      "Batch 36. Data shape torch.Size([32, 3, 224, 224]) Loss 0.18569955229759216\n",
      "Batch 37. Data shape torch.Size([32, 3, 224, 224]) Loss 0.15316754579544067\n",
      "Batch 38. Data shape torch.Size([32, 3, 224, 224]) Loss 0.2799702286720276\n",
      "Batch 39. Data shape torch.Size([32, 3, 224, 224]) Loss 0.12307585775852203\n",
      "Batch 40. Data shape torch.Size([22, 3, 224, 224]) Loss 0.2618514597415924\n",
      "Valid loss improved from 0.225641 to 0.192080. Saving model ...\n",
      "Epoch: 03/50 | time: 8.0m 41.42s | lr: 1.0000e-05 | train/loss: 0.21755 | val/loss: 0.19208 | val/accuracy: 0.82835 | val/AUC: 0.91128 | val/Kappa: 0.67929\n",
      "Epoch: 4 Train batch 10 loss: 0.2126666158437729, 6.3% complete\n",
      "Epoch: 4 Train batch 20 loss: 0.2292599081993103, 12.6% complete\n",
      "Epoch: 4 Train batch 30 loss: 0.17696607112884521, 18.9% complete\n",
      "Epoch: 4 Train batch 40 loss: 0.1822965443134308, 25.2% complete\n",
      "Epoch: 4 Train batch 50 loss: 0.17245590686798096, 31.4% complete\n",
      "Epoch: 4 Train batch 60 loss: 0.25677722692489624, 37.7% complete\n",
      "Epoch: 4 Train batch 70 loss: 0.21737155318260193, 44.0% complete\n",
      "Epoch: 4 Train batch 80 loss: 0.1391461044549942, 50.3% complete\n",
      "Epoch: 4 Train batch 90 loss: 0.206832155585289, 56.6% complete\n",
      "Epoch: 4 Train batch 100 loss: 0.13227148354053497, 62.9% complete\n",
      "Epoch: 4 Train batch 110 loss: 0.16125710308551788, 69.2% complete\n",
      "Epoch: 4 Train batch 120 loss: 0.12159736454486847, 75.5% complete\n",
      "Epoch: 4 Train batch 130 loss: 0.18565379083156586, 81.8% complete\n",
      "Epoch: 4 Train batch 140 loss: 0.1289442777633667, 88.1% complete\n",
      "Epoch: 4 Train batch 150 loss: 0.2658909857273102, 94.3% complete\n",
      "Batch 1. Data shape torch.Size([32, 3, 224, 224]) Loss 0.13371655344963074\n",
      "Batch 2. Data shape torch.Size([32, 3, 224, 224]) Loss 0.21046166121959686\n",
      "Batch 3. Data shape torch.Size([32, 3, 224, 224]) Loss 0.24783971905708313\n",
      "Batch 4. Data shape torch.Size([32, 3, 224, 224]) Loss 0.2285907119512558\n",
      "Batch 5. Data shape torch.Size([32, 3, 224, 224]) Loss 0.2617062032222748\n",
      "Batch 6. Data shape torch.Size([32, 3, 224, 224]) Loss 0.242670938372612\n",
      "Batch 7. Data shape torch.Size([32, 3, 224, 224]) Loss 0.25426363945007324\n",
      "Batch 8. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1873718649148941\n",
      "Batch 9. Data shape torch.Size([32, 3, 224, 224]) Loss 0.11358800530433655\n",
      "Batch 10. Data shape torch.Size([32, 3, 224, 224]) Loss 0.16247323155403137\n",
      "Batch 11. Data shape torch.Size([32, 3, 224, 224]) Loss 0.14351502060890198\n",
      "Batch 12. Data shape torch.Size([32, 3, 224, 224]) Loss 0.14503788948059082\n",
      "Batch 13. Data shape torch.Size([32, 3, 224, 224]) Loss 0.20867247879505157\n",
      "Batch 14. Data shape torch.Size([32, 3, 224, 224]) Loss 0.20387083292007446\n",
      "Batch 15. Data shape torch.Size([32, 3, 224, 224]) Loss 0.15317493677139282\n",
      "Batch 16. Data shape torch.Size([32, 3, 224, 224]) Loss 0.15946878492832184\n",
      "Batch 17. Data shape torch.Size([32, 3, 224, 224]) Loss 0.16462717950344086\n",
      "Batch 18. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1920037567615509\n",
      "Batch 19. Data shape torch.Size([32, 3, 224, 224]) Loss 0.18104901909828186\n",
      "Batch 20. Data shape torch.Size([32, 3, 224, 224]) Loss 0.13401605188846588\n",
      "Batch 21. Data shape torch.Size([32, 3, 224, 224]) Loss 0.15692922472953796\n",
      "Batch 22. Data shape torch.Size([32, 3, 224, 224]) Loss 0.30158859491348267\n",
      "Batch 23. Data shape torch.Size([32, 3, 224, 224]) Loss 0.11329315602779388\n",
      "Batch 24. Data shape torch.Size([32, 3, 224, 224]) Loss 0.21447688341140747\n",
      "Batch 25. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1687398999929428\n",
      "Batch 26. Data shape torch.Size([32, 3, 224, 224]) Loss 0.2027512490749359\n",
      "Batch 27. Data shape torch.Size([32, 3, 224, 224]) Loss 0.19548171758651733\n",
      "Batch 28. Data shape torch.Size([32, 3, 224, 224]) Loss 0.23229056596755981\n",
      "Batch 29. Data shape torch.Size([32, 3, 224, 224]) Loss 0.12504398822784424\n",
      "Batch 30. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1932782232761383\n",
      "Batch 31. Data shape torch.Size([32, 3, 224, 224]) Loss 0.18159985542297363\n",
      "Batch 32. Data shape torch.Size([32, 3, 224, 224]) Loss 0.16385827958583832\n",
      "Batch 33. Data shape torch.Size([32, 3, 224, 224]) Loss 0.0494830347597599\n",
      "Batch 34. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1781165450811386\n",
      "Batch 35. Data shape torch.Size([32, 3, 224, 224]) Loss 0.20544031262397766\n",
      "Batch 36. Data shape torch.Size([32, 3, 224, 224]) Loss 0.12815779447555542\n",
      "Batch 37. Data shape torch.Size([32, 3, 224, 224]) Loss 0.22828610241413116\n",
      "Batch 38. Data shape torch.Size([32, 3, 224, 224]) Loss 0.14131882786750793\n",
      "Batch 39. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1197022795677185\n",
      "Batch 40. Data shape torch.Size([22, 3, 224, 224]) Loss 0.19457024335861206\n",
      "Valid loss improved from 0.192080 to 0.180563. Saving model ...\n",
      "Epoch: 04/50 | time: 10.0m 44.22s | lr: 1.0000e-05 | train/loss: 0.19548 | val/loss: 0.18056 | val/accuracy: 0.83937 | val/AUC: 0.92287 | val/Kappa: 0.69844\n",
      "Epoch: 5 Train batch 10 loss: 0.18953312933444977, 6.3% complete\n",
      "Epoch: 5 Train batch 20 loss: 0.3365318477153778, 12.6% complete\n",
      "Epoch: 5 Train batch 30 loss: 0.2059732973575592, 18.9% complete\n",
      "Epoch: 5 Train batch 40 loss: 0.12362419068813324, 25.2% complete\n",
      "Epoch: 5 Train batch 50 loss: 0.16992300748825073, 31.4% complete\n",
      "Epoch: 5 Train batch 60 loss: 0.16861003637313843, 37.7% complete\n",
      "Epoch: 5 Train batch 70 loss: 0.1534140408039093, 44.0% complete\n",
      "Epoch: 5 Train batch 80 loss: 0.15225644409656525, 50.3% complete\n",
      "Epoch: 5 Train batch 90 loss: 0.1778249591588974, 56.6% complete\n",
      "Epoch: 5 Train batch 100 loss: 0.24645906686782837, 62.9% complete\n",
      "Epoch: 5 Train batch 110 loss: 0.3032982647418976, 69.2% complete\n",
      "Epoch: 5 Train batch 120 loss: 0.15225477516651154, 75.5% complete\n",
      "Epoch: 5 Train batch 130 loss: 0.18420055508613586, 81.8% complete\n",
      "Epoch: 5 Train batch 140 loss: 0.20138423144817352, 88.1% complete\n",
      "Epoch: 5 Train batch 150 loss: 0.26939162611961365, 94.3% complete\n",
      "Batch 1. Data shape torch.Size([32, 3, 224, 224]) Loss 0.27241915464401245\n",
      "Batch 2. Data shape torch.Size([32, 3, 224, 224]) Loss 0.11462821066379547\n",
      "Batch 3. Data shape torch.Size([32, 3, 224, 224]) Loss 0.193821519613266\n",
      "Batch 4. Data shape torch.Size([32, 3, 224, 224]) Loss 0.13555650413036346\n",
      "Batch 5. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09748169779777527\n",
      "Batch 6. Data shape torch.Size([32, 3, 224, 224]) Loss 0.19515305757522583\n",
      "Batch 7. Data shape torch.Size([32, 3, 224, 224]) Loss 0.14927224814891815\n",
      "Batch 8. Data shape torch.Size([32, 3, 224, 224]) Loss 0.13734009861946106\n",
      "Batch 9. Data shape torch.Size([32, 3, 224, 224]) Loss 0.20392447710037231\n",
      "Batch 10. Data shape torch.Size([32, 3, 224, 224]) Loss 0.17413243651390076\n",
      "Batch 11. Data shape torch.Size([32, 3, 224, 224]) Loss 0.17655572295188904\n",
      "Batch 12. Data shape torch.Size([32, 3, 224, 224]) Loss 0.10725238174200058\n",
      "Batch 13. Data shape torch.Size([32, 3, 224, 224]) Loss 0.13663817942142487\n",
      "Batch 14. Data shape torch.Size([32, 3, 224, 224]) Loss 0.19530163705348969\n",
      "Batch 15. Data shape torch.Size([32, 3, 224, 224]) Loss 0.2592836022377014\n",
      "Batch 16. Data shape torch.Size([32, 3, 224, 224]) Loss 0.18291744589805603\n",
      "Batch 17. Data shape torch.Size([32, 3, 224, 224]) Loss 0.20509490370750427\n",
      "Batch 18. Data shape torch.Size([32, 3, 224, 224]) Loss 0.16656440496444702\n",
      "Batch 19. Data shape torch.Size([32, 3, 224, 224]) Loss 0.16092289984226227\n",
      "Batch 20. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1564241498708725\n",
      "Batch 21. Data shape torch.Size([32, 3, 224, 224]) Loss 0.24849000573158264\n",
      "Batch 22. Data shape torch.Size([32, 3, 224, 224]) Loss 0.11078086495399475\n",
      "Batch 23. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08913829922676086\n",
      "Batch 24. Data shape torch.Size([32, 3, 224, 224]) Loss 0.16647392511367798\n",
      "Batch 25. Data shape torch.Size([32, 3, 224, 224]) Loss 0.2234925925731659\n",
      "Batch 26. Data shape torch.Size([32, 3, 224, 224]) Loss 0.20792129635810852\n",
      "Batch 27. Data shape torch.Size([32, 3, 224, 224]) Loss 0.2069007158279419\n",
      "Batch 28. Data shape torch.Size([32, 3, 224, 224]) Loss 0.12565141916275024\n",
      "Batch 29. Data shape torch.Size([32, 3, 224, 224]) Loss 0.21597523987293243\n",
      "Batch 30. Data shape torch.Size([32, 3, 224, 224]) Loss 0.10587788373231888\n",
      "Batch 31. Data shape torch.Size([32, 3, 224, 224]) Loss 0.18789176642894745\n",
      "Batch 32. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1314360797405243\n",
      "Batch 33. Data shape torch.Size([32, 3, 224, 224]) Loss 0.2002933919429779\n",
      "Batch 34. Data shape torch.Size([32, 3, 224, 224]) Loss 0.11146365851163864\n",
      "Batch 35. Data shape torch.Size([32, 3, 224, 224]) Loss 0.175681471824646\n",
      "Batch 36. Data shape torch.Size([32, 3, 224, 224]) Loss 0.2335195243358612\n",
      "Batch 37. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08616439998149872\n",
      "Batch 38. Data shape torch.Size([32, 3, 224, 224]) Loss 0.18020187318325043\n",
      "Batch 39. Data shape torch.Size([32, 3, 224, 224]) Loss 0.2083851397037506\n",
      "Batch 40. Data shape torch.Size([22, 3, 224, 224]) Loss 0.11909586191177368\n",
      "Valid loss improved from 0.180563 to 0.168888. Saving model ...\n",
      "Epoch: 05/50 | time: 8.0m 26.12s | lr: 1.0000e-05 | train/loss: 0.18162 | val/loss: 0.16889 | val/accuracy: 0.84724 | val/AUC: 0.92960 | val/Kappa: 0.71364\n",
      "Epoch: 6 Train batch 10 loss: 0.1787497103214264, 6.3% complete\n",
      "Epoch: 6 Train batch 20 loss: 0.2923906743526459, 12.6% complete\n",
      "Epoch: 6 Train batch 30 loss: 0.15703831613063812, 18.9% complete\n",
      "Epoch: 6 Train batch 40 loss: 0.11699683964252472, 25.2% complete\n",
      "Epoch: 6 Train batch 50 loss: 0.2178822159767151, 31.4% complete\n",
      "Epoch: 6 Train batch 60 loss: 0.25107845664024353, 37.7% complete\n",
      "Epoch: 6 Train batch 70 loss: 0.1133028045296669, 44.0% complete\n",
      "Epoch: 6 Train batch 80 loss: 0.21387548744678497, 50.3% complete\n",
      "Epoch: 6 Train batch 90 loss: 0.2539284825325012, 56.6% complete\n",
      "Epoch: 6 Train batch 100 loss: 0.09495135396718979, 62.9% complete\n",
      "Epoch: 6 Train batch 110 loss: 0.1633804887533188, 69.2% complete\n",
      "Epoch: 6 Train batch 120 loss: 0.18727974593639374, 75.5% complete\n",
      "Epoch: 6 Train batch 130 loss: 0.11216677725315094, 81.8% complete\n",
      "Epoch: 6 Train batch 140 loss: 0.22694285213947296, 88.1% complete\n",
      "Epoch: 6 Train batch 150 loss: 0.1427290290594101, 94.3% complete\n",
      "Batch 1. Data shape torch.Size([32, 3, 224, 224]) Loss 0.20031049847602844\n",
      "Batch 2. Data shape torch.Size([32, 3, 224, 224]) Loss 0.2079474925994873\n",
      "Batch 3. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1831696778535843\n",
      "Batch 4. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1837572157382965\n",
      "Batch 5. Data shape torch.Size([32, 3, 224, 224]) Loss 0.10651281476020813\n",
      "Batch 6. Data shape torch.Size([32, 3, 224, 224]) Loss 0.14548000693321228\n",
      "Batch 7. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09682990610599518\n",
      "Batch 8. Data shape torch.Size([32, 3, 224, 224]) Loss 0.15937253832817078\n",
      "Batch 9. Data shape torch.Size([32, 3, 224, 224]) Loss 0.11360229551792145\n",
      "Batch 10. Data shape torch.Size([32, 3, 224, 224]) Loss 0.16388079524040222\n",
      "Batch 11. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1947544515132904\n",
      "Batch 12. Data shape torch.Size([32, 3, 224, 224]) Loss 0.105992391705513\n",
      "Batch 13. Data shape torch.Size([32, 3, 224, 224]) Loss 0.21053744852542877\n",
      "Batch 14. Data shape torch.Size([32, 3, 224, 224]) Loss 0.17500390112400055\n",
      "Batch 15. Data shape torch.Size([32, 3, 224, 224]) Loss 0.2203831672668457\n",
      "Batch 16. Data shape torch.Size([32, 3, 224, 224]) Loss 0.23441943526268005\n",
      "Batch 17. Data shape torch.Size([32, 3, 224, 224]) Loss 0.11800923943519592\n",
      "Batch 18. Data shape torch.Size([32, 3, 224, 224]) Loss 0.15900862216949463\n",
      "Batch 19. Data shape torch.Size([32, 3, 224, 224]) Loss 0.26372772455215454\n",
      "Batch 20. Data shape torch.Size([32, 3, 224, 224]) Loss 0.13684526085853577\n",
      "Batch 21. Data shape torch.Size([32, 3, 224, 224]) Loss 0.14797921478748322\n",
      "Batch 22. Data shape torch.Size([32, 3, 224, 224]) Loss 0.17829740047454834\n",
      "Batch 23. Data shape torch.Size([32, 3, 224, 224]) Loss 0.14828632771968842\n",
      "Batch 24. Data shape torch.Size([32, 3, 224, 224]) Loss 0.19664037227630615\n",
      "Batch 25. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08616265654563904\n",
      "Batch 26. Data shape torch.Size([32, 3, 224, 224]) Loss 0.12803635001182556\n",
      "Batch 27. Data shape torch.Size([32, 3, 224, 224]) Loss 0.14028006792068481\n",
      "Batch 28. Data shape torch.Size([32, 3, 224, 224]) Loss 0.13303504884243011\n",
      "Batch 29. Data shape torch.Size([32, 3, 224, 224]) Loss 0.06202603504061699\n",
      "Batch 30. Data shape torch.Size([32, 3, 224, 224]) Loss 0.15284638106822968\n",
      "Batch 31. Data shape torch.Size([32, 3, 224, 224]) Loss 0.15043403208255768\n",
      "Batch 32. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1864546537399292\n",
      "Batch 33. Data shape torch.Size([32, 3, 224, 224]) Loss 0.23084618151187897\n",
      "Batch 34. Data shape torch.Size([32, 3, 224, 224]) Loss 0.20668821036815643\n",
      "Batch 35. Data shape torch.Size([32, 3, 224, 224]) Loss 0.14240391552448273\n",
      "Batch 36. Data shape torch.Size([32, 3, 224, 224]) Loss 0.20216885209083557\n",
      "Batch 37. Data shape torch.Size([32, 3, 224, 224]) Loss 0.10662924498319626\n",
      "Batch 38. Data shape torch.Size([32, 3, 224, 224]) Loss 0.15094271302223206\n",
      "Batch 39. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1715363711118698\n",
      "Batch 40. Data shape torch.Size([22, 3, 224, 224]) Loss 0.05037481337785721\n",
      "Valid loss improved from 0.168888 to 0.158790. Saving model ...\n",
      "Epoch: 06/50 | time: 10.0m 9.314s | lr: 1.0000e-05 | train/loss: 0.17229 | val/loss: 0.15879 | val/accuracy: 0.85197 | val/AUC: 0.93735 | val/Kappa: 0.72168\n",
      "Epoch: 7 Train batch 10 loss: 0.20515696704387665, 6.3% complete\n",
      "Epoch: 7 Train batch 20 loss: 0.14450348913669586, 12.6% complete\n",
      "Epoch: 7 Train batch 30 loss: 0.1763487458229065, 18.9% complete\n",
      "Epoch: 7 Train batch 40 loss: 0.17315590381622314, 25.2% complete\n",
      "Epoch: 7 Train batch 50 loss: 0.17169539630413055, 31.4% complete\n",
      "Epoch: 7 Train batch 60 loss: 0.10915154218673706, 37.7% complete\n",
      "Epoch: 7 Train batch 70 loss: 0.13640393316745758, 44.0% complete\n",
      "Epoch: 7 Train batch 80 loss: 0.16890215873718262, 50.3% complete\n",
      "Epoch: 7 Train batch 90 loss: 0.17266151309013367, 56.6% complete\n",
      "Epoch: 7 Train batch 100 loss: 0.11714215576648712, 62.9% complete\n",
      "Epoch: 7 Train batch 110 loss: 0.09803345799446106, 69.2% complete\n",
      "Epoch: 7 Train batch 120 loss: 0.1788153499364853, 75.5% complete\n",
      "Epoch: 7 Train batch 130 loss: 0.22045157849788666, 81.8% complete\n",
      "Epoch: 7 Train batch 140 loss: 0.12801402807235718, 88.1% complete\n",
      "Epoch: 7 Train batch 150 loss: 0.12814074754714966, 94.3% complete\n",
      "Batch 1. Data shape torch.Size([32, 3, 224, 224]) Loss 0.19729582965373993\n",
      "Batch 2. Data shape torch.Size([32, 3, 224, 224]) Loss 0.19101954996585846\n",
      "Batch 3. Data shape torch.Size([32, 3, 224, 224]) Loss 0.11521980166435242\n",
      "Batch 4. Data shape torch.Size([32, 3, 224, 224]) Loss 0.13750702142715454\n",
      "Batch 5. Data shape torch.Size([32, 3, 224, 224]) Loss 0.10892249643802643\n",
      "Batch 6. Data shape torch.Size([32, 3, 224, 224]) Loss 0.19314192235469818\n",
      "Batch 7. Data shape torch.Size([32, 3, 224, 224]) Loss 0.2481106072664261\n",
      "Batch 8. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09812171757221222\n",
      "Batch 9. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1885966807603836\n",
      "Batch 10. Data shape torch.Size([32, 3, 224, 224]) Loss 0.2633042335510254\n",
      "Batch 11. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1833721399307251\n",
      "Batch 12. Data shape torch.Size([32, 3, 224, 224]) Loss 0.20518849790096283\n",
      "Batch 13. Data shape torch.Size([32, 3, 224, 224]) Loss 0.11339268833398819\n",
      "Batch 14. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09858005493879318\n",
      "Batch 15. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07413145899772644\n",
      "Batch 16. Data shape torch.Size([32, 3, 224, 224]) Loss 0.17430752515792847\n",
      "Batch 17. Data shape torch.Size([32, 3, 224, 224]) Loss 0.10412952303886414\n",
      "Batch 18. Data shape torch.Size([32, 3, 224, 224]) Loss 0.17643189430236816\n",
      "Batch 19. Data shape torch.Size([32, 3, 224, 224]) Loss 0.15891730785369873\n",
      "Batch 20. Data shape torch.Size([32, 3, 224, 224]) Loss 0.12413254380226135\n",
      "Batch 21. Data shape torch.Size([32, 3, 224, 224]) Loss 0.15375450253486633\n",
      "Batch 22. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1492041051387787\n",
      "Batch 23. Data shape torch.Size([32, 3, 224, 224]) Loss 0.10895322263240814\n",
      "Batch 24. Data shape torch.Size([32, 3, 224, 224]) Loss 0.23104768991470337\n",
      "Batch 25. Data shape torch.Size([32, 3, 224, 224]) Loss 0.13123542070388794\n",
      "Batch 26. Data shape torch.Size([32, 3, 224, 224]) Loss 0.12657031416893005\n",
      "Batch 27. Data shape torch.Size([32, 3, 224, 224]) Loss 0.10600774735212326\n",
      "Batch 28. Data shape torch.Size([32, 3, 224, 224]) Loss 0.11613930016756058\n",
      "Batch 29. Data shape torch.Size([32, 3, 224, 224]) Loss 0.15931552648544312\n",
      "Batch 30. Data shape torch.Size([32, 3, 224, 224]) Loss 0.16834688186645508\n",
      "Batch 31. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1563040167093277\n",
      "Batch 32. Data shape torch.Size([32, 3, 224, 224]) Loss 0.23834437131881714\n",
      "Batch 33. Data shape torch.Size([32, 3, 224, 224]) Loss 0.14263129234313965\n",
      "Batch 34. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1779596209526062\n",
      "Batch 35. Data shape torch.Size([32, 3, 224, 224]) Loss 0.13479694724082947\n",
      "Batch 36. Data shape torch.Size([32, 3, 224, 224]) Loss 0.15049618482589722\n",
      "Batch 37. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1346890926361084\n",
      "Batch 38. Data shape torch.Size([32, 3, 224, 224]) Loss 0.10901818424463272\n",
      "Batch 39. Data shape torch.Size([32, 3, 224, 224]) Loss 0.12792877852916718\n",
      "Batch 40. Data shape torch.Size([22, 3, 224, 224]) Loss 0.08048813045024872\n",
      "Valid loss improved from 0.158790 to 0.151426. Saving model ...\n",
      "Epoch: 07/50 | time: 6.0m 20.22s | lr: 1.0000e-05 | train/loss: 0.16079 | val/loss: 0.15143 | val/accuracy: 0.85827 | val/AUC: 0.93826 | val/Kappa: 0.73144\n",
      "Epoch: 8 Train batch 10 loss: 0.13306239247322083, 6.3% complete\n",
      "Epoch: 8 Train batch 20 loss: 0.127629354596138, 12.6% complete\n",
      "Epoch: 8 Train batch 30 loss: 0.13923543691635132, 18.9% complete\n",
      "Epoch: 8 Train batch 40 loss: 0.17729692161083221, 25.2% complete\n",
      "Epoch: 8 Train batch 50 loss: 0.22823232412338257, 31.4% complete\n",
      "Epoch: 8 Train batch 60 loss: 0.15916743874549866, 37.7% complete\n",
      "Epoch: 8 Train batch 70 loss: 0.10791825503110886, 44.0% complete\n",
      "Epoch: 8 Train batch 80 loss: 0.22572824358940125, 50.3% complete\n",
      "Epoch: 8 Train batch 90 loss: 0.07481763511896133, 56.6% complete\n",
      "Epoch: 8 Train batch 100 loss: 0.1810116320848465, 62.9% complete\n",
      "Epoch: 8 Train batch 110 loss: 0.1253785640001297, 69.2% complete\n",
      "Epoch: 8 Train batch 120 loss: 0.10838323831558228, 75.5% complete\n",
      "Epoch: 8 Train batch 130 loss: 0.2032461166381836, 81.8% complete\n",
      "Epoch: 8 Train batch 140 loss: 0.10147668421268463, 88.1% complete\n",
      "Epoch: 8 Train batch 150 loss: 0.17766669392585754, 94.3% complete\n",
      "Batch 1. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1418468952178955\n",
      "Batch 2. Data shape torch.Size([32, 3, 224, 224]) Loss 0.19595783948898315\n",
      "Batch 3. Data shape torch.Size([32, 3, 224, 224]) Loss 0.14719358086585999\n",
      "Batch 4. Data shape torch.Size([32, 3, 224, 224]) Loss 0.13718801736831665\n",
      "Batch 5. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1472592055797577\n",
      "Batch 6. Data shape torch.Size([32, 3, 224, 224]) Loss 0.10158030688762665\n",
      "Batch 7. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1086873710155487\n",
      "Batch 8. Data shape torch.Size([32, 3, 224, 224]) Loss 0.15913552045822144\n",
      "Batch 9. Data shape torch.Size([32, 3, 224, 224]) Loss 0.14490272104740143\n",
      "Batch 10. Data shape torch.Size([32, 3, 224, 224]) Loss 0.13042065501213074\n",
      "Batch 11. Data shape torch.Size([32, 3, 224, 224]) Loss 0.091525137424469\n",
      "Batch 12. Data shape torch.Size([32, 3, 224, 224]) Loss 0.14016041159629822\n",
      "Batch 13. Data shape torch.Size([32, 3, 224, 224]) Loss 0.18268173933029175\n",
      "Batch 14. Data shape torch.Size([32, 3, 224, 224]) Loss 0.17197877168655396\n",
      "Batch 15. Data shape torch.Size([32, 3, 224, 224]) Loss 0.14158350229263306\n",
      "Batch 16. Data shape torch.Size([32, 3, 224, 224]) Loss 0.17395848035812378\n",
      "Batch 17. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1578252911567688\n",
      "Batch 18. Data shape torch.Size([32, 3, 224, 224]) Loss 0.20070111751556396\n",
      "Batch 19. Data shape torch.Size([32, 3, 224, 224]) Loss 0.10034028440713882\n",
      "Batch 20. Data shape torch.Size([32, 3, 224, 224]) Loss 0.23139597475528717\n",
      "Batch 21. Data shape torch.Size([32, 3, 224, 224]) Loss 0.11960660666227341\n",
      "Batch 22. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1657680869102478\n",
      "Batch 23. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1211944967508316\n",
      "Batch 24. Data shape torch.Size([32, 3, 224, 224]) Loss 0.12260376662015915\n",
      "Batch 25. Data shape torch.Size([32, 3, 224, 224]) Loss 0.21851541101932526\n",
      "Batch 26. Data shape torch.Size([32, 3, 224, 224]) Loss 0.12079090625047684\n",
      "Batch 27. Data shape torch.Size([32, 3, 224, 224]) Loss 0.11297789216041565\n",
      "Batch 28. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09985668957233429\n",
      "Batch 29. Data shape torch.Size([32, 3, 224, 224]) Loss 0.10443079471588135\n",
      "Batch 30. Data shape torch.Size([32, 3, 224, 224]) Loss 0.15304286777973175\n",
      "Batch 31. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09194599837064743\n",
      "Batch 32. Data shape torch.Size([32, 3, 224, 224]) Loss 0.10673309862613678\n",
      "Batch 33. Data shape torch.Size([32, 3, 224, 224]) Loss 0.16227728128433228\n",
      "Batch 34. Data shape torch.Size([32, 3, 224, 224]) Loss 0.18165647983551025\n",
      "Batch 35. Data shape torch.Size([32, 3, 224, 224]) Loss 0.11499014496803284\n",
      "Batch 36. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09087928384542465\n",
      "Batch 37. Data shape torch.Size([32, 3, 224, 224]) Loss 0.16000600159168243\n",
      "Batch 38. Data shape torch.Size([32, 3, 224, 224]) Loss 0.11688470840454102\n",
      "Batch 39. Data shape torch.Size([32, 3, 224, 224]) Loss 0.22759756445884705\n",
      "Batch 40. Data shape torch.Size([22, 3, 224, 224]) Loss 0.26498082280158997\n",
      "Valid loss improved from 0.151426 to 0.146577. Saving model ...\n",
      "Epoch: 08/50 | time: 6.0m 16.07s | lr: 1.0000e-05 | train/loss: 0.15278 | val/loss: 0.14658 | val/accuracy: 0.86220 | val/AUC: 0.94574 | val/Kappa: 0.74012\n",
      "Epoch: 9 Train batch 10 loss: 0.11470573395490646, 6.3% complete\n",
      "Epoch: 9 Train batch 20 loss: 0.14218086004257202, 12.6% complete\n",
      "Epoch: 9 Train batch 30 loss: 0.14700931310653687, 18.9% complete\n",
      "Epoch: 9 Train batch 40 loss: 0.17840680480003357, 25.2% complete\n",
      "Epoch: 9 Train batch 50 loss: 0.14066462218761444, 31.4% complete\n",
      "Epoch: 9 Train batch 60 loss: 0.1826503574848175, 37.7% complete\n",
      "Epoch: 9 Train batch 70 loss: 0.10199815779924393, 44.0% complete\n",
      "Epoch: 9 Train batch 80 loss: 0.1341008096933365, 50.3% complete\n",
      "Epoch: 9 Train batch 90 loss: 0.19507691264152527, 56.6% complete\n",
      "Epoch: 9 Train batch 100 loss: 0.1190888062119484, 62.9% complete\n",
      "Epoch: 9 Train batch 110 loss: 0.07694321870803833, 69.2% complete\n",
      "Epoch: 9 Train batch 120 loss: 0.11186740547418594, 75.5% complete\n",
      "Epoch: 9 Train batch 130 loss: 0.18738260865211487, 81.8% complete\n",
      "Epoch: 9 Train batch 140 loss: 0.13021577894687653, 88.1% complete\n",
      "Epoch: 9 Train batch 150 loss: 0.21841569244861603, 94.3% complete\n",
      "Batch 1. Data shape torch.Size([32, 3, 224, 224]) Loss 0.13887132704257965\n",
      "Batch 2. Data shape torch.Size([32, 3, 224, 224]) Loss 0.17531491816043854\n",
      "Batch 3. Data shape torch.Size([32, 3, 224, 224]) Loss 0.13853874802589417\n",
      "Batch 4. Data shape torch.Size([32, 3, 224, 224]) Loss 0.20334923267364502\n",
      "Batch 5. Data shape torch.Size([32, 3, 224, 224]) Loss 0.25402218103408813\n",
      "Batch 6. Data shape torch.Size([32, 3, 224, 224]) Loss 0.06862515211105347\n",
      "Batch 7. Data shape torch.Size([32, 3, 224, 224]) Loss 0.15299579501152039\n",
      "Batch 8. Data shape torch.Size([32, 3, 224, 224]) Loss 0.13802361488342285\n",
      "Batch 9. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1934777945280075\n",
      "Batch 10. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1744210422039032\n",
      "Batch 11. Data shape torch.Size([32, 3, 224, 224]) Loss 0.14138415455818176\n",
      "Batch 12. Data shape torch.Size([32, 3, 224, 224]) Loss 0.11076555401086807\n",
      "Batch 13. Data shape torch.Size([32, 3, 224, 224]) Loss 0.11578117311000824\n",
      "Batch 14. Data shape torch.Size([32, 3, 224, 224]) Loss 0.136631578207016\n",
      "Batch 15. Data shape torch.Size([32, 3, 224, 224]) Loss 0.15628132224082947\n",
      "Batch 16. Data shape torch.Size([32, 3, 224, 224]) Loss 0.10106640309095383\n",
      "Batch 17. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09721502661705017\n",
      "Batch 18. Data shape torch.Size([32, 3, 224, 224]) Loss 0.10645902156829834\n",
      "Batch 19. Data shape torch.Size([32, 3, 224, 224]) Loss 0.20177283883094788\n",
      "Batch 20. Data shape torch.Size([32, 3, 224, 224]) Loss 0.0868075042963028\n",
      "Batch 21. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07793309539556503\n",
      "Batch 22. Data shape torch.Size([32, 3, 224, 224]) Loss 0.24086996912956238\n",
      "Batch 23. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1974640041589737\n",
      "Batch 24. Data shape torch.Size([32, 3, 224, 224]) Loss 0.15225273370742798\n",
      "Batch 25. Data shape torch.Size([32, 3, 224, 224]) Loss 0.13331180810928345\n",
      "Batch 26. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07152025401592255\n",
      "Batch 27. Data shape torch.Size([32, 3, 224, 224]) Loss 0.12988412380218506\n",
      "Batch 28. Data shape torch.Size([32, 3, 224, 224]) Loss 0.13561369478702545\n",
      "Batch 29. Data shape torch.Size([32, 3, 224, 224]) Loss 0.12394441664218903\n",
      "Batch 30. Data shape torch.Size([32, 3, 224, 224]) Loss 0.15035350620746613\n",
      "Batch 31. Data shape torch.Size([32, 3, 224, 224]) Loss 0.21183210611343384\n",
      "Batch 32. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1701294332742691\n",
      "Batch 33. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07224123179912567\n",
      "Batch 34. Data shape torch.Size([32, 3, 224, 224]) Loss 0.17947742342948914\n",
      "Batch 35. Data shape torch.Size([32, 3, 224, 224]) Loss 0.16577082872390747\n",
      "Batch 36. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1407983899116516\n",
      "Batch 37. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08099888265132904\n",
      "Batch 38. Data shape torch.Size([32, 3, 224, 224]) Loss 0.13397055864334106\n",
      "Batch 39. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07196713984012604\n",
      "Batch 40. Data shape torch.Size([22, 3, 224, 224]) Loss 0.12220770865678787\n",
      "Valid loss improved from 0.146577 to 0.141359. Saving model ...\n",
      "Epoch: 09/50 | time: 6.0m 14.68s | lr: 1.0000e-05 | train/loss: 0.14762 | val/loss: 0.14136 | val/accuracy: 0.86457 | val/AUC: 0.94609 | val/Kappa: 0.74531\n",
      "Epoch: 10 Train batch 10 loss: 0.14427566528320312, 6.3% complete\n",
      "Epoch: 10 Train batch 20 loss: 0.10169119387865067, 12.6% complete\n",
      "Epoch: 10 Train batch 30 loss: 0.11848211288452148, 18.9% complete\n",
      "Epoch: 10 Train batch 40 loss: 0.10320558398962021, 25.2% complete\n",
      "Epoch: 10 Train batch 50 loss: 0.1843024641275406, 31.4% complete\n",
      "Epoch: 10 Train batch 60 loss: 0.12829869985580444, 37.7% complete\n",
      "Epoch: 10 Train batch 70 loss: 0.13210685551166534, 44.0% complete\n",
      "Epoch: 10 Train batch 80 loss: 0.13101698458194733, 50.3% complete\n",
      "Epoch: 10 Train batch 90 loss: 0.11102190613746643, 56.6% complete\n",
      "Epoch: 10 Train batch 100 loss: 0.1105009987950325, 62.9% complete\n",
      "Epoch: 10 Train batch 110 loss: 0.09150843322277069, 69.2% complete\n",
      "Epoch: 10 Train batch 120 loss: 0.20402203500270844, 75.5% complete\n",
      "Epoch: 10 Train batch 130 loss: 0.11695648729801178, 81.8% complete\n",
      "Epoch: 10 Train batch 140 loss: 0.1071198582649231, 88.1% complete\n",
      "Epoch: 10 Train batch 150 loss: 0.14058507978916168, 94.3% complete\n",
      "Batch 1. Data shape torch.Size([32, 3, 224, 224]) Loss 0.0794091522693634\n",
      "Batch 2. Data shape torch.Size([32, 3, 224, 224]) Loss 0.11927680671215057\n",
      "Batch 3. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09615975618362427\n",
      "Batch 4. Data shape torch.Size([32, 3, 224, 224]) Loss 0.2756529152393341\n",
      "Batch 5. Data shape torch.Size([32, 3, 224, 224]) Loss 0.14493148028850555\n",
      "Batch 6. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07434606552124023\n",
      "Batch 7. Data shape torch.Size([32, 3, 224, 224]) Loss 0.11979137361049652\n",
      "Batch 8. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1759023368358612\n",
      "Batch 9. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1801833063364029\n",
      "Batch 10. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09038031846284866\n",
      "Batch 11. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07997097074985504\n",
      "Batch 12. Data shape torch.Size([32, 3, 224, 224]) Loss 0.21158495545387268\n",
      "Batch 13. Data shape torch.Size([32, 3, 224, 224]) Loss 0.15417873859405518\n",
      "Batch 14. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1492735743522644\n",
      "Batch 15. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07700268924236298\n",
      "Batch 16. Data shape torch.Size([32, 3, 224, 224]) Loss 0.12196655571460724\n",
      "Batch 17. Data shape torch.Size([32, 3, 224, 224]) Loss 0.2138707935810089\n",
      "Batch 18. Data shape torch.Size([32, 3, 224, 224]) Loss 0.13352131843566895\n",
      "Batch 19. Data shape torch.Size([32, 3, 224, 224]) Loss 0.13223445415496826\n",
      "Batch 20. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08314502239227295\n",
      "Batch 21. Data shape torch.Size([32, 3, 224, 224]) Loss 0.13168597221374512\n",
      "Batch 22. Data shape torch.Size([32, 3, 224, 224]) Loss 0.06968915462493896\n",
      "Batch 23. Data shape torch.Size([32, 3, 224, 224]) Loss 0.14965349435806274\n",
      "Batch 24. Data shape torch.Size([32, 3, 224, 224]) Loss 0.0954476147890091\n",
      "Batch 25. Data shape torch.Size([32, 3, 224, 224]) Loss 0.14707574248313904\n",
      "Batch 26. Data shape torch.Size([32, 3, 224, 224]) Loss 0.12748637795448303\n",
      "Batch 27. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07835792750120163\n",
      "Batch 28. Data shape torch.Size([32, 3, 224, 224]) Loss 0.10747137665748596\n",
      "Batch 29. Data shape torch.Size([32, 3, 224, 224]) Loss 0.10475384443998337\n",
      "Batch 30. Data shape torch.Size([32, 3, 224, 224]) Loss 0.16257473826408386\n",
      "Batch 31. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08240868151187897\n",
      "Batch 32. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08163374662399292\n",
      "Batch 33. Data shape torch.Size([32, 3, 224, 224]) Loss 0.12480401992797852\n",
      "Batch 34. Data shape torch.Size([32, 3, 224, 224]) Loss 0.19065594673156738\n",
      "Batch 35. Data shape torch.Size([32, 3, 224, 224]) Loss 0.14965736865997314\n",
      "Batch 36. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1705264300107956\n",
      "Batch 37. Data shape torch.Size([32, 3, 224, 224]) Loss 0.14538152515888214\n",
      "Batch 38. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1318209171295166\n",
      "Batch 39. Data shape torch.Size([32, 3, 224, 224]) Loss 0.21472367644309998\n",
      "Batch 40. Data shape torch.Size([22, 3, 224, 224]) Loss 0.20899014174938202\n",
      "Valid loss improved from 0.141359 to 0.134690. Saving model ...\n",
      "Epoch: 10/50 | time: 6.0m 11.53s | lr: 1.0000e-05 | train/loss: 0.13860 | val/loss: 0.13469 | val/accuracy: 0.86850 | val/AUC: 0.95265 | val/Kappa: 0.75236\n",
      "Epoch: 11 Train batch 10 loss: 0.13788935542106628, 6.3% complete\n",
      "Epoch: 11 Train batch 20 loss: 0.12826260924339294, 12.6% complete\n",
      "Epoch: 11 Train batch 30 loss: 0.13980351388454437, 18.9% complete\n",
      "Epoch: 11 Train batch 40 loss: 0.2956089675426483, 25.2% complete\n",
      "Epoch: 11 Train batch 50 loss: 0.09348491579294205, 31.4% complete\n",
      "Epoch: 11 Train batch 60 loss: 0.08349724858999252, 37.7% complete\n",
      "Epoch: 11 Train batch 70 loss: 0.18133090436458588, 44.0% complete\n",
      "Epoch: 11 Train batch 80 loss: 0.1116684079170227, 50.3% complete\n",
      "Epoch: 11 Train batch 90 loss: 0.04985880106687546, 56.6% complete\n",
      "Epoch: 11 Train batch 100 loss: 0.13849776983261108, 62.9% complete\n",
      "Epoch: 11 Train batch 110 loss: 0.11125128716230392, 69.2% complete\n",
      "Epoch: 11 Train batch 120 loss: 0.12297745048999786, 75.5% complete\n",
      "Epoch: 11 Train batch 130 loss: 0.18693432211875916, 81.8% complete\n",
      "Epoch: 11 Train batch 140 loss: 0.12943117320537567, 88.1% complete\n",
      "Epoch: 11 Train batch 150 loss: 0.14885231852531433, 94.3% complete\n",
      "Batch 1. Data shape torch.Size([32, 3, 224, 224]) Loss 0.11976759880781174\n",
      "Batch 2. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1021018698811531\n",
      "Batch 3. Data shape torch.Size([32, 3, 224, 224]) Loss 0.15660697221755981\n",
      "Batch 4. Data shape torch.Size([32, 3, 224, 224]) Loss 0.18964354693889618\n",
      "Batch 5. Data shape torch.Size([32, 3, 224, 224]) Loss 0.15168966352939606\n",
      "Batch 6. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09458029270172119\n",
      "Batch 7. Data shape torch.Size([32, 3, 224, 224]) Loss 0.06515796482563019\n",
      "Batch 8. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09324340522289276\n",
      "Batch 9. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09456470608711243\n",
      "Batch 10. Data shape torch.Size([32, 3, 224, 224]) Loss 0.10472167283296585\n",
      "Batch 11. Data shape torch.Size([32, 3, 224, 224]) Loss 0.0901680663228035\n",
      "Batch 12. Data shape torch.Size([32, 3, 224, 224]) Loss 0.16288606822490692\n",
      "Batch 13. Data shape torch.Size([32, 3, 224, 224]) Loss 0.14841344952583313\n",
      "Batch 14. Data shape torch.Size([32, 3, 224, 224]) Loss 0.16072598099708557\n",
      "Batch 15. Data shape torch.Size([32, 3, 224, 224]) Loss 0.13860511779785156\n",
      "Batch 16. Data shape torch.Size([32, 3, 224, 224]) Loss 0.14677146077156067\n",
      "Batch 17. Data shape torch.Size([32, 3, 224, 224]) Loss 0.18276965618133545\n",
      "Batch 18. Data shape torch.Size([32, 3, 224, 224]) Loss 0.0924869105219841\n",
      "Batch 19. Data shape torch.Size([32, 3, 224, 224]) Loss 0.16998139023780823\n",
      "Batch 20. Data shape torch.Size([32, 3, 224, 224]) Loss 0.15757915377616882\n",
      "Batch 21. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1469283252954483\n",
      "Batch 22. Data shape torch.Size([32, 3, 224, 224]) Loss 0.11349645256996155\n",
      "Batch 23. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09333004057407379\n",
      "Batch 24. Data shape torch.Size([32, 3, 224, 224]) Loss 0.23258501291275024\n",
      "Batch 25. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09929455816745758\n",
      "Batch 26. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1714177429676056\n",
      "Batch 27. Data shape torch.Size([32, 3, 224, 224]) Loss 0.18661673367023468\n",
      "Batch 28. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08524453639984131\n",
      "Batch 29. Data shape torch.Size([32, 3, 224, 224]) Loss 0.13392208516597748\n",
      "Batch 30. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08821631968021393\n",
      "Batch 31. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07208648324012756\n",
      "Batch 32. Data shape torch.Size([32, 3, 224, 224]) Loss 0.21873146295547485\n",
      "Batch 33. Data shape torch.Size([32, 3, 224, 224]) Loss 0.19639751315116882\n",
      "Batch 34. Data shape torch.Size([32, 3, 224, 224]) Loss 0.11380529403686523\n",
      "Batch 35. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09657251089811325\n",
      "Batch 36. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09434103220701218\n",
      "Batch 37. Data shape torch.Size([32, 3, 224, 224]) Loss 0.17944835126399994\n",
      "Batch 38. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1444810926914215\n",
      "Batch 39. Data shape torch.Size([32, 3, 224, 224]) Loss 0.10896067321300507\n",
      "Batch 40. Data shape torch.Size([22, 3, 224, 224]) Loss 0.09268604964017868\n",
      "Valid loss improved from 0.134690 to 0.132276. Saving model ...\n",
      "Epoch: 11/50 | time: 6.0m 25.69s | lr: 1.0000e-05 | train/loss: 0.13890 | val/loss: 0.13228 | val/accuracy: 0.86929 | val/AUC: 0.95148 | val/Kappa: 0.75395\n",
      "Epoch: 12 Train batch 10 loss: 0.1231732964515686, 6.3% complete\n",
      "Epoch: 12 Train batch 20 loss: 0.06161459535360336, 12.6% complete\n",
      "Epoch: 12 Train batch 30 loss: 0.16482208669185638, 18.9% complete\n",
      "Epoch: 12 Train batch 40 loss: 0.17981462180614471, 25.2% complete\n",
      "Epoch: 12 Train batch 50 loss: 0.11178161203861237, 31.4% complete\n",
      "Epoch: 12 Train batch 60 loss: 0.0770559161901474, 37.7% complete\n",
      "Epoch: 12 Train batch 70 loss: 0.09196349233388901, 44.0% complete\n",
      "Epoch: 12 Train batch 80 loss: 0.08349617570638657, 50.3% complete\n",
      "Epoch: 12 Train batch 90 loss: 0.16616575419902802, 56.6% complete\n",
      "Epoch: 12 Train batch 100 loss: 0.12192696332931519, 62.9% complete\n",
      "Epoch: 12 Train batch 110 loss: 0.06643887609243393, 69.2% complete\n",
      "Epoch: 12 Train batch 120 loss: 0.05887129530310631, 75.5% complete\n",
      "Epoch: 12 Train batch 130 loss: 0.07241451740264893, 81.8% complete\n",
      "Epoch: 12 Train batch 140 loss: 0.19961892068386078, 88.1% complete\n",
      "Epoch: 12 Train batch 150 loss: 0.13904604315757751, 94.3% complete\n",
      "Batch 1. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09420586377382278\n",
      "Batch 2. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1071053072810173\n",
      "Batch 3. Data shape torch.Size([32, 3, 224, 224]) Loss 0.14417743682861328\n",
      "Batch 4. Data shape torch.Size([32, 3, 224, 224]) Loss 0.183763325214386\n",
      "Batch 5. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08859707415103912\n",
      "Batch 6. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1496288776397705\n",
      "Batch 7. Data shape torch.Size([32, 3, 224, 224]) Loss 0.16329273581504822\n",
      "Batch 8. Data shape torch.Size([32, 3, 224, 224]) Loss 0.12623091042041779\n",
      "Batch 9. Data shape torch.Size([32, 3, 224, 224]) Loss 0.0843401551246643\n",
      "Batch 10. Data shape torch.Size([32, 3, 224, 224]) Loss 0.11284299939870834\n",
      "Batch 11. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1263384222984314\n",
      "Batch 12. Data shape torch.Size([32, 3, 224, 224]) Loss 0.11080878973007202\n",
      "Batch 13. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08315721154212952\n",
      "Batch 14. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1642378568649292\n",
      "Batch 15. Data shape torch.Size([32, 3, 224, 224]) Loss 0.17079779505729675\n",
      "Batch 16. Data shape torch.Size([32, 3, 224, 224]) Loss 0.11035600304603577\n",
      "Batch 17. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08064809441566467\n",
      "Batch 18. Data shape torch.Size([32, 3, 224, 224]) Loss 0.05332402139902115\n",
      "Batch 19. Data shape torch.Size([32, 3, 224, 224]) Loss 0.13477766513824463\n",
      "Batch 20. Data shape torch.Size([32, 3, 224, 224]) Loss 0.11327113956212997\n",
      "Batch 21. Data shape torch.Size([32, 3, 224, 224]) Loss 0.05503961816430092\n",
      "Batch 22. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1399974226951599\n",
      "Batch 23. Data shape torch.Size([32, 3, 224, 224]) Loss 0.10207866132259369\n",
      "Batch 24. Data shape torch.Size([32, 3, 224, 224]) Loss 0.11423061043024063\n",
      "Batch 25. Data shape torch.Size([32, 3, 224, 224]) Loss 0.14102059602737427\n",
      "Batch 26. Data shape torch.Size([32, 3, 224, 224]) Loss 0.12834373116493225\n",
      "Batch 27. Data shape torch.Size([32, 3, 224, 224]) Loss 0.13355983793735504\n",
      "Batch 28. Data shape torch.Size([32, 3, 224, 224]) Loss 0.0834774523973465\n",
      "Batch 29. Data shape torch.Size([32, 3, 224, 224]) Loss 0.23503270745277405\n",
      "Batch 30. Data shape torch.Size([32, 3, 224, 224]) Loss 0.13858723640441895\n",
      "Batch 31. Data shape torch.Size([32, 3, 224, 224]) Loss 0.13053536415100098\n",
      "Batch 32. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09971002489328384\n",
      "Batch 33. Data shape torch.Size([32, 3, 224, 224]) Loss 0.24713017046451569\n",
      "Batch 34. Data shape torch.Size([32, 3, 224, 224]) Loss 0.11165751516819\n",
      "Batch 35. Data shape torch.Size([32, 3, 224, 224]) Loss 0.2310395985841751\n",
      "Batch 36. Data shape torch.Size([32, 3, 224, 224]) Loss 0.13498064875602722\n",
      "Batch 37. Data shape torch.Size([32, 3, 224, 224]) Loss 0.10501907765865326\n",
      "Batch 38. Data shape torch.Size([32, 3, 224, 224]) Loss 0.22883905470371246\n",
      "Batch 39. Data shape torch.Size([32, 3, 224, 224]) Loss 0.05621856078505516\n",
      "Batch 40. Data shape torch.Size([22, 3, 224, 224]) Loss 0.14840154349803925\n",
      "Valid loss improved from 0.132276 to 0.129170. Saving model ...\n",
      "Epoch: 12/50 | time: 6.0m 23.72s | lr: 1.0000e-05 | train/loss: 0.13078 | val/loss: 0.12917 | val/accuracy: 0.87008 | val/AUC: 0.95547 | val/Kappa: 0.75736\n",
      "Epoch: 13 Train batch 10 loss: 0.15298761427402496, 6.3% complete\n",
      "Epoch: 13 Train batch 20 loss: 0.12225013226270676, 12.6% complete\n",
      "Epoch: 13 Train batch 30 loss: 0.19009798765182495, 18.9% complete\n",
      "Epoch: 13 Train batch 40 loss: 0.10547944903373718, 25.2% complete\n",
      "Epoch: 13 Train batch 50 loss: 0.12111129611730576, 31.4% complete\n",
      "Epoch: 13 Train batch 60 loss: 0.15439631044864655, 37.7% complete\n",
      "Epoch: 13 Train batch 70 loss: 0.18253552913665771, 44.0% complete\n",
      "Epoch: 13 Train batch 80 loss: 0.18389827013015747, 50.3% complete\n",
      "Epoch: 13 Train batch 90 loss: 0.07428695261478424, 56.6% complete\n",
      "Epoch: 13 Train batch 100 loss: 0.13441261649131775, 62.9% complete\n",
      "Epoch: 13 Train batch 110 loss: 0.1798684149980545, 69.2% complete\n",
      "Epoch: 13 Train batch 120 loss: 0.0682498961687088, 75.5% complete\n",
      "Epoch: 13 Train batch 130 loss: 0.08803518861532211, 81.8% complete\n",
      "Epoch: 13 Train batch 140 loss: 0.12430400401353836, 88.1% complete\n",
      "Epoch: 13 Train batch 150 loss: 0.12125246226787567, 94.3% complete\n",
      "Batch 1. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09870359301567078\n",
      "Batch 2. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1330108493566513\n",
      "Batch 3. Data shape torch.Size([32, 3, 224, 224]) Loss 0.15826115012168884\n",
      "Batch 4. Data shape torch.Size([32, 3, 224, 224]) Loss 0.15029166638851166\n",
      "Batch 5. Data shape torch.Size([32, 3, 224, 224]) Loss 0.16737225651741028\n",
      "Batch 6. Data shape torch.Size([32, 3, 224, 224]) Loss 0.10213136672973633\n",
      "Batch 7. Data shape torch.Size([32, 3, 224, 224]) Loss 0.0355636328458786\n",
      "Batch 8. Data shape torch.Size([32, 3, 224, 224]) Loss 0.13945627212524414\n",
      "Batch 9. Data shape torch.Size([32, 3, 224, 224]) Loss 0.11323180049657822\n",
      "Batch 10. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09960958361625671\n",
      "Batch 11. Data shape torch.Size([32, 3, 224, 224]) Loss 0.11062613874673843\n",
      "Batch 12. Data shape torch.Size([32, 3, 224, 224]) Loss 0.16094745695590973\n",
      "Batch 13. Data shape torch.Size([32, 3, 224, 224]) Loss 0.06989401578903198\n",
      "Batch 14. Data shape torch.Size([32, 3, 224, 224]) Loss 0.16331139206886292\n",
      "Batch 15. Data shape torch.Size([32, 3, 224, 224]) Loss 0.14549139142036438\n",
      "Batch 16. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09308451414108276\n",
      "Batch 17. Data shape torch.Size([32, 3, 224, 224]) Loss 0.12529052793979645\n",
      "Batch 18. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07678692042827606\n",
      "Batch 19. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1334156095981598\n",
      "Batch 20. Data shape torch.Size([32, 3, 224, 224]) Loss 0.11240711808204651\n",
      "Batch 21. Data shape torch.Size([32, 3, 224, 224]) Loss 0.11278112232685089\n",
      "Batch 22. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1253429502248764\n",
      "Batch 23. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07885894179344177\n",
      "Batch 24. Data shape torch.Size([32, 3, 224, 224]) Loss 0.17308858036994934\n",
      "Batch 25. Data shape torch.Size([32, 3, 224, 224]) Loss 0.11567705869674683\n",
      "Batch 26. Data shape torch.Size([32, 3, 224, 224]) Loss 0.10685364902019501\n",
      "Batch 27. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09394654631614685\n",
      "Batch 28. Data shape torch.Size([32, 3, 224, 224]) Loss 0.20007206499576569\n",
      "Batch 29. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07878278195858002\n",
      "Batch 30. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1420610398054123\n",
      "Batch 31. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09844057261943817\n",
      "Batch 32. Data shape torch.Size([32, 3, 224, 224]) Loss 0.10428479313850403\n",
      "Batch 33. Data shape torch.Size([32, 3, 224, 224]) Loss 0.05189887434244156\n",
      "Batch 34. Data shape torch.Size([32, 3, 224, 224]) Loss 0.3188263773918152\n",
      "Batch 35. Data shape torch.Size([32, 3, 224, 224]) Loss 0.14694498479366302\n",
      "Batch 36. Data shape torch.Size([32, 3, 224, 224]) Loss 0.20789214968681335\n",
      "Batch 37. Data shape torch.Size([32, 3, 224, 224]) Loss 0.14627188444137573\n",
      "Batch 38. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07020998746156693\n",
      "Batch 39. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08719790726900101\n",
      "Batch 40. Data shape torch.Size([22, 3, 224, 224]) Loss 0.12439333647489548\n",
      "Valid loss improved from 0.129170 to 0.124318. Saving model ...\n",
      "Epoch: 13/50 | time: 6.0m 44.91s | lr: 1.0000e-05 | train/loss: 0.12093 | val/loss: 0.12432 | val/accuracy: 0.88268 | val/AUC: 0.95517 | val/Kappa: 0.78088\n",
      "Epoch: 14 Train batch 10 loss: 0.08446785807609558, 6.3% complete\n",
      "Epoch: 14 Train batch 20 loss: 0.060024045407772064, 12.6% complete\n",
      "Epoch: 14 Train batch 30 loss: 0.1316535323858261, 18.9% complete\n",
      "Epoch: 14 Train batch 40 loss: 0.1432921588420868, 25.2% complete\n",
      "Epoch: 14 Train batch 50 loss: 0.0795024037361145, 31.4% complete\n",
      "Epoch: 14 Train batch 60 loss: 0.15726089477539062, 37.7% complete\n",
      "Epoch: 14 Train batch 70 loss: 0.09969861805438995, 44.0% complete\n",
      "Epoch: 14 Train batch 80 loss: 0.08939039707183838, 50.3% complete\n",
      "Epoch: 14 Train batch 90 loss: 0.13573865592479706, 56.6% complete\n",
      "Epoch: 14 Train batch 100 loss: 0.09128604829311371, 62.9% complete\n",
      "Epoch: 14 Train batch 110 loss: 0.1313423067331314, 69.2% complete\n",
      "Epoch: 14 Train batch 120 loss: 0.1285436898469925, 75.5% complete\n",
      "Epoch: 14 Train batch 130 loss: 0.08797428011894226, 81.8% complete\n",
      "Epoch: 14 Train batch 140 loss: 0.09106969088315964, 88.1% complete\n",
      "Epoch: 14 Train batch 150 loss: 0.0902944877743721, 94.3% complete\n",
      "Batch 1. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08691330254077911\n",
      "Batch 2. Data shape torch.Size([32, 3, 224, 224]) Loss 0.15007400512695312\n",
      "Batch 3. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09412139654159546\n",
      "Batch 4. Data shape torch.Size([32, 3, 224, 224]) Loss 0.030101435258984566\n",
      "Batch 5. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07133544236421585\n",
      "Batch 6. Data shape torch.Size([32, 3, 224, 224]) Loss 0.11599572002887726\n",
      "Batch 7. Data shape torch.Size([32, 3, 224, 224]) Loss 0.11819912493228912\n",
      "Batch 8. Data shape torch.Size([32, 3, 224, 224]) Loss 0.10977385193109512\n",
      "Batch 9. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07448363304138184\n",
      "Batch 10. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09103220701217651\n",
      "Batch 11. Data shape torch.Size([32, 3, 224, 224]) Loss 0.06626199185848236\n",
      "Batch 12. Data shape torch.Size([32, 3, 224, 224]) Loss 0.10289008915424347\n",
      "Batch 13. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1149502545595169\n",
      "Batch 14. Data shape torch.Size([32, 3, 224, 224]) Loss 0.125440776348114\n",
      "Batch 15. Data shape torch.Size([32, 3, 224, 224]) Loss 0.11428390443325043\n",
      "Batch 16. Data shape torch.Size([32, 3, 224, 224]) Loss 0.19600939750671387\n",
      "Batch 17. Data shape torch.Size([32, 3, 224, 224]) Loss 0.03103279322385788\n",
      "Batch 18. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1320633590221405\n",
      "Batch 19. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1748567819595337\n",
      "Batch 20. Data shape torch.Size([32, 3, 224, 224]) Loss 0.06961459666490555\n",
      "Batch 21. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1415141373872757\n",
      "Batch 22. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09837165474891663\n",
      "Batch 23. Data shape torch.Size([32, 3, 224, 224]) Loss 0.15886089205741882\n",
      "Batch 24. Data shape torch.Size([32, 3, 224, 224]) Loss 0.14921453595161438\n",
      "Batch 25. Data shape torch.Size([32, 3, 224, 224]) Loss 0.12663830816745758\n",
      "Batch 26. Data shape torch.Size([32, 3, 224, 224]) Loss 0.13831251859664917\n",
      "Batch 27. Data shape torch.Size([32, 3, 224, 224]) Loss 0.19229909777641296\n",
      "Batch 28. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09311746060848236\n",
      "Batch 29. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07514557242393494\n",
      "Batch 30. Data shape torch.Size([32, 3, 224, 224]) Loss 0.06599723547697067\n",
      "Batch 31. Data shape torch.Size([32, 3, 224, 224]) Loss 0.06423995643854141\n",
      "Batch 32. Data shape torch.Size([32, 3, 224, 224]) Loss 0.12638045847415924\n",
      "Batch 33. Data shape torch.Size([32, 3, 224, 224]) Loss 0.2158675491809845\n",
      "Batch 34. Data shape torch.Size([32, 3, 224, 224]) Loss 0.13279758393764496\n",
      "Batch 35. Data shape torch.Size([32, 3, 224, 224]) Loss 0.20581501722335815\n",
      "Batch 36. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1537548154592514\n",
      "Batch 37. Data shape torch.Size([32, 3, 224, 224]) Loss 0.13770589232444763\n",
      "Batch 38. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09027829021215439\n",
      "Batch 39. Data shape torch.Size([32, 3, 224, 224]) Loss 0.22488807141780853\n",
      "Batch 40. Data shape torch.Size([22, 3, 224, 224]) Loss 0.246856689453125\n",
      "Valid loss improved from 0.124318 to 0.122687. Saving model ...\n",
      "Epoch: 14/50 | time: 7.0m 11.16s | lr: 1.0000e-05 | train/loss: 0.12424 | val/loss: 0.12269 | val/accuracy: 0.87953 | val/AUC: 0.96354 | val/Kappa: 0.77722\n",
      "Epoch: 15 Train batch 10 loss: 0.10107319802045822, 6.3% complete\n",
      "Epoch: 15 Train batch 20 loss: 0.08011674135923386, 12.6% complete\n",
      "Epoch: 15 Train batch 30 loss: 0.10932628810405731, 18.9% complete\n",
      "Epoch: 15 Train batch 40 loss: 0.05378495529294014, 25.2% complete\n",
      "Epoch: 15 Train batch 50 loss: 0.10223358869552612, 31.4% complete\n",
      "Epoch: 15 Train batch 60 loss: 0.058790188282728195, 37.7% complete\n",
      "Epoch: 15 Train batch 70 loss: 0.06898880749940872, 44.0% complete\n",
      "Epoch: 15 Train batch 80 loss: 0.10953007638454437, 50.3% complete\n",
      "Epoch: 15 Train batch 90 loss: 0.09155113250017166, 56.6% complete\n",
      "Epoch: 15 Train batch 100 loss: 0.03869616240262985, 62.9% complete\n",
      "Epoch: 15 Train batch 110 loss: 0.14169737696647644, 69.2% complete\n",
      "Epoch: 15 Train batch 120 loss: 0.07325810194015503, 75.5% complete\n",
      "Epoch: 15 Train batch 130 loss: 0.14567607641220093, 81.8% complete\n",
      "Epoch: 15 Train batch 140 loss: 0.14796335995197296, 88.1% complete\n",
      "Epoch: 15 Train batch 150 loss: 0.11831751465797424, 94.3% complete\n",
      "Batch 1. Data shape torch.Size([32, 3, 224, 224]) Loss 0.14324499666690826\n",
      "Batch 2. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1355641782283783\n",
      "Batch 3. Data shape torch.Size([32, 3, 224, 224]) Loss 0.13757777214050293\n",
      "Batch 4. Data shape torch.Size([32, 3, 224, 224]) Loss 0.15143398940563202\n",
      "Batch 5. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09786863625049591\n",
      "Batch 6. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08265787363052368\n",
      "Batch 7. Data shape torch.Size([32, 3, 224, 224]) Loss 0.13170483708381653\n",
      "Batch 8. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1392218917608261\n",
      "Batch 9. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08573156595230103\n",
      "Batch 10. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1529710441827774\n",
      "Batch 11. Data shape torch.Size([32, 3, 224, 224]) Loss 0.04677484929561615\n",
      "Batch 12. Data shape torch.Size([32, 3, 224, 224]) Loss 0.16473688185214996\n",
      "Batch 13. Data shape torch.Size([32, 3, 224, 224]) Loss 0.21748846769332886\n",
      "Batch 14. Data shape torch.Size([32, 3, 224, 224]) Loss 0.19069281220436096\n",
      "Batch 15. Data shape torch.Size([32, 3, 224, 224]) Loss 0.061279404908418655\n",
      "Batch 16. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07128674536943436\n",
      "Batch 17. Data shape torch.Size([32, 3, 224, 224]) Loss 0.10617058724164963\n",
      "Batch 18. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08979103714227676\n",
      "Batch 19. Data shape torch.Size([32, 3, 224, 224]) Loss 0.11047204583883286\n",
      "Batch 20. Data shape torch.Size([32, 3, 224, 224]) Loss 0.13483938574790955\n",
      "Batch 21. Data shape torch.Size([32, 3, 224, 224]) Loss 0.14009930193424225\n",
      "Batch 22. Data shape torch.Size([32, 3, 224, 224]) Loss 0.05386394262313843\n",
      "Batch 23. Data shape torch.Size([32, 3, 224, 224]) Loss 0.10977905988693237\n",
      "Batch 24. Data shape torch.Size([32, 3, 224, 224]) Loss 0.11635161936283112\n",
      "Batch 25. Data shape torch.Size([32, 3, 224, 224]) Loss 0.083411805331707\n",
      "Batch 26. Data shape torch.Size([32, 3, 224, 224]) Loss 0.10680298507213593\n",
      "Batch 27. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1581423282623291\n",
      "Batch 28. Data shape torch.Size([32, 3, 224, 224]) Loss 0.17823737859725952\n",
      "Batch 29. Data shape torch.Size([32, 3, 224, 224]) Loss 0.05412393435835838\n",
      "Batch 30. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09644176810979843\n",
      "Batch 31. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1830815225839615\n",
      "Batch 32. Data shape torch.Size([32, 3, 224, 224]) Loss 0.06384344398975372\n",
      "Batch 33. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07678182423114777\n",
      "Batch 34. Data shape torch.Size([32, 3, 224, 224]) Loss 0.060125887393951416\n",
      "Batch 35. Data shape torch.Size([32, 3, 224, 224]) Loss 0.12359681725502014\n",
      "Batch 36. Data shape torch.Size([32, 3, 224, 224]) Loss 0.16979031264781952\n",
      "Batch 37. Data shape torch.Size([32, 3, 224, 224]) Loss 0.05934726819396019\n",
      "Batch 38. Data shape torch.Size([32, 3, 224, 224]) Loss 0.17480500042438507\n",
      "Batch 39. Data shape torch.Size([32, 3, 224, 224]) Loss 0.06563352793455124\n",
      "Batch 40. Data shape torch.Size([22, 3, 224, 224]) Loss 0.13706393539905548\n",
      "Valid loss improved from 0.122687 to 0.116571. Saving model ...\n",
      "Epoch: 15/50 | time: 7.0m 17.39s | lr: 1.0000e-05 | train/loss: 0.11431 | val/loss: 0.11657 | val/accuracy: 0.89055 | val/AUC: 0.96299 | val/Kappa: 0.79715\n",
      "Epoch: 16 Train batch 10 loss: 0.1814572662115097, 6.3% complete\n",
      "Epoch: 16 Train batch 20 loss: 0.11074446141719818, 12.6% complete\n",
      "Epoch: 16 Train batch 30 loss: 0.08191580325365067, 18.9% complete\n",
      "Epoch: 16 Train batch 40 loss: 0.07893203943967819, 25.2% complete\n",
      "Epoch: 16 Train batch 50 loss: 0.13947324454784393, 31.4% complete\n",
      "Epoch: 16 Train batch 60 loss: 0.15703384578227997, 37.7% complete\n",
      "Epoch: 16 Train batch 70 loss: 0.12960638105869293, 44.0% complete\n",
      "Epoch: 16 Train batch 80 loss: 0.12897488474845886, 50.3% complete\n",
      "Epoch: 16 Train batch 90 loss: 0.07220572233200073, 56.6% complete\n",
      "Epoch: 16 Train batch 100 loss: 0.0851089209318161, 62.9% complete\n",
      "Epoch: 16 Train batch 110 loss: 0.0738740786910057, 69.2% complete\n",
      "Epoch: 16 Train batch 120 loss: 0.1282339096069336, 75.5% complete\n",
      "Epoch: 16 Train batch 130 loss: 0.13706257939338684, 81.8% complete\n",
      "Epoch: 16 Train batch 140 loss: 0.155972421169281, 88.1% complete\n",
      "Epoch: 16 Train batch 150 loss: 0.11132367700338364, 94.3% complete\n",
      "Batch 1. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07515332847833633\n",
      "Batch 2. Data shape torch.Size([32, 3, 224, 224]) Loss 0.12118673324584961\n",
      "Batch 3. Data shape torch.Size([32, 3, 224, 224]) Loss 0.17528975009918213\n",
      "Batch 4. Data shape torch.Size([32, 3, 224, 224]) Loss 0.13732437789440155\n",
      "Batch 5. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08815677464008331\n",
      "Batch 6. Data shape torch.Size([32, 3, 224, 224]) Loss 0.19442851841449738\n",
      "Batch 7. Data shape torch.Size([32, 3, 224, 224]) Loss 0.10316010564565659\n",
      "Batch 8. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08821777999401093\n",
      "Batch 9. Data shape torch.Size([32, 3, 224, 224]) Loss 0.19943609833717346\n",
      "Batch 10. Data shape torch.Size([32, 3, 224, 224]) Loss 0.12585210800170898\n",
      "Batch 11. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09131042659282684\n",
      "Batch 12. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08899524807929993\n",
      "Batch 13. Data shape torch.Size([32, 3, 224, 224]) Loss 0.0917196050286293\n",
      "Batch 14. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07349227368831635\n",
      "Batch 15. Data shape torch.Size([32, 3, 224, 224]) Loss 0.0878685861825943\n",
      "Batch 16. Data shape torch.Size([32, 3, 224, 224]) Loss 0.11738533526659012\n",
      "Batch 17. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09886272996664047\n",
      "Batch 18. Data shape torch.Size([32, 3, 224, 224]) Loss 0.04199179634451866\n",
      "Batch 19. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1263192892074585\n",
      "Batch 20. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07886512577533722\n",
      "Batch 21. Data shape torch.Size([32, 3, 224, 224]) Loss 0.15691789984703064\n",
      "Batch 22. Data shape torch.Size([32, 3, 224, 224]) Loss 0.11471989750862122\n",
      "Batch 23. Data shape torch.Size([32, 3, 224, 224]) Loss 0.06724627315998077\n",
      "Batch 24. Data shape torch.Size([32, 3, 224, 224]) Loss 0.15750667452812195\n",
      "Batch 25. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08732400834560394\n",
      "Batch 26. Data shape torch.Size([32, 3, 224, 224]) Loss 0.054108936339616776\n",
      "Batch 27. Data shape torch.Size([32, 3, 224, 224]) Loss 0.13117413222789764\n",
      "Batch 28. Data shape torch.Size([32, 3, 224, 224]) Loss 0.14991895854473114\n",
      "Batch 29. Data shape torch.Size([32, 3, 224, 224]) Loss 0.14849013090133667\n",
      "Batch 30. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09683874249458313\n",
      "Batch 31. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09386754035949707\n",
      "Batch 32. Data shape torch.Size([32, 3, 224, 224]) Loss 0.10842719674110413\n",
      "Batch 33. Data shape torch.Size([32, 3, 224, 224]) Loss 0.0741395577788353\n",
      "Batch 34. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09603607654571533\n",
      "Batch 35. Data shape torch.Size([32, 3, 224, 224]) Loss 0.068329818546772\n",
      "Batch 36. Data shape torch.Size([32, 3, 224, 224]) Loss 0.14009800553321838\n",
      "Batch 37. Data shape torch.Size([32, 3, 224, 224]) Loss 0.18054194748401642\n",
      "Batch 38. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1734030395746231\n",
      "Batch 39. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08869659900665283\n",
      "Batch 40. Data shape torch.Size([22, 3, 224, 224]) Loss 0.11063595861196518\n",
      "Valid loss improved from 0.116571 to 0.112586. Saving model ...\n",
      "Epoch: 16/50 | time: 7.0m 25.86s | lr: 1.0000e-05 | train/loss: 0.10976 | val/loss: 0.11259 | val/accuracy: 0.88740 | val/AUC: 0.96655 | val/Kappa: 0.79083\n",
      "Epoch: 17 Train batch 10 loss: 0.19282826781272888, 6.3% complete\n",
      "Epoch: 17 Train batch 20 loss: 0.14998020231723785, 12.6% complete\n",
      "Epoch: 17 Train batch 30 loss: 0.08940829336643219, 18.9% complete\n",
      "Epoch: 17 Train batch 40 loss: 0.08692338317632675, 25.2% complete\n",
      "Epoch: 17 Train batch 50 loss: 0.12201621383428574, 31.4% complete\n",
      "Epoch: 17 Train batch 60 loss: 0.10329046100378036, 37.7% complete\n",
      "Epoch: 17 Train batch 70 loss: 0.09627889841794968, 44.0% complete\n",
      "Epoch: 17 Train batch 80 loss: 0.12770411372184753, 50.3% complete\n",
      "Epoch: 17 Train batch 90 loss: 0.15324153006076813, 56.6% complete\n",
      "Epoch: 17 Train batch 100 loss: 0.1389562487602234, 62.9% complete\n",
      "Epoch: 17 Train batch 110 loss: 0.07734230160713196, 69.2% complete\n",
      "Epoch: 17 Train batch 120 loss: 0.14250998198986053, 75.5% complete\n",
      "Epoch: 17 Train batch 130 loss: 0.08532729744911194, 81.8% complete\n",
      "Epoch: 17 Train batch 140 loss: 0.06063473969697952, 88.1% complete\n",
      "Epoch: 17 Train batch 150 loss: 0.0814124345779419, 94.3% complete\n",
      "Batch 1. Data shape torch.Size([32, 3, 224, 224]) Loss 0.17788055539131165\n",
      "Batch 2. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09510983526706696\n",
      "Batch 3. Data shape torch.Size([32, 3, 224, 224]) Loss 0.12420359253883362\n",
      "Batch 4. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09870002418756485\n",
      "Batch 5. Data shape torch.Size([32, 3, 224, 224]) Loss 0.11927833408117294\n",
      "Batch 6. Data shape torch.Size([32, 3, 224, 224]) Loss 0.21544083952903748\n",
      "Batch 7. Data shape torch.Size([32, 3, 224, 224]) Loss 0.12446033954620361\n",
      "Batch 8. Data shape torch.Size([32, 3, 224, 224]) Loss 0.06471426784992218\n",
      "Batch 9. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07767745852470398\n",
      "Batch 10. Data shape torch.Size([32, 3, 224, 224]) Loss 0.06951838731765747\n",
      "Batch 11. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09906736016273499\n",
      "Batch 12. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07600553333759308\n",
      "Batch 13. Data shape torch.Size([32, 3, 224, 224]) Loss 0.05940372496843338\n",
      "Batch 14. Data shape torch.Size([32, 3, 224, 224]) Loss 0.18650561571121216\n",
      "Batch 15. Data shape torch.Size([32, 3, 224, 224]) Loss 0.13273748755455017\n",
      "Batch 16. Data shape torch.Size([32, 3, 224, 224]) Loss 0.11924449354410172\n",
      "Batch 17. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09566108137369156\n",
      "Batch 18. Data shape torch.Size([32, 3, 224, 224]) Loss 0.13865697383880615\n",
      "Batch 19. Data shape torch.Size([32, 3, 224, 224]) Loss 0.05643107369542122\n",
      "Batch 20. Data shape torch.Size([32, 3, 224, 224]) Loss 0.203843355178833\n",
      "Batch 21. Data shape torch.Size([32, 3, 224, 224]) Loss 0.11892282962799072\n",
      "Batch 22. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08758717030286789\n",
      "Batch 23. Data shape torch.Size([32, 3, 224, 224]) Loss 0.12998487055301666\n",
      "Batch 24. Data shape torch.Size([32, 3, 224, 224]) Loss 0.033427558839321136\n",
      "Batch 25. Data shape torch.Size([32, 3, 224, 224]) Loss 0.0936533659696579\n",
      "Batch 26. Data shape torch.Size([32, 3, 224, 224]) Loss 0.22508078813552856\n",
      "Batch 27. Data shape torch.Size([32, 3, 224, 224]) Loss 0.047221601009368896\n",
      "Batch 28. Data shape torch.Size([32, 3, 224, 224]) Loss 0.055213265120983124\n",
      "Batch 29. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1900741457939148\n",
      "Batch 30. Data shape torch.Size([32, 3, 224, 224]) Loss 0.042540617287158966\n",
      "Batch 31. Data shape torch.Size([32, 3, 224, 224]) Loss 0.12719042599201202\n",
      "Batch 32. Data shape torch.Size([32, 3, 224, 224]) Loss 0.14160357415676117\n",
      "Batch 33. Data shape torch.Size([32, 3, 224, 224]) Loss 0.11482982337474823\n",
      "Batch 34. Data shape torch.Size([32, 3, 224, 224]) Loss 0.11498413980007172\n",
      "Batch 35. Data shape torch.Size([32, 3, 224, 224]) Loss 0.06398498266935349\n",
      "Batch 36. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1645539253950119\n",
      "Batch 37. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08714306354522705\n",
      "Batch 38. Data shape torch.Size([32, 3, 224, 224]) Loss 0.11228874325752258\n",
      "Batch 39. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07733910530805588\n",
      "Batch 40. Data shape torch.Size([22, 3, 224, 224]) Loss 0.1156248077750206\n",
      "Valid loss improved from 0.112586 to 0.111945. Saving model ...\n",
      "Epoch: 17/50 | time: 7.0m 10.46s | lr: 1.0000e-05 | train/loss: 0.11352 | val/loss: 0.11194 | val/accuracy: 0.89764 | val/AUC: 0.96508 | val/Kappa: 0.81017\n",
      "Epoch: 18 Train batch 10 loss: 0.10682888329029083, 6.3% complete\n",
      "Epoch: 18 Train batch 20 loss: 0.10456253588199615, 12.6% complete\n",
      "Epoch: 18 Train batch 30 loss: 0.07660504430532455, 18.9% complete\n",
      "Epoch: 18 Train batch 40 loss: 0.08043141663074493, 25.2% complete\n",
      "Epoch: 18 Train batch 50 loss: 0.036741651594638824, 31.4% complete\n",
      "Epoch: 18 Train batch 60 loss: 0.13391615450382233, 37.7% complete\n",
      "Epoch: 18 Train batch 70 loss: 0.1244969442486763, 44.0% complete\n",
      "Epoch: 18 Train batch 80 loss: 0.0495123527944088, 50.3% complete\n",
      "Epoch: 18 Train batch 90 loss: 0.06634370237588882, 56.6% complete\n",
      "Epoch: 18 Train batch 100 loss: 0.19390949606895447, 62.9% complete\n",
      "Epoch: 18 Train batch 110 loss: 0.08933372795581818, 69.2% complete\n",
      "Epoch: 18 Train batch 120 loss: 0.03761027008295059, 75.5% complete\n",
      "Epoch: 18 Train batch 130 loss: 0.08719819784164429, 81.8% complete\n",
      "Epoch: 18 Train batch 140 loss: 0.047279149293899536, 88.1% complete\n",
      "Epoch: 18 Train batch 150 loss: 0.0996374785900116, 94.3% complete\n",
      "Batch 1. Data shape torch.Size([32, 3, 224, 224]) Loss 0.207281231880188\n",
      "Batch 2. Data shape torch.Size([32, 3, 224, 224]) Loss 0.03603656589984894\n",
      "Batch 3. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08490001410245895\n",
      "Batch 4. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09461016952991486\n",
      "Batch 5. Data shape torch.Size([32, 3, 224, 224]) Loss 0.10418584197759628\n",
      "Batch 6. Data shape torch.Size([32, 3, 224, 224]) Loss 0.0880136638879776\n",
      "Batch 7. Data shape torch.Size([32, 3, 224, 224]) Loss 0.10092531144618988\n",
      "Batch 8. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1450118124485016\n",
      "Batch 9. Data shape torch.Size([32, 3, 224, 224]) Loss 0.04591362178325653\n",
      "Batch 10. Data shape torch.Size([32, 3, 224, 224]) Loss 0.14139463007450104\n",
      "Batch 11. Data shape torch.Size([32, 3, 224, 224]) Loss 0.15824095904827118\n",
      "Batch 12. Data shape torch.Size([32, 3, 224, 224]) Loss 0.17944489419460297\n",
      "Batch 13. Data shape torch.Size([32, 3, 224, 224]) Loss 0.06882680952548981\n",
      "Batch 14. Data shape torch.Size([32, 3, 224, 224]) Loss 0.16638028621673584\n",
      "Batch 15. Data shape torch.Size([32, 3, 224, 224]) Loss 0.23732304573059082\n",
      "Batch 16. Data shape torch.Size([32, 3, 224, 224]) Loss 0.14163395762443542\n",
      "Batch 17. Data shape torch.Size([32, 3, 224, 224]) Loss 0.10481467843055725\n",
      "Batch 18. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09892985969781876\n",
      "Batch 19. Data shape torch.Size([32, 3, 224, 224]) Loss 0.05491367727518082\n",
      "Batch 20. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1269809603691101\n",
      "Batch 21. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09175949543714523\n",
      "Batch 22. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08627019077539444\n",
      "Batch 23. Data shape torch.Size([32, 3, 224, 224]) Loss 0.15212774276733398\n",
      "Batch 24. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08243931084871292\n",
      "Batch 25. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09249817579984665\n",
      "Batch 26. Data shape torch.Size([32, 3, 224, 224]) Loss 0.06956949830055237\n",
      "Batch 27. Data shape torch.Size([32, 3, 224, 224]) Loss 0.10937005281448364\n",
      "Batch 28. Data shape torch.Size([32, 3, 224, 224]) Loss 0.11834139376878738\n",
      "Batch 29. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07466347515583038\n",
      "Batch 30. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07044979929924011\n",
      "Batch 31. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08618102222681046\n",
      "Batch 32. Data shape torch.Size([32, 3, 224, 224]) Loss 0.10448378324508667\n",
      "Batch 33. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08126132190227509\n",
      "Batch 34. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08443352580070496\n",
      "Batch 35. Data shape torch.Size([32, 3, 224, 224]) Loss 0.0859132930636406\n",
      "Batch 36. Data shape torch.Size([32, 3, 224, 224]) Loss 0.10863622277975082\n",
      "Batch 37. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1612076461315155\n",
      "Batch 38. Data shape torch.Size([32, 3, 224, 224]) Loss 0.10524392873048782\n",
      "Batch 39. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1046704351902008\n",
      "Batch 40. Data shape torch.Size([22, 3, 224, 224]) Loss 0.11297332495450974\n",
      "Valid loss improved from 0.111945 to 0.109206. Saving model ...\n",
      "Epoch: 18/50 | time: 7.0m 10.36s | lr: 1.0000e-05 | train/loss: 0.10486 | val/loss: 0.10921 | val/accuracy: 0.89685 | val/AUC: 0.96850 | val/Kappa: 0.80938\n",
      "Epoch: 19 Train batch 10 loss: 0.1621418297290802, 6.3% complete\n",
      "Epoch: 19 Train batch 20 loss: 0.11775436252355576, 12.6% complete\n",
      "Epoch: 19 Train batch 30 loss: 0.05796097591519356, 18.9% complete\n",
      "Epoch: 19 Train batch 40 loss: 0.07880859822034836, 25.2% complete\n",
      "Epoch: 19 Train batch 50 loss: 0.05628383904695511, 31.4% complete\n",
      "Epoch: 19 Train batch 60 loss: 0.17676609754562378, 37.7% complete\n",
      "Epoch: 19 Train batch 70 loss: 0.13766580820083618, 44.0% complete\n",
      "Epoch: 19 Train batch 80 loss: 0.046992480754852295, 50.3% complete\n",
      "Epoch: 19 Train batch 90 loss: 0.17916955053806305, 56.6% complete\n",
      "Epoch: 19 Train batch 100 loss: 0.12102800607681274, 62.9% complete\n",
      "Epoch: 19 Train batch 110 loss: 0.06874127686023712, 69.2% complete\n",
      "Epoch: 19 Train batch 120 loss: 0.07449262589216232, 75.5% complete\n",
      "Epoch: 19 Train batch 130 loss: 0.11259859800338745, 81.8% complete\n",
      "Epoch: 19 Train batch 140 loss: 0.09912532567977905, 88.1% complete\n",
      "Epoch: 19 Train batch 150 loss: 0.0892941951751709, 94.3% complete\n",
      "Batch 1. Data shape torch.Size([32, 3, 224, 224]) Loss 0.11608809232711792\n",
      "Batch 2. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08039535582065582\n",
      "Batch 3. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1366191804409027\n",
      "Batch 4. Data shape torch.Size([32, 3, 224, 224]) Loss 0.06883113086223602\n",
      "Batch 5. Data shape torch.Size([32, 3, 224, 224]) Loss 0.14659187197685242\n",
      "Batch 6. Data shape torch.Size([32, 3, 224, 224]) Loss 0.11457457393407822\n",
      "Batch 7. Data shape torch.Size([32, 3, 224, 224]) Loss 0.12975119054317474\n",
      "Batch 8. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08712806552648544\n",
      "Batch 9. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08401620388031006\n",
      "Batch 10. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09233132004737854\n",
      "Batch 11. Data shape torch.Size([32, 3, 224, 224]) Loss 0.0796438530087471\n",
      "Batch 12. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08231188356876373\n",
      "Batch 13. Data shape torch.Size([32, 3, 224, 224]) Loss 0.16721974313259125\n",
      "Batch 14. Data shape torch.Size([32, 3, 224, 224]) Loss 0.10190548747777939\n",
      "Batch 15. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07978707551956177\n",
      "Batch 16. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08891024440526962\n",
      "Batch 17. Data shape torch.Size([32, 3, 224, 224]) Loss 0.10848172754049301\n",
      "Batch 18. Data shape torch.Size([32, 3, 224, 224]) Loss 0.12020930647850037\n",
      "Batch 19. Data shape torch.Size([32, 3, 224, 224]) Loss 0.0979214683175087\n",
      "Batch 20. Data shape torch.Size([32, 3, 224, 224]) Loss 0.179477721452713\n",
      "Batch 21. Data shape torch.Size([32, 3, 224, 224]) Loss 0.13443909585475922\n",
      "Batch 22. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07569868862628937\n",
      "Batch 23. Data shape torch.Size([32, 3, 224, 224]) Loss 0.11438556015491486\n",
      "Batch 24. Data shape torch.Size([32, 3, 224, 224]) Loss 0.15435993671417236\n",
      "Batch 25. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09924937784671783\n",
      "Batch 26. Data shape torch.Size([32, 3, 224, 224]) Loss 0.029490230605006218\n",
      "Batch 27. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07103261351585388\n",
      "Batch 28. Data shape torch.Size([32, 3, 224, 224]) Loss 0.12458796799182892\n",
      "Batch 29. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08690448850393295\n",
      "Batch 30. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09701918065547943\n",
      "Batch 31. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1226998046040535\n",
      "Batch 32. Data shape torch.Size([32, 3, 224, 224]) Loss 0.15729066729545593\n",
      "Batch 33. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07002179324626923\n",
      "Batch 34. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08801758289337158\n",
      "Batch 35. Data shape torch.Size([32, 3, 224, 224]) Loss 0.15623629093170166\n",
      "Batch 36. Data shape torch.Size([32, 3, 224, 224]) Loss 0.11448749154806137\n",
      "Batch 37. Data shape torch.Size([32, 3, 224, 224]) Loss 0.11763914674520493\n",
      "Batch 38. Data shape torch.Size([32, 3, 224, 224]) Loss 0.12151889503002167\n",
      "Batch 39. Data shape torch.Size([32, 3, 224, 224]) Loss 0.038003433495759964\n",
      "Batch 40. Data shape torch.Size([22, 3, 224, 224]) Loss 0.14728371798992157\n",
      "Valid loss improved from 0.109206 to 0.107064. Saving model ...\n",
      "Epoch: 19/50 | time: 7.0m 5.899s | lr: 1.0000e-05 | train/loss: 0.10292 | val/loss: 0.10706 | val/accuracy: 0.90787 | val/AUC: 0.96851 | val/Kappa: 0.83143\n",
      "Epoch: 20 Train batch 10 loss: 0.049666233360767365, 6.3% complete\n",
      "Epoch: 20 Train batch 20 loss: 0.05862627178430557, 12.6% complete\n",
      "Epoch: 20 Train batch 30 loss: 0.10819368064403534, 18.9% complete\n",
      "Epoch: 20 Train batch 40 loss: 0.09719810634851456, 25.2% complete\n",
      "Epoch: 20 Train batch 50 loss: 0.1662362962961197, 31.4% complete\n",
      "Epoch: 20 Train batch 60 loss: 0.12313913553953171, 37.7% complete\n",
      "Epoch: 20 Train batch 70 loss: 0.14045102894306183, 44.0% complete\n",
      "Epoch: 20 Train batch 80 loss: 0.16986216604709625, 50.3% complete\n",
      "Epoch: 20 Train batch 90 loss: 0.0897739827632904, 56.6% complete\n",
      "Epoch: 20 Train batch 100 loss: 0.0848076120018959, 62.9% complete\n",
      "Epoch: 20 Train batch 110 loss: 0.14033760130405426, 69.2% complete\n",
      "Epoch: 20 Train batch 120 loss: 0.12896868586540222, 75.5% complete\n",
      "Epoch: 20 Train batch 130 loss: 0.069554902613163, 81.8% complete\n",
      "Epoch: 20 Train batch 140 loss: 0.05772361159324646, 88.1% complete\n",
      "Epoch: 20 Train batch 150 loss: 0.09760083258152008, 94.3% complete\n",
      "Batch 1. Data shape torch.Size([32, 3, 224, 224]) Loss 0.12771616876125336\n",
      "Batch 2. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07863908261060715\n",
      "Batch 3. Data shape torch.Size([32, 3, 224, 224]) Loss 0.25899550318717957\n",
      "Batch 4. Data shape torch.Size([32, 3, 224, 224]) Loss 0.027486000210046768\n",
      "Batch 5. Data shape torch.Size([32, 3, 224, 224]) Loss 0.10919436067342758\n",
      "Batch 6. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09311741590499878\n",
      "Batch 7. Data shape torch.Size([32, 3, 224, 224]) Loss 0.12360086292028427\n",
      "Batch 8. Data shape torch.Size([32, 3, 224, 224]) Loss 0.12861496210098267\n",
      "Batch 9. Data shape torch.Size([32, 3, 224, 224]) Loss 0.0437837578356266\n",
      "Batch 10. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1349572092294693\n",
      "Batch 11. Data shape torch.Size([32, 3, 224, 224]) Loss 0.14985015988349915\n",
      "Batch 12. Data shape torch.Size([32, 3, 224, 224]) Loss 0.03717438131570816\n",
      "Batch 13. Data shape torch.Size([32, 3, 224, 224]) Loss 0.10278977453708649\n",
      "Batch 14. Data shape torch.Size([32, 3, 224, 224]) Loss 0.0646514743566513\n",
      "Batch 15. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09328410029411316\n",
      "Batch 16. Data shape torch.Size([32, 3, 224, 224]) Loss 0.18680348992347717\n",
      "Batch 17. Data shape torch.Size([32, 3, 224, 224]) Loss 0.0796598494052887\n",
      "Batch 18. Data shape torch.Size([32, 3, 224, 224]) Loss 0.12221351265907288\n",
      "Batch 19. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07643626630306244\n",
      "Batch 20. Data shape torch.Size([32, 3, 224, 224]) Loss 0.06369610130786896\n",
      "Batch 21. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08546780049800873\n",
      "Batch 22. Data shape torch.Size([32, 3, 224, 224]) Loss 0.15344911813735962\n",
      "Batch 23. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07811663299798965\n",
      "Batch 24. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07918599247932434\n",
      "Batch 25. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08173684775829315\n",
      "Batch 26. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09361427277326584\n",
      "Batch 27. Data shape torch.Size([32, 3, 224, 224]) Loss 0.13253244757652283\n",
      "Batch 28. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1026974469423294\n",
      "Batch 29. Data shape torch.Size([32, 3, 224, 224]) Loss 0.10371369123458862\n",
      "Batch 30. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09996505081653595\n",
      "Batch 31. Data shape torch.Size([32, 3, 224, 224]) Loss 0.04084556922316551\n",
      "Batch 32. Data shape torch.Size([32, 3, 224, 224]) Loss 0.15850012004375458\n",
      "Batch 33. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1427285075187683\n",
      "Batch 34. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09443017840385437\n",
      "Batch 35. Data shape torch.Size([32, 3, 224, 224]) Loss 0.15937495231628418\n",
      "Batch 36. Data shape torch.Size([32, 3, 224, 224]) Loss 0.050442978739738464\n",
      "Batch 37. Data shape torch.Size([32, 3, 224, 224]) Loss 0.19032372534275055\n",
      "Batch 38. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08613577485084534\n",
      "Batch 39. Data shape torch.Size([32, 3, 224, 224]) Loss 0.04608245939016342\n",
      "Batch 40. Data shape torch.Size([22, 3, 224, 224]) Loss 0.0406649112701416\n",
      "Valid loss improved from 0.107064 to 0.103067. Saving model ...\n",
      "Epoch: 20/50 | time: 7.0m 6.483s | lr: 1.0000e-05 | train/loss: 0.09939 | val/loss: 0.10307 | val/accuracy: 0.89764 | val/AUC: 0.97071 | val/Kappa: 0.81225\n",
      "Epoch: 21 Train batch 10 loss: 0.17041799426078796, 6.3% complete\n",
      "Epoch: 21 Train batch 20 loss: 0.10332002490758896, 12.6% complete\n",
      "Epoch: 21 Train batch 30 loss: 0.0935516208410263, 18.9% complete\n",
      "Epoch: 21 Train batch 40 loss: 0.19294019043445587, 25.2% complete\n",
      "Epoch: 21 Train batch 50 loss: 0.09683030098676682, 31.4% complete\n",
      "Epoch: 21 Train batch 60 loss: 0.10395938903093338, 37.7% complete\n",
      "Epoch: 21 Train batch 70 loss: 0.12326820939779282, 44.0% complete\n",
      "Epoch: 21 Train batch 80 loss: 0.0807352066040039, 50.3% complete\n",
      "Epoch: 21 Train batch 90 loss: 0.1080343946814537, 56.6% complete\n",
      "Epoch: 21 Train batch 100 loss: 0.09857984632253647, 62.9% complete\n",
      "Epoch: 21 Train batch 110 loss: 0.05876683071255684, 69.2% complete\n",
      "Epoch: 21 Train batch 120 loss: 0.125177800655365, 75.5% complete\n",
      "Epoch: 21 Train batch 130 loss: 0.12589867413043976, 81.8% complete\n",
      "Epoch: 21 Train batch 140 loss: 0.07726597785949707, 88.1% complete\n",
      "Epoch: 21 Train batch 150 loss: 0.1260228008031845, 94.3% complete\n",
      "Batch 1. Data shape torch.Size([32, 3, 224, 224]) Loss 0.10440884530544281\n",
      "Batch 2. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1140255257487297\n",
      "Batch 3. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07449260354042053\n",
      "Batch 4. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08233556151390076\n",
      "Batch 5. Data shape torch.Size([32, 3, 224, 224]) Loss 0.127595916390419\n",
      "Batch 6. Data shape torch.Size([32, 3, 224, 224]) Loss 0.05960950627923012\n",
      "Batch 7. Data shape torch.Size([32, 3, 224, 224]) Loss 0.05811707675457001\n",
      "Batch 8. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07055823504924774\n",
      "Batch 9. Data shape torch.Size([32, 3, 224, 224]) Loss 0.13369542360305786\n",
      "Batch 10. Data shape torch.Size([32, 3, 224, 224]) Loss 0.12285300344228745\n",
      "Batch 11. Data shape torch.Size([32, 3, 224, 224]) Loss 0.06721846759319305\n",
      "Batch 12. Data shape torch.Size([32, 3, 224, 224]) Loss 0.06933248788118362\n",
      "Batch 13. Data shape torch.Size([32, 3, 224, 224]) Loss 0.0532916858792305\n",
      "Batch 14. Data shape torch.Size([32, 3, 224, 224]) Loss 0.13539764285087585\n",
      "Batch 15. Data shape torch.Size([32, 3, 224, 224]) Loss 0.12237174808979034\n",
      "Batch 16. Data shape torch.Size([32, 3, 224, 224]) Loss 0.12953411042690277\n",
      "Batch 17. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09049966186285019\n",
      "Batch 18. Data shape torch.Size([32, 3, 224, 224]) Loss 0.24187885224819183\n",
      "Batch 19. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09572114050388336\n",
      "Batch 20. Data shape torch.Size([32, 3, 224, 224]) Loss 0.046799033880233765\n",
      "Batch 21. Data shape torch.Size([32, 3, 224, 224]) Loss 0.12476050108671188\n",
      "Batch 22. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07468515634536743\n",
      "Batch 23. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1258174180984497\n",
      "Batch 24. Data shape torch.Size([32, 3, 224, 224]) Loss 0.04379231855273247\n",
      "Batch 25. Data shape torch.Size([32, 3, 224, 224]) Loss 0.0923420712351799\n",
      "Batch 26. Data shape torch.Size([32, 3, 224, 224]) Loss 0.11376810073852539\n",
      "Batch 27. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1633267104625702\n",
      "Batch 28. Data shape torch.Size([32, 3, 224, 224]) Loss 0.10846732556819916\n",
      "Batch 29. Data shape torch.Size([32, 3, 224, 224]) Loss 0.21039190888404846\n",
      "Batch 30. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09016110002994537\n",
      "Batch 31. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09485691040754318\n",
      "Batch 32. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09602957963943481\n",
      "Batch 33. Data shape torch.Size([32, 3, 224, 224]) Loss 0.047612305730581284\n",
      "Batch 34. Data shape torch.Size([32, 3, 224, 224]) Loss 0.04139332473278046\n",
      "Batch 35. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09492441266775131\n",
      "Batch 36. Data shape torch.Size([32, 3, 224, 224]) Loss 0.06901533901691437\n",
      "Batch 37. Data shape torch.Size([32, 3, 224, 224]) Loss 0.16280467808246613\n",
      "Batch 38. Data shape torch.Size([32, 3, 224, 224]) Loss 0.06943954527378082\n",
      "Batch 39. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09370767325162888\n",
      "Batch 40. Data shape torch.Size([22, 3, 224, 224]) Loss 0.17718195915222168\n",
      "Valid loss improved from 0.103067 to 0.102355. Saving model ...\n",
      "Epoch: 21/50 | time: 7.0m 18.53s | lr: 1.0000e-05 | train/loss: 0.09383 | val/loss: 0.10236 | val/accuracy: 0.89921 | val/AUC: 0.97216 | val/Kappa: 0.81401\n",
      "Epoch: 22 Train batch 10 loss: 0.1109205111861229, 6.3% complete\n",
      "Epoch: 22 Train batch 20 loss: 0.10482272505760193, 12.6% complete\n",
      "Epoch: 22 Train batch 30 loss: 0.09862859547138214, 18.9% complete\n",
      "Epoch: 22 Train batch 40 loss: 0.06809509545564651, 25.2% complete\n",
      "Epoch: 22 Train batch 50 loss: 0.048658616840839386, 31.4% complete\n",
      "Epoch: 22 Train batch 60 loss: 0.15482249855995178, 37.7% complete\n",
      "Epoch: 22 Train batch 70 loss: 0.1612698882818222, 44.0% complete\n",
      "Epoch: 22 Train batch 80 loss: 0.05388699471950531, 50.3% complete\n",
      "Epoch: 22 Train batch 90 loss: 0.08520978689193726, 56.6% complete\n",
      "Epoch: 22 Train batch 100 loss: 0.08628027141094208, 62.9% complete\n",
      "Epoch: 22 Train batch 110 loss: 0.10610686242580414, 69.2% complete\n",
      "Epoch: 22 Train batch 120 loss: 0.09416864812374115, 75.5% complete\n",
      "Epoch: 22 Train batch 130 loss: 0.15699703991413116, 81.8% complete\n",
      "Epoch: 22 Train batch 140 loss: 0.07440503686666489, 88.1% complete\n",
      "Epoch: 22 Train batch 150 loss: 0.08987445384263992, 94.3% complete\n",
      "Batch 1. Data shape torch.Size([32, 3, 224, 224]) Loss 0.0295405350625515\n",
      "Batch 2. Data shape torch.Size([32, 3, 224, 224]) Loss 0.030685987323522568\n",
      "Batch 3. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08044940233230591\n",
      "Batch 4. Data shape torch.Size([32, 3, 224, 224]) Loss 0.16524328291416168\n",
      "Batch 5. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07077260315418243\n",
      "Batch 6. Data shape torch.Size([32, 3, 224, 224]) Loss 0.15590237081050873\n",
      "Batch 7. Data shape torch.Size([32, 3, 224, 224]) Loss 0.11502483487129211\n",
      "Batch 8. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09501710534095764\n",
      "Batch 9. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1001465916633606\n",
      "Batch 10. Data shape torch.Size([32, 3, 224, 224]) Loss 0.13939765095710754\n",
      "Batch 11. Data shape torch.Size([32, 3, 224, 224]) Loss 0.11856183409690857\n",
      "Batch 12. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1456305831670761\n",
      "Batch 13. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09608461707830429\n",
      "Batch 14. Data shape torch.Size([32, 3, 224, 224]) Loss 0.05726476386189461\n",
      "Batch 15. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1208995133638382\n",
      "Batch 16. Data shape torch.Size([32, 3, 224, 224]) Loss 0.10614117980003357\n",
      "Batch 17. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09709087014198303\n",
      "Batch 18. Data shape torch.Size([32, 3, 224, 224]) Loss 0.0660674199461937\n",
      "Batch 19. Data shape torch.Size([32, 3, 224, 224]) Loss 0.15535224974155426\n",
      "Batch 20. Data shape torch.Size([32, 3, 224, 224]) Loss 0.13543134927749634\n",
      "Batch 21. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1986636221408844\n",
      "Batch 22. Data shape torch.Size([32, 3, 224, 224]) Loss 0.10187582671642303\n",
      "Batch 23. Data shape torch.Size([32, 3, 224, 224]) Loss 0.06315997242927551\n",
      "Batch 24. Data shape torch.Size([32, 3, 224, 224]) Loss 0.048092927783727646\n",
      "Batch 25. Data shape torch.Size([32, 3, 224, 224]) Loss 0.11155159026384354\n",
      "Batch 26. Data shape torch.Size([32, 3, 224, 224]) Loss 0.0647459328174591\n",
      "Batch 27. Data shape torch.Size([32, 3, 224, 224]) Loss 0.10348852723836899\n",
      "Batch 28. Data shape torch.Size([32, 3, 224, 224]) Loss 0.13026611506938934\n",
      "Batch 29. Data shape torch.Size([32, 3, 224, 224]) Loss 0.12025416642427444\n",
      "Batch 30. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08100081980228424\n",
      "Batch 31. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09121981263160706\n",
      "Batch 32. Data shape torch.Size([32, 3, 224, 224]) Loss 0.16538269817829132\n",
      "Batch 33. Data shape torch.Size([32, 3, 224, 224]) Loss 0.03946109861135483\n",
      "Batch 34. Data shape torch.Size([32, 3, 224, 224]) Loss 0.10095873475074768\n",
      "Batch 35. Data shape torch.Size([32, 3, 224, 224]) Loss 0.026994019746780396\n",
      "Batch 36. Data shape torch.Size([32, 3, 224, 224]) Loss 0.0723869800567627\n",
      "Batch 37. Data shape torch.Size([32, 3, 224, 224]) Loss 0.0491819903254509\n",
      "Batch 38. Data shape torch.Size([32, 3, 224, 224]) Loss 0.051138803362846375\n",
      "Batch 39. Data shape torch.Size([32, 3, 224, 224]) Loss 0.05010274797677994\n",
      "Batch 40. Data shape torch.Size([22, 3, 224, 224]) Loss 0.19827468693256378\n",
      "Valid loss improved from 0.102355 to 0.098723. Saving model ...\n",
      "Epoch: 22/50 | time: 7.0m 15.67s | lr: 1.0000e-05 | train/loss: 0.09132 | val/loss: 0.09872 | val/accuracy: 0.90551 | val/AUC: 0.97278 | val/Kappa: 0.82681\n",
      "Epoch: 23 Train batch 10 loss: 0.07837241888046265, 6.3% complete\n",
      "Epoch: 23 Train batch 20 loss: 0.06670365482568741, 12.6% complete\n",
      "Epoch: 23 Train batch 30 loss: 0.1036926731467247, 18.9% complete\n",
      "Epoch: 23 Train batch 40 loss: 0.1114177331328392, 25.2% complete\n",
      "Epoch: 23 Train batch 50 loss: 0.07106128334999084, 31.4% complete\n",
      "Epoch: 23 Train batch 60 loss: 0.11254478245973587, 37.7% complete\n",
      "Epoch: 23 Train batch 70 loss: 0.107904352247715, 44.0% complete\n",
      "Epoch: 23 Train batch 80 loss: 0.054944369941949844, 50.3% complete\n",
      "Epoch: 23 Train batch 90 loss: 0.10263022780418396, 56.6% complete\n",
      "Epoch: 23 Train batch 100 loss: 0.121258944272995, 62.9% complete\n",
      "Epoch: 23 Train batch 110 loss: 0.1559446156024933, 69.2% complete\n",
      "Epoch: 23 Train batch 120 loss: 0.04986654967069626, 75.5% complete\n",
      "Epoch: 23 Train batch 130 loss: 0.1107102483510971, 81.8% complete\n",
      "Epoch: 23 Train batch 140 loss: 0.09811890870332718, 88.1% complete\n",
      "Epoch: 23 Train batch 150 loss: 0.0704583004117012, 94.3% complete\n",
      "Batch 1. Data shape torch.Size([32, 3, 224, 224]) Loss 0.10337477922439575\n",
      "Batch 2. Data shape torch.Size([32, 3, 224, 224]) Loss 0.11314916610717773\n",
      "Batch 3. Data shape torch.Size([32, 3, 224, 224]) Loss 0.10183276236057281\n",
      "Batch 4. Data shape torch.Size([32, 3, 224, 224]) Loss 0.02467821165919304\n",
      "Batch 5. Data shape torch.Size([32, 3, 224, 224]) Loss 0.10318703204393387\n",
      "Batch 6. Data shape torch.Size([32, 3, 224, 224]) Loss 0.17935535311698914\n",
      "Batch 7. Data shape torch.Size([32, 3, 224, 224]) Loss 0.13347128033638\n",
      "Batch 8. Data shape torch.Size([32, 3, 224, 224]) Loss 0.10505319386720657\n",
      "Batch 9. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08889062702655792\n",
      "Batch 10. Data shape torch.Size([32, 3, 224, 224]) Loss 0.10696651041507721\n",
      "Batch 11. Data shape torch.Size([32, 3, 224, 224]) Loss 0.05955100804567337\n",
      "Batch 12. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09101881086826324\n",
      "Batch 13. Data shape torch.Size([32, 3, 224, 224]) Loss 0.14712874591350555\n",
      "Batch 14. Data shape torch.Size([32, 3, 224, 224]) Loss 0.04645442217588425\n",
      "Batch 15. Data shape torch.Size([32, 3, 224, 224]) Loss 0.10202842205762863\n",
      "Batch 16. Data shape torch.Size([32, 3, 224, 224]) Loss 0.05842318385839462\n",
      "Batch 17. Data shape torch.Size([32, 3, 224, 224]) Loss 0.0921393632888794\n",
      "Batch 18. Data shape torch.Size([32, 3, 224, 224]) Loss 0.03464382886886597\n",
      "Batch 19. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08036050200462341\n",
      "Batch 20. Data shape torch.Size([32, 3, 224, 224]) Loss 0.15298756957054138\n",
      "Batch 21. Data shape torch.Size([32, 3, 224, 224]) Loss 0.11113734543323517\n",
      "Batch 22. Data shape torch.Size([32, 3, 224, 224]) Loss 0.06999307870864868\n",
      "Batch 23. Data shape torch.Size([32, 3, 224, 224]) Loss 0.028594059869647026\n",
      "Batch 24. Data shape torch.Size([32, 3, 224, 224]) Loss 0.22779765725135803\n",
      "Batch 25. Data shape torch.Size([32, 3, 224, 224]) Loss 0.029238954186439514\n",
      "Batch 26. Data shape torch.Size([32, 3, 224, 224]) Loss 0.10587256401777267\n",
      "Batch 27. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1562877595424652\n",
      "Batch 28. Data shape torch.Size([32, 3, 224, 224]) Loss 0.12235867232084274\n",
      "Batch 29. Data shape torch.Size([32, 3, 224, 224]) Loss 0.10469107329845428\n",
      "Batch 30. Data shape torch.Size([32, 3, 224, 224]) Loss 0.06524855643510818\n",
      "Batch 31. Data shape torch.Size([32, 3, 224, 224]) Loss 0.0918087437748909\n",
      "Batch 32. Data shape torch.Size([32, 3, 224, 224]) Loss 0.02797052450478077\n",
      "Batch 33. Data shape torch.Size([32, 3, 224, 224]) Loss 0.04711594060063362\n",
      "Batch 34. Data shape torch.Size([32, 3, 224, 224]) Loss 0.10884612798690796\n",
      "Batch 35. Data shape torch.Size([32, 3, 224, 224]) Loss 0.05401567742228508\n",
      "Batch 36. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07897056639194489\n",
      "Batch 37. Data shape torch.Size([32, 3, 224, 224]) Loss 0.11935712397098541\n",
      "Batch 38. Data shape torch.Size([32, 3, 224, 224]) Loss 0.11322108656167984\n",
      "Batch 39. Data shape torch.Size([32, 3, 224, 224]) Loss 0.13954821228981018\n",
      "Batch 40. Data shape torch.Size([22, 3, 224, 224]) Loss 0.16399802267551422\n",
      "Valid loss improved from 0.098723 to 0.097269. Saving model ...\n",
      "Epoch: 23/50 | time: 7.0m 38.27s | lr: 1.0000e-05 | train/loss: 0.09215 | val/loss: 0.09727 | val/accuracy: 0.90551 | val/AUC: 0.97463 | val/Kappa: 0.82531\n",
      "Epoch: 24 Train batch 10 loss: 0.15571188926696777, 6.3% complete\n",
      "Epoch: 24 Train batch 20 loss: 0.10059897601604462, 12.6% complete\n",
      "Epoch: 24 Train batch 30 loss: 0.11351244151592255, 18.9% complete\n",
      "Epoch: 24 Train batch 40 loss: 0.13515721261501312, 25.2% complete\n",
      "Epoch: 24 Train batch 50 loss: 0.12771204113960266, 31.4% complete\n",
      "Epoch: 24 Train batch 60 loss: 0.06783518940210342, 37.7% complete\n",
      "Epoch: 24 Train batch 70 loss: 0.08379032462835312, 44.0% complete\n",
      "Epoch: 24 Train batch 80 loss: 0.06289582699537277, 50.3% complete\n",
      "Epoch: 24 Train batch 90 loss: 0.13534027338027954, 56.6% complete\n",
      "Epoch: 24 Train batch 100 loss: 0.08161225914955139, 62.9% complete\n",
      "Epoch: 24 Train batch 110 loss: 0.04430864751338959, 69.2% complete\n",
      "Epoch: 24 Train batch 120 loss: 0.03742431476712227, 75.5% complete\n",
      "Epoch: 24 Train batch 130 loss: 0.047188568860292435, 81.8% complete\n",
      "Epoch: 24 Train batch 140 loss: 0.17217837274074554, 88.1% complete\n",
      "Epoch: 24 Train batch 150 loss: 0.0796864777803421, 94.3% complete\n",
      "Batch 1. Data shape torch.Size([32, 3, 224, 224]) Loss 0.21928687393665314\n",
      "Batch 2. Data shape torch.Size([32, 3, 224, 224]) Loss 0.11739891022443771\n",
      "Batch 3. Data shape torch.Size([32, 3, 224, 224]) Loss 0.049558766186237335\n",
      "Batch 4. Data shape torch.Size([32, 3, 224, 224]) Loss 0.04179055988788605\n",
      "Batch 5. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1883632093667984\n",
      "Batch 6. Data shape torch.Size([32, 3, 224, 224]) Loss 0.06268533319234848\n",
      "Batch 7. Data shape torch.Size([32, 3, 224, 224]) Loss 0.0903010442852974\n",
      "Batch 8. Data shape torch.Size([32, 3, 224, 224]) Loss 0.10523228347301483\n",
      "Batch 9. Data shape torch.Size([32, 3, 224, 224]) Loss 0.06625483185052872\n",
      "Batch 10. Data shape torch.Size([32, 3, 224, 224]) Loss 0.057486698031425476\n",
      "Batch 11. Data shape torch.Size([32, 3, 224, 224]) Loss 0.10524687170982361\n",
      "Batch 12. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07775890082120895\n",
      "Batch 13. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1409582793712616\n",
      "Batch 14. Data shape torch.Size([32, 3, 224, 224]) Loss 0.15055018663406372\n",
      "Batch 15. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1404990404844284\n",
      "Batch 16. Data shape torch.Size([32, 3, 224, 224]) Loss 0.04891987517476082\n",
      "Batch 17. Data shape torch.Size([32, 3, 224, 224]) Loss 0.0493706613779068\n",
      "Batch 18. Data shape torch.Size([32, 3, 224, 224]) Loss 0.06354118883609772\n",
      "Batch 19. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1099151074886322\n",
      "Batch 20. Data shape torch.Size([32, 3, 224, 224]) Loss 0.030871666967868805\n",
      "Batch 21. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07834689319133759\n",
      "Batch 22. Data shape torch.Size([32, 3, 224, 224]) Loss 0.058520518243312836\n",
      "Batch 23. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07972237467765808\n",
      "Batch 24. Data shape torch.Size([32, 3, 224, 224]) Loss 0.15825042128562927\n",
      "Batch 25. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1590944230556488\n",
      "Batch 26. Data shape torch.Size([32, 3, 224, 224]) Loss 0.06483994424343109\n",
      "Batch 27. Data shape torch.Size([32, 3, 224, 224]) Loss 0.12259364128112793\n",
      "Batch 28. Data shape torch.Size([32, 3, 224, 224]) Loss 0.15053433179855347\n",
      "Batch 29. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09406710416078568\n",
      "Batch 30. Data shape torch.Size([32, 3, 224, 224]) Loss 0.16428843140602112\n",
      "Batch 31. Data shape torch.Size([32, 3, 224, 224]) Loss 0.10755409300327301\n",
      "Batch 32. Data shape torch.Size([32, 3, 224, 224]) Loss 0.06271188706159592\n",
      "Batch 33. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07213680446147919\n",
      "Batch 34. Data shape torch.Size([32, 3, 224, 224]) Loss 0.10594546049833298\n",
      "Batch 35. Data shape torch.Size([32, 3, 224, 224]) Loss 0.10313805937767029\n",
      "Batch 36. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08879274874925613\n",
      "Batch 37. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08057814091444016\n",
      "Batch 38. Data shape torch.Size([32, 3, 224, 224]) Loss 0.091506227850914\n",
      "Batch 39. Data shape torch.Size([32, 3, 224, 224]) Loss 0.12793365120887756\n",
      "Batch 40. Data shape torch.Size([22, 3, 224, 224]) Loss 0.06354249268770218\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Epoch: 24/50 | time: 8.0m 7.327s | lr: 1.0000e-05 | train/loss: 0.08641 | val/loss: 0.09875 | val/accuracy: 0.90551 | val/AUC: 0.97204 | val/Kappa: 0.82588\n",
      "Epoch: 25 Train batch 10 loss: 0.11656548827886581, 6.3% complete\n",
      "Epoch: 25 Train batch 20 loss: 0.04377447068691254, 12.6% complete\n",
      "Epoch: 25 Train batch 30 loss: 0.109845370054245, 18.9% complete\n",
      "Epoch: 25 Train batch 40 loss: 0.06579410284757614, 25.2% complete\n",
      "Epoch: 25 Train batch 50 loss: 0.06612735241651535, 31.4% complete\n",
      "Epoch: 25 Train batch 60 loss: 0.09521754831075668, 37.7% complete\n",
      "Epoch: 25 Train batch 70 loss: 0.070223867893219, 44.0% complete\n",
      "Epoch: 25 Train batch 80 loss: 0.0964680090546608, 50.3% complete\n",
      "Epoch: 25 Train batch 90 loss: 0.07407769560813904, 56.6% complete\n",
      "Epoch: 25 Train batch 100 loss: 0.13458454608917236, 62.9% complete\n",
      "Epoch: 25 Train batch 110 loss: 0.037077393382787704, 69.2% complete\n",
      "Epoch: 25 Train batch 120 loss: 0.041234083473682404, 75.5% complete\n",
      "Epoch: 25 Train batch 130 loss: 0.03880563750863075, 81.8% complete\n",
      "Epoch: 25 Train batch 140 loss: 0.07898137718439102, 88.1% complete\n",
      "Epoch: 25 Train batch 150 loss: 0.1094597801566124, 94.3% complete\n",
      "Batch 1. Data shape torch.Size([32, 3, 224, 224]) Loss 0.0652085468173027\n",
      "Batch 2. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08532722294330597\n",
      "Batch 3. Data shape torch.Size([32, 3, 224, 224]) Loss 0.10635338723659515\n",
      "Batch 4. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09197738766670227\n",
      "Batch 5. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09619832038879395\n",
      "Batch 6. Data shape torch.Size([32, 3, 224, 224]) Loss 0.056306641548871994\n",
      "Batch 7. Data shape torch.Size([32, 3, 224, 224]) Loss 0.10669978708028793\n",
      "Batch 8. Data shape torch.Size([32, 3, 224, 224]) Loss 0.03607998788356781\n",
      "Batch 9. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08996746689081192\n",
      "Batch 10. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07254625856876373\n",
      "Batch 11. Data shape torch.Size([32, 3, 224, 224]) Loss 0.05452363193035126\n",
      "Batch 12. Data shape torch.Size([32, 3, 224, 224]) Loss 0.15249182283878326\n",
      "Batch 13. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1429046392440796\n",
      "Batch 14. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07393969595432281\n",
      "Batch 15. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07840336859226227\n",
      "Batch 16. Data shape torch.Size([32, 3, 224, 224]) Loss 0.057720184326171875\n",
      "Batch 17. Data shape torch.Size([32, 3, 224, 224]) Loss 0.13397961854934692\n",
      "Batch 18. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09223219752311707\n",
      "Batch 19. Data shape torch.Size([32, 3, 224, 224]) Loss 0.10010120272636414\n",
      "Batch 20. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1137816309928894\n",
      "Batch 21. Data shape torch.Size([32, 3, 224, 224]) Loss 0.04056389629840851\n",
      "Batch 22. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08134575933218002\n",
      "Batch 23. Data shape torch.Size([32, 3, 224, 224]) Loss 0.13136303424835205\n",
      "Batch 24. Data shape torch.Size([32, 3, 224, 224]) Loss 0.10429896414279938\n",
      "Batch 25. Data shape torch.Size([32, 3, 224, 224]) Loss 0.06553038954734802\n",
      "Batch 26. Data shape torch.Size([32, 3, 224, 224]) Loss 0.04736567288637161\n",
      "Batch 27. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07756161689758301\n",
      "Batch 28. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1086273267865181\n",
      "Batch 29. Data shape torch.Size([32, 3, 224, 224]) Loss 0.15194390714168549\n",
      "Batch 30. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08080381900072098\n",
      "Batch 31. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1223616749048233\n",
      "Batch 32. Data shape torch.Size([32, 3, 224, 224]) Loss 0.15808507800102234\n",
      "Batch 33. Data shape torch.Size([32, 3, 224, 224]) Loss 0.056720755994319916\n",
      "Batch 34. Data shape torch.Size([32, 3, 224, 224]) Loss 0.12000376731157303\n",
      "Batch 35. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09783992916345596\n",
      "Batch 36. Data shape torch.Size([32, 3, 224, 224]) Loss 0.14575543999671936\n",
      "Batch 37. Data shape torch.Size([32, 3, 224, 224]) Loss 0.10607948899269104\n",
      "Batch 38. Data shape torch.Size([32, 3, 224, 224]) Loss 0.0992591381072998\n",
      "Batch 39. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09680099040269852\n",
      "Batch 40. Data shape torch.Size([22, 3, 224, 224]) Loss 0.08280889689922333\n",
      "Valid loss improved from 0.097269 to 0.094547. Saving model ...\n",
      "Epoch: 25/50 | time: 8.0m 53.8s | lr: 1.0000e-05 | train/loss: 0.08188 | val/loss: 0.09455 | val/accuracy: 0.91339 | val/AUC: 0.97429 | val/Kappa: 0.84194\n",
      "Epoch: 26 Train batch 10 loss: 0.03784825652837753, 6.3% complete\n",
      "Epoch: 26 Train batch 20 loss: 0.06989330798387527, 12.6% complete\n",
      "Epoch: 26 Train batch 30 loss: 0.08220390975475311, 18.9% complete\n",
      "Epoch: 26 Train batch 40 loss: 0.05940673500299454, 25.2% complete\n",
      "Epoch: 26 Train batch 50 loss: 0.08762814104557037, 31.4% complete\n",
      "Epoch: 26 Train batch 60 loss: 0.06568142026662827, 37.7% complete\n",
      "Epoch: 26 Train batch 70 loss: 0.10106763988733292, 44.0% complete\n",
      "Epoch: 26 Train batch 80 loss: 0.11755803972482681, 50.3% complete\n",
      "Epoch: 26 Train batch 90 loss: 0.03321569412946701, 56.6% complete\n",
      "Epoch: 26 Train batch 100 loss: 0.04998588562011719, 62.9% complete\n",
      "Epoch: 26 Train batch 110 loss: 0.026406947523355484, 69.2% complete\n",
      "Epoch: 26 Train batch 120 loss: 0.08266064524650574, 75.5% complete\n",
      "Epoch: 26 Train batch 130 loss: 0.0697171539068222, 81.8% complete\n",
      "Epoch: 26 Train batch 140 loss: 0.10221821069717407, 88.1% complete\n",
      "Epoch: 26 Train batch 150 loss: 0.08983803540468216, 94.3% complete\n",
      "Batch 1. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1325390785932541\n",
      "Batch 2. Data shape torch.Size([32, 3, 224, 224]) Loss 0.056606799364089966\n",
      "Batch 3. Data shape torch.Size([32, 3, 224, 224]) Loss 0.12591378390789032\n",
      "Batch 4. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1397334337234497\n",
      "Batch 5. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09881703555583954\n",
      "Batch 6. Data shape torch.Size([32, 3, 224, 224]) Loss 0.0659954771399498\n",
      "Batch 7. Data shape torch.Size([32, 3, 224, 224]) Loss 0.054717473685741425\n",
      "Batch 8. Data shape torch.Size([32, 3, 224, 224]) Loss 0.20466162264347076\n",
      "Batch 9. Data shape torch.Size([32, 3, 224, 224]) Loss 0.10525277256965637\n",
      "Batch 10. Data shape torch.Size([32, 3, 224, 224]) Loss 0.12928670644760132\n",
      "Batch 11. Data shape torch.Size([32, 3, 224, 224]) Loss 0.10531672835350037\n",
      "Batch 12. Data shape torch.Size([32, 3, 224, 224]) Loss 0.03526170179247856\n",
      "Batch 13. Data shape torch.Size([32, 3, 224, 224]) Loss 0.13133279979228973\n",
      "Batch 14. Data shape torch.Size([32, 3, 224, 224]) Loss 0.11260540038347244\n",
      "Batch 15. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09993872046470642\n",
      "Batch 16. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07218973338603973\n",
      "Batch 17. Data shape torch.Size([32, 3, 224, 224]) Loss 0.05122598260641098\n",
      "Batch 18. Data shape torch.Size([32, 3, 224, 224]) Loss 0.05852271616458893\n",
      "Batch 19. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07499758899211884\n",
      "Batch 20. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07811802625656128\n",
      "Batch 21. Data shape torch.Size([32, 3, 224, 224]) Loss 0.020608846098184586\n",
      "Batch 22. Data shape torch.Size([32, 3, 224, 224]) Loss 0.15498632192611694\n",
      "Batch 23. Data shape torch.Size([32, 3, 224, 224]) Loss 0.04235505312681198\n",
      "Batch 24. Data shape torch.Size([32, 3, 224, 224]) Loss 0.11479800194501877\n",
      "Batch 25. Data shape torch.Size([32, 3, 224, 224]) Loss 0.06583151966333389\n",
      "Batch 26. Data shape torch.Size([32, 3, 224, 224]) Loss 0.06125975400209427\n",
      "Batch 27. Data shape torch.Size([32, 3, 224, 224]) Loss 0.14061713218688965\n",
      "Batch 28. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07664911448955536\n",
      "Batch 29. Data shape torch.Size([32, 3, 224, 224]) Loss 0.15785305202007294\n",
      "Batch 30. Data shape torch.Size([32, 3, 224, 224]) Loss 0.05927051603794098\n",
      "Batch 31. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08124887943267822\n",
      "Batch 32. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08133068680763245\n",
      "Batch 33. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1021234542131424\n",
      "Batch 34. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09368672966957092\n",
      "Batch 35. Data shape torch.Size([32, 3, 224, 224]) Loss 0.11692934483289719\n",
      "Batch 36. Data shape torch.Size([32, 3, 224, 224]) Loss 0.11790579557418823\n",
      "Batch 37. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07378669083118439\n",
      "Batch 38. Data shape torch.Size([32, 3, 224, 224]) Loss 0.0946890264749527\n",
      "Batch 39. Data shape torch.Size([32, 3, 224, 224]) Loss 0.11412980407476425\n",
      "Batch 40. Data shape torch.Size([22, 3, 224, 224]) Loss 0.02547951601445675\n",
      "Valid loss improved from 0.094547 to 0.093214. Saving model ...\n",
      "Epoch: 26/50 | time: 9.0m 9.447s | lr: 1.0000e-05 | train/loss: 0.07988 | val/loss: 0.09321 | val/accuracy: 0.91102 | val/AUC: 0.97387 | val/Kappa: 0.83841\n",
      "Epoch: 27 Train batch 10 loss: 0.1144494041800499, 6.3% complete\n",
      "Epoch: 27 Train batch 20 loss: 0.13663266599178314, 12.6% complete\n",
      "Epoch: 27 Train batch 30 loss: 0.12808659672737122, 18.9% complete\n",
      "Epoch: 27 Train batch 40 loss: 0.19432410597801208, 25.2% complete\n",
      "Epoch: 27 Train batch 50 loss: 0.053835365921258926, 31.4% complete\n",
      "Epoch: 27 Train batch 60 loss: 0.1414175033569336, 37.7% complete\n",
      "Epoch: 27 Train batch 70 loss: 0.10017145425081253, 44.0% complete\n",
      "Epoch: 27 Train batch 80 loss: 0.12538118660449982, 50.3% complete\n",
      "Epoch: 27 Train batch 90 loss: 0.042029835283756256, 56.6% complete\n",
      "Epoch: 27 Train batch 100 loss: 0.043905697762966156, 62.9% complete\n",
      "Epoch: 27 Train batch 110 loss: 0.06877782940864563, 69.2% complete\n",
      "Epoch: 27 Train batch 120 loss: 0.06135309860110283, 75.5% complete\n",
      "Epoch: 27 Train batch 130 loss: 0.04901639372110367, 81.8% complete\n",
      "Epoch: 27 Train batch 140 loss: 0.10742093622684479, 88.1% complete\n",
      "Epoch: 27 Train batch 150 loss: 0.0782342180609703, 94.3% complete\n",
      "Batch 1. Data shape torch.Size([32, 3, 224, 224]) Loss 0.14122410118579865\n",
      "Batch 2. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09615623205900192\n",
      "Batch 3. Data shape torch.Size([32, 3, 224, 224]) Loss 0.10415158420801163\n",
      "Batch 4. Data shape torch.Size([32, 3, 224, 224]) Loss 0.06568015366792679\n",
      "Batch 5. Data shape torch.Size([32, 3, 224, 224]) Loss 0.04996958374977112\n",
      "Batch 6. Data shape torch.Size([32, 3, 224, 224]) Loss 0.05511387065052986\n",
      "Batch 7. Data shape torch.Size([32, 3, 224, 224]) Loss 0.06044746935367584\n",
      "Batch 8. Data shape torch.Size([32, 3, 224, 224]) Loss 0.04162948206067085\n",
      "Batch 9. Data shape torch.Size([32, 3, 224, 224]) Loss 0.12950943410396576\n",
      "Batch 10. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07391650229692459\n",
      "Batch 11. Data shape torch.Size([32, 3, 224, 224]) Loss 0.05683749541640282\n",
      "Batch 12. Data shape torch.Size([32, 3, 224, 224]) Loss 0.039556510746479034\n",
      "Batch 13. Data shape torch.Size([32, 3, 224, 224]) Loss 0.04385137930512428\n",
      "Batch 14. Data shape torch.Size([32, 3, 224, 224]) Loss 0.0528586320579052\n",
      "Batch 15. Data shape torch.Size([32, 3, 224, 224]) Loss 0.04311492294073105\n",
      "Batch 16. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09336072206497192\n",
      "Batch 17. Data shape torch.Size([32, 3, 224, 224]) Loss 0.16158242523670197\n",
      "Batch 18. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1461237668991089\n",
      "Batch 19. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08474290370941162\n",
      "Batch 20. Data shape torch.Size([32, 3, 224, 224]) Loss 0.06885639578104019\n",
      "Batch 21. Data shape torch.Size([32, 3, 224, 224]) Loss 0.05349712073802948\n",
      "Batch 22. Data shape torch.Size([32, 3, 224, 224]) Loss 0.11617197096347809\n",
      "Batch 23. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09897680580615997\n",
      "Batch 24. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1626283824443817\n",
      "Batch 25. Data shape torch.Size([32, 3, 224, 224]) Loss 0.2030109167098999\n",
      "Batch 26. Data shape torch.Size([32, 3, 224, 224]) Loss 0.11199137568473816\n",
      "Batch 27. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09977047145366669\n",
      "Batch 28. Data shape torch.Size([32, 3, 224, 224]) Loss 0.12674275040626526\n",
      "Batch 29. Data shape torch.Size([32, 3, 224, 224]) Loss 0.11119507253170013\n",
      "Batch 30. Data shape torch.Size([32, 3, 224, 224]) Loss 0.03476464003324509\n",
      "Batch 31. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1615704596042633\n",
      "Batch 32. Data shape torch.Size([32, 3, 224, 224]) Loss 0.0512978658080101\n",
      "Batch 33. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1608269065618515\n",
      "Batch 34. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08264491707086563\n",
      "Batch 35. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07849575579166412\n",
      "Batch 36. Data shape torch.Size([32, 3, 224, 224]) Loss 0.06978505849838257\n",
      "Batch 37. Data shape torch.Size([32, 3, 224, 224]) Loss 0.15362441539764404\n",
      "Batch 38. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08634132146835327\n",
      "Batch 39. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1533082276582718\n",
      "Batch 40. Data shape torch.Size([22, 3, 224, 224]) Loss 0.0386107861995697\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Epoch: 27/50 | time: 17.0m 29.7s | lr: 1.0000e-05 | train/loss: 0.07969 | val/loss: 0.09410 | val/accuracy: 0.91339 | val/AUC: 0.97324 | val/Kappa: 0.84139\n",
      "Epoch: 28 Train batch 10 loss: 0.07707209885120392, 6.3% complete\n",
      "Epoch: 28 Train batch 20 loss: 0.06262151896953583, 12.6% complete\n",
      "Epoch: 28 Train batch 30 loss: 0.15564900636672974, 18.9% complete\n",
      "Epoch: 28 Train batch 40 loss: 0.11761821061372757, 25.2% complete\n",
      "Epoch: 28 Train batch 50 loss: 0.051956675946712494, 31.4% complete\n",
      "Epoch: 28 Train batch 60 loss: 0.08218582719564438, 37.7% complete\n",
      "Epoch: 28 Train batch 70 loss: 0.09123000502586365, 44.0% complete\n",
      "Epoch: 28 Train batch 80 loss: 0.04880146682262421, 50.3% complete\n",
      "Epoch: 28 Train batch 90 loss: 0.036178238689899445, 56.6% complete\n",
      "Epoch: 28 Train batch 100 loss: 0.08778847754001617, 62.9% complete\n",
      "Epoch: 28 Train batch 110 loss: 0.05497625470161438, 69.2% complete\n",
      "Epoch: 28 Train batch 120 loss: 0.07642871141433716, 75.5% complete\n",
      "Epoch: 28 Train batch 130 loss: 0.02686622366309166, 81.8% complete\n",
      "Epoch: 28 Train batch 140 loss: 0.057106196880340576, 88.1% complete\n",
      "Epoch: 28 Train batch 150 loss: 0.06631671637296677, 94.3% complete\n",
      "Batch 1. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08500050008296967\n",
      "Batch 2. Data shape torch.Size([32, 3, 224, 224]) Loss 0.13378304243087769\n",
      "Batch 3. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09747468680143356\n",
      "Batch 4. Data shape torch.Size([32, 3, 224, 224]) Loss 0.06337489187717438\n",
      "Batch 5. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1899566352367401\n",
      "Batch 6. Data shape torch.Size([32, 3, 224, 224]) Loss 0.11127807945013046\n",
      "Batch 7. Data shape torch.Size([32, 3, 224, 224]) Loss 0.10781444609165192\n",
      "Batch 8. Data shape torch.Size([32, 3, 224, 224]) Loss 0.04892071709036827\n",
      "Batch 9. Data shape torch.Size([32, 3, 224, 224]) Loss 0.10640459507703781\n",
      "Batch 10. Data shape torch.Size([32, 3, 224, 224]) Loss 0.06256039440631866\n",
      "Batch 11. Data shape torch.Size([32, 3, 224, 224]) Loss 0.0450437106192112\n",
      "Batch 12. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1355019360780716\n",
      "Batch 13. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09731574356555939\n",
      "Batch 14. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07982215285301208\n",
      "Batch 15. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08895507454872131\n",
      "Batch 16. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08424250781536102\n",
      "Batch 17. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1510348916053772\n",
      "Batch 18. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08474639058113098\n",
      "Batch 19. Data shape torch.Size([32, 3, 224, 224]) Loss 0.15255464613437653\n",
      "Batch 20. Data shape torch.Size([32, 3, 224, 224]) Loss 0.06411664932966232\n",
      "Batch 21. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08960892260074615\n",
      "Batch 22. Data shape torch.Size([32, 3, 224, 224]) Loss 0.17906098067760468\n",
      "Batch 23. Data shape torch.Size([32, 3, 224, 224]) Loss 0.06459483504295349\n",
      "Batch 24. Data shape torch.Size([32, 3, 224, 224]) Loss 0.06269521266222\n",
      "Batch 25. Data shape torch.Size([32, 3, 224, 224]) Loss 0.056952763348817825\n",
      "Batch 26. Data shape torch.Size([32, 3, 224, 224]) Loss 0.04522823542356491\n",
      "Batch 27. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09952765703201294\n",
      "Batch 28. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1265619397163391\n",
      "Batch 29. Data shape torch.Size([32, 3, 224, 224]) Loss 0.06234818696975708\n",
      "Batch 30. Data shape torch.Size([32, 3, 224, 224]) Loss 0.10563576221466064\n",
      "Batch 31. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08664840459823608\n",
      "Batch 32. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07055802643299103\n",
      "Batch 33. Data shape torch.Size([32, 3, 224, 224]) Loss 0.06244268640875816\n",
      "Batch 34. Data shape torch.Size([32, 3, 224, 224]) Loss 0.038895562291145325\n",
      "Batch 35. Data shape torch.Size([32, 3, 224, 224]) Loss 0.04942910373210907\n",
      "Batch 36. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08793604373931885\n",
      "Batch 37. Data shape torch.Size([32, 3, 224, 224]) Loss 0.04695194214582443\n",
      "Batch 38. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1030854731798172\n",
      "Batch 39. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07346421480178833\n",
      "Batch 40. Data shape torch.Size([22, 3, 224, 224]) Loss 0.13134264945983887\n",
      "Valid loss improved from 0.093214 to 0.090822. Saving model ...\n",
      "Epoch: 28/50 | time: 7.0m 1.636s | lr: 1.0000e-05 | train/loss: 0.07114 | val/loss: 0.09082 | val/accuracy: 0.91417 | val/AUC: 0.97628 | val/Kappa: 0.84344\n",
      "Epoch: 29 Train batch 10 loss: 0.03907955437898636, 6.3% complete\n",
      "Epoch: 29 Train batch 20 loss: 0.05067365616559982, 12.6% complete\n",
      "Epoch: 29 Train batch 30 loss: 0.07267580181360245, 18.9% complete\n",
      "Epoch: 29 Train batch 40 loss: 0.03240715339779854, 25.2% complete\n",
      "Epoch: 29 Train batch 50 loss: 0.034042809158563614, 31.4% complete\n",
      "Epoch: 29 Train batch 60 loss: 0.07038933783769608, 37.7% complete\n",
      "Epoch: 29 Train batch 70 loss: 0.094304658472538, 44.0% complete\n",
      "Epoch: 29 Train batch 80 loss: 0.06467123329639435, 50.3% complete\n",
      "Epoch: 29 Train batch 90 loss: 0.06232842057943344, 56.6% complete\n",
      "Epoch: 29 Train batch 100 loss: 0.04652788117527962, 62.9% complete\n",
      "Epoch: 29 Train batch 110 loss: 0.017358342185616493, 69.2% complete\n",
      "Epoch: 29 Train batch 120 loss: 0.08692173659801483, 75.5% complete\n",
      "Epoch: 29 Train batch 130 loss: 0.037674225866794586, 81.8% complete\n",
      "Epoch: 29 Train batch 140 loss: 0.03377559781074524, 88.1% complete\n",
      "Epoch: 29 Train batch 150 loss: 0.067329540848732, 94.3% complete\n",
      "Batch 1. Data shape torch.Size([32, 3, 224, 224]) Loss 0.25779640674591064\n",
      "Batch 2. Data shape torch.Size([32, 3, 224, 224]) Loss 0.029195636510849\n",
      "Batch 3. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07360565662384033\n",
      "Batch 4. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1475052535533905\n",
      "Batch 5. Data shape torch.Size([32, 3, 224, 224]) Loss 0.0723806768655777\n",
      "Batch 6. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1382034868001938\n",
      "Batch 7. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07850293815135956\n",
      "Batch 8. Data shape torch.Size([32, 3, 224, 224]) Loss 0.05828285217285156\n",
      "Batch 9. Data shape torch.Size([32, 3, 224, 224]) Loss 0.05257754027843475\n",
      "Batch 10. Data shape torch.Size([32, 3, 224, 224]) Loss 0.04389994964003563\n",
      "Batch 11. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1532249003648758\n",
      "Batch 12. Data shape torch.Size([32, 3, 224, 224]) Loss 0.13282012939453125\n",
      "Batch 13. Data shape torch.Size([32, 3, 224, 224]) Loss 0.13542520999908447\n",
      "Batch 14. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1194738894701004\n",
      "Batch 15. Data shape torch.Size([32, 3, 224, 224]) Loss 0.10320557653903961\n",
      "Batch 16. Data shape torch.Size([32, 3, 224, 224]) Loss 0.04549185931682587\n",
      "Batch 17. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07091072201728821\n",
      "Batch 18. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1093607172369957\n",
      "Batch 19. Data shape torch.Size([32, 3, 224, 224]) Loss 0.132074236869812\n",
      "Batch 20. Data shape torch.Size([32, 3, 224, 224]) Loss 0.0651135966181755\n",
      "Batch 21. Data shape torch.Size([32, 3, 224, 224]) Loss 0.026904752478003502\n",
      "Batch 22. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1303250938653946\n",
      "Batch 23. Data shape torch.Size([32, 3, 224, 224]) Loss 0.037230975925922394\n",
      "Batch 24. Data shape torch.Size([32, 3, 224, 224]) Loss 0.10441182553768158\n",
      "Batch 25. Data shape torch.Size([32, 3, 224, 224]) Loss 0.06567249447107315\n",
      "Batch 26. Data shape torch.Size([32, 3, 224, 224]) Loss 0.06910648196935654\n",
      "Batch 27. Data shape torch.Size([32, 3, 224, 224]) Loss 0.0841863751411438\n",
      "Batch 28. Data shape torch.Size([32, 3, 224, 224]) Loss 0.13106076419353485\n",
      "Batch 29. Data shape torch.Size([32, 3, 224, 224]) Loss 0.04126330465078354\n",
      "Batch 30. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09108569473028183\n",
      "Batch 31. Data shape torch.Size([32, 3, 224, 224]) Loss 0.03157401084899902\n",
      "Batch 32. Data shape torch.Size([32, 3, 224, 224]) Loss 0.044921115040779114\n",
      "Batch 33. Data shape torch.Size([32, 3, 224, 224]) Loss 0.073958620429039\n",
      "Batch 34. Data shape torch.Size([32, 3, 224, 224]) Loss 0.05507313087582588\n",
      "Batch 35. Data shape torch.Size([32, 3, 224, 224]) Loss 0.10145560652017593\n",
      "Batch 36. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09356775879859924\n",
      "Batch 37. Data shape torch.Size([32, 3, 224, 224]) Loss 0.05891215428709984\n",
      "Batch 38. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08032915741205215\n",
      "Batch 39. Data shape torch.Size([32, 3, 224, 224]) Loss 0.11982634663581848\n",
      "Batch 40. Data shape torch.Size([22, 3, 224, 224]) Loss 0.14049173891544342\n",
      "Valid loss improved from 0.090822 to 0.090010. Saving model ...\n",
      "Epoch: 29/50 | time: 7.0m 44.94s | lr: 1.0000e-05 | train/loss: 0.07620 | val/loss: 0.09001 | val/accuracy: 0.91417 | val/AUC: 0.97705 | val/Kappa: 0.84236\n",
      "Epoch: 30 Train batch 10 loss: 0.05194574594497681, 6.3% complete\n",
      "Epoch: 30 Train batch 20 loss: 0.18411627411842346, 12.6% complete\n",
      "Epoch: 30 Train batch 30 loss: 0.09040006250143051, 18.9% complete\n",
      "Epoch: 30 Train batch 40 loss: 0.08445727080106735, 25.2% complete\n",
      "Epoch: 30 Train batch 50 loss: 0.11556840687990189, 31.4% complete\n",
      "Epoch: 30 Train batch 60 loss: 0.08235214650630951, 37.7% complete\n",
      "Epoch: 30 Train batch 70 loss: 0.06532389670610428, 44.0% complete\n",
      "Epoch: 30 Train batch 80 loss: 0.02949795126914978, 50.3% complete\n",
      "Epoch: 30 Train batch 90 loss: 0.042413514107465744, 56.6% complete\n",
      "Epoch: 30 Train batch 100 loss: 0.05746433511376381, 62.9% complete\n",
      "Epoch: 30 Train batch 110 loss: 0.041192907840013504, 69.2% complete\n",
      "Epoch: 30 Train batch 120 loss: 0.08925676345825195, 75.5% complete\n",
      "Epoch: 30 Train batch 130 loss: 0.07375391572713852, 81.8% complete\n",
      "Epoch: 30 Train batch 140 loss: 0.11027219891548157, 88.1% complete\n",
      "Epoch: 30 Train batch 150 loss: 0.05237965285778046, 94.3% complete\n",
      "Batch 1. Data shape torch.Size([32, 3, 224, 224]) Loss 0.034176964312791824\n",
      "Batch 2. Data shape torch.Size([32, 3, 224, 224]) Loss 0.06633709371089935\n",
      "Batch 3. Data shape torch.Size([32, 3, 224, 224]) Loss 0.13590824604034424\n",
      "Batch 4. Data shape torch.Size([32, 3, 224, 224]) Loss 0.030888080596923828\n",
      "Batch 5. Data shape torch.Size([32, 3, 224, 224]) Loss 0.10280847549438477\n",
      "Batch 6. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07489251345396042\n",
      "Batch 7. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07679110765457153\n",
      "Batch 8. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08697544038295746\n",
      "Batch 9. Data shape torch.Size([32, 3, 224, 224]) Loss 0.11160213500261307\n",
      "Batch 10. Data shape torch.Size([32, 3, 224, 224]) Loss 0.06707096844911575\n",
      "Batch 11. Data shape torch.Size([32, 3, 224, 224]) Loss 0.16678017377853394\n",
      "Batch 12. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09745136648416519\n",
      "Batch 13. Data shape torch.Size([32, 3, 224, 224]) Loss 0.06719876080751419\n",
      "Batch 14. Data shape torch.Size([32, 3, 224, 224]) Loss 0.11259210109710693\n",
      "Batch 15. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07334671914577484\n",
      "Batch 16. Data shape torch.Size([32, 3, 224, 224]) Loss 0.04632442444562912\n",
      "Batch 17. Data shape torch.Size([32, 3, 224, 224]) Loss 0.0845649242401123\n",
      "Batch 18. Data shape torch.Size([32, 3, 224, 224]) Loss 0.15650656819343567\n",
      "Batch 19. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1082824319601059\n",
      "Batch 20. Data shape torch.Size([32, 3, 224, 224]) Loss 0.044958241283893585\n",
      "Batch 21. Data shape torch.Size([32, 3, 224, 224]) Loss 0.05640227720141411\n",
      "Batch 22. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09750552475452423\n",
      "Batch 23. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1084163635969162\n",
      "Batch 24. Data shape torch.Size([32, 3, 224, 224]) Loss 0.10433632135391235\n",
      "Batch 25. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07991284132003784\n",
      "Batch 26. Data shape torch.Size([32, 3, 224, 224]) Loss 0.11402874439954758\n",
      "Batch 27. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09628743678331375\n",
      "Batch 28. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08080905675888062\n",
      "Batch 29. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09887826442718506\n",
      "Batch 30. Data shape torch.Size([32, 3, 224, 224]) Loss 0.042212605476379395\n",
      "Batch 31. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1614428162574768\n",
      "Batch 32. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1004987508058548\n",
      "Batch 33. Data shape torch.Size([32, 3, 224, 224]) Loss 0.06962531805038452\n",
      "Batch 34. Data shape torch.Size([32, 3, 224, 224]) Loss 0.03453674167394638\n",
      "Batch 35. Data shape torch.Size([32, 3, 224, 224]) Loss 0.0716245248913765\n",
      "Batch 36. Data shape torch.Size([32, 3, 224, 224]) Loss 0.06556330621242523\n",
      "Batch 37. Data shape torch.Size([32, 3, 224, 224]) Loss 0.19521400332450867\n",
      "Batch 38. Data shape torch.Size([32, 3, 224, 224]) Loss 0.05816253274679184\n",
      "Batch 39. Data shape torch.Size([32, 3, 224, 224]) Loss 0.02843460440635681\n",
      "Batch 40. Data shape torch.Size([22, 3, 224, 224]) Loss 0.1490832269191742\n",
      "Valid loss improved from 0.090010 to 0.088961. Saving model ...\n",
      "Epoch: 30/50 | time: 8.0m 17.76s | lr: 1.0000e-05 | train/loss: 0.07199 | val/loss: 0.08896 | val/accuracy: 0.91654 | val/AUC: 0.97697 | val/Kappa: 0.84816\n",
      "Epoch: 31 Train batch 10 loss: 0.03937097638845444, 6.3% complete\n",
      "Epoch: 31 Train batch 20 loss: 0.06880713999271393, 12.6% complete\n",
      "Epoch: 31 Train batch 30 loss: 0.0710262656211853, 18.9% complete\n",
      "Epoch: 31 Train batch 40 loss: 0.015012236312031746, 25.2% complete\n",
      "Epoch: 31 Train batch 50 loss: 0.031871479004621506, 31.4% complete\n",
      "Epoch: 31 Train batch 60 loss: 0.11616584658622742, 37.7% complete\n",
      "Epoch: 31 Train batch 70 loss: 0.1342836171388626, 44.0% complete\n",
      "Epoch: 31 Train batch 80 loss: 0.02857014536857605, 50.3% complete\n",
      "Epoch: 31 Train batch 90 loss: 0.07562313973903656, 56.6% complete\n",
      "Epoch: 31 Train batch 100 loss: 0.08208084851503372, 62.9% complete\n",
      "Epoch: 31 Train batch 110 loss: 0.08358997106552124, 69.2% complete\n",
      "Epoch: 31 Train batch 120 loss: 0.05457126349210739, 75.5% complete\n",
      "Epoch: 31 Train batch 130 loss: 0.1269824355840683, 81.8% complete\n",
      "Epoch: 31 Train batch 140 loss: 0.07096757739782333, 88.1% complete\n",
      "Epoch: 31 Train batch 150 loss: 0.016307231038808823, 94.3% complete\n",
      "Batch 1. Data shape torch.Size([32, 3, 224, 224]) Loss 0.04783070832490921\n",
      "Batch 2. Data shape torch.Size([32, 3, 224, 224]) Loss 0.12765422463417053\n",
      "Batch 3. Data shape torch.Size([32, 3, 224, 224]) Loss 0.12151932716369629\n",
      "Batch 4. Data shape torch.Size([32, 3, 224, 224]) Loss 0.02356412261724472\n",
      "Batch 5. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09055951982736588\n",
      "Batch 6. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07587142288684845\n",
      "Batch 7. Data shape torch.Size([32, 3, 224, 224]) Loss 0.014585096389055252\n",
      "Batch 8. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07848797738552094\n",
      "Batch 9. Data shape torch.Size([32, 3, 224, 224]) Loss 0.06055055558681488\n",
      "Batch 10. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08730053901672363\n",
      "Batch 11. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08085818588733673\n",
      "Batch 12. Data shape torch.Size([32, 3, 224, 224]) Loss 0.05469007417559624\n",
      "Batch 13. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07572420686483383\n",
      "Batch 14. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07238845527172089\n",
      "Batch 15. Data shape torch.Size([32, 3, 224, 224]) Loss 0.050654493272304535\n",
      "Batch 16. Data shape torch.Size([32, 3, 224, 224]) Loss 0.2103910744190216\n",
      "Batch 17. Data shape torch.Size([32, 3, 224, 224]) Loss 0.03783774748444557\n",
      "Batch 18. Data shape torch.Size([32, 3, 224, 224]) Loss 0.19823932647705078\n",
      "Batch 19. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08169509470462799\n",
      "Batch 20. Data shape torch.Size([32, 3, 224, 224]) Loss 0.03359244391322136\n",
      "Batch 21. Data shape torch.Size([32, 3, 224, 224]) Loss 0.053724680095911026\n",
      "Batch 22. Data shape torch.Size([32, 3, 224, 224]) Loss 0.17080730199813843\n",
      "Batch 23. Data shape torch.Size([32, 3, 224, 224]) Loss 0.15519630908966064\n",
      "Batch 24. Data shape torch.Size([32, 3, 224, 224]) Loss 0.02607322297990322\n",
      "Batch 25. Data shape torch.Size([32, 3, 224, 224]) Loss 0.12365329265594482\n",
      "Batch 26. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1277557760477066\n",
      "Batch 27. Data shape torch.Size([32, 3, 224, 224]) Loss 0.13191547989845276\n",
      "Batch 28. Data shape torch.Size([32, 3, 224, 224]) Loss 0.049862973392009735\n",
      "Batch 29. Data shape torch.Size([32, 3, 224, 224]) Loss 0.12055554986000061\n",
      "Batch 30. Data shape torch.Size([32, 3, 224, 224]) Loss 0.11517346650362015\n",
      "Batch 31. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08616112172603607\n",
      "Batch 32. Data shape torch.Size([32, 3, 224, 224]) Loss 0.13219372928142548\n",
      "Batch 33. Data shape torch.Size([32, 3, 224, 224]) Loss 0.100436732172966\n",
      "Batch 34. Data shape torch.Size([32, 3, 224, 224]) Loss 0.10176139324903488\n",
      "Batch 35. Data shape torch.Size([32, 3, 224, 224]) Loss 0.023162443190813065\n",
      "Batch 36. Data shape torch.Size([32, 3, 224, 224]) Loss 0.047786712646484375\n",
      "Batch 37. Data shape torch.Size([32, 3, 224, 224]) Loss 0.14445114135742188\n",
      "Batch 38. Data shape torch.Size([32, 3, 224, 224]) Loss 0.12119647860527039\n",
      "Batch 39. Data shape torch.Size([32, 3, 224, 224]) Loss 0.056153349578380585\n",
      "Batch 40. Data shape torch.Size([22, 3, 224, 224]) Loss 0.14477188885211945\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Epoch: 31/50 | time: 8.0m 0.9424s | lr: 1.0000e-05 | train/loss: 0.06845 | val/loss: 0.09142 | val/accuracy: 0.91102 | val/AUC: 0.97689 | val/Kappa: 0.83633\n",
      "Epoch: 32 Train batch 10 loss: 0.09944260120391846, 6.3% complete\n",
      "Epoch: 32 Train batch 20 loss: 0.010423989035189152, 12.6% complete\n",
      "Epoch: 32 Train batch 30 loss: 0.014880262315273285, 18.9% complete\n",
      "Epoch: 32 Train batch 40 loss: 0.027599547058343887, 25.2% complete\n",
      "Epoch: 32 Train batch 50 loss: 0.04416162148118019, 31.4% complete\n",
      "Epoch: 32 Train batch 60 loss: 0.13984541594982147, 37.7% complete\n",
      "Epoch: 32 Train batch 70 loss: 0.06384848058223724, 44.0% complete\n",
      "Epoch: 32 Train batch 80 loss: 0.0656091496348381, 50.3% complete\n",
      "Epoch: 32 Train batch 90 loss: 0.08359023928642273, 56.6% complete\n",
      "Epoch: 32 Train batch 100 loss: 0.05762191861867905, 62.9% complete\n",
      "Epoch: 32 Train batch 110 loss: 0.08005256950855255, 69.2% complete\n",
      "Epoch: 32 Train batch 120 loss: 0.0709427148103714, 75.5% complete\n",
      "Epoch: 32 Train batch 130 loss: 0.09254147112369537, 81.8% complete\n",
      "Epoch: 32 Train batch 140 loss: 0.09921515733003616, 88.1% complete\n",
      "Epoch: 32 Train batch 150 loss: 0.03399888053536415, 94.3% complete\n",
      "Batch 1. Data shape torch.Size([32, 3, 224, 224]) Loss 0.22472424805164337\n",
      "Batch 2. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07780959457159042\n",
      "Batch 3. Data shape torch.Size([32, 3, 224, 224]) Loss 0.032674044370651245\n",
      "Batch 4. Data shape torch.Size([32, 3, 224, 224]) Loss 0.06145589426159859\n",
      "Batch 5. Data shape torch.Size([32, 3, 224, 224]) Loss 0.15641283988952637\n",
      "Batch 6. Data shape torch.Size([32, 3, 224, 224]) Loss 0.12831000983715057\n",
      "Batch 7. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09784932434558868\n",
      "Batch 8. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08545105159282684\n",
      "Batch 9. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09225459396839142\n",
      "Batch 10. Data shape torch.Size([32, 3, 224, 224]) Loss 0.061550840735435486\n",
      "Batch 11. Data shape torch.Size([32, 3, 224, 224]) Loss 0.025332070887088776\n",
      "Batch 12. Data shape torch.Size([32, 3, 224, 224]) Loss 0.18554890155792236\n",
      "Batch 13. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08006764948368073\n",
      "Batch 14. Data shape torch.Size([32, 3, 224, 224]) Loss 0.0863417237997055\n",
      "Batch 15. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08156292140483856\n",
      "Batch 16. Data shape torch.Size([32, 3, 224, 224]) Loss 0.10544702410697937\n",
      "Batch 17. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09190645068883896\n",
      "Batch 18. Data shape torch.Size([32, 3, 224, 224]) Loss 0.05143309757113457\n",
      "Batch 19. Data shape torch.Size([32, 3, 224, 224]) Loss 0.02697022072970867\n",
      "Batch 20. Data shape torch.Size([32, 3, 224, 224]) Loss 0.11274920403957367\n",
      "Batch 21. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09775390475988388\n",
      "Batch 22. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1597030609846115\n",
      "Batch 23. Data shape torch.Size([32, 3, 224, 224]) Loss 0.11568684875965118\n",
      "Batch 24. Data shape torch.Size([32, 3, 224, 224]) Loss 0.05667753517627716\n",
      "Batch 25. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09177318215370178\n",
      "Batch 26. Data shape torch.Size([32, 3, 224, 224]) Loss 0.16788840293884277\n",
      "Batch 27. Data shape torch.Size([32, 3, 224, 224]) Loss 0.02439752034842968\n",
      "Batch 28. Data shape torch.Size([32, 3, 224, 224]) Loss 0.04784101992845535\n",
      "Batch 29. Data shape torch.Size([32, 3, 224, 224]) Loss 0.02091020904481411\n",
      "Batch 30. Data shape torch.Size([32, 3, 224, 224]) Loss 0.10512342303991318\n",
      "Batch 31. Data shape torch.Size([32, 3, 224, 224]) Loss 0.10665425658226013\n",
      "Batch 32. Data shape torch.Size([32, 3, 224, 224]) Loss 0.06769299507141113\n",
      "Batch 33. Data shape torch.Size([32, 3, 224, 224]) Loss 0.11434929817914963\n",
      "Batch 34. Data shape torch.Size([32, 3, 224, 224]) Loss 0.10225040465593338\n",
      "Batch 35. Data shape torch.Size([32, 3, 224, 224]) Loss 0.028208531439304352\n",
      "Batch 36. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1056940034031868\n",
      "Batch 37. Data shape torch.Size([32, 3, 224, 224]) Loss 0.05748111754655838\n",
      "Batch 38. Data shape torch.Size([32, 3, 224, 224]) Loss 0.06675047427415848\n",
      "Batch 39. Data shape torch.Size([32, 3, 224, 224]) Loss 0.11838275194168091\n",
      "Batch 40. Data shape torch.Size([22, 3, 224, 224]) Loss 0.07769279181957245\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Epoch: 32/50 | time: 7.0m 56.06s | lr: 1.0000e-05 | train/loss: 0.07024 | val/loss: 0.08997 | val/accuracy: 0.91575 | val/AUC: 0.97455 | val/Kappa: 0.84732\n",
      "Epoch: 33 Train batch 10 loss: 0.01839258149266243, 6.3% complete\n",
      "Epoch: 33 Train batch 20 loss: 0.11562687903642654, 12.6% complete\n",
      "Epoch: 33 Train batch 30 loss: 0.052885230630636215, 18.9% complete\n",
      "Epoch: 33 Train batch 40 loss: 0.04394542798399925, 25.2% complete\n",
      "Epoch: 33 Train batch 50 loss: 0.05320679023861885, 31.4% complete\n",
      "Epoch: 33 Train batch 60 loss: 0.032056815922260284, 37.7% complete\n",
      "Epoch: 33 Train batch 70 loss: 0.052635788917541504, 44.0% complete\n",
      "Epoch: 33 Train batch 80 loss: 0.049966271966695786, 50.3% complete\n",
      "Epoch: 33 Train batch 90 loss: 0.06399646401405334, 56.6% complete\n",
      "Epoch: 33 Train batch 100 loss: 0.0939367413520813, 62.9% complete\n",
      "Epoch: 33 Train batch 110 loss: 0.09315172582864761, 69.2% complete\n",
      "Epoch: 33 Train batch 120 loss: 0.022727152332663536, 75.5% complete\n",
      "Epoch: 33 Train batch 130 loss: 0.0466848649084568, 81.8% complete\n",
      "Epoch: 33 Train batch 140 loss: 0.022022387012839317, 88.1% complete\n",
      "Epoch: 33 Train batch 150 loss: 0.09050993621349335, 94.3% complete\n",
      "Batch 1. Data shape torch.Size([32, 3, 224, 224]) Loss 0.017357472330331802\n",
      "Batch 2. Data shape torch.Size([32, 3, 224, 224]) Loss 0.03681919351220131\n",
      "Batch 3. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08589061349630356\n",
      "Batch 4. Data shape torch.Size([32, 3, 224, 224]) Loss 0.021963709965348244\n",
      "Batch 5. Data shape torch.Size([32, 3, 224, 224]) Loss 0.05122135579586029\n",
      "Batch 6. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09780313819646835\n",
      "Batch 7. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08328089863061905\n",
      "Batch 8. Data shape torch.Size([32, 3, 224, 224]) Loss 0.20664450526237488\n",
      "Batch 9. Data shape torch.Size([32, 3, 224, 224]) Loss 0.06746870279312134\n",
      "Batch 10. Data shape torch.Size([32, 3, 224, 224]) Loss 0.06195668503642082\n",
      "Batch 11. Data shape torch.Size([32, 3, 224, 224]) Loss 0.06802406907081604\n",
      "Batch 12. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1179235577583313\n",
      "Batch 13. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1351953148841858\n",
      "Batch 14. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09097634255886078\n",
      "Batch 15. Data shape torch.Size([32, 3, 224, 224]) Loss 0.02753361687064171\n",
      "Batch 16. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08038949966430664\n",
      "Batch 17. Data shape torch.Size([32, 3, 224, 224]) Loss 0.18349283933639526\n",
      "Batch 18. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1373804211616516\n",
      "Batch 19. Data shape torch.Size([32, 3, 224, 224]) Loss 0.076959028840065\n",
      "Batch 20. Data shape torch.Size([32, 3, 224, 224]) Loss 0.0759962722659111\n",
      "Batch 21. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07977374643087387\n",
      "Batch 22. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08844691514968872\n",
      "Batch 23. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09214608371257782\n",
      "Batch 24. Data shape torch.Size([32, 3, 224, 224]) Loss 0.0660032257437706\n",
      "Batch 25. Data shape torch.Size([32, 3, 224, 224]) Loss 0.14259621500968933\n",
      "Batch 26. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09730292856693268\n",
      "Batch 27. Data shape torch.Size([32, 3, 224, 224]) Loss 0.05498532950878143\n",
      "Batch 28. Data shape torch.Size([32, 3, 224, 224]) Loss 0.19400382041931152\n",
      "Batch 29. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09129321575164795\n",
      "Batch 30. Data shape torch.Size([32, 3, 224, 224]) Loss 0.028700999915599823\n",
      "Batch 31. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09684251248836517\n",
      "Batch 32. Data shape torch.Size([32, 3, 224, 224]) Loss 0.05683637782931328\n",
      "Batch 33. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1372273564338684\n",
      "Batch 34. Data shape torch.Size([32, 3, 224, 224]) Loss 0.035300880670547485\n",
      "Batch 35. Data shape torch.Size([32, 3, 224, 224]) Loss 0.02122657373547554\n",
      "Batch 36. Data shape torch.Size([32, 3, 224, 224]) Loss 0.14783774316310883\n",
      "Batch 37. Data shape torch.Size([32, 3, 224, 224]) Loss 0.034033797681331635\n",
      "Batch 38. Data shape torch.Size([32, 3, 224, 224]) Loss 0.15217119455337524\n",
      "Batch 39. Data shape torch.Size([32, 3, 224, 224]) Loss 0.05747520178556442\n",
      "Batch 40. Data shape torch.Size([22, 3, 224, 224]) Loss 0.08072466403245926\n",
      "Valid loss improved from 0.088961 to 0.086980. Saving model ...\n",
      "Epoch: 33/50 | time: 7.0m 41.07s | lr: 1.0000e-05 | train/loss: 0.06502 | val/loss: 0.08698 | val/accuracy: 0.91339 | val/AUC: 0.97754 | val/Kappa: 0.84154\n",
      "Epoch: 34 Train batch 10 loss: 0.11619511246681213, 6.3% complete\n",
      "Epoch: 34 Train batch 20 loss: 0.15681672096252441, 12.6% complete\n",
      "Epoch: 34 Train batch 30 loss: 0.009847098030149937, 18.9% complete\n",
      "Epoch: 34 Train batch 40 loss: 0.034655362367630005, 25.2% complete\n",
      "Epoch: 34 Train batch 50 loss: 0.04149075970053673, 31.4% complete\n",
      "Epoch: 34 Train batch 60 loss: 0.06801870465278625, 37.7% complete\n",
      "Epoch: 34 Train batch 70 loss: 0.045623283833265305, 44.0% complete\n",
      "Epoch: 34 Train batch 80 loss: 0.0913894921541214, 50.3% complete\n",
      "Epoch: 34 Train batch 90 loss: 0.06482496857643127, 56.6% complete\n",
      "Epoch: 34 Train batch 100 loss: 0.10922976583242416, 62.9% complete\n",
      "Epoch: 34 Train batch 110 loss: 0.027116594836115837, 69.2% complete\n",
      "Epoch: 34 Train batch 120 loss: 0.057537153363227844, 75.5% complete\n",
      "Epoch: 34 Train batch 130 loss: 0.037572767585515976, 81.8% complete\n",
      "Epoch: 34 Train batch 140 loss: 0.07841231673955917, 88.1% complete\n",
      "Epoch: 34 Train batch 150 loss: 0.024238038808107376, 94.3% complete\n",
      "Batch 1. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07072407007217407\n",
      "Batch 2. Data shape torch.Size([32, 3, 224, 224]) Loss 0.0953640341758728\n",
      "Batch 3. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07867198437452316\n",
      "Batch 4. Data shape torch.Size([32, 3, 224, 224]) Loss 0.018972985446453094\n",
      "Batch 5. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08103688806295395\n",
      "Batch 6. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09377831965684891\n",
      "Batch 7. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07270711660385132\n",
      "Batch 8. Data shape torch.Size([32, 3, 224, 224]) Loss 0.0832037627696991\n",
      "Batch 9. Data shape torch.Size([32, 3, 224, 224]) Loss 0.13045695424079895\n",
      "Batch 10. Data shape torch.Size([32, 3, 224, 224]) Loss 0.10069632530212402\n",
      "Batch 11. Data shape torch.Size([32, 3, 224, 224]) Loss 0.05525609105825424\n",
      "Batch 12. Data shape torch.Size([32, 3, 224, 224]) Loss 0.10255852341651917\n",
      "Batch 13. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07185535132884979\n",
      "Batch 14. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1836727261543274\n",
      "Batch 15. Data shape torch.Size([32, 3, 224, 224]) Loss 0.11256954818964005\n",
      "Batch 16. Data shape torch.Size([32, 3, 224, 224]) Loss 0.05483746528625488\n",
      "Batch 17. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07942093163728714\n",
      "Batch 18. Data shape torch.Size([32, 3, 224, 224]) Loss 0.116391122341156\n",
      "Batch 19. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08603322505950928\n",
      "Batch 20. Data shape torch.Size([32, 3, 224, 224]) Loss 0.0526936873793602\n",
      "Batch 21. Data shape torch.Size([32, 3, 224, 224]) Loss 0.06545455753803253\n",
      "Batch 22. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07856325805187225\n",
      "Batch 23. Data shape torch.Size([32, 3, 224, 224]) Loss 0.06399574875831604\n",
      "Batch 24. Data shape torch.Size([32, 3, 224, 224]) Loss 0.024640576913952827\n",
      "Batch 25. Data shape torch.Size([32, 3, 224, 224]) Loss 0.052154988050460815\n",
      "Batch 26. Data shape torch.Size([32, 3, 224, 224]) Loss 0.10404032468795776\n",
      "Batch 27. Data shape torch.Size([32, 3, 224, 224]) Loss 0.055613111704587936\n",
      "Batch 28. Data shape torch.Size([32, 3, 224, 224]) Loss 0.04982448369264603\n",
      "Batch 29. Data shape torch.Size([32, 3, 224, 224]) Loss 0.10119207203388214\n",
      "Batch 30. Data shape torch.Size([32, 3, 224, 224]) Loss 0.16335515677928925\n",
      "Batch 31. Data shape torch.Size([32, 3, 224, 224]) Loss 0.021741509437561035\n",
      "Batch 32. Data shape torch.Size([32, 3, 224, 224]) Loss 0.13157439231872559\n",
      "Batch 33. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09881218522787094\n",
      "Batch 34. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08606443554162979\n",
      "Batch 35. Data shape torch.Size([32, 3, 224, 224]) Loss 0.0798758715391159\n",
      "Batch 36. Data shape torch.Size([32, 3, 224, 224]) Loss 0.14828121662139893\n",
      "Batch 37. Data shape torch.Size([32, 3, 224, 224]) Loss 0.12180641293525696\n",
      "Batch 38. Data shape torch.Size([32, 3, 224, 224]) Loss 0.10494844615459442\n",
      "Batch 39. Data shape torch.Size([32, 3, 224, 224]) Loss 0.05689578503370285\n",
      "Batch 40. Data shape torch.Size([22, 3, 224, 224]) Loss 0.24120089411735535\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Epoch: 34/50 | time: 7.0m 50.07s | lr: 1.0000e-05 | train/loss: 0.06365 | val/loss: 0.08977 | val/accuracy: 0.91811 | val/AUC: 0.97572 | val/Kappa: 0.85082\n",
      "Epoch: 35 Train batch 10 loss: 0.016380522400140762, 6.3% complete\n",
      "Epoch: 35 Train batch 20 loss: 0.10463440418243408, 12.6% complete\n",
      "Epoch: 35 Train batch 30 loss: 0.044726088643074036, 18.9% complete\n",
      "Epoch: 35 Train batch 40 loss: 0.033952053636312485, 25.2% complete\n",
      "Epoch: 35 Train batch 50 loss: 0.06827016919851303, 31.4% complete\n",
      "Epoch: 35 Train batch 60 loss: 0.05009286850690842, 37.7% complete\n",
      "Epoch: 35 Train batch 70 loss: 0.07492552697658539, 44.0% complete\n",
      "Epoch: 35 Train batch 80 loss: 0.039971381425857544, 50.3% complete\n",
      "Epoch: 35 Train batch 90 loss: 0.09126916527748108, 56.6% complete\n",
      "Epoch: 35 Train batch 100 loss: 0.13081027567386627, 62.9% complete\n",
      "Epoch: 35 Train batch 110 loss: 0.0654226541519165, 69.2% complete\n",
      "Epoch: 35 Train batch 120 loss: 0.057767514139413834, 75.5% complete\n",
      "Epoch: 35 Train batch 130 loss: 0.020499393343925476, 81.8% complete\n",
      "Epoch: 35 Train batch 140 loss: 0.01793218031525612, 88.1% complete\n",
      "Epoch: 35 Train batch 150 loss: 0.05899810045957565, 94.3% complete\n",
      "Batch 1. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09152578562498093\n",
      "Batch 2. Data shape torch.Size([32, 3, 224, 224]) Loss 0.18766841292381287\n",
      "Batch 3. Data shape torch.Size([32, 3, 224, 224]) Loss 0.04618207365274429\n",
      "Batch 4. Data shape torch.Size([32, 3, 224, 224]) Loss 0.05370495840907097\n",
      "Batch 5. Data shape torch.Size([32, 3, 224, 224]) Loss 0.03368862345814705\n",
      "Batch 6. Data shape torch.Size([32, 3, 224, 224]) Loss 0.13990344107151031\n",
      "Batch 7. Data shape torch.Size([32, 3, 224, 224]) Loss 0.10496769100427628\n",
      "Batch 8. Data shape torch.Size([32, 3, 224, 224]) Loss 0.052405864000320435\n",
      "Batch 9. Data shape torch.Size([32, 3, 224, 224]) Loss 0.028415821492671967\n",
      "Batch 10. Data shape torch.Size([32, 3, 224, 224]) Loss 0.044889599084854126\n",
      "Batch 11. Data shape torch.Size([32, 3, 224, 224]) Loss 0.11177946627140045\n",
      "Batch 12. Data shape torch.Size([32, 3, 224, 224]) Loss 0.06641294807195663\n",
      "Batch 13. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08812347799539566\n",
      "Batch 14. Data shape torch.Size([32, 3, 224, 224]) Loss 0.12476865947246552\n",
      "Batch 15. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08513779938220978\n",
      "Batch 16. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1414565145969391\n",
      "Batch 17. Data shape torch.Size([32, 3, 224, 224]) Loss 0.038914963603019714\n",
      "Batch 18. Data shape torch.Size([32, 3, 224, 224]) Loss 0.11731462180614471\n",
      "Batch 19. Data shape torch.Size([32, 3, 224, 224]) Loss 0.05091279745101929\n",
      "Batch 20. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1051788181066513\n",
      "Batch 21. Data shape torch.Size([32, 3, 224, 224]) Loss 0.11397213488817215\n",
      "Batch 22. Data shape torch.Size([32, 3, 224, 224]) Loss 0.06435095518827438\n",
      "Batch 23. Data shape torch.Size([32, 3, 224, 224]) Loss 0.072332464158535\n",
      "Batch 24. Data shape torch.Size([32, 3, 224, 224]) Loss 0.023590998724102974\n",
      "Batch 25. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07918208092451096\n",
      "Batch 26. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08112499862909317\n",
      "Batch 27. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07939406484365463\n",
      "Batch 28. Data shape torch.Size([32, 3, 224, 224]) Loss 0.0906340628862381\n",
      "Batch 29. Data shape torch.Size([32, 3, 224, 224]) Loss 0.10831411182880402\n",
      "Batch 30. Data shape torch.Size([32, 3, 224, 224]) Loss 0.15751153230667114\n",
      "Batch 31. Data shape torch.Size([32, 3, 224, 224]) Loss 0.04581046849489212\n",
      "Batch 32. Data shape torch.Size([32, 3, 224, 224]) Loss 0.0493692085146904\n",
      "Batch 33. Data shape torch.Size([32, 3, 224, 224]) Loss 0.15800917148590088\n",
      "Batch 34. Data shape torch.Size([32, 3, 224, 224]) Loss 0.11381769180297852\n",
      "Batch 35. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07710389792919159\n",
      "Batch 36. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1352221816778183\n",
      "Batch 37. Data shape torch.Size([32, 3, 224, 224]) Loss 0.05828191339969635\n",
      "Batch 38. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07500703632831573\n",
      "Batch 39. Data shape torch.Size([32, 3, 224, 224]) Loss 0.10252170264720917\n",
      "Batch 40. Data shape torch.Size([22, 3, 224, 224]) Loss 0.09152691066265106\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Epoch: 35/50 | time: 7.0m 45.05s | lr: 1.0000e-05 | train/loss: 0.05892 | val/loss: 0.08726 | val/accuracy: 0.91811 | val/AUC: 0.97780 | val/Kappa: 0.85095\n",
      "Epoch: 36 Train batch 10 loss: 0.07340799272060394, 6.3% complete\n",
      "Epoch: 36 Train batch 20 loss: 0.02075570449233055, 12.6% complete\n",
      "Epoch: 36 Train batch 30 loss: 0.09261869639158249, 18.9% complete\n",
      "Epoch: 36 Train batch 40 loss: 0.04164490848779678, 25.2% complete\n",
      "Epoch: 36 Train batch 50 loss: 0.04179634153842926, 31.4% complete\n",
      "Epoch: 36 Train batch 60 loss: 0.12705381214618683, 37.7% complete\n",
      "Epoch: 36 Train batch 70 loss: 0.06178472936153412, 44.0% complete\n",
      "Epoch: 36 Train batch 80 loss: 0.03762312978506088, 50.3% complete\n",
      "Epoch: 36 Train batch 90 loss: 0.087408147752285, 56.6% complete\n",
      "Epoch: 36 Train batch 100 loss: 0.0359664261341095, 62.9% complete\n",
      "Epoch: 36 Train batch 110 loss: 0.023510819301009178, 69.2% complete\n",
      "Epoch: 36 Train batch 120 loss: 0.026380538940429688, 75.5% complete\n",
      "Epoch: 36 Train batch 130 loss: 0.005987592972815037, 81.8% complete\n",
      "Epoch: 36 Train batch 140 loss: 0.10775894671678543, 88.1% complete\n",
      "Epoch: 36 Train batch 150 loss: 0.1176503449678421, 94.3% complete\n",
      "Batch 1. Data shape torch.Size([32, 3, 224, 224]) Loss 0.12980414927005768\n",
      "Batch 2. Data shape torch.Size([32, 3, 224, 224]) Loss 0.02415338158607483\n",
      "Batch 3. Data shape torch.Size([32, 3, 224, 224]) Loss 0.062004007399082184\n",
      "Batch 4. Data shape torch.Size([32, 3, 224, 224]) Loss 0.06785432994365692\n",
      "Batch 5. Data shape torch.Size([32, 3, 224, 224]) Loss 0.213474303483963\n",
      "Batch 6. Data shape torch.Size([32, 3, 224, 224]) Loss 0.24164219200611115\n",
      "Batch 7. Data shape torch.Size([32, 3, 224, 224]) Loss 0.02332961931824684\n",
      "Batch 8. Data shape torch.Size([32, 3, 224, 224]) Loss 0.06205129250884056\n",
      "Batch 9. Data shape torch.Size([32, 3, 224, 224]) Loss 0.06645890325307846\n",
      "Batch 10. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1239096000790596\n",
      "Batch 11. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08809730410575867\n",
      "Batch 12. Data shape torch.Size([32, 3, 224, 224]) Loss 0.0898728296160698\n",
      "Batch 13. Data shape torch.Size([32, 3, 224, 224]) Loss 0.11143209785223007\n",
      "Batch 14. Data shape torch.Size([32, 3, 224, 224]) Loss 0.045654140412807465\n",
      "Batch 15. Data shape torch.Size([32, 3, 224, 224]) Loss 0.029816705733537674\n",
      "Batch 16. Data shape torch.Size([32, 3, 224, 224]) Loss 0.0777304619550705\n",
      "Batch 17. Data shape torch.Size([32, 3, 224, 224]) Loss 0.10023152083158493\n",
      "Batch 18. Data shape torch.Size([32, 3, 224, 224]) Loss 0.06716404855251312\n",
      "Batch 19. Data shape torch.Size([32, 3, 224, 224]) Loss 0.12321329861879349\n",
      "Batch 20. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09373807907104492\n",
      "Batch 21. Data shape torch.Size([32, 3, 224, 224]) Loss 0.040699444711208344\n",
      "Batch 22. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09102154523134232\n",
      "Batch 23. Data shape torch.Size([32, 3, 224, 224]) Loss 0.01929733343422413\n",
      "Batch 24. Data shape torch.Size([32, 3, 224, 224]) Loss 0.06804779171943665\n",
      "Batch 25. Data shape torch.Size([32, 3, 224, 224]) Loss 0.14280933141708374\n",
      "Batch 26. Data shape torch.Size([32, 3, 224, 224]) Loss 0.0748957097530365\n",
      "Batch 27. Data shape torch.Size([32, 3, 224, 224]) Loss 0.04251321405172348\n",
      "Batch 28. Data shape torch.Size([32, 3, 224, 224]) Loss 0.025919750332832336\n",
      "Batch 29. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08068758994340897\n",
      "Batch 30. Data shape torch.Size([32, 3, 224, 224]) Loss 0.10847674310207367\n",
      "Batch 31. Data shape torch.Size([32, 3, 224, 224]) Loss 0.0522783100605011\n",
      "Batch 32. Data shape torch.Size([32, 3, 224, 224]) Loss 0.06437863409519196\n",
      "Batch 33. Data shape torch.Size([32, 3, 224, 224]) Loss 0.20947903394699097\n",
      "Batch 34. Data shape torch.Size([32, 3, 224, 224]) Loss 0.040107667446136475\n",
      "Batch 35. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09233270585536957\n",
      "Batch 36. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07190953195095062\n",
      "Batch 37. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07585761696100235\n",
      "Batch 38. Data shape torch.Size([32, 3, 224, 224]) Loss 0.0817534402012825\n",
      "Batch 39. Data shape torch.Size([32, 3, 224, 224]) Loss 0.028446009382605553\n",
      "Batch 40. Data shape torch.Size([22, 3, 224, 224]) Loss 0.07069528847932816\n",
      "Valid loss improved from 0.086980 to 0.083081. Saving model ...\n",
      "Epoch: 36/50 | time: 7.0m 48.02s | lr: 1.0000e-05 | train/loss: 0.06080 | val/loss: 0.08308 | val/accuracy: 0.92126 | val/AUC: 0.97944 | val/Kappa: 0.85785\n",
      "Epoch: 37 Train batch 10 loss: 0.07942382991313934, 6.3% complete\n",
      "Epoch: 37 Train batch 20 loss: 0.07333999872207642, 12.6% complete\n",
      "Epoch: 37 Train batch 30 loss: 0.13966724276542664, 18.9% complete\n",
      "Epoch: 37 Train batch 40 loss: 0.04240482673048973, 25.2% complete\n",
      "Epoch: 37 Train batch 50 loss: 0.062310412526130676, 31.4% complete\n",
      "Epoch: 37 Train batch 60 loss: 0.04394582659006119, 37.7% complete\n",
      "Epoch: 37 Train batch 70 loss: 0.03361491858959198, 44.0% complete\n",
      "Epoch: 37 Train batch 80 loss: 0.05367843806743622, 50.3% complete\n",
      "Epoch: 37 Train batch 90 loss: 0.07236599922180176, 56.6% complete\n",
      "Epoch: 37 Train batch 100 loss: 0.039799440652132034, 62.9% complete\n",
      "Epoch: 37 Train batch 110 loss: 0.04315769672393799, 69.2% complete\n",
      "Epoch: 37 Train batch 120 loss: 0.09618087857961655, 75.5% complete\n",
      "Epoch: 37 Train batch 130 loss: 0.06627064943313599, 81.8% complete\n",
      "Epoch: 37 Train batch 140 loss: 0.10573503375053406, 88.1% complete\n",
      "Epoch: 37 Train batch 150 loss: 0.028073644265532494, 94.3% complete\n",
      "Batch 1. Data shape torch.Size([32, 3, 224, 224]) Loss 0.057355500757694244\n",
      "Batch 2. Data shape torch.Size([32, 3, 224, 224]) Loss 0.13321316242218018\n",
      "Batch 3. Data shape torch.Size([32, 3, 224, 224]) Loss 0.02816445380449295\n",
      "Batch 4. Data shape torch.Size([32, 3, 224, 224]) Loss 0.13667383790016174\n",
      "Batch 5. Data shape torch.Size([32, 3, 224, 224]) Loss 0.0776083692908287\n",
      "Batch 6. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08587803691625595\n",
      "Batch 7. Data shape torch.Size([32, 3, 224, 224]) Loss 0.035690054297447205\n",
      "Batch 8. Data shape torch.Size([32, 3, 224, 224]) Loss 0.10059835761785507\n",
      "Batch 9. Data shape torch.Size([32, 3, 224, 224]) Loss 0.04563499987125397\n",
      "Batch 10. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08802825957536697\n",
      "Batch 11. Data shape torch.Size([32, 3, 224, 224]) Loss 0.05225692689418793\n",
      "Batch 12. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08058169484138489\n",
      "Batch 13. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09435652196407318\n",
      "Batch 14. Data shape torch.Size([32, 3, 224, 224]) Loss 0.14869274199008942\n",
      "Batch 15. Data shape torch.Size([32, 3, 224, 224]) Loss 0.11357909440994263\n",
      "Batch 16. Data shape torch.Size([32, 3, 224, 224]) Loss 0.15252536535263062\n",
      "Batch 17. Data shape torch.Size([32, 3, 224, 224]) Loss 0.05058405548334122\n",
      "Batch 18. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07222115248441696\n",
      "Batch 19. Data shape torch.Size([32, 3, 224, 224]) Loss 0.13135769963264465\n",
      "Batch 20. Data shape torch.Size([32, 3, 224, 224]) Loss 0.056680768728256226\n",
      "Batch 21. Data shape torch.Size([32, 3, 224, 224]) Loss 0.06693297624588013\n",
      "Batch 22. Data shape torch.Size([32, 3, 224, 224]) Loss 0.05735485255718231\n",
      "Batch 23. Data shape torch.Size([32, 3, 224, 224]) Loss 0.06596028804779053\n",
      "Batch 24. Data shape torch.Size([32, 3, 224, 224]) Loss 0.017199072986841202\n",
      "Batch 25. Data shape torch.Size([32, 3, 224, 224]) Loss 0.06216253340244293\n",
      "Batch 26. Data shape torch.Size([32, 3, 224, 224]) Loss 0.050973258912563324\n",
      "Batch 27. Data shape torch.Size([32, 3, 224, 224]) Loss 0.10767954587936401\n",
      "Batch 28. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1554785519838333\n",
      "Batch 29. Data shape torch.Size([32, 3, 224, 224]) Loss 0.061720870435237885\n",
      "Batch 30. Data shape torch.Size([32, 3, 224, 224]) Loss 0.03882652893662453\n",
      "Batch 31. Data shape torch.Size([32, 3, 224, 224]) Loss 0.046624746173620224\n",
      "Batch 32. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09558141231536865\n",
      "Batch 33. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1657453179359436\n",
      "Batch 34. Data shape torch.Size([32, 3, 224, 224]) Loss 0.019351188093423843\n",
      "Batch 35. Data shape torch.Size([32, 3, 224, 224]) Loss 0.12984652817249298\n",
      "Batch 36. Data shape torch.Size([32, 3, 224, 224]) Loss 0.17532576620578766\n",
      "Batch 37. Data shape torch.Size([32, 3, 224, 224]) Loss 0.0657346174120903\n",
      "Batch 38. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09438268840312958\n",
      "Batch 39. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07396230101585388\n",
      "Batch 40. Data shape torch.Size([22, 3, 224, 224]) Loss 0.07625029981136322\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Epoch: 37/50 | time: 7.0m 33.88s | lr: 1.0000e-05 | train/loss: 0.05911 | val/loss: 0.08422 | val/accuracy: 0.91732 | val/AUC: 0.97884 | val/Kappa: 0.85145\n",
      "Epoch: 38 Train batch 10 loss: 0.03329899162054062, 6.3% complete\n",
      "Epoch: 38 Train batch 20 loss: 0.05742071568965912, 12.6% complete\n",
      "Epoch: 38 Train batch 30 loss: 0.07747963815927505, 18.9% complete\n",
      "Epoch: 38 Train batch 40 loss: 0.0367044061422348, 25.2% complete\n",
      "Epoch: 38 Train batch 50 loss: 0.025041773915290833, 31.4% complete\n",
      "Epoch: 38 Train batch 60 loss: 0.10798778384923935, 37.7% complete\n",
      "Epoch: 38 Train batch 70 loss: 0.06588620692491531, 44.0% complete\n",
      "Epoch: 38 Train batch 80 loss: 0.017498698085546494, 50.3% complete\n",
      "Epoch: 38 Train batch 90 loss: 0.037349067628383636, 56.6% complete\n",
      "Epoch: 38 Train batch 100 loss: 0.024796394631266594, 62.9% complete\n",
      "Epoch: 38 Train batch 110 loss: 0.03342461585998535, 69.2% complete\n",
      "Epoch: 38 Train batch 120 loss: 0.06334242969751358, 75.5% complete\n",
      "Epoch: 38 Train batch 130 loss: 0.014787431806325912, 81.8% complete\n",
      "Epoch: 38 Train batch 140 loss: 0.020076792687177658, 88.1% complete\n",
      "Epoch: 38 Train batch 150 loss: 0.05293336883187294, 94.3% complete\n",
      "Batch 1. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07694718986749649\n",
      "Batch 2. Data shape torch.Size([32, 3, 224, 224]) Loss 0.15266048908233643\n",
      "Batch 3. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08838392794132233\n",
      "Batch 4. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08614088594913483\n",
      "Batch 5. Data shape torch.Size([32, 3, 224, 224]) Loss 0.0314769446849823\n",
      "Batch 6. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08062995970249176\n",
      "Batch 7. Data shape torch.Size([32, 3, 224, 224]) Loss 0.040716201066970825\n",
      "Batch 8. Data shape torch.Size([32, 3, 224, 224]) Loss 0.03216700255870819\n",
      "Batch 9. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08126290887594223\n",
      "Batch 10. Data shape torch.Size([32, 3, 224, 224]) Loss 0.053881190717220306\n",
      "Batch 11. Data shape torch.Size([32, 3, 224, 224]) Loss 0.050013720989227295\n",
      "Batch 12. Data shape torch.Size([32, 3, 224, 224]) Loss 0.084892138838768\n",
      "Batch 13. Data shape torch.Size([32, 3, 224, 224]) Loss 0.10232707858085632\n",
      "Batch 14. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07640144973993301\n",
      "Batch 15. Data shape torch.Size([32, 3, 224, 224]) Loss 0.055553290992975235\n",
      "Batch 16. Data shape torch.Size([32, 3, 224, 224]) Loss 0.03133117035031319\n",
      "Batch 17. Data shape torch.Size([32, 3, 224, 224]) Loss 0.13368849456310272\n",
      "Batch 18. Data shape torch.Size([32, 3, 224, 224]) Loss 0.12603910267353058\n",
      "Batch 19. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09644928574562073\n",
      "Batch 20. Data shape torch.Size([32, 3, 224, 224]) Loss 0.16792908310890198\n",
      "Batch 21. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07674989104270935\n",
      "Batch 22. Data shape torch.Size([32, 3, 224, 224]) Loss 0.057025760412216187\n",
      "Batch 23. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09945186227560043\n",
      "Batch 24. Data shape torch.Size([32, 3, 224, 224]) Loss 0.10131005942821503\n",
      "Batch 25. Data shape torch.Size([32, 3, 224, 224]) Loss 0.13192208111286163\n",
      "Batch 26. Data shape torch.Size([32, 3, 224, 224]) Loss 0.052799396216869354\n",
      "Batch 27. Data shape torch.Size([32, 3, 224, 224]) Loss 0.13054771721363068\n",
      "Batch 28. Data shape torch.Size([32, 3, 224, 224]) Loss 0.13333800435066223\n",
      "Batch 29. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08605466037988663\n",
      "Batch 30. Data shape torch.Size([32, 3, 224, 224]) Loss 0.03287506103515625\n",
      "Batch 31. Data shape torch.Size([32, 3, 224, 224]) Loss 0.0633736252784729\n",
      "Batch 32. Data shape torch.Size([32, 3, 224, 224]) Loss 0.06515473127365112\n",
      "Batch 33. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07740511000156403\n",
      "Batch 34. Data shape torch.Size([32, 3, 224, 224]) Loss 0.036618415266275406\n",
      "Batch 35. Data shape torch.Size([32, 3, 224, 224]) Loss 0.13653156161308289\n",
      "Batch 36. Data shape torch.Size([32, 3, 224, 224]) Loss 0.045361004769802094\n",
      "Batch 37. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09428635984659195\n",
      "Batch 38. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08323514461517334\n",
      "Batch 39. Data shape torch.Size([32, 3, 224, 224]) Loss 0.056418389081954956\n",
      "Batch 40. Data shape torch.Size([22, 3, 224, 224]) Loss 0.09538299590349197\n",
      "Valid loss improved from 0.083081 to 0.082618. Saving model ...\n",
      "Epoch: 38/50 | time: 7.0m 47.56s | lr: 1.0000e-05 | train/loss: 0.05748 | val/loss: 0.08262 | val/accuracy: 0.92756 | val/AUC: 0.98004 | val/Kappa: 0.86885\n",
      "Epoch: 39 Train batch 10 loss: 0.07862164825201035, 6.3% complete\n",
      "Epoch: 39 Train batch 20 loss: 0.08739099651575089, 12.6% complete\n",
      "Epoch: 39 Train batch 30 loss: 0.07369579374790192, 18.9% complete\n",
      "Epoch: 39 Train batch 40 loss: 0.0425696037709713, 25.2% complete\n",
      "Epoch: 39 Train batch 50 loss: 0.052866414189338684, 31.4% complete\n",
      "Epoch: 39 Train batch 60 loss: 0.082842618227005, 37.7% complete\n",
      "Epoch: 39 Train batch 70 loss: 0.051307253539562225, 44.0% complete\n",
      "Epoch: 39 Train batch 80 loss: 0.08014931529760361, 50.3% complete\n",
      "Epoch: 39 Train batch 90 loss: 0.04924476146697998, 56.6% complete\n",
      "Epoch: 39 Train batch 100 loss: 0.024343838915228844, 62.9% complete\n",
      "Epoch: 39 Train batch 110 loss: 0.05027254670858383, 69.2% complete\n",
      "Epoch: 39 Train batch 120 loss: 0.032256487756967545, 75.5% complete\n",
      "Epoch: 39 Train batch 130 loss: 0.0949074774980545, 81.8% complete\n",
      "Epoch: 39 Train batch 140 loss: 0.06639528274536133, 88.1% complete\n",
      "Epoch: 39 Train batch 150 loss: 0.04866309463977814, 94.3% complete\n",
      "Batch 1. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1001717820763588\n",
      "Batch 2. Data shape torch.Size([32, 3, 224, 224]) Loss 0.04844975098967552\n",
      "Batch 3. Data shape torch.Size([32, 3, 224, 224]) Loss 0.02532300166785717\n",
      "Batch 4. Data shape torch.Size([32, 3, 224, 224]) Loss 0.06262233853340149\n",
      "Batch 5. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08707800507545471\n",
      "Batch 6. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1224939227104187\n",
      "Batch 7. Data shape torch.Size([32, 3, 224, 224]) Loss 0.06551070511341095\n",
      "Batch 8. Data shape torch.Size([32, 3, 224, 224]) Loss 0.02453552559018135\n",
      "Batch 9. Data shape torch.Size([32, 3, 224, 224]) Loss 0.014712976291775703\n",
      "Batch 10. Data shape torch.Size([32, 3, 224, 224]) Loss 0.034838926047086716\n",
      "Batch 11. Data shape torch.Size([32, 3, 224, 224]) Loss 0.12559378147125244\n",
      "Batch 12. Data shape torch.Size([32, 3, 224, 224]) Loss 0.17862486839294434\n",
      "Batch 13. Data shape torch.Size([32, 3, 224, 224]) Loss 0.050349388271570206\n",
      "Batch 14. Data shape torch.Size([32, 3, 224, 224]) Loss 0.06684097647666931\n",
      "Batch 15. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07432308048009872\n",
      "Batch 16. Data shape torch.Size([32, 3, 224, 224]) Loss 0.045078735798597336\n",
      "Batch 17. Data shape torch.Size([32, 3, 224, 224]) Loss 0.13926416635513306\n",
      "Batch 18. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1020205020904541\n",
      "Batch 19. Data shape torch.Size([32, 3, 224, 224]) Loss 0.04252780228853226\n",
      "Batch 20. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07976417243480682\n",
      "Batch 21. Data shape torch.Size([32, 3, 224, 224]) Loss 0.21984350681304932\n",
      "Batch 22. Data shape torch.Size([32, 3, 224, 224]) Loss 0.06846236437559128\n",
      "Batch 23. Data shape torch.Size([32, 3, 224, 224]) Loss 0.04535772651433945\n",
      "Batch 24. Data shape torch.Size([32, 3, 224, 224]) Loss 0.18256166577339172\n",
      "Batch 25. Data shape torch.Size([32, 3, 224, 224]) Loss 0.05563303455710411\n",
      "Batch 26. Data shape torch.Size([32, 3, 224, 224]) Loss 0.048863548785448074\n",
      "Batch 27. Data shape torch.Size([32, 3, 224, 224]) Loss 0.23776644468307495\n",
      "Batch 28. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1018022894859314\n",
      "Batch 29. Data shape torch.Size([32, 3, 224, 224]) Loss 0.0747513696551323\n",
      "Batch 30. Data shape torch.Size([32, 3, 224, 224]) Loss 0.19765059649944305\n",
      "Batch 31. Data shape torch.Size([32, 3, 224, 224]) Loss 0.043350860476493835\n",
      "Batch 32. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08963043242692947\n",
      "Batch 33. Data shape torch.Size([32, 3, 224, 224]) Loss 0.049835335463285446\n",
      "Batch 34. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09631503373384476\n",
      "Batch 35. Data shape torch.Size([32, 3, 224, 224]) Loss 0.047099530696868896\n",
      "Batch 36. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09901099652051926\n",
      "Batch 37. Data shape torch.Size([32, 3, 224, 224]) Loss 0.042330604046583176\n",
      "Batch 38. Data shape torch.Size([32, 3, 224, 224]) Loss 0.041261062026023865\n",
      "Batch 39. Data shape torch.Size([32, 3, 224, 224]) Loss 0.20123961567878723\n",
      "Batch 40. Data shape torch.Size([22, 3, 224, 224]) Loss 0.04194479435682297\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Epoch: 39/50 | time: 8.0m 4.133s | lr: 1.0000e-05 | train/loss: 0.05623 | val/loss: 0.08687 | val/accuracy: 0.91024 | val/AUC: 0.97870 | val/Kappa: 0.83478\n",
      "Epoch: 40 Train batch 10 loss: 0.03306996077299118, 6.3% complete\n",
      "Epoch: 40 Train batch 20 loss: 0.10851654410362244, 12.6% complete\n",
      "Epoch: 40 Train batch 30 loss: 0.01702766865491867, 18.9% complete\n",
      "Epoch: 40 Train batch 40 loss: 0.0485791340470314, 25.2% complete\n",
      "Epoch: 40 Train batch 50 loss: 0.021968506276607513, 31.4% complete\n",
      "Epoch: 40 Train batch 60 loss: 0.06810559332370758, 37.7% complete\n",
      "Epoch: 40 Train batch 70 loss: 0.029477452859282494, 44.0% complete\n",
      "Epoch: 40 Train batch 80 loss: 0.03433962166309357, 50.3% complete\n",
      "Epoch: 40 Train batch 90 loss: 0.005808557383716106, 56.6% complete\n",
      "Epoch: 40 Train batch 100 loss: 0.06798852235078812, 62.9% complete\n",
      "Epoch: 40 Train batch 110 loss: 0.09244410693645477, 69.2% complete\n",
      "Epoch: 40 Train batch 120 loss: 0.019350724294781685, 75.5% complete\n",
      "Epoch: 40 Train batch 130 loss: 0.08058325946331024, 81.8% complete\n",
      "Epoch: 40 Train batch 140 loss: 0.08401502668857574, 88.1% complete\n",
      "Epoch: 40 Train batch 150 loss: 0.05200815200805664, 94.3% complete\n",
      "Batch 1. Data shape torch.Size([32, 3, 224, 224]) Loss 0.039223648607730865\n",
      "Batch 2. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07643528282642365\n",
      "Batch 3. Data shape torch.Size([32, 3, 224, 224]) Loss 0.0590374693274498\n",
      "Batch 4. Data shape torch.Size([32, 3, 224, 224]) Loss 0.06430637836456299\n",
      "Batch 5. Data shape torch.Size([32, 3, 224, 224]) Loss 0.0357121080160141\n",
      "Batch 6. Data shape torch.Size([32, 3, 224, 224]) Loss 0.03645412623882294\n",
      "Batch 7. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08842016756534576\n",
      "Batch 8. Data shape torch.Size([32, 3, 224, 224]) Loss 0.05524319410324097\n",
      "Batch 9. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09212084114551544\n",
      "Batch 10. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1712454855442047\n",
      "Batch 11. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1130455881357193\n",
      "Batch 12. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07358017563819885\n",
      "Batch 13. Data shape torch.Size([32, 3, 224, 224]) Loss 0.10742007195949554\n",
      "Batch 14. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1905129849910736\n",
      "Batch 15. Data shape torch.Size([32, 3, 224, 224]) Loss 0.05041965842247009\n",
      "Batch 16. Data shape torch.Size([32, 3, 224, 224]) Loss 0.10347907245159149\n",
      "Batch 17. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09712252765893936\n",
      "Batch 18. Data shape torch.Size([32, 3, 224, 224]) Loss 0.10080583393573761\n",
      "Batch 19. Data shape torch.Size([32, 3, 224, 224]) Loss 0.044635921716690063\n",
      "Batch 20. Data shape torch.Size([32, 3, 224, 224]) Loss 0.056354403495788574\n",
      "Batch 21. Data shape torch.Size([32, 3, 224, 224]) Loss 0.04600829631090164\n",
      "Batch 22. Data shape torch.Size([32, 3, 224, 224]) Loss 0.01813104748725891\n",
      "Batch 23. Data shape torch.Size([32, 3, 224, 224]) Loss 0.030924204736948013\n",
      "Batch 24. Data shape torch.Size([32, 3, 224, 224]) Loss 0.18791522085666656\n",
      "Batch 25. Data shape torch.Size([32, 3, 224, 224]) Loss 0.012138421647250652\n",
      "Batch 26. Data shape torch.Size([32, 3, 224, 224]) Loss 0.14494073390960693\n",
      "Batch 27. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09868744015693665\n",
      "Batch 28. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1112288162112236\n",
      "Batch 29. Data shape torch.Size([32, 3, 224, 224]) Loss 0.04702039062976837\n",
      "Batch 30. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07308872044086456\n",
      "Batch 31. Data shape torch.Size([32, 3, 224, 224]) Loss 0.2143486738204956\n",
      "Batch 32. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09931787848472595\n",
      "Batch 33. Data shape torch.Size([32, 3, 224, 224]) Loss 0.13728387653827667\n",
      "Batch 34. Data shape torch.Size([32, 3, 224, 224]) Loss 0.12301235646009445\n",
      "Batch 35. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07649042457342148\n",
      "Batch 36. Data shape torch.Size([32, 3, 224, 224]) Loss 0.06910353153944016\n",
      "Batch 37. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08156069368124008\n",
      "Batch 38. Data shape torch.Size([32, 3, 224, 224]) Loss 0.02749442681670189\n",
      "Batch 39. Data shape torch.Size([32, 3, 224, 224]) Loss 0.04380747303366661\n",
      "Batch 40. Data shape torch.Size([22, 3, 224, 224]) Loss 0.15913954377174377\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Epoch: 40/50 | time: 7.0m 41.21s | lr: 1.0000e-05 | train/loss: 0.05560 | val/loss: 0.08643 | val/accuracy: 0.92047 | val/AUC: 0.97776 | val/Kappa: 0.85521\n",
      "Epoch: 41 Train batch 10 loss: 0.09597999602556229, 6.3% complete\n",
      "Epoch: 41 Train batch 20 loss: 0.1059855967760086, 12.6% complete\n",
      "Epoch: 41 Train batch 30 loss: 0.05367862805724144, 18.9% complete\n",
      "Epoch: 41 Train batch 40 loss: 0.05297715216875076, 25.2% complete\n",
      "Epoch: 41 Train batch 50 loss: 0.09754157066345215, 31.4% complete\n",
      "Epoch: 41 Train batch 60 loss: 0.0308541227132082, 37.7% complete\n",
      "Epoch: 41 Train batch 70 loss: 0.02634485997259617, 44.0% complete\n",
      "Epoch: 41 Train batch 80 loss: 0.02414865233004093, 50.3% complete\n",
      "Epoch: 41 Train batch 90 loss: 0.07812682539224625, 56.6% complete\n",
      "Epoch: 41 Train batch 100 loss: 0.06538891047239304, 62.9% complete\n",
      "Epoch: 41 Train batch 110 loss: 0.0873236134648323, 69.2% complete\n",
      "Epoch: 41 Train batch 120 loss: 0.1164066269993782, 75.5% complete\n",
      "Epoch: 41 Train batch 130 loss: 0.1579783409833908, 81.8% complete\n",
      "Epoch: 41 Train batch 140 loss: 0.026081811636686325, 88.1% complete\n",
      "Epoch: 41 Train batch 150 loss: 0.014388409443199635, 94.3% complete\n",
      "Batch 1. Data shape torch.Size([32, 3, 224, 224]) Loss 0.06163811683654785\n",
      "Batch 2. Data shape torch.Size([32, 3, 224, 224]) Loss 0.05862920358777046\n",
      "Batch 3. Data shape torch.Size([32, 3, 224, 224]) Loss 0.05723896995186806\n",
      "Batch 4. Data shape torch.Size([32, 3, 224, 224]) Loss 0.11144711822271347\n",
      "Batch 5. Data shape torch.Size([32, 3, 224, 224]) Loss 0.03758108615875244\n",
      "Batch 6. Data shape torch.Size([32, 3, 224, 224]) Loss 0.04169946163892746\n",
      "Batch 7. Data shape torch.Size([32, 3, 224, 224]) Loss 0.0806635171175003\n",
      "Batch 8. Data shape torch.Size([32, 3, 224, 224]) Loss 0.06703214347362518\n",
      "Batch 9. Data shape torch.Size([32, 3, 224, 224]) Loss 0.025448139756917953\n",
      "Batch 10. Data shape torch.Size([32, 3, 224, 224]) Loss 0.01883009448647499\n",
      "Batch 11. Data shape torch.Size([32, 3, 224, 224]) Loss 0.0953385978937149\n",
      "Batch 12. Data shape torch.Size([32, 3, 224, 224]) Loss 0.14375489950180054\n",
      "Batch 13. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07232227176427841\n",
      "Batch 14. Data shape torch.Size([32, 3, 224, 224]) Loss 0.13870373368263245\n",
      "Batch 15. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1395171582698822\n",
      "Batch 16. Data shape torch.Size([32, 3, 224, 224]) Loss 0.024546239525079727\n",
      "Batch 17. Data shape torch.Size([32, 3, 224, 224]) Loss 0.02575254812836647\n",
      "Batch 18. Data shape torch.Size([32, 3, 224, 224]) Loss 0.054515667259693146\n",
      "Batch 19. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07604394853115082\n",
      "Batch 20. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09534701704978943\n",
      "Batch 21. Data shape torch.Size([32, 3, 224, 224]) Loss 0.0586351677775383\n",
      "Batch 22. Data shape torch.Size([32, 3, 224, 224]) Loss 0.06016722321510315\n",
      "Batch 23. Data shape torch.Size([32, 3, 224, 224]) Loss 0.06748780608177185\n",
      "Batch 24. Data shape torch.Size([32, 3, 224, 224]) Loss 0.06608439981937408\n",
      "Batch 25. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09209700673818588\n",
      "Batch 26. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08060102164745331\n",
      "Batch 27. Data shape torch.Size([32, 3, 224, 224]) Loss 0.005059818737208843\n",
      "Batch 28. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1237855777144432\n",
      "Batch 29. Data shape torch.Size([32, 3, 224, 224]) Loss 0.021649811416864395\n",
      "Batch 30. Data shape torch.Size([32, 3, 224, 224]) Loss 0.19475243985652924\n",
      "Batch 31. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1914089173078537\n",
      "Batch 32. Data shape torch.Size([32, 3, 224, 224]) Loss 0.11144357919692993\n",
      "Batch 33. Data shape torch.Size([32, 3, 224, 224]) Loss 0.06592296808958054\n",
      "Batch 34. Data shape torch.Size([32, 3, 224, 224]) Loss 0.06930118799209595\n",
      "Batch 35. Data shape torch.Size([32, 3, 224, 224]) Loss 0.06615909934043884\n",
      "Batch 36. Data shape torch.Size([32, 3, 224, 224]) Loss 0.048940710723400116\n",
      "Batch 37. Data shape torch.Size([32, 3, 224, 224]) Loss 0.12001105397939682\n",
      "Batch 38. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07612940669059753\n",
      "Batch 39. Data shape torch.Size([32, 3, 224, 224]) Loss 0.18911093473434448\n",
      "Batch 40. Data shape torch.Size([22, 3, 224, 224]) Loss 0.03358808904886246\n",
      "Valid loss improved from 0.082618 to 0.079210. Saving model ...\n",
      "Epoch: 41/50 | time: 7.0m 52.92s | lr: 1.0000e-05 | train/loss: 0.05201 | val/loss: 0.07921 | val/accuracy: 0.92441 | val/AUC: 0.98111 | val/Kappa: 0.86235\n",
      "Epoch: 42 Train batch 10 loss: 0.027303798124194145, 6.3% complete\n",
      "Epoch: 42 Train batch 20 loss: 0.03691818565130234, 12.6% complete\n",
      "Epoch: 42 Train batch 30 loss: 0.012941471301019192, 18.9% complete\n",
      "Epoch: 42 Train batch 40 loss: 0.011448548175394535, 25.2% complete\n",
      "Epoch: 42 Train batch 50 loss: 0.03578123450279236, 31.4% complete\n",
      "Epoch: 42 Train batch 60 loss: 0.017481256276369095, 37.7% complete\n",
      "Epoch: 42 Train batch 70 loss: 0.07229030877351761, 44.0% complete\n",
      "Epoch: 42 Train batch 80 loss: 0.02035406231880188, 50.3% complete\n",
      "Epoch: 42 Train batch 90 loss: 0.02630634605884552, 56.6% complete\n",
      "Epoch: 42 Train batch 100 loss: 0.05529806762933731, 62.9% complete\n",
      "Epoch: 42 Train batch 110 loss: 0.09490987658500671, 69.2% complete\n",
      "Epoch: 42 Train batch 120 loss: 0.06632959097623825, 75.5% complete\n",
      "Epoch: 42 Train batch 130 loss: 0.03631115332245827, 81.8% complete\n",
      "Epoch: 42 Train batch 140 loss: 0.035001397132873535, 88.1% complete\n",
      "Epoch: 42 Train batch 150 loss: 0.06420435011386871, 94.3% complete\n",
      "Batch 1. Data shape torch.Size([32, 3, 224, 224]) Loss 0.03332929313182831\n",
      "Batch 2. Data shape torch.Size([32, 3, 224, 224]) Loss 0.038650281727313995\n",
      "Batch 3. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08820898085832596\n",
      "Batch 4. Data shape torch.Size([32, 3, 224, 224]) Loss 0.0790448784828186\n",
      "Batch 5. Data shape torch.Size([32, 3, 224, 224]) Loss 0.05512263998389244\n",
      "Batch 6. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07372531294822693\n",
      "Batch 7. Data shape torch.Size([32, 3, 224, 224]) Loss 0.041563890874385834\n",
      "Batch 8. Data shape torch.Size([32, 3, 224, 224]) Loss 0.05003156512975693\n",
      "Batch 9. Data shape torch.Size([32, 3, 224, 224]) Loss 0.03803348168730736\n",
      "Batch 10. Data shape torch.Size([32, 3, 224, 224]) Loss 0.0417683869600296\n",
      "Batch 11. Data shape torch.Size([32, 3, 224, 224]) Loss 0.04630708694458008\n",
      "Batch 12. Data shape torch.Size([32, 3, 224, 224]) Loss 0.27992182970046997\n",
      "Batch 13. Data shape torch.Size([32, 3, 224, 224]) Loss 0.0654563158750534\n",
      "Batch 14. Data shape torch.Size([32, 3, 224, 224]) Loss 0.14440298080444336\n",
      "Batch 15. Data shape torch.Size([32, 3, 224, 224]) Loss 0.035451993346214294\n",
      "Batch 16. Data shape torch.Size([32, 3, 224, 224]) Loss 0.19599252939224243\n",
      "Batch 17. Data shape torch.Size([32, 3, 224, 224]) Loss 0.014692096039652824\n",
      "Batch 18. Data shape torch.Size([32, 3, 224, 224]) Loss 0.10483665764331818\n",
      "Batch 19. Data shape torch.Size([32, 3, 224, 224]) Loss 0.15660665929317474\n",
      "Batch 20. Data shape torch.Size([32, 3, 224, 224]) Loss 0.04168100282549858\n",
      "Batch 21. Data shape torch.Size([32, 3, 224, 224]) Loss 0.04608069360256195\n",
      "Batch 22. Data shape torch.Size([32, 3, 224, 224]) Loss 0.056212034076452255\n",
      "Batch 23. Data shape torch.Size([32, 3, 224, 224]) Loss 0.06669884920120239\n",
      "Batch 24. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09429842233657837\n",
      "Batch 25. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1457958072423935\n",
      "Batch 26. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07344818115234375\n",
      "Batch 27. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07989341765642166\n",
      "Batch 28. Data shape torch.Size([32, 3, 224, 224]) Loss 0.04297376424074173\n",
      "Batch 29. Data shape torch.Size([32, 3, 224, 224]) Loss 0.12165603041648865\n",
      "Batch 30. Data shape torch.Size([32, 3, 224, 224]) Loss 0.13140666484832764\n",
      "Batch 31. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09129272401332855\n",
      "Batch 32. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1966741383075714\n",
      "Batch 33. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08219066262245178\n",
      "Batch 34. Data shape torch.Size([32, 3, 224, 224]) Loss 0.24216794967651367\n",
      "Batch 35. Data shape torch.Size([32, 3, 224, 224]) Loss 0.04202237352728844\n",
      "Batch 36. Data shape torch.Size([32, 3, 224, 224]) Loss 0.06980658322572708\n",
      "Batch 37. Data shape torch.Size([32, 3, 224, 224]) Loss 0.17095570266246796\n",
      "Batch 38. Data shape torch.Size([32, 3, 224, 224]) Loss 0.02221027761697769\n",
      "Batch 39. Data shape torch.Size([32, 3, 224, 224]) Loss 0.03570001199841499\n",
      "Batch 40. Data shape torch.Size([22, 3, 224, 224]) Loss 0.07053831964731216\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Epoch: 42/50 | time: 7.0m 56.18s | lr: 1.0000e-05 | train/loss: 0.05467 | val/loss: 0.08767 | val/accuracy: 0.91575 | val/AUC: 0.97780 | val/Kappa: 0.84793\n",
      "Epoch: 43 Train batch 10 loss: 0.023632928729057312, 6.3% complete\n",
      "Epoch: 43 Train batch 20 loss: 0.07977412641048431, 12.6% complete\n",
      "Epoch: 43 Train batch 30 loss: 0.09045824408531189, 18.9% complete\n",
      "Epoch: 43 Train batch 40 loss: 0.053161151707172394, 25.2% complete\n",
      "Epoch: 43 Train batch 50 loss: 0.02876255474984646, 31.4% complete\n",
      "Epoch: 43 Train batch 60 loss: 0.08034435659646988, 37.7% complete\n",
      "Epoch: 43 Train batch 70 loss: 0.039144039154052734, 44.0% complete\n",
      "Epoch: 43 Train batch 80 loss: 0.07394544780254364, 50.3% complete\n",
      "Epoch: 43 Train batch 90 loss: 0.06896685808897018, 56.6% complete\n",
      "Epoch: 43 Train batch 100 loss: 0.06048344075679779, 62.9% complete\n",
      "Epoch: 43 Train batch 110 loss: 0.021990692242980003, 69.2% complete\n",
      "Epoch: 43 Train batch 120 loss: 0.06374172121286392, 75.5% complete\n",
      "Epoch: 43 Train batch 130 loss: 0.03449084982275963, 81.8% complete\n",
      "Epoch: 43 Train batch 140 loss: 0.05417357012629509, 88.1% complete\n",
      "Epoch: 43 Train batch 150 loss: 0.0234842412173748, 94.3% complete\n",
      "Batch 1. Data shape torch.Size([32, 3, 224, 224]) Loss 0.01659528911113739\n",
      "Batch 2. Data shape torch.Size([32, 3, 224, 224]) Loss 0.049812741577625275\n",
      "Batch 3. Data shape torch.Size([32, 3, 224, 224]) Loss 0.04781510308384895\n",
      "Batch 4. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08187563717365265\n",
      "Batch 5. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1344245970249176\n",
      "Batch 6. Data shape torch.Size([32, 3, 224, 224]) Loss 0.05629061535000801\n",
      "Batch 7. Data shape torch.Size([32, 3, 224, 224]) Loss 0.016235671937465668\n",
      "Batch 8. Data shape torch.Size([32, 3, 224, 224]) Loss 0.16616159677505493\n",
      "Batch 9. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09209533780813217\n",
      "Batch 10. Data shape torch.Size([32, 3, 224, 224]) Loss 0.11525005102157593\n",
      "Batch 11. Data shape torch.Size([32, 3, 224, 224]) Loss 0.016677716746926308\n",
      "Batch 12. Data shape torch.Size([32, 3, 224, 224]) Loss 0.026651712134480476\n",
      "Batch 13. Data shape torch.Size([32, 3, 224, 224]) Loss 0.06783206015825272\n",
      "Batch 14. Data shape torch.Size([32, 3, 224, 224]) Loss 0.10905265808105469\n",
      "Batch 15. Data shape torch.Size([32, 3, 224, 224]) Loss 0.19679462909698486\n",
      "Batch 16. Data shape torch.Size([32, 3, 224, 224]) Loss 0.0712786465883255\n",
      "Batch 17. Data shape torch.Size([32, 3, 224, 224]) Loss 0.019385404884815216\n",
      "Batch 18. Data shape torch.Size([32, 3, 224, 224]) Loss 0.11693207919597626\n",
      "Batch 19. Data shape torch.Size([32, 3, 224, 224]) Loss 0.03927410766482353\n",
      "Batch 20. Data shape torch.Size([32, 3, 224, 224]) Loss 0.17814841866493225\n",
      "Batch 21. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09979710727930069\n",
      "Batch 22. Data shape torch.Size([32, 3, 224, 224]) Loss 0.022067615762352943\n",
      "Batch 23. Data shape torch.Size([32, 3, 224, 224]) Loss 0.13252009451389313\n",
      "Batch 24. Data shape torch.Size([32, 3, 224, 224]) Loss 0.055520690977573395\n",
      "Batch 25. Data shape torch.Size([32, 3, 224, 224]) Loss 0.03328567370772362\n",
      "Batch 26. Data shape torch.Size([32, 3, 224, 224]) Loss 0.15508168935775757\n",
      "Batch 27. Data shape torch.Size([32, 3, 224, 224]) Loss 0.2283996045589447\n",
      "Batch 28. Data shape torch.Size([32, 3, 224, 224]) Loss 0.06049754470586777\n",
      "Batch 29. Data shape torch.Size([32, 3, 224, 224]) Loss 0.10795269161462784\n",
      "Batch 30. Data shape torch.Size([32, 3, 224, 224]) Loss 0.05620630085468292\n",
      "Batch 31. Data shape torch.Size([32, 3, 224, 224]) Loss 0.015658598393201828\n",
      "Batch 32. Data shape torch.Size([32, 3, 224, 224]) Loss 0.04147354140877724\n",
      "Batch 33. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1140582412481308\n",
      "Batch 34. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08774655312299728\n",
      "Batch 35. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08441765606403351\n",
      "Batch 36. Data shape torch.Size([32, 3, 224, 224]) Loss 0.14189296960830688\n",
      "Batch 37. Data shape torch.Size([32, 3, 224, 224]) Loss 0.031456783413887024\n",
      "Batch 38. Data shape torch.Size([32, 3, 224, 224]) Loss 0.11616655439138412\n",
      "Batch 39. Data shape torch.Size([32, 3, 224, 224]) Loss 0.05679986625909805\n",
      "Batch 40. Data shape torch.Size([22, 3, 224, 224]) Loss 0.1501672863960266\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Epoch: 43/50 | time: 8.0m 29.36s | lr: 1.0000e-05 | train/loss: 0.05109 | val/loss: 0.08524 | val/accuracy: 0.92126 | val/AUC: 0.98059 | val/Kappa: 0.85554\n",
      "Epoch: 44 Train batch 10 loss: 0.01964757964015007, 6.3% complete\n",
      "Epoch: 44 Train batch 20 loss: 0.04899141937494278, 12.6% complete\n",
      "Epoch: 44 Train batch 30 loss: 0.029509462416172028, 18.9% complete\n",
      "Epoch: 44 Train batch 40 loss: 0.09437444061040878, 25.2% complete\n",
      "Epoch: 44 Train batch 50 loss: 0.038122598081827164, 31.4% complete\n",
      "Epoch: 44 Train batch 60 loss: 0.02459455281496048, 37.7% complete\n",
      "Epoch: 44 Train batch 70 loss: 0.05206261947751045, 44.0% complete\n",
      "Epoch: 44 Train batch 80 loss: 0.036950066685676575, 50.3% complete\n",
      "Epoch: 44 Train batch 90 loss: 0.0610724613070488, 56.6% complete\n",
      "Epoch: 44 Train batch 100 loss: 0.029343005269765854, 62.9% complete\n",
      "Epoch: 44 Train batch 110 loss: 0.0428973026573658, 69.2% complete\n",
      "Epoch: 44 Train batch 120 loss: 0.009264577180147171, 75.5% complete\n",
      "Epoch: 44 Train batch 130 loss: 0.07358206063508987, 81.8% complete\n",
      "Epoch: 44 Train batch 140 loss: 0.047025565057992935, 88.1% complete\n",
      "Epoch: 44 Train batch 150 loss: 0.1265190839767456, 94.3% complete\n",
      "Batch 1. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1409856081008911\n",
      "Batch 2. Data shape torch.Size([32, 3, 224, 224]) Loss 0.05211086571216583\n",
      "Batch 3. Data shape torch.Size([32, 3, 224, 224]) Loss 0.13639295101165771\n",
      "Batch 4. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1545247733592987\n",
      "Batch 5. Data shape torch.Size([32, 3, 224, 224]) Loss 0.05607818812131882\n",
      "Batch 6. Data shape torch.Size([32, 3, 224, 224]) Loss 0.0426446869969368\n",
      "Batch 7. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07873715460300446\n",
      "Batch 8. Data shape torch.Size([32, 3, 224, 224]) Loss 0.10929876565933228\n",
      "Batch 9. Data shape torch.Size([32, 3, 224, 224]) Loss 0.11006700247526169\n",
      "Batch 10. Data shape torch.Size([32, 3, 224, 224]) Loss 0.03355629742145538\n",
      "Batch 11. Data shape torch.Size([32, 3, 224, 224]) Loss 0.05126174911856651\n",
      "Batch 12. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09897170215845108\n",
      "Batch 13. Data shape torch.Size([32, 3, 224, 224]) Loss 0.04066997393965721\n",
      "Batch 14. Data shape torch.Size([32, 3, 224, 224]) Loss 0.057498857378959656\n",
      "Batch 15. Data shape torch.Size([32, 3, 224, 224]) Loss 0.10356369614601135\n",
      "Batch 16. Data shape torch.Size([32, 3, 224, 224]) Loss 0.14945869147777557\n",
      "Batch 17. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07898548245429993\n",
      "Batch 18. Data shape torch.Size([32, 3, 224, 224]) Loss 0.01680450141429901\n",
      "Batch 19. Data shape torch.Size([32, 3, 224, 224]) Loss 0.022094696760177612\n",
      "Batch 20. Data shape torch.Size([32, 3, 224, 224]) Loss 0.05254044383764267\n",
      "Batch 21. Data shape torch.Size([32, 3, 224, 224]) Loss 0.05843784660100937\n",
      "Batch 22. Data shape torch.Size([32, 3, 224, 224]) Loss 0.11503402143716812\n",
      "Batch 23. Data shape torch.Size([32, 3, 224, 224]) Loss 0.057580217719078064\n",
      "Batch 24. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07819020003080368\n",
      "Batch 25. Data shape torch.Size([32, 3, 224, 224]) Loss 0.13104462623596191\n",
      "Batch 26. Data shape torch.Size([32, 3, 224, 224]) Loss 0.053329236805438995\n",
      "Batch 27. Data shape torch.Size([32, 3, 224, 224]) Loss 0.04788818210363388\n",
      "Batch 28. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1449083387851715\n",
      "Batch 29. Data shape torch.Size([32, 3, 224, 224]) Loss 0.052181415259838104\n",
      "Batch 30. Data shape torch.Size([32, 3, 224, 224]) Loss 0.056833915412425995\n",
      "Batch 31. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07536880671977997\n",
      "Batch 32. Data shape torch.Size([32, 3, 224, 224]) Loss 0.0736006572842598\n",
      "Batch 33. Data shape torch.Size([32, 3, 224, 224]) Loss 0.025678467005491257\n",
      "Batch 34. Data shape torch.Size([32, 3, 224, 224]) Loss 0.25887370109558105\n",
      "Batch 35. Data shape torch.Size([32, 3, 224, 224]) Loss 0.016438046470284462\n",
      "Batch 36. Data shape torch.Size([32, 3, 224, 224]) Loss 0.11279527842998505\n",
      "Batch 37. Data shape torch.Size([32, 3, 224, 224]) Loss 0.04418756440281868\n",
      "Batch 38. Data shape torch.Size([32, 3, 224, 224]) Loss 0.10900606960058212\n",
      "Batch 39. Data shape torch.Size([32, 3, 224, 224]) Loss 0.109142005443573\n",
      "Batch 40. Data shape torch.Size([22, 3, 224, 224]) Loss 0.023065486922860146\n",
      "EarlyStopping counter: 3 out of 5\n",
      "Epoch: 44/50 | time: 7.0m 54.31s | lr: 1.0000e-05 | train/loss: 0.05055 | val/loss: 0.08075 | val/accuracy: 0.91969 | val/AUC: 0.98025 | val/Kappa: 0.85495\n",
      "Epoch: 45 Train batch 10 loss: 0.11169355362653732, 6.3% complete\n",
      "Epoch: 45 Train batch 20 loss: 0.030916059389710426, 12.6% complete\n",
      "Epoch: 45 Train batch 30 loss: 0.03485660254955292, 18.9% complete\n",
      "Epoch: 45 Train batch 40 loss: 0.0370955690741539, 25.2% complete\n",
      "Epoch: 45 Train batch 50 loss: 0.03173293173313141, 31.4% complete\n",
      "Epoch: 45 Train batch 60 loss: 0.05585798993706703, 37.7% complete\n",
      "Epoch: 45 Train batch 70 loss: 0.026066530495882034, 44.0% complete\n",
      "Epoch: 45 Train batch 80 loss: 0.03489353507757187, 50.3% complete\n",
      "Epoch: 45 Train batch 90 loss: 0.01870882138609886, 56.6% complete\n",
      "Epoch: 45 Train batch 100 loss: 0.0746343582868576, 62.9% complete\n",
      "Epoch: 45 Train batch 110 loss: 0.05810824781656265, 69.2% complete\n",
      "Epoch: 45 Train batch 120 loss: 0.035883452743291855, 75.5% complete\n",
      "Epoch: 45 Train batch 130 loss: 0.05605299770832062, 81.8% complete\n",
      "Epoch: 45 Train batch 140 loss: 0.040033191442489624, 88.1% complete\n",
      "Epoch: 45 Train batch 150 loss: 0.05117662250995636, 94.3% complete\n",
      "Batch 1. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08601251244544983\n",
      "Batch 2. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07905114442110062\n",
      "Batch 3. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07723085582256317\n",
      "Batch 4. Data shape torch.Size([32, 3, 224, 224]) Loss 0.05046984925866127\n",
      "Batch 5. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1667327880859375\n",
      "Batch 6. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07185223698616028\n",
      "Batch 7. Data shape torch.Size([32, 3, 224, 224]) Loss 0.15311893820762634\n",
      "Batch 8. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1438976228237152\n",
      "Batch 9. Data shape torch.Size([32, 3, 224, 224]) Loss 0.17369204759597778\n",
      "Batch 10. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09632642567157745\n",
      "Batch 11. Data shape torch.Size([32, 3, 224, 224]) Loss 0.13091444969177246\n",
      "Batch 12. Data shape torch.Size([32, 3, 224, 224]) Loss 0.13535383343696594\n",
      "Batch 13. Data shape torch.Size([32, 3, 224, 224]) Loss 0.024272266775369644\n",
      "Batch 14. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07069480419158936\n",
      "Batch 15. Data shape torch.Size([32, 3, 224, 224]) Loss 0.016033632680773735\n",
      "Batch 16. Data shape torch.Size([32, 3, 224, 224]) Loss 0.05043778195977211\n",
      "Batch 17. Data shape torch.Size([32, 3, 224, 224]) Loss 0.021949267014861107\n",
      "Batch 18. Data shape torch.Size([32, 3, 224, 224]) Loss 0.02947888895869255\n",
      "Batch 19. Data shape torch.Size([32, 3, 224, 224]) Loss 0.061807483434677124\n",
      "Batch 20. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07727459073066711\n",
      "Batch 21. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07361642271280289\n",
      "Batch 22. Data shape torch.Size([32, 3, 224, 224]) Loss 0.020992599427700043\n",
      "Batch 23. Data shape torch.Size([32, 3, 224, 224]) Loss 0.10731176286935806\n",
      "Batch 24. Data shape torch.Size([32, 3, 224, 224]) Loss 0.05000176653265953\n",
      "Batch 25. Data shape torch.Size([32, 3, 224, 224]) Loss 0.06136295199394226\n",
      "Batch 26. Data shape torch.Size([32, 3, 224, 224]) Loss 0.02777482010424137\n",
      "Batch 27. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08644832670688629\n",
      "Batch 28. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07118832319974899\n",
      "Batch 29. Data shape torch.Size([32, 3, 224, 224]) Loss 0.026605624705553055\n",
      "Batch 30. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1442146748304367\n",
      "Batch 31. Data shape torch.Size([32, 3, 224, 224]) Loss 0.0792221873998642\n",
      "Batch 32. Data shape torch.Size([32, 3, 224, 224]) Loss 0.05180578678846359\n",
      "Batch 33. Data shape torch.Size([32, 3, 224, 224]) Loss 0.01726885512471199\n",
      "Batch 34. Data shape torch.Size([32, 3, 224, 224]) Loss 0.028454989194869995\n",
      "Batch 35. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1472497135400772\n",
      "Batch 36. Data shape torch.Size([32, 3, 224, 224]) Loss 0.06426487118005753\n",
      "Batch 37. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07536725699901581\n",
      "Batch 38. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09832675755023956\n",
      "Batch 39. Data shape torch.Size([32, 3, 224, 224]) Loss 0.04484283924102783\n",
      "Batch 40. Data shape torch.Size([22, 3, 224, 224]) Loss 0.04443710669875145\n",
      "Valid loss improved from 0.079210 to 0.075934. Saving model ...\n",
      "Epoch: 45/50 | time: 7.0m 49.77s | lr: 1.0000e-05 | train/loss: 0.04803 | val/loss: 0.07593 | val/accuracy: 0.92992 | val/AUC: 0.98271 | val/Kappa: 0.87349\n",
      "Epoch: 46 Train batch 10 loss: 0.016707897186279297, 6.3% complete\n",
      "Epoch: 46 Train batch 20 loss: 0.055373385548591614, 12.6% complete\n",
      "Epoch: 46 Train batch 30 loss: 0.1492394357919693, 18.9% complete\n",
      "Epoch: 46 Train batch 40 loss: 0.1169123649597168, 25.2% complete\n",
      "Epoch: 46 Train batch 50 loss: 0.0057603055611252785, 31.4% complete\n",
      "Epoch: 46 Train batch 60 loss: 0.06741151958703995, 37.7% complete\n",
      "Epoch: 46 Train batch 70 loss: 0.02924543432891369, 44.0% complete\n",
      "Epoch: 46 Train batch 80 loss: 0.01970488950610161, 50.3% complete\n",
      "Epoch: 46 Train batch 90 loss: 0.08169640600681305, 56.6% complete\n",
      "Epoch: 46 Train batch 100 loss: 0.011881277896463871, 62.9% complete\n",
      "Epoch: 46 Train batch 110 loss: 0.01081772055476904, 69.2% complete\n",
      "Epoch: 46 Train batch 120 loss: 0.014801288954913616, 75.5% complete\n",
      "Epoch: 46 Train batch 130 loss: 0.05486707389354706, 81.8% complete\n",
      "Epoch: 46 Train batch 140 loss: 0.06157872453331947, 88.1% complete\n",
      "Epoch: 46 Train batch 150 loss: 0.05502954497933388, 94.3% complete\n",
      "Batch 1. Data shape torch.Size([32, 3, 224, 224]) Loss 0.02857375517487526\n",
      "Batch 2. Data shape torch.Size([32, 3, 224, 224]) Loss 0.03946669027209282\n",
      "Batch 3. Data shape torch.Size([32, 3, 224, 224]) Loss 0.06852458417415619\n",
      "Batch 4. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1473846435546875\n",
      "Batch 5. Data shape torch.Size([32, 3, 224, 224]) Loss 0.05159987136721611\n",
      "Batch 6. Data shape torch.Size([32, 3, 224, 224]) Loss 0.06224333494901657\n",
      "Batch 7. Data shape torch.Size([32, 3, 224, 224]) Loss 0.06239962577819824\n",
      "Batch 8. Data shape torch.Size([32, 3, 224, 224]) Loss 0.056505851447582245\n",
      "Batch 9. Data shape torch.Size([32, 3, 224, 224]) Loss 0.06006770581007004\n",
      "Batch 10. Data shape torch.Size([32, 3, 224, 224]) Loss 0.04545324668288231\n",
      "Batch 11. Data shape torch.Size([32, 3, 224, 224]) Loss 0.0887095183134079\n",
      "Batch 12. Data shape torch.Size([32, 3, 224, 224]) Loss 0.016835778951644897\n",
      "Batch 13. Data shape torch.Size([32, 3, 224, 224]) Loss 0.16941311955451965\n",
      "Batch 14. Data shape torch.Size([32, 3, 224, 224]) Loss 0.16925182938575745\n",
      "Batch 15. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09700287133455276\n",
      "Batch 16. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09202812612056732\n",
      "Batch 17. Data shape torch.Size([32, 3, 224, 224]) Loss 0.05561525747179985\n",
      "Batch 18. Data shape torch.Size([32, 3, 224, 224]) Loss 0.10941149294376373\n",
      "Batch 19. Data shape torch.Size([32, 3, 224, 224]) Loss 0.05374649912118912\n",
      "Batch 20. Data shape torch.Size([32, 3, 224, 224]) Loss 0.10262161493301392\n",
      "Batch 21. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08017164468765259\n",
      "Batch 22. Data shape torch.Size([32, 3, 224, 224]) Loss 0.0823574960231781\n",
      "Batch 23. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08624899387359619\n",
      "Batch 24. Data shape torch.Size([32, 3, 224, 224]) Loss 0.13652943074703217\n",
      "Batch 25. Data shape torch.Size([32, 3, 224, 224]) Loss 0.06537913531064987\n",
      "Batch 26. Data shape torch.Size([32, 3, 224, 224]) Loss 0.10873576998710632\n",
      "Batch 27. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09360641986131668\n",
      "Batch 28. Data shape torch.Size([32, 3, 224, 224]) Loss 0.02383876033127308\n",
      "Batch 29. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08805830031633377\n",
      "Batch 30. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08151710778474808\n",
      "Batch 31. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1520114243030548\n",
      "Batch 32. Data shape torch.Size([32, 3, 224, 224]) Loss 0.006062340922653675\n",
      "Batch 33. Data shape torch.Size([32, 3, 224, 224]) Loss 0.15109804272651672\n",
      "Batch 34. Data shape torch.Size([32, 3, 224, 224]) Loss 0.02177697792649269\n",
      "Batch 35. Data shape torch.Size([32, 3, 224, 224]) Loss 0.025379294529557228\n",
      "Batch 36. Data shape torch.Size([32, 3, 224, 224]) Loss 0.0181877464056015\n",
      "Batch 37. Data shape torch.Size([32, 3, 224, 224]) Loss 0.04403243958950043\n",
      "Batch 38. Data shape torch.Size([32, 3, 224, 224]) Loss 0.03451307862997055\n",
      "Batch 39. Data shape torch.Size([32, 3, 224, 224]) Loss 0.12374065816402435\n",
      "Batch 40. Data shape torch.Size([22, 3, 224, 224]) Loss 0.07858659327030182\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Epoch: 46/50 | time: 8.0m 7.609s | lr: 1.0000e-05 | train/loss: 0.04894 | val/loss: 0.07697 | val/accuracy: 0.92677 | val/AUC: 0.98268 | val/Kappa: 0.86741\n",
      "Epoch: 47 Train batch 10 loss: 0.010951812379062176, 6.3% complete\n",
      "Epoch: 47 Train batch 20 loss: 0.019635044038295746, 12.6% complete\n",
      "Epoch: 47 Train batch 30 loss: 0.016772691160440445, 18.9% complete\n",
      "Epoch: 47 Train batch 40 loss: 0.03566252067685127, 25.2% complete\n",
      "Epoch: 47 Train batch 50 loss: 0.042091548442840576, 31.4% complete\n",
      "Epoch: 47 Train batch 60 loss: 0.0877203494310379, 37.7% complete\n",
      "Epoch: 47 Train batch 70 loss: 0.04665480926632881, 44.0% complete\n",
      "Epoch: 47 Train batch 80 loss: 0.004238207824528217, 50.3% complete\n",
      "Epoch: 47 Train batch 90 loss: 0.05109882354736328, 56.6% complete\n",
      "Epoch: 47 Train batch 100 loss: 0.016805555671453476, 62.9% complete\n",
      "Epoch: 47 Train batch 110 loss: 0.03778891637921333, 69.2% complete\n",
      "Epoch: 47 Train batch 120 loss: 0.08978205919265747, 75.5% complete\n",
      "Epoch: 47 Train batch 130 loss: 0.044431060552597046, 81.8% complete\n",
      "Epoch: 47 Train batch 140 loss: 0.06529369205236435, 88.1% complete\n",
      "Epoch: 47 Train batch 150 loss: 0.025039419531822205, 94.3% complete\n",
      "Batch 1. Data shape torch.Size([32, 3, 224, 224]) Loss 0.11150059103965759\n",
      "Batch 2. Data shape torch.Size([32, 3, 224, 224]) Loss 0.14101988077163696\n",
      "Batch 3. Data shape torch.Size([32, 3, 224, 224]) Loss 0.06270630657672882\n",
      "Batch 4. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07620923221111298\n",
      "Batch 5. Data shape torch.Size([32, 3, 224, 224]) Loss 0.039791494607925415\n",
      "Batch 6. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07884583622217178\n",
      "Batch 7. Data shape torch.Size([32, 3, 224, 224]) Loss 0.06665806472301483\n",
      "Batch 8. Data shape torch.Size([32, 3, 224, 224]) Loss 0.04304845631122589\n",
      "Batch 9. Data shape torch.Size([32, 3, 224, 224]) Loss 0.030314583331346512\n",
      "Batch 10. Data shape torch.Size([32, 3, 224, 224]) Loss 0.06414458155632019\n",
      "Batch 11. Data shape torch.Size([32, 3, 224, 224]) Loss 0.05571680888533592\n",
      "Batch 12. Data shape torch.Size([32, 3, 224, 224]) Loss 0.053406618535518646\n",
      "Batch 13. Data shape torch.Size([32, 3, 224, 224]) Loss 0.049865368753671646\n",
      "Batch 14. Data shape torch.Size([32, 3, 224, 224]) Loss 0.05661320686340332\n",
      "Batch 15. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08551701158285141\n",
      "Batch 16. Data shape torch.Size([32, 3, 224, 224]) Loss 0.02578316628932953\n",
      "Batch 17. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07426843047142029\n",
      "Batch 18. Data shape torch.Size([32, 3, 224, 224]) Loss 0.05557958409190178\n",
      "Batch 19. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09032472968101501\n",
      "Batch 20. Data shape torch.Size([32, 3, 224, 224]) Loss 0.0817025750875473\n",
      "Batch 21. Data shape torch.Size([32, 3, 224, 224]) Loss 0.14487573504447937\n",
      "Batch 22. Data shape torch.Size([32, 3, 224, 224]) Loss 0.007968454621732235\n",
      "Batch 23. Data shape torch.Size([32, 3, 224, 224]) Loss 0.05841279774904251\n",
      "Batch 24. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08371905982494354\n",
      "Batch 25. Data shape torch.Size([32, 3, 224, 224]) Loss 0.0743054524064064\n",
      "Batch 26. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09253964573144913\n",
      "Batch 27. Data shape torch.Size([32, 3, 224, 224]) Loss 0.17816422879695892\n",
      "Batch 28. Data shape torch.Size([32, 3, 224, 224]) Loss 0.0175822451710701\n",
      "Batch 29. Data shape torch.Size([32, 3, 224, 224]) Loss 0.060624781996011734\n",
      "Batch 30. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07869191467761993\n",
      "Batch 31. Data shape torch.Size([32, 3, 224, 224]) Loss 0.04082402586936951\n",
      "Batch 32. Data shape torch.Size([32, 3, 224, 224]) Loss 0.11316466331481934\n",
      "Batch 33. Data shape torch.Size([32, 3, 224, 224]) Loss 0.12093628942966461\n",
      "Batch 34. Data shape torch.Size([32, 3, 224, 224]) Loss 0.10305599123239517\n",
      "Batch 35. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07761301100254059\n",
      "Batch 36. Data shape torch.Size([32, 3, 224, 224]) Loss 0.10621781647205353\n",
      "Batch 37. Data shape torch.Size([32, 3, 224, 224]) Loss 0.14068657159805298\n",
      "Batch 38. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08110260218381882\n",
      "Batch 39. Data shape torch.Size([32, 3, 224, 224]) Loss 0.12867769598960876\n",
      "Batch 40. Data shape torch.Size([22, 3, 224, 224]) Loss 0.021172942593693733\n",
      "EarlyStopping counter: 2 out of 5\n",
      "Epoch: 47/50 | time: 8.0m 32.11s | lr: 1.0000e-05 | train/loss: 0.04758 | val/loss: 0.07683 | val/accuracy: 0.92677 | val/AUC: 0.98329 | val/Kappa: 0.86725\n",
      "Epoch: 48 Train batch 10 loss: 0.035606078803539276, 6.3% complete\n",
      "Epoch: 48 Train batch 20 loss: -0.00015107356011867523, 12.6% complete\n",
      "Epoch: 48 Train batch 30 loss: 0.040943827480077744, 18.9% complete\n",
      "Epoch: 48 Train batch 40 loss: 0.04073476791381836, 25.2% complete\n",
      "Epoch: 48 Train batch 50 loss: 0.04945534095168114, 31.4% complete\n",
      "Epoch: 48 Train batch 60 loss: 0.0122013408690691, 37.7% complete\n",
      "Epoch: 48 Train batch 70 loss: 0.06681087613105774, 44.0% complete\n",
      "Epoch: 48 Train batch 80 loss: 0.04856439679861069, 50.3% complete\n",
      "Epoch: 48 Train batch 90 loss: 0.10801845788955688, 56.6% complete\n",
      "Epoch: 48 Train batch 100 loss: 0.015920713543891907, 62.9% complete\n",
      "Epoch: 48 Train batch 110 loss: 0.047814760357141495, 69.2% complete\n",
      "Epoch: 48 Train batch 120 loss: 0.021739020943641663, 75.5% complete\n",
      "Epoch: 48 Train batch 130 loss: 0.046403974294662476, 81.8% complete\n",
      "Epoch: 48 Train batch 140 loss: 0.058608487248420715, 88.1% complete\n",
      "Epoch: 48 Train batch 150 loss: 0.14152882993221283, 94.3% complete\n",
      "Batch 1. Data shape torch.Size([32, 3, 224, 224]) Loss 0.05829504877328873\n",
      "Batch 2. Data shape torch.Size([32, 3, 224, 224]) Loss 0.03681938350200653\n",
      "Batch 3. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08771953731775284\n",
      "Batch 4. Data shape torch.Size([32, 3, 224, 224]) Loss 0.06578470766544342\n",
      "Batch 5. Data shape torch.Size([32, 3, 224, 224]) Loss 0.043124496936798096\n",
      "Batch 6. Data shape torch.Size([32, 3, 224, 224]) Loss 0.06479627639055252\n",
      "Batch 7. Data shape torch.Size([32, 3, 224, 224]) Loss 0.11228528618812561\n",
      "Batch 8. Data shape torch.Size([32, 3, 224, 224]) Loss 0.11127710342407227\n",
      "Batch 9. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07652857899665833\n",
      "Batch 10. Data shape torch.Size([32, 3, 224, 224]) Loss 0.031913746148347855\n",
      "Batch 11. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07145669311285019\n",
      "Batch 12. Data shape torch.Size([32, 3, 224, 224]) Loss 0.05457812175154686\n",
      "Batch 13. Data shape torch.Size([32, 3, 224, 224]) Loss 0.13781724870204926\n",
      "Batch 14. Data shape torch.Size([32, 3, 224, 224]) Loss 0.12787017226219177\n",
      "Batch 15. Data shape torch.Size([32, 3, 224, 224]) Loss 0.13269391655921936\n",
      "Batch 16. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08612321317195892\n",
      "Batch 17. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08672311902046204\n",
      "Batch 18. Data shape torch.Size([32, 3, 224, 224]) Loss 0.10374046862125397\n",
      "Batch 19. Data shape torch.Size([32, 3, 224, 224]) Loss 0.13300226628780365\n",
      "Batch 20. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08227081596851349\n",
      "Batch 21. Data shape torch.Size([32, 3, 224, 224]) Loss 0.053945060819387436\n",
      "Batch 22. Data shape torch.Size([32, 3, 224, 224]) Loss 0.0661567896604538\n",
      "Batch 23. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08784934878349304\n",
      "Batch 24. Data shape torch.Size([32, 3, 224, 224]) Loss 0.0478486493229866\n",
      "Batch 25. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09852319955825806\n",
      "Batch 26. Data shape torch.Size([32, 3, 224, 224]) Loss 0.020747829228639603\n",
      "Batch 27. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07855121046304703\n",
      "Batch 28. Data shape torch.Size([32, 3, 224, 224]) Loss 0.051918454468250275\n",
      "Batch 29. Data shape torch.Size([32, 3, 224, 224]) Loss 0.06837493181228638\n",
      "Batch 30. Data shape torch.Size([32, 3, 224, 224]) Loss 0.05872124806046486\n",
      "Batch 31. Data shape torch.Size([32, 3, 224, 224]) Loss 0.054798878729343414\n",
      "Batch 32. Data shape torch.Size([32, 3, 224, 224]) Loss 0.01845027692615986\n",
      "Batch 33. Data shape torch.Size([32, 3, 224, 224]) Loss 0.018986526876688004\n",
      "Batch 34. Data shape torch.Size([32, 3, 224, 224]) Loss 0.056275948882102966\n",
      "Batch 35. Data shape torch.Size([32, 3, 224, 224]) Loss 0.048092007637023926\n",
      "Batch 36. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07278348505496979\n",
      "Batch 37. Data shape torch.Size([32, 3, 224, 224]) Loss 0.04383780062198639\n",
      "Batch 38. Data shape torch.Size([32, 3, 224, 224]) Loss 0.14614276587963104\n",
      "Batch 39. Data shape torch.Size([32, 3, 224, 224]) Loss 0.04152849689126015\n",
      "Batch 40. Data shape torch.Size([22, 3, 224, 224]) Loss 0.0997147262096405\n",
      "Valid loss improved from 0.075934 to 0.073452. Saving model ...\n",
      "Epoch: 48/50 | time: 8.0m 18.03s | lr: 1.0000e-05 | train/loss: 0.04420 | val/loss: 0.07345 | val/accuracy: 0.93543 | val/AUC: 0.98349 | val/Kappa: 0.88281\n",
      "Epoch: 49 Train batch 10 loss: 0.06412655115127563, 6.3% complete\n",
      "Epoch: 49 Train batch 20 loss: 0.07987108081579208, 12.6% complete\n",
      "Epoch: 49 Train batch 30 loss: 0.03370970860123634, 18.9% complete\n",
      "Epoch: 49 Train batch 40 loss: 0.04301564395427704, 25.2% complete\n",
      "Epoch: 49 Train batch 50 loss: 0.06762883067131042, 31.4% complete\n",
      "Epoch: 49 Train batch 60 loss: 0.0018696673214435577, 37.7% complete\n",
      "Epoch: 49 Train batch 70 loss: 0.05658857524394989, 44.0% complete\n",
      "Epoch: 49 Train batch 80 loss: 0.04628162831068039, 50.3% complete\n",
      "Epoch: 49 Train batch 90 loss: 0.031146958470344543, 56.6% complete\n",
      "Epoch: 49 Train batch 100 loss: 0.01606735587120056, 62.9% complete\n",
      "Epoch: 49 Train batch 110 loss: 0.08850336074829102, 69.2% complete\n",
      "Epoch: 49 Train batch 120 loss: 0.07362087815999985, 75.5% complete\n",
      "Epoch: 49 Train batch 130 loss: 0.027944691479206085, 81.8% complete\n",
      "Epoch: 49 Train batch 140 loss: 0.1141415610909462, 88.1% complete\n",
      "Epoch: 49 Train batch 150 loss: 0.07741644978523254, 94.3% complete\n",
      "Batch 1. Data shape torch.Size([32, 3, 224, 224]) Loss 0.04256068915128708\n",
      "Batch 2. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08391252160072327\n",
      "Batch 3. Data shape torch.Size([32, 3, 224, 224]) Loss 0.05075199156999588\n",
      "Batch 4. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1613587886095047\n",
      "Batch 5. Data shape torch.Size([32, 3, 224, 224]) Loss 0.13818955421447754\n",
      "Batch 6. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08356121927499771\n",
      "Batch 7. Data shape torch.Size([32, 3, 224, 224]) Loss 0.10773342102766037\n",
      "Batch 8. Data shape torch.Size([32, 3, 224, 224]) Loss 0.021681029349565506\n",
      "Batch 9. Data shape torch.Size([32, 3, 224, 224]) Loss 0.0642557442188263\n",
      "Batch 10. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07847139239311218\n",
      "Batch 11. Data shape torch.Size([32, 3, 224, 224]) Loss 0.047247983515262604\n",
      "Batch 12. Data shape torch.Size([32, 3, 224, 224]) Loss 0.05249996483325958\n",
      "Batch 13. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07532906532287598\n",
      "Batch 14. Data shape torch.Size([32, 3, 224, 224]) Loss 0.1501525193452835\n",
      "Batch 15. Data shape torch.Size([32, 3, 224, 224]) Loss 0.0158394668251276\n",
      "Batch 16. Data shape torch.Size([32, 3, 224, 224]) Loss 0.05743329972028732\n",
      "Batch 17. Data shape torch.Size([32, 3, 224, 224]) Loss 0.06002286449074745\n",
      "Batch 18. Data shape torch.Size([32, 3, 224, 224]) Loss 0.02826869860291481\n",
      "Batch 19. Data shape torch.Size([32, 3, 224, 224]) Loss 0.10565007477998734\n",
      "Batch 20. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09745704382658005\n",
      "Batch 21. Data shape torch.Size([32, 3, 224, 224]) Loss 0.06822089105844498\n",
      "Batch 22. Data shape torch.Size([32, 3, 224, 224]) Loss 0.04719797521829605\n",
      "Batch 23. Data shape torch.Size([32, 3, 224, 224]) Loss 0.04435596242547035\n",
      "Batch 24. Data shape torch.Size([32, 3, 224, 224]) Loss 0.019160505384206772\n",
      "Batch 25. Data shape torch.Size([32, 3, 224, 224]) Loss 0.06757164001464844\n",
      "Batch 26. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07656992971897125\n",
      "Batch 27. Data shape torch.Size([32, 3, 224, 224]) Loss 0.11264120787382126\n",
      "Batch 28. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08728502690792084\n",
      "Batch 29. Data shape torch.Size([32, 3, 224, 224]) Loss 0.16279315948486328\n",
      "Batch 30. Data shape torch.Size([32, 3, 224, 224]) Loss 0.009110543876886368\n",
      "Batch 31. Data shape torch.Size([32, 3, 224, 224]) Loss 0.04840825870633125\n",
      "Batch 32. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07392683625221252\n",
      "Batch 33. Data shape torch.Size([32, 3, 224, 224]) Loss 0.03533284366130829\n",
      "Batch 34. Data shape torch.Size([32, 3, 224, 224]) Loss 0.06713023781776428\n",
      "Batch 35. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09918773174285889\n",
      "Batch 36. Data shape torch.Size([32, 3, 224, 224]) Loss 0.025483405217528343\n",
      "Batch 37. Data shape torch.Size([32, 3, 224, 224]) Loss 0.11690293252468109\n",
      "Batch 38. Data shape torch.Size([32, 3, 224, 224]) Loss 0.10709508508443832\n",
      "Batch 39. Data shape torch.Size([32, 3, 224, 224]) Loss 0.012487530708312988\n",
      "Batch 40. Data shape torch.Size([22, 3, 224, 224]) Loss 0.04060464724898338\n",
      "Valid loss improved from 0.073452 to 0.071096. Saving model ...\n",
      "Epoch: 49/50 | time: 7.0m 56.98s | lr: 1.0000e-05 | train/loss: 0.04184 | val/loss: 0.07110 | val/accuracy: 0.93543 | val/AUC: 0.98476 | val/Kappa: 0.88307\n",
      "Epoch: 50 Train batch 10 loss: 0.010784612037241459, 6.3% complete\n",
      "Epoch: 50 Train batch 20 loss: 0.037417709827423096, 12.6% complete\n",
      "Epoch: 50 Train batch 30 loss: 0.025611702352762222, 18.9% complete\n",
      "Epoch: 50 Train batch 40 loss: 0.027630358934402466, 25.2% complete\n",
      "Epoch: 50 Train batch 50 loss: 0.055220600217580795, 31.4% complete\n",
      "Epoch: 50 Train batch 60 loss: 0.013614860363304615, 37.7% complete\n",
      "Epoch: 50 Train batch 70 loss: 0.01390029862523079, 44.0% complete\n",
      "Epoch: 50 Train batch 80 loss: 0.03157031908631325, 50.3% complete\n",
      "Epoch: 50 Train batch 90 loss: 0.035256244242191315, 56.6% complete\n",
      "Epoch: 50 Train batch 100 loss: 0.1063220277428627, 62.9% complete\n",
      "Epoch: 50 Train batch 110 loss: 0.07622595876455307, 69.2% complete\n",
      "Epoch: 50 Train batch 120 loss: 0.04101204127073288, 75.5% complete\n",
      "Epoch: 50 Train batch 130 loss: 0.03908470645546913, 81.8% complete\n",
      "Epoch: 50 Train batch 140 loss: 0.07538333535194397, 88.1% complete\n",
      "Epoch: 50 Train batch 150 loss: 0.048679858446121216, 94.3% complete\n",
      "Batch 1. Data shape torch.Size([32, 3, 224, 224]) Loss 0.06504921615123749\n",
      "Batch 2. Data shape torch.Size([32, 3, 224, 224]) Loss 0.0685381293296814\n",
      "Batch 3. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07911048829555511\n",
      "Batch 4. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09128616005182266\n",
      "Batch 5. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08367788791656494\n",
      "Batch 6. Data shape torch.Size([32, 3, 224, 224]) Loss 0.0942089706659317\n",
      "Batch 7. Data shape torch.Size([32, 3, 224, 224]) Loss 0.033897340297698975\n",
      "Batch 8. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09890367090702057\n",
      "Batch 9. Data shape torch.Size([32, 3, 224, 224]) Loss 0.29786252975463867\n",
      "Batch 10. Data shape torch.Size([32, 3, 224, 224]) Loss 0.06279134750366211\n",
      "Batch 11. Data shape torch.Size([32, 3, 224, 224]) Loss 0.04043188318610191\n",
      "Batch 12. Data shape torch.Size([32, 3, 224, 224]) Loss 0.054942477494478226\n",
      "Batch 13. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07640263438224792\n",
      "Batch 14. Data shape torch.Size([32, 3, 224, 224]) Loss 0.05417287349700928\n",
      "Batch 15. Data shape torch.Size([32, 3, 224, 224]) Loss 0.05471739172935486\n",
      "Batch 16. Data shape torch.Size([32, 3, 224, 224]) Loss 0.14382201433181763\n",
      "Batch 17. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09249550104141235\n",
      "Batch 18. Data shape torch.Size([32, 3, 224, 224]) Loss 0.031907327473163605\n",
      "Batch 19. Data shape torch.Size([32, 3, 224, 224]) Loss 0.05202997475862503\n",
      "Batch 20. Data shape torch.Size([32, 3, 224, 224]) Loss 0.04094073176383972\n",
      "Batch 21. Data shape torch.Size([32, 3, 224, 224]) Loss 0.048192303627729416\n",
      "Batch 22. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08395839482545853\n",
      "Batch 23. Data shape torch.Size([32, 3, 224, 224]) Loss 0.01625479757785797\n",
      "Batch 24. Data shape torch.Size([32, 3, 224, 224]) Loss 0.04514516890048981\n",
      "Batch 25. Data shape torch.Size([32, 3, 224, 224]) Loss 0.15455956757068634\n",
      "Batch 26. Data shape torch.Size([32, 3, 224, 224]) Loss 0.030940210446715355\n",
      "Batch 27. Data shape torch.Size([32, 3, 224, 224]) Loss 0.02052564173936844\n",
      "Batch 28. Data shape torch.Size([32, 3, 224, 224]) Loss 0.08817712962627411\n",
      "Batch 29. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09778355062007904\n",
      "Batch 30. Data shape torch.Size([32, 3, 224, 224]) Loss 0.022063586860895157\n",
      "Batch 31. Data shape torch.Size([32, 3, 224, 224]) Loss 0.057008471339941025\n",
      "Batch 32. Data shape torch.Size([32, 3, 224, 224]) Loss 0.014401175081729889\n",
      "Batch 33. Data shape torch.Size([32, 3, 224, 224]) Loss 0.057334885001182556\n",
      "Batch 34. Data shape torch.Size([32, 3, 224, 224]) Loss 0.02036924660205841\n",
      "Batch 35. Data shape torch.Size([32, 3, 224, 224]) Loss 0.05498994514346123\n",
      "Batch 36. Data shape torch.Size([32, 3, 224, 224]) Loss 0.06106260418891907\n",
      "Batch 37. Data shape torch.Size([32, 3, 224, 224]) Loss 0.17172329127788544\n",
      "Batch 38. Data shape torch.Size([32, 3, 224, 224]) Loss 0.09985076636075974\n",
      "Batch 39. Data shape torch.Size([32, 3, 224, 224]) Loss 0.07969117164611816\n",
      "Batch 40. Data shape torch.Size([22, 3, 224, 224]) Loss 0.006064964458346367\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Epoch: 50/50 | time: 7.0m 57.17s | lr: 1.0000e-05 | train/loss: 0.04116 | val/loss: 0.07118 | val/accuracy: 0.93150 | val/AUC: 0.98467 | val/Kappa: 0.87527\n",
      "Testing...\n",
      "Test Accuracy: 0.93150\n",
      "Test AUC: 0.98467\n",
      "Test AUC Scores: [0.98822301 0.98899744 0.97677848]\n",
      "Test Kappa: 0.87527\n",
      "Target 0 - Precision: 0.94614, Recall: 0.95870, F-score: 0.95238, Sensitivity: 0.9587020648967551, Specificity: 0.9375, Support: 678\n",
      "Target 1 - Precision: 0.92564, Recall: 0.94980, F-score: 0.93756, Sensitivity: 0.9497991967871486, Specificity: 0.9507772020725389, Support: 498\n",
      "Target 2 - Precision: 0.83333, Recall: 0.63830, F-score: 0.72289, Sensitivity: 0.6382978723404256, Specificity: 0.9897959183673469, Support: 94\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.95       678\n",
      "           1       0.93      0.95      0.94       498\n",
      "           2       0.83      0.64      0.72        94\n",
      "\n",
      "    accuracy                           0.93      1270\n",
      "   macro avg       0.90      0.85      0.87      1270\n",
      "weighted avg       0.93      0.93      0.93      1270\n",
      "\n",
      "\n",
      "Testing complete.\n",
      "Run complete. Total time: 06:38:29\n"
     ]
    }
   ],
   "source": [
    "command = 'python ../train.py --train_path \"../datasets/challenge2/train\" \\\n",
    "                        --train_masks_path \"../datasets_masks/challenge2/train\" \\\n",
    "                        --valid_path \"../datasets/challenge2/val\" \\\n",
    "                        --experiment_name \"ClassifierSegExperiment\" \\\n",
    "                        --network_name \"VGG16_BN_Attention\" \\\n",
    "                        --max_epochs \"50\" \\\n",
    "                        --base_lr \"0.00001\" \\\n",
    "                        --batch_size \"32\" \\\n",
    "                        --verbose \"2\" \\\n",
    "                        --focal_loss \\\n",
    "                        --multi'\n",
    "\n",
    "# run the function to excute the command\n",
    "_ = execute_cmd_realtime(command, log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excuting training pipeline with 50 epochs and 5 folds.\n",
      "Loading data with 3 class labels...\n",
      "Loading the data from ../datasets/challenge2/train\n",
      "Loading the data from ../datasets/challenge2/val\n",
      "Using segmentation masks for training...\n",
      "train_images: 5082, train_masks: 5082, train_labels: 5082\n",
      "val_images: 1270, val_masks: 1270, val_labels: 1270\n",
      "Class weights: [0.62427817 0.85023427 4.50443262]\n",
      "Creating a classifier experiment using VGG16_BN_Attention network.\n",
      "Using VGG16_BN_Attention with configurations: num_classes='3', normalize_attn='False'\n",
      "Using focal loss.\n",
      "Using dice loss.\n"
     ]
    }
   ],
   "source": [
    "# 2023-12-29_0940_VGG16_BN_Attention\n",
    "command = 'python ../train_cv.py \\\n",
    "                    --train_path \"../datasets/challenge2/train\" \\\n",
    "                    --train_masks_path \"../datasets_masks/challenge2/train\" \\\n",
    "                    --valid_path \"../datasets/challenge2/val\" \\\n",
    "                    --valid_masks_path \"../datasets_masks/challenge2/val\"\\\n",
    "                    --experiment_name \"ClassifierSegExperimentCV\" \\\n",
    "                    --network_name \"VGG16_BN_Attention\" \\\n",
    "                    --max_epochs \"50\" \\\n",
    "                    --base_lr \"0.00001\" \\\n",
    "                    --num_folds \"5\" \\\n",
    "                    --batch_size \"32\" \\\n",
    "                    --verbose \"1\" \\\n",
    "                    --focal_loss \\\n",
    "                    --multi'\n",
    "\n",
    "# run the function to excute the command\n",
    "_ = execute_cmd_realtime(command, log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excuting inference script...\n",
      "Namespace(test_path='../datasets/challenge2/val', output='outputs', experiment_name='ClassifierSegExperimentCV', network_name='VGG16_BN_Attention', max_epochs=50, batch_size=32, base_lr=1e-05, img_size=224, seed=42, timeframe='2023-12-29_0940', verbose=2, multi=True, report=True, ensemble=True)\n",
      "Constructed output path: outputs/ClassifierSegExperimentCV_224_epo50_bs32_lr1e-05_s42/2023-12-29_0940_VGG16_BN_Attention. Searching for models...\n",
      "Found 5 models. Starting loading the models.\n",
      "Loading data with 3 class labels from ../datasets/challenge2/val path...\n",
      "Dataset labels: {'mel': 0, 'bcc': 1, 'scc': 2} dictionary.\n",
      "Loading the data from ../datasets/challenge2/val\n",
      "Dataset length: 1270\n",
      "Using VGG16_BN_Attention with configurations: num_classes='3', normalize_attn='False'\n",
      "Using VGG16_BN_Attention with configurations: num_classes='3', normalize_attn='False'\n",
      "Using VGG16_BN_Attention with configurations: num_classes='3', normalize_attn='False'\n",
      "Using VGG16_BN_Attention with configurations: num_classes='3', normalize_attn='False'\n",
      "Using VGG16_BN_Attention with configurations: num_classes='3', normalize_attn='False'\n",
      "\n",
      "Inference:   0%|          | 0/40 [00:00<?, ?it/s]\n",
      "Inference:   2%|▎         | 1/40 [00:05<03:47,  5.84s/it]\n",
      "Inference:   5%|▌         | 2/40 [00:06<01:48,  2.85s/it]\n",
      "Inference:   8%|▊         | 3/40 [00:07<01:10,  1.89s/it]\n",
      "Inference:  10%|█         | 4/40 [00:08<00:51,  1.44s/it]\n",
      "Inference:  12%|█▎        | 5/40 [00:08<00:41,  1.19s/it]\n",
      "Inference:  15%|█▌        | 6/40 [00:09<00:35,  1.04s/it]\n",
      "Inference:  18%|█▊        | 7/40 [00:10<00:31,  1.06it/s]\n",
      "Inference:  20%|██        | 8/40 [00:11<00:28,  1.13it/s]\n",
      "Inference:  22%|██▎       | 9/40 [00:11<00:26,  1.19it/s]\n",
      "Inference:  25%|██▌       | 10/40 [00:12<00:24,  1.23it/s]\n",
      "Inference:  28%|██▊       | 11/40 [00:13<00:23,  1.26it/s]\n",
      "Inference:  30%|███       | 12/40 [00:14<00:21,  1.28it/s]\n",
      "Inference:  32%|███▎      | 13/40 [00:14<00:20,  1.30it/s]\n",
      "Inference:  35%|███▌      | 14/40 [00:15<00:19,  1.31it/s]\n",
      "Inference:  38%|███▊      | 15/40 [00:16<00:19,  1.31it/s]\n",
      "Inference:  40%|████      | 16/40 [00:17<00:18,  1.32it/s]\n",
      "Inference:  42%|████▎     | 17/40 [00:17<00:17,  1.32it/s]\n",
      "Inference:  45%|████▌     | 18/40 [00:18<00:16,  1.32it/s]\n",
      "Inference:  48%|████▊     | 19/40 [00:19<00:15,  1.33it/s]\n",
      "Inference:  50%|█████     | 20/40 [00:20<00:15,  1.33it/s]\n",
      "Inference:  52%|█████▎    | 21/40 [00:20<00:14,  1.33it/s]\n",
      "Inference:  55%|█████▌    | 22/40 [00:21<00:13,  1.33it/s]\n",
      "Inference:  57%|█████▊    | 23/40 [00:22<00:12,  1.33it/s]\n",
      "Inference:  60%|██████    | 24/40 [00:23<00:12,  1.33it/s]\n",
      "Inference:  62%|██████▎   | 25/40 [00:23<00:11,  1.33it/s]\n",
      "Inference:  65%|██████▌   | 26/40 [00:24<00:10,  1.33it/s]\n",
      "Inference:  68%|██████▊   | 27/40 [00:25<00:09,  1.33it/s]\n",
      "Inference:  70%|███████   | 28/40 [00:26<00:09,  1.33it/s]\n",
      "Inference:  72%|███████▎  | 29/40 [00:26<00:08,  1.33it/s]\n",
      "Inference:  75%|███████▌  | 30/40 [00:27<00:07,  1.33it/s]\n",
      "Inference:  78%|███████▊  | 31/40 [00:28<00:06,  1.33it/s]\n",
      "Inference:  80%|████████  | 32/40 [00:29<00:06,  1.33it/s]\n",
      "Inference:  82%|████████▎ | 33/40 [00:29<00:05,  1.33it/s]\n",
      "Inference:  85%|████████▌ | 34/40 [00:30<00:04,  1.33it/s]\n",
      "Inference:  88%|████████▊ | 35/40 [00:31<00:03,  1.33it/s]\n",
      "Inference:  90%|█████████ | 36/40 [00:32<00:03,  1.33it/s]\n",
      "Inference:  92%|█████████▎| 37/40 [00:32<00:02,  1.33it/s]\n",
      "Inference:  95%|█████████▌| 38/40 [00:33<00:01,  1.33it/s]\n",
      "Inference:  98%|█████████▊| 39/40 [00:34<00:00,  1.33it/s]\n",
      "Inference: 100%|██████████| 40/40 [00:36<00:00,  1.11s/it]\n",
      "Inference: 100%|██████████| 40/40 [00:36<00:00,  1.10it/s]\n",
      "Results exported to: outputs/ClassifierSegExperimentCV_224_epo50_bs32_lr1e-05_s42/2023-12-29_0940_VGG16_BN_Attention/ClassifierSegExperimentCV_224_epo50_bs32_lr1e-05_s42_2023-12-29_0940_VGG16_BN_Attention.csv\n",
      "Computing AUC scores for each class...\n",
      "Figure(1500x600)\n",
      "Majority vote AUC: 0.99811\n",
      "Majority vote AUC Scores: [0.99789225 0.99870206 0.99773846]\n",
      "Majority vote accuracy: 0.9755905511811024\n",
      "Majority vote kappa: 0.9561797952905245\n",
      "Target 0 - Precision: 0.98808, Recall: 0.97788, F-score: 0.98295, Sensitivity: 0.9778761061946902, Specificity: 0.9864864864864865, Support: 678\n",
      "Target 1 - Precision: 0.97018, Recall: 0.97992, F-score: 0.97502, Sensitivity: 0.9799196787148594, Specificity: 0.9805699481865285, Support: 498\n",
      "Target 2 - Precision: 0.91667, Recall: 0.93617, F-score: 0.92632, Sensitivity: 0.9361702127659575, Specificity: 0.9931972789115646, Support: 94\n",
      "(   {   'accuracy': 0.9755905511811024,\n",
      "        'auc': 0.9981109232924158,\n",
      "        'auc_scores': [   0.9978922506577373,\n",
      "                          0.9987020621345485,\n",
      "                          0.9977384570849616],\n",
      "        'fscore': [0.9829503335804298, 0.975024975024975, 0.9263157894736843],\n",
      "        'kappa': 0.9561797952905245,\n",
      "        'precision': [   0.9880774962742176,\n",
      "                         0.9701789264413518,\n",
      "                         0.9166666666666666],\n",
      "        'recall': [0.9778761061946902, 0.9799196787148594, 0.9361702127659575],\n",
      "        'sensitivity': [   0.9778761061946902,\n",
      "                           0.9799196787148594,\n",
      "                           0.9361702127659575],\n",
      "        'specificity': [   0.9864864864864865,\n",
      "                           0.9805699481865285,\n",
      "                           0.9931972789115646],\n",
      "        'support': [678, 498, 94]},)\n"
     ]
    }
   ],
   "source": [
    "# BEST RESULT CHALLENGE 2\n",
    "command = 'python ../inference.py --test_path \"../datasets/challenge2/val\" \\\n",
    "                    --experiment_name \"ClassifierSegExperimentCV\" \\\n",
    "                    --network_name \"VGG16_BN_Attention\" \\\n",
    "                    --max_epochs \"50\" \\\n",
    "                    --base_lr \"0.00001\" \\\n",
    "                    --batch_size \"32\" \\\n",
    "                    --timeframe \"2023-12-29_0940\" \\\n",
    "                    --verbose \"2\" \\\n",
    "                    --multi \\\n",
    "                    --ensemble \\\n",
    "                    --report'\n",
    "\n",
    "# run the function to excute the command\n",
    "_ = execute_cmd_realtime(command, log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excuting inference script...\n",
      "Namespace(test_path='../datasets/challenge2/val', output='outputs', experiment_name='ClassifierSegExperimentCV', network_name='VGG16_BN_Attention', max_epochs=50, batch_size=32, base_lr=1e-05, img_size=224, seed=42, timeframe='2023-12-29_0940', verbose=2, multi=True, report=True, ensemble=True, combination_strategy='majority_vote', upscale_factor=8, gradcam=False)\n",
      "Constructed output path: outputs/ClassifierSegExperimentCV_224_epo50_bs32_lr1e-05_s42/2023-12-29_0940_VGG16_BN_Attention. Searching for models...\n",
      "Found 5 models.\n",
      "Loading data with 3 class labels from ../datasets/challenge2/val path...\n",
      "Dataset labels: {'mel': 0, 'bcc': 1, 'scc': 2} dictionary.\n",
      "Loading the data from ../datasets/challenge2/val\n",
      "Dataset length: 1270\n",
      "Using VGG16_BN_Attention with configurations: num_classes='3', normalize_attn='False'\n",
      "Using VGG16_BN_Attention with configurations: num_classes='3', normalize_attn='False'\n",
      "Using VGG16_BN_Attention with configurations: num_classes='3', normalize_attn='False'\n",
      "Using VGG16_BN_Attention with configurations: num_classes='3', normalize_attn='False'\n",
      "Using VGG16_BN_Attention with configurations: num_classes='3', normalize_attn='False'\n",
      "\n",
      "Inference:   0%|          | 0/40 [00:00<?, ?it/s]\n",
      "Inference:   2%|▎         | 1/40 [01:44<1:07:38, 104.06s/it]\n",
      "Inference:   5%|▌         | 2/40 [01:44<27:27, 43.35s/it]   \n",
      "Inference:   8%|▊         | 3/40 [01:45<14:43, 23.88s/it]\n",
      "Inference:  10%|█         | 4/40 [01:46<08:50, 14.73s/it]\n",
      "Inference:  12%|█▎        | 5/40 [01:47<05:39,  9.69s/it]\n",
      "Inference:  15%|█▌        | 6/40 [01:47<03:47,  6.69s/it]\n",
      "Inference:  18%|█▊        | 7/40 [01:48<02:37,  4.76s/it]\n",
      "Inference:  20%|██        | 8/40 [01:49<01:51,  3.48s/it]\n",
      "Inference:  22%|██▎       | 9/40 [01:50<01:21,  2.63s/it]\n",
      "Inference:  25%|██▌       | 10/40 [01:50<01:01,  2.05s/it]\n",
      "Inference:  28%|██▊       | 11/40 [01:51<00:47,  1.64s/it]\n",
      "Inference:  30%|███       | 12/40 [01:52<00:37,  1.35s/it]\n",
      "Inference:  32%|███▎      | 13/40 [01:53<00:31,  1.15s/it]\n",
      "Inference:  35%|███▌      | 14/40 [01:53<00:26,  1.01s/it]\n",
      "Inference:  38%|███▊      | 15/40 [01:54<00:22,  1.09it/s]\n",
      "Inference:  40%|████      | 16/40 [01:55<00:20,  1.19it/s]\n",
      "Inference:  42%|████▎     | 17/40 [01:55<00:18,  1.26it/s]\n",
      "Inference:  45%|████▌     | 18/40 [01:56<00:16,  1.33it/s]\n",
      "Inference:  48%|████▊     | 19/40 [01:57<00:15,  1.37it/s]\n",
      "Inference:  50%|█████     | 20/40 [01:57<00:14,  1.41it/s]\n",
      "Inference:  52%|█████▎    | 21/40 [01:58<00:13,  1.44it/s]\n",
      "Inference:  55%|█████▌    | 22/40 [01:59<00:12,  1.46it/s]\n",
      "Inference:  57%|█████▊    | 23/40 [01:59<00:11,  1.47it/s]\n",
      "Inference:  60%|██████    | 24/40 [02:00<00:10,  1.49it/s]\n",
      "Inference:  62%|██████▎   | 25/40 [02:01<00:10,  1.49it/s]\n",
      "Inference:  65%|██████▌   | 26/40 [02:01<00:09,  1.50it/s]\n",
      "Inference:  68%|██████▊   | 27/40 [02:02<00:08,  1.51it/s]\n",
      "Inference:  70%|███████   | 28/40 [02:03<00:07,  1.51it/s]\n",
      "Inference:  72%|███████▎  | 29/40 [02:03<00:07,  1.51it/s]\n",
      "Inference:  75%|███████▌  | 30/40 [02:04<00:06,  1.52it/s]\n",
      "Inference:  78%|███████▊  | 31/40 [02:05<00:05,  1.52it/s]\n",
      "Inference:  80%|████████  | 32/40 [02:05<00:05,  1.52it/s]\n",
      "Inference:  82%|████████▎ | 33/40 [02:06<00:04,  1.52it/s]\n",
      "Inference:  85%|████████▌ | 34/40 [02:07<00:03,  1.52it/s]\n",
      "Inference:  88%|████████▊ | 35/40 [02:07<00:03,  1.52it/s]\n",
      "Inference:  90%|█████████ | 36/40 [02:08<00:02,  1.52it/s]\n",
      "Inference:  92%|█████████▎| 37/40 [02:09<00:01,  1.52it/s]\n",
      "Inference:  95%|█████████▌| 38/40 [02:09<00:01,  1.52it/s]\n",
      "Inference:  98%|█████████▊| 39/40 [02:10<00:00,  1.52it/s]\n",
      "Inference: 100%|██████████| 40/40 [02:12<00:00,  1.01it/s]\n",
      "Inference: 100%|██████████| 40/40 [02:12<00:00,  3.30s/it]\n",
      "all_predictions shape: (5, 1270)\n",
      "all_probabilities shape: (5, 1270, 3)\n",
      "Combination strategy is majority_vote. Computing the majority vote...\n",
      "Average probabilities: [[0.0557933  0.6696652  0.2745414 ]\n",
      " [0.0382046  0.9375885  0.02420693]\n",
      " [0.02623783 0.89356565 0.08019648]\n",
      " ...\n",
      " [0.2611936  0.2302496  0.5085567 ]\n",
      " [0.0099835  0.17312597 0.81689054]\n",
      " [0.21899271 0.3619659  0.4190414 ]]\n",
      "Results exported to: outputs/ClassifierSegExperimentCV_224_epo50_bs32_lr1e-05_s42/2023-12-29_0940_VGG16_BN_Attention/ch2_majority_vote_val_ClassifierSegExperimentCV_224_epo50_bs32_lr1e-05_s42_2023-12-29_0940_VGG16_BN_Attention.csv\n",
      "Computing AUC scores for each class...\n",
      "Figure(1500x600)\n",
      "Majority vote AUC: 0.99811\n",
      "Majority vote AUC Scores: [0.99789225 0.99870206 0.99773846]\n",
      "Majority vote accuracy: 0.9755905511811024\n",
      "Majority vote kappa: 0.9561797952905245\n",
      "Target 0 - Precision: 0.98808, Recall: 0.97788, F-score: 0.98295, Sensitivity: 0.9778761061946902, Specificity: 0.9864864864864865, Support: 678\n",
      "Target 1 - Precision: 0.97018, Recall: 0.97992, F-score: 0.97502, Sensitivity: 0.9799196787148594, Specificity: 0.9805699481865285, Support: 498\n",
      "Target 2 - Precision: 0.91667, Recall: 0.93617, F-score: 0.92632, Sensitivity: 0.9361702127659575, Specificity: 0.9931972789115646, Support: 94\n",
      "(   {   'accuracy': 0.9755905511811024,\n",
      "        'auc': 0.9981109232924158,\n",
      "        'auc_scores': [   0.9978922506577373,\n",
      "                          0.9987020621345485,\n",
      "                          0.9977384570849616],\n",
      "        'fscore': [0.9829503335804298, 0.975024975024975, 0.9263157894736843],\n",
      "        'kappa': 0.9561797952905245,\n",
      "        'precision': [   0.9880774962742176,\n",
      "                         0.9701789264413518,\n",
      "                         0.9166666666666666],\n",
      "        'recall': [0.9778761061946902, 0.9799196787148594, 0.9361702127659575],\n",
      "        'sensitivity': [   0.9778761061946902,\n",
      "                           0.9799196787148594,\n",
      "                           0.9361702127659575],\n",
      "        'specificity': [   0.9864864864864865,\n",
      "                           0.9805699481865285,\n",
      "                           0.9931972789115646],\n",
      "        'support': [678, 498, 94]},)\n"
     ]
    }
   ],
   "source": [
    "# Running inference on valid split for best results challenge 2 (ensemble) to see if everything is ok\n",
    "command = 'python ../inference.py --test_path \"../datasets/challenge2/val\" \\\n",
    "                    --experiment_name \"ClassifierSegExperimentCV\" \\\n",
    "                    --network_name \"VGG16_BN_Attention\" \\\n",
    "                    --max_epochs \"50\" \\\n",
    "                    --base_lr \"0.00001\" \\\n",
    "                    --batch_size \"32\" \\\n",
    "                    --timeframe \"2023-12-29_0940\" \\\n",
    "                    --verbose \"2\" \\\n",
    "                    --multi \\\n",
    "                    --ensemble \\\n",
    "                    --report'\n",
    "\n",
    "# run the function to excute the command\n",
    "_ = execute_cmd_realtime(command, log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excuting inference script...\n",
      "Namespace(test_path='../datasets/challenge2/test', output='outputs', experiment_name='ClassifierSegExperimentCV', network_name='VGG16_BN_Attention', max_epochs=50, batch_size=32, base_lr=1e-05, img_size=224, seed=42, timeframe='2023-12-29_0940', verbose=2, multi=True, report=False, ensemble=True, combination_strategy='majority_vote', upscale_factor=8, gradcam=False)\n",
      "Constructed output path: outputs/ClassifierSegExperimentCV_224_epo50_bs32_lr1e-05_s42/2023-12-29_0940_VGG16_BN_Attention. Searching for models...\n",
      "Found 5 models.\n",
      "Loading data with unknown class labels from ../datasets/challenge2/test path...\n",
      "Dataset labels: {'testX': -911, 'testY': -922, 'testZ': -933} dictionary.\n",
      "Loading the data from ../datasets/challenge2/test\n",
      "Forcing n_classes to be based on the length of the labels dictionary...\n",
      "Before: 1\n",
      "After: 3\n",
      "Dataset length: 2121\n",
      "Using VGG16_BN_Attention with configurations: num_classes='3', normalize_attn='False'\n",
      "Using VGG16_BN_Attention with configurations: num_classes='3', normalize_attn='False'\n",
      "Using VGG16_BN_Attention with configurations: num_classes='3', normalize_attn='False'\n",
      "Using VGG16_BN_Attention with configurations: num_classes='3', normalize_attn='False'\n",
      "Using VGG16_BN_Attention with configurations: num_classes='3', normalize_attn='False'\n",
      "\n",
      "Inference:   0%|          | 0/67 [00:00<?, ?it/s]\n",
      "Inference:   1%|▏         | 1/67 [01:48<1:58:59, 108.17s/it]\n",
      "Inference:   3%|▎         | 2/67 [01:49<48:48, 45.05s/it]   \n",
      "Inference:   4%|▍         | 3/67 [01:49<26:29, 24.84s/it]\n",
      "Inference:   6%|▌         | 4/67 [01:50<16:07, 15.36s/it]\n",
      "Inference:   7%|▋         | 5/67 [01:51<10:28, 10.14s/it]\n",
      "Inference:   9%|▉         | 6/67 [01:52<07:05,  6.97s/it]\n",
      "Inference:  10%|█         | 7/67 [01:53<04:57,  4.96s/it]\n",
      "Inference:  12%|█▏        | 8/67 [01:53<03:34,  3.64s/it]\n",
      "Inference:  13%|█▎        | 9/67 [01:54<02:39,  2.74s/it]\n",
      "Inference:  15%|█▍        | 10/67 [01:55<02:01,  2.14s/it]\n",
      "Inference:  16%|█▋        | 11/67 [01:56<01:35,  1.71s/it]\n",
      "Inference:  18%|█▊        | 12/67 [01:57<01:17,  1.41s/it]\n",
      "Inference:  19%|█▉        | 13/67 [01:57<01:04,  1.20s/it]\n",
      "Inference:  21%|██        | 14/67 [01:58<00:56,  1.06s/it]\n",
      "Inference:  22%|██▏       | 15/67 [01:59<00:49,  1.04it/s]\n",
      "Inference:  24%|██▍       | 16/67 [01:59<00:45,  1.12it/s]\n",
      "Inference:  25%|██▌       | 17/67 [02:00<00:41,  1.20it/s]\n",
      "Inference:  27%|██▋       | 18/67 [02:01<00:38,  1.26it/s]\n",
      "Inference:  28%|██▊       | 19/67 [02:02<00:36,  1.31it/s]\n",
      "Inference:  30%|██▉       | 20/67 [02:02<00:35,  1.34it/s]\n",
      "Inference:  31%|███▏      | 21/67 [02:03<00:33,  1.36it/s]\n",
      "Inference:  33%|███▎      | 22/67 [02:04<00:32,  1.39it/s]\n",
      "Inference:  34%|███▍      | 23/67 [02:04<00:31,  1.40it/s]\n",
      "Inference:  36%|███▌      | 24/67 [02:05<00:30,  1.42it/s]\n",
      "Inference:  37%|███▋      | 25/67 [02:06<00:29,  1.43it/s]\n",
      "Inference:  39%|███▉      | 26/67 [02:06<00:28,  1.44it/s]\n",
      "Inference:  40%|████      | 27/67 [02:07<00:27,  1.45it/s]\n",
      "Inference:  42%|████▏     | 28/67 [02:08<00:26,  1.45it/s]\n",
      "Inference:  43%|████▎     | 29/67 [02:08<00:26,  1.45it/s]\n",
      "Inference:  45%|████▍     | 30/67 [02:09<00:25,  1.45it/s]\n",
      "Inference:  46%|████▋     | 31/67 [02:10<00:24,  1.46it/s]\n",
      "Inference:  48%|████▊     | 32/67 [02:10<00:23,  1.47it/s]\n",
      "Inference:  49%|████▉     | 33/67 [02:11<00:23,  1.48it/s]\n",
      "Inference:  51%|█████     | 34/67 [02:12<00:22,  1.48it/s]\n",
      "Inference:  52%|█████▏    | 35/67 [02:12<00:21,  1.49it/s]\n",
      "Inference:  54%|█████▎    | 36/67 [02:13<00:20,  1.49it/s]\n",
      "Inference:  55%|█████▌    | 37/67 [02:14<00:20,  1.50it/s]\n",
      "Inference:  57%|█████▋    | 38/67 [02:14<00:19,  1.51it/s]\n",
      "Inference:  58%|█████▊    | 39/67 [02:15<00:18,  1.52it/s]\n",
      "Inference:  60%|█████▉    | 40/67 [02:16<00:17,  1.52it/s]\n",
      "Inference:  61%|██████    | 41/67 [02:16<00:17,  1.52it/s]\n",
      "Inference:  63%|██████▎   | 42/67 [02:17<00:16,  1.52it/s]\n",
      "Inference:  64%|██████▍   | 43/67 [02:18<00:15,  1.53it/s]\n",
      "Inference:  66%|██████▌   | 44/67 [02:18<00:15,  1.52it/s]\n",
      "Inference:  67%|██████▋   | 45/67 [02:19<00:14,  1.52it/s]\n",
      "Inference:  69%|██████▊   | 46/67 [02:20<00:13,  1.51it/s]\n",
      "Inference:  70%|███████   | 47/67 [02:20<00:13,  1.51it/s]\n",
      "Inference:  72%|███████▏  | 48/67 [02:21<00:12,  1.51it/s]\n",
      "Inference:  73%|███████▎  | 49/67 [02:22<00:11,  1.50it/s]\n",
      "Inference:  75%|███████▍  | 50/67 [02:22<00:11,  1.51it/s]\n",
      "Inference:  76%|███████▌  | 51/67 [02:23<00:10,  1.50it/s]\n",
      "Inference:  78%|███████▊  | 52/67 [02:24<00:09,  1.50it/s]\n",
      "Inference:  79%|███████▉  | 53/67 [02:24<00:09,  1.50it/s]\n",
      "Inference:  81%|████████  | 54/67 [02:25<00:08,  1.51it/s]\n",
      "Inference:  82%|████████▏ | 55/67 [02:26<00:07,  1.51it/s]\n",
      "Inference:  84%|████████▎ | 56/67 [02:26<00:07,  1.51it/s]\n",
      "Inference:  85%|████████▌ | 57/67 [02:27<00:06,  1.51it/s]\n",
      "Inference:  87%|████████▋ | 58/67 [02:28<00:05,  1.51it/s]\n",
      "Inference:  88%|████████▊ | 59/67 [02:28<00:05,  1.51it/s]\n",
      "Inference:  90%|████████▉ | 60/67 [02:29<00:04,  1.51it/s]\n",
      "Inference:  91%|█████████ | 61/67 [02:30<00:03,  1.52it/s]\n",
      "Inference:  93%|█████████▎| 62/67 [02:30<00:03,  1.53it/s]\n",
      "Inference:  94%|█████████▍| 63/67 [02:31<00:02,  1.53it/s]\n",
      "Inference:  96%|█████████▌| 64/67 [02:32<00:01,  1.54it/s]\n",
      "Inference:  97%|█████████▋| 65/67 [02:32<00:01,  1.54it/s]\n",
      "Inference:  99%|█████████▊| 66/67 [02:33<00:00,  1.54it/s]\n",
      "Inference: 100%|██████████| 67/67 [02:34<00:00,  1.30it/s]\n",
      "Inference: 100%|██████████| 67/67 [02:34<00:00,  2.31s/it]\n",
      "all_predictions shape: (5, 2121)\n",
      "all_probabilities shape: (5, 2121, 3)\n",
      "Combination strategy is majority_vote. Computing the majority vote...\n",
      "Average probabilities: [[0.04856452 0.1000803  0.8513552 ]\n",
      " [0.0403467  0.8111399  0.14851338]\n",
      " [0.0374686  0.80985165 0.1526797 ]\n",
      " ...\n",
      " [0.27869728 0.40833527 0.31296745]\n",
      " [0.78197736 0.06115351 0.15686914]\n",
      " [0.15807287 0.6775602  0.1643669 ]]\n",
      "Results exported to: outputs/ClassifierSegExperimentCV_224_epo50_bs32_lr1e-05_s42/2023-12-29_0940_VGG16_BN_Attention/ch2_majority_vote_test_ClassifierSegExperimentCV_224_epo50_bs32_lr1e-05_s42_2023-12-29_0940_VGG16_BN_Attention.csv\n"
     ]
    }
   ],
   "source": [
    "# Running inference on test split for best results challenge 2 (ensemble)\n",
    "# Majority Voting Ensemble\n",
    "# Note that for ensuring that shuffle is False, we also exported the prediction filenames to the same csv file\n",
    "# that filenames column has to be deleted manually before submission\n",
    "command = 'python ../inference.py --test_path \"../datasets/challenge2/test\" \\\n",
    "                    --experiment_name \"ClassifierSegExperimentCV\" \\\n",
    "                    --network_name \"VGG16_BN_Attention\" \\\n",
    "                    --max_epochs \"50\" \\\n",
    "                    --base_lr \"0.00001\" \\\n",
    "                    --batch_size \"32\" \\\n",
    "                    --timeframe \"2023-12-29_0940\" \\\n",
    "                    --verbose \"2\" \\\n",
    "                    --multi \\\n",
    "                    --ensemble'\n",
    "\n",
    "# run the function to excute the command\n",
    "_ = execute_cmd_realtime(command, log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excuting inference script...\n",
      "Namespace(test_path='../datasets/challenge2/test', output='outputs', experiment_name='BestK3', network_name='VGG16_BN_Attention', max_epochs=50, batch_size=32, base_lr=1e-05, img_size=224, seed=42, timeframe='2023-12-29_0940', verbose=2, multi=True, report=False, ensemble=True, combination_strategy='majority_vote', upscale_factor=8, gradcam=False)\n",
      "Constructed output path: outputs/BestK3_224_epo50_bs32_lr1e-05_s42/2023-12-29_0940_VGG16_BN_Attention. Searching for models...\n",
      "Found 3 models.\n",
      "Loading data with unknown class labels from ../datasets/challenge2/test path...\n",
      "Dataset labels: {'testX': -911, 'testY': -922, 'testZ': -933} dictionary.\n",
      "Loading the data from ../datasets/challenge2/test\n",
      "Forcing n_classes to be based on the length of the labels dictionary...\n",
      "Before: 1\n",
      "After: 3\n",
      "Dataset length: 2121\n",
      "Using VGG16_BN_Attention with configurations: num_classes='3', normalize_attn='False'\n",
      "Using VGG16_BN_Attention with configurations: num_classes='3', normalize_attn='False'\n",
      "Using VGG16_BN_Attention with configurations: num_classes='3', normalize_attn='False'\n",
      "\n",
      "Inference:   0%|          | 0/67 [00:00<?, ?it/s]\n",
      "Inference:   1%|▏         | 1/67 [00:31<34:52, 31.70s/it]\n",
      "Inference:   3%|▎         | 2/67 [00:32<14:24, 13.30s/it]\n",
      "Inference:   4%|▍         | 3/67 [00:32<07:57,  7.46s/it]\n",
      "Inference:   6%|▌         | 4/67 [00:33<04:56,  4.71s/it]\n",
      "Inference:   7%|▋         | 5/67 [00:33<03:17,  3.19s/it]\n",
      "Inference:   9%|▉         | 6/67 [00:34<02:18,  2.28s/it]\n",
      "Inference:  10%|█         | 7/67 [00:34<01:41,  1.70s/it]\n",
      "Inference:  12%|█▏        | 8/67 [00:35<01:17,  1.32s/it]\n",
      "Inference:  13%|█▎        | 9/67 [00:35<01:01,  1.06s/it]\n",
      "Inference:  15%|█▍        | 10/67 [00:36<00:50,  1.13it/s]\n",
      "Inference:  16%|█▋        | 11/67 [00:36<00:42,  1.31it/s]\n",
      "Inference:  18%|█▊        | 12/67 [00:37<00:37,  1.47it/s]\n",
      "Inference:  19%|█▉        | 13/67 [00:37<00:33,  1.61it/s]\n",
      "Inference:  21%|██        | 14/67 [00:38<00:30,  1.75it/s]\n",
      "Inference:  22%|██▏       | 15/67 [00:38<00:27,  1.86it/s]\n",
      "Inference:  24%|██▍       | 16/67 [00:38<00:26,  1.95it/s]\n",
      "Inference:  25%|██▌       | 17/67 [00:39<00:24,  2.04it/s]\n",
      "Inference:  27%|██▋       | 18/67 [00:39<00:23,  2.11it/s]\n",
      "Inference:  28%|██▊       | 19/67 [00:40<00:22,  2.17it/s]\n",
      "Inference:  30%|██▉       | 20/67 [00:40<00:21,  2.20it/s]\n",
      "Inference:  31%|███▏      | 21/67 [00:41<00:20,  2.24it/s]\n",
      "Inference:  33%|███▎      | 22/67 [00:41<00:19,  2.27it/s]\n",
      "Inference:  34%|███▍      | 23/67 [00:41<00:19,  2.30it/s]\n",
      "Inference:  36%|███▌      | 24/67 [00:42<00:18,  2.30it/s]\n",
      "Inference:  37%|███▋      | 25/67 [00:42<00:18,  2.32it/s]\n",
      "Inference:  39%|███▉      | 26/67 [00:43<00:17,  2.33it/s]\n",
      "Inference:  40%|████      | 27/67 [00:43<00:17,  2.35it/s]\n",
      "Inference:  42%|████▏     | 28/67 [00:44<00:16,  2.36it/s]\n",
      "Inference:  43%|████▎     | 29/67 [00:44<00:16,  2.37it/s]\n",
      "Inference:  45%|████▍     | 30/67 [00:44<00:15,  2.39it/s]\n",
      "Inference:  46%|████▋     | 31/67 [00:45<00:15,  2.39it/s]\n",
      "Inference:  48%|████▊     | 32/67 [00:45<00:14,  2.40it/s]\n",
      "Inference:  49%|████▉     | 33/67 [00:46<00:14,  2.41it/s]\n",
      "Inference:  51%|█████     | 34/67 [00:46<00:13,  2.42it/s]\n",
      "Inference:  52%|█████▏    | 35/67 [00:46<00:13,  2.43it/s]\n",
      "Inference:  54%|█████▎    | 36/67 [00:47<00:12,  2.42it/s]\n",
      "Inference:  55%|█████▌    | 37/67 [00:47<00:12,  2.40it/s]\n",
      "Inference:  57%|█████▋    | 38/67 [00:48<00:12,  2.40it/s]\n",
      "Inference:  58%|█████▊    | 39/67 [00:48<00:11,  2.40it/s]\n",
      "Inference:  60%|█████▉    | 40/67 [00:49<00:11,  2.41it/s]\n",
      "Inference:  61%|██████    | 41/67 [00:49<00:10,  2.42it/s]\n",
      "Inference:  63%|██████▎   | 42/67 [00:49<00:10,  2.40it/s]\n",
      "Inference:  64%|██████▍   | 43/67 [00:50<00:09,  2.43it/s]\n",
      "Inference:  66%|██████▌   | 44/67 [00:50<00:09,  2.44it/s]\n",
      "Inference:  67%|██████▋   | 45/67 [00:51<00:08,  2.45it/s]\n",
      "Inference:  69%|██████▊   | 46/67 [00:51<00:08,  2.46it/s]\n",
      "Inference:  70%|███████   | 47/67 [00:51<00:08,  2.46it/s]\n",
      "Inference:  72%|███████▏  | 48/67 [00:52<00:07,  2.47it/s]\n",
      "Inference:  73%|███████▎  | 49/67 [00:52<00:07,  2.48it/s]\n",
      "Inference:  75%|███████▍  | 50/67 [00:53<00:06,  2.48it/s]\n",
      "Inference:  76%|███████▌  | 51/67 [00:53<00:06,  2.48it/s]\n",
      "Inference:  78%|███████▊  | 52/67 [00:53<00:06,  2.48it/s]\n",
      "Inference:  79%|███████▉  | 53/67 [00:54<00:05,  2.50it/s]\n",
      "Inference:  81%|████████  | 54/67 [00:54<00:05,  2.50it/s]\n",
      "Inference:  82%|████████▏ | 55/67 [00:55<00:04,  2.47it/s]\n",
      "Inference:  84%|████████▎ | 56/67 [00:55<00:04,  2.47it/s]\n",
      "Inference:  85%|████████▌ | 57/67 [00:55<00:04,  2.49it/s]\n",
      "Inference:  87%|████████▋ | 58/67 [00:56<00:03,  2.48it/s]\n",
      "Inference:  88%|████████▊ | 59/67 [00:56<00:03,  2.48it/s]\n",
      "Inference:  90%|████████▉ | 60/67 [00:57<00:02,  2.48it/s]\n",
      "Inference:  91%|█████████ | 61/67 [00:57<00:02,  2.48it/s]\n",
      "Inference:  93%|█████████▎| 62/67 [00:57<00:02,  2.50it/s]\n",
      "Inference:  94%|█████████▍| 63/67 [00:58<00:01,  2.51it/s]\n",
      "Inference:  96%|█████████▌| 64/67 [00:58<00:01,  2.52it/s]\n",
      "Inference:  97%|█████████▋| 65/67 [00:59<00:00,  2.53it/s]\n",
      "Inference:  99%|█████████▊| 66/67 [00:59<00:00,  2.55it/s]\n",
      "Inference: 100%|██████████| 67/67 [01:00<00:00,  1.98it/s]\n",
      "Inference: 100%|██████████| 67/67 [01:00<00:00,  1.11it/s]\n",
      "all_predictions shape: (3, 2121)\n",
      "all_probabilities shape: (3, 2121, 3)\n",
      "Combination strategy is majority_vote. Computing the majority vote...\n",
      "Average probabilities: [[0.02999242 0.07420763 0.89579993]\n",
      " [0.03994111 0.7840274  0.17603149]\n",
      " [0.03668012 0.76562744 0.19769238]\n",
      " ...\n",
      " [0.27264452 0.40111208 0.32624343]\n",
      " [0.7947905  0.05705102 0.14815848]\n",
      " [0.17636561 0.6478038  0.17583056]]\n",
      "Results exported to: outputs/BestK3_224_epo50_bs32_lr1e-05_s42/2023-12-29_0940_VGG16_BN_Attention/ch2_majority_vote_test_BestK3_224_epo50_bs32_lr1e-05_s42_2023-12-29_0940_VGG16_BN_Attention.csv\n"
     ]
    }
   ],
   "source": [
    "# Inferencing only the best 3 folds models from the baseline in the same folder << on the test set >>\n",
    "# BEST 3 FOLDS CHALLENGE 2 <<SUBMISSION>>\n",
    "command = 'python ../inference.py --test_path \"../datasets/challenge2/test\" \\\n",
    "                    --experiment_name \"BestK3\" \\\n",
    "                    --network_name \"VGG16_BN_Attention\" \\\n",
    "                    --max_epochs \"50\" \\\n",
    "                    --base_lr \"0.00001\" \\\n",
    "                    --batch_size \"32\" \\\n",
    "                    --timeframe \"2023-12-29_0940\" \\\n",
    "                    --verbose \"2\" \\\n",
    "                    --multi \\\n",
    "                    --ensemble'\n",
    "\n",
    "# run the function to excute the command\n",
    "_ = execute_cmd_realtime(command, log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excuting inference script...\n",
      "Namespace(test_path='../datasets/challenge2/val', output='outputs', experiment_name='ClassifierSegExperimentCV', network_name='VGG16_BN_Attention', max_epochs=50, batch_size=32, base_lr=1e-05, img_size=224, seed=42, timeframe='2023-12-29_0940', verbose=2, multi=True, report=True, ensemble=True, combination_strategy='majority_vote', upscale_factor=8, gradcam=False)\n",
      "Constructed output path: outputs/ClassifierSegExperimentCV_224_epo50_bs32_lr1e-05_s42/2023-12-29_0940_VGG16_BN_Attention. Searching for models...\n",
      "Found 5 models.\n",
      "Loading data with 3 class labels from ../datasets/challenge2/val path...\n",
      "Dataset labels: {'mel': 0, 'bcc': 1, 'scc': 2} dictionary.\n",
      "Loading the data from ../datasets/challenge2/val\n",
      "Dataset length: 1270\n",
      "Using VGG16_BN_Attention with configurations: num_classes='3', normalize_attn='False'\n",
      "Using VGG16_BN_Attention with configurations: num_classes='3', normalize_attn='False'\n",
      "Using VGG16_BN_Attention with configurations: num_classes='3', normalize_attn='False'\n",
      "Using VGG16_BN_Attention with configurations: num_classes='3', normalize_attn='False'\n",
      "Using VGG16_BN_Attention with configurations: num_classes='3', normalize_attn='False'\n",
      "\n",
      "Inference:   0%|          | 0/40 [00:00<?, ?it/s]\n",
      "Inference:   2%|▎         | 1/40 [01:57<1:16:10, 117.20s/it]\n",
      "Inference:   5%|▌         | 2/40 [01:57<30:50, 48.69s/it]   \n",
      "Inference:   8%|▊         | 3/40 [01:58<16:31, 26.80s/it]\n",
      "Inference:  10%|█         | 4/40 [01:59<09:55, 16.53s/it]\n",
      "Inference:  12%|█▎        | 5/40 [02:00<06:20, 10.86s/it]\n",
      "Inference:  15%|█▌        | 6/40 [02:01<04:13,  7.44s/it]\n",
      "Inference:  18%|█▊        | 7/40 [02:01<02:53,  5.26s/it]\n",
      "Inference:  20%|██        | 8/40 [02:02<02:02,  3.83s/it]\n",
      "Inference:  22%|██▎       | 9/40 [02:03<01:29,  2.88s/it]\n",
      "Inference:  25%|██▌       | 10/40 [02:04<01:06,  2.22s/it]\n",
      "Inference:  28%|██▊       | 11/40 [02:04<00:51,  1.76s/it]\n",
      "Inference:  30%|███       | 12/40 [02:05<00:40,  1.44s/it]\n",
      "Inference:  32%|███▎      | 13/40 [02:06<00:32,  1.21s/it]\n",
      "Inference:  35%|███▌      | 14/40 [02:06<00:27,  1.04s/it]\n",
      "Inference:  38%|███▊      | 15/40 [02:07<00:23,  1.08it/s]\n",
      "Inference:  40%|████      | 16/40 [02:08<00:20,  1.17it/s]\n",
      "Inference:  42%|████▎     | 17/40 [02:08<00:18,  1.25it/s]\n",
      "Inference:  45%|████▌     | 18/40 [02:09<00:16,  1.31it/s]\n",
      "Inference:  48%|████▊     | 19/40 [02:10<00:15,  1.36it/s]\n",
      "Inference:  50%|█████     | 20/40 [02:10<00:14,  1.41it/s]\n",
      "Inference:  52%|█████▎    | 21/40 [02:11<00:13,  1.45it/s]\n",
      "Inference:  55%|█████▌    | 22/40 [02:12<00:14,  1.21it/s]\n",
      "Inference:  57%|█████▊    | 23/40 [02:13<00:13,  1.22it/s]\n",
      "Inference:  60%|██████    | 24/40 [02:14<00:12,  1.26it/s]\n",
      "Inference:  62%|██████▎   | 25/40 [02:14<00:11,  1.30it/s]\n",
      "Inference:  65%|██████▌   | 26/40 [02:16<00:13,  1.08it/s]\n",
      "Inference:  68%|██████▊   | 27/40 [02:17<00:11,  1.11it/s]\n",
      "Inference:  70%|███████   | 28/40 [02:17<00:10,  1.17it/s]\n",
      "Inference:  72%|███████▎  | 29/40 [02:18<00:08,  1.23it/s]\n",
      "Inference:  75%|███████▌  | 30/40 [02:19<00:07,  1.25it/s]\n",
      "Inference:  78%|███████▊  | 31/40 [02:22<00:12,  1.41s/it]\n",
      "Inference:  80%|████████  | 32/40 [02:22<00:09,  1.18s/it]\n",
      "Inference:  82%|████████▎ | 33/40 [02:24<00:08,  1.21s/it]\n",
      "Inference:  85%|████████▌ | 34/40 [02:28<00:13,  2.18s/it]\n",
      "Inference:  88%|████████▊ | 35/40 [02:29<00:08,  1.79s/it]\n",
      "Inference:  90%|█████████ | 36/40 [02:30<00:05,  1.46s/it]\n",
      "Inference:  92%|█████████▎| 37/40 [02:31<00:04,  1.40s/it]\n",
      "Inference:  95%|█████████▌| 38/40 [02:35<00:04,  2.30s/it]\n",
      "Inference:  98%|█████████▊| 39/40 [02:38<00:02,  2.41s/it]\n",
      "Inference: 100%|██████████| 40/40 [02:45<00:00,  3.75s/it]\n",
      "Inference: 100%|██████████| 40/40 [02:45<00:00,  4.14s/it]\n",
      "all_predictions shape: (5, 1270)\n",
      "all_probabilities shape: (5, 1270, 3)\n",
      "Combination strategy is majority_vote. Computing the majority vote...\n",
      "Average probabilities: [[0.0557933  0.6696651  0.27454162]\n",
      " [0.03820459 0.9375885  0.02420692]\n",
      " [0.02623783 0.89356565 0.08019648]\n",
      " ...\n",
      " [0.2611936  0.2302496  0.5085567 ]\n",
      " [0.0099835  0.17312597 0.81689054]\n",
      " [0.21899271 0.3619659  0.4190414 ]]\n",
      "Results exported to: outputs/ClassifierSegExperimentCV_224_epo50_bs32_lr1e-05_s42/2023-12-29_0940_VGG16_BN_Attention/ch2_majority_vote_val_ClassifierSegExperimentCV_224_epo50_bs32_lr1e-05_s42_2023-12-29_0940_VGG16_BN_Attention.csv\n",
      "Computing AUC scores for each class...\n",
      "Figure(1500x600)\n",
      "Majority vote AUC: 0.99811\n",
      "Majority vote AUC Scores: [0.99789225 0.99870206 0.99773846]\n",
      "Majority vote accuracy: 0.9755905511811024\n",
      "Majority vote kappa: 0.9561797952905245\n",
      "Target 0 - Precision: 0.98808, Recall: 0.97788, F-score: 0.98295, Sensitivity: 0.9778761061946902, Specificity: 0.9864864864864865, Support: 678\n",
      "Target 1 - Precision: 0.97018, Recall: 0.97992, F-score: 0.97502, Sensitivity: 0.9799196787148594, Specificity: 0.9805699481865285, Support: 498\n",
      "Target 2 - Precision: 0.91667, Recall: 0.93617, F-score: 0.92632, Sensitivity: 0.9361702127659575, Specificity: 0.9931972789115646, Support: 94\n",
      "(   {   'accuracy': 0.9755905511811024,\n",
      "        'auc': 0.9981109232924158,\n",
      "        'auc_scores': [   0.9978922506577373,\n",
      "                          0.9987020621345485,\n",
      "                          0.9977384570849616],\n",
      "        'fscore': [0.9829503335804298, 0.975024975024975, 0.9263157894736843],\n",
      "        'kappa': 0.9561797952905245,\n",
      "        'precision': [   0.9880774962742176,\n",
      "                         0.9701789264413518,\n",
      "                         0.9166666666666666],\n",
      "        'recall': [0.9778761061946902, 0.9799196787148594, 0.9361702127659575],\n",
      "        'sensitivity': [   0.9778761061946902,\n",
      "                           0.9799196787148594,\n",
      "                           0.9361702127659575],\n",
      "        'specificity': [   0.9864864864864865,\n",
      "                           0.9805699481865285,\n",
      "                           0.9931972789115646],\n",
      "        'support': [678, 498, 94]},)\n"
     ]
    }
   ],
   "source": [
    "# BEST RESULT CHALLENGE 2\n",
    "# command = 'python ../inference.py --test_path \"../datasets/challenge2/val\" \\\n",
    "#                     --experiment_name \"ClassifierSegExperimentCV\" \\\n",
    "#                     --network_name \"VGG16_BN_Attention\" \\\n",
    "#                     --max_epochs \"50\" \\\n",
    "#                     --base_lr \"0.00001\" \\\n",
    "#                     --batch_size \"32\" \\\n",
    "#                     --timeframe \"2023-12-29_0940\" \\\n",
    "#                     --verbose \"2\" \\\n",
    "#                     --multi \\\n",
    "#                     --ensemble \\\n",
    "#                     --report'\n",
    "\n",
    "# command = 'python ../inference.py --test_path \"../datasets/challenge2/val\" \\\n",
    "#                     --experiment_name \"ClassifierSegExperimentCV\" \\\n",
    "#                     --network_name \"VGG16_BN_Attention\" \\\n",
    "#                     --max_epochs \"50\" \\\n",
    "#                     --base_lr \"0.00001\" \\\n",
    "#                     --batch_size \"32\" \\\n",
    "#                     --timeframe \"2023-12-29_0940\" \\\n",
    "#                     --verbose \"2\" \\\n",
    "#                     --multi \\\n",
    "#                     --ensemble \\\n",
    "#                     --report \\\n",
    "#                     --combination_strategy \"weighted_voting\"'\n",
    "\n",
    "# command = 'python ../inference.py --test_path \"../datasets/challenge2/val\" \\\n",
    "#                     --experiment_name \"ClassifierSegExperimentCV\" \\\n",
    "#                     --network_name \"VGG16_BN_Attention\" \\\n",
    "#                     --max_epochs \"50\" \\\n",
    "#                     --base_lr \"0.00001\" \\\n",
    "#                     --batch_size \"32\" \\\n",
    "#                     --timeframe \"2023-12-29_0940\" \\\n",
    "#                     --verbose \"2\" \\\n",
    "#                     --multi \\\n",
    "#                     --ensemble \\\n",
    "#                     --report'\n",
    "\n",
    "# command = 'python ../inference.py --test_path \"../datasets/challenge2/val\" \\\n",
    "#                     --experiment_name \"ClassifierSegExperimentCV\" \\\n",
    "#                     --network_name \"VGG16_BN_Attention\" \\\n",
    "#                     --max_epochs \"50\" \\\n",
    "#                     --base_lr \"0.00001\" \\\n",
    "#                     --batch_size \"32\" \\\n",
    "#                     --timeframe \"2023-12-29_0940\" \\\n",
    "#                     --verbose \"2\" \\\n",
    "#                     --multi \\\n",
    "#                     --ensemble \\\n",
    "#                     --report \\\n",
    "#                     --gradcam'\n",
    "\n",
    "\n",
    "# run the function to excute the command\n",
    "_ = execute_cmd_realtime(command, log=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changes to hair augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excuting training pipeline with 50 epochs...\n",
      "Loading data with 3 class labels...\n",
      "Loading the data from ../datasets/challenge2/train\n",
      "Loading the data from ../datasets/challenge2/val\n",
      "Using segmentation masks for training...\n",
      "train_images: 5082, train_masks: 5082, train_labels: 5082\n",
      "Class weights: [0.62440103 0.84997491 4.50531915]\n",
      "Creating a classifier experiment using VGG16_BN_Attention network.\n",
      "Using VGG16_BN_Attention with configurations: num_classes='3', normalize_attn='False'\n",
      "Using focal loss.\n",
      "Using dice loss.\n",
      "Experiment started.\n",
      "Epoch: 1 Train batch 10 loss: 0.47001636028289795, 6.3% complete\n",
      "Epoch: 1 Train batch 20 loss: 0.4486575722694397, 12.6% complete\n"
     ]
    }
   ],
   "source": [
    "# BEST Single Model\n",
    "# 2024-01-02_2253_VGG16_BN_Attention\n",
    "command = 'python ../train.py --train_path \"../datasets/challenge2/train\" \\\n",
    "                        --train_masks_path \"../datasets_masks/challenge2/train\" \\\n",
    "                        --valid_path \"../datasets/challenge2/val\" \\\n",
    "                        --experiment_name \"ClassifierSegExperiment\" \\\n",
    "                        --network_name \"VGG16_BN_Attention\" \\\n",
    "                        --max_epochs \"50\" \\\n",
    "                        --base_lr \"0.00001\" \\\n",
    "                        --batch_size \"32\" \\\n",
    "                        --verbose \"2\" \\\n",
    "                        --focal_loss \\\n",
    "                        --multi'\n",
    "\n",
    "# run the function to excute the command\n",
    "_ = execute_cmd_realtime(command, log=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "2024-01-03 13:00:28.754 | INFO     | experiments.ClassifierSegExperiment:run_test:387 - Test Accuracy: 0.93386\n",
    "2024-01-03 13:00:28.755 | INFO     | experiments.ClassifierSegExperiment:run_test:388 - Test AUC: 0.98470\n",
    "2024-01-03 13:00:28.756 | INFO     | experiments.ClassifierSegExperiment:run_test:389 - Test AUC Scores: [0.98784182 0.98899484 0.97724888]\n",
    "2024-01-03 13:00:28.756 | INFO     | experiments.ClassifierSegExperiment:run_test:390 - Test Kappa: 0.87990\n",
    "2024-01-03 13:00:28.756 | INFO     | experiments.ClassifierSegExperiment:run_test:394 - Target 0 - Precision: 0.95051, Recall: 0.96313, F-score: 0.95678, Sensitivity: 0.9631268436578171, Specificity: 0.9425675675675675, Support: 678\n",
    "2024-01-03 13:00:28.757 | INFO     | experiments.ClassifierSegExperiment:run_test:394 - Target 1 - Precision: 0.93267, Recall: 0.94578, F-score: 0.93918, Sensitivity: 0.9457831325301205, Specificity: 0.9559585492227979, Support: 498\n",
    "2024-01-03 13:00:28.757 | INFO     | experiments.ClassifierSegExperiment:run_test:394 - Target 2 - Precision: 0.79487, Recall: 0.65957, F-score: 0.72093, Sensitivity: 0.6595744680851063, Specificity: 0.9863945578231292, Support: 94\n",
    "2024-01-03 13:00:28.757 | INFO     | experiments.ClassifierSegExperiment:run_test:396 - \n",
    "Classification Report:\n",
    "            precision    recall  f1-score   support\n",
    "\n",
    "            0       0.95      0.96      0.96       678\n",
    "            1       0.93      0.95      0.94       498\n",
    "            2       0.79      0.66      0.72        94\n",
    "\n",
    "      accuracy                            0.93      1270\n",
    "      macro avg       0.89      0.86      0.87      1270\n",
    "      weighted avg    0.93      0.93      0.93      1270\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excuting training pipeline with 50 epochs and 5 folds.\n",
      "Loading data with 3 class labels...\n",
      "Loading the data from ../datasets/challenge2/train\n",
      "Loading the data from ../datasets/challenge2/val\n",
      "Using segmentation masks for training...\n",
      "train_images: 5082, train_masks: 5082, train_labels: 5082\n",
      "val_images: 1270, val_masks: 1270, val_labels: 1270\n",
      "Class weights: [0.62427817 0.85023427 4.50443262]\n",
      "Creating a classifier experiment using VGG16_BN_Attention network.\n",
      "Using VGG16_BN_Attention with configurations: num_classes='3', normalize_attn='False'\n",
      "Using focal loss.\n",
      "Using dice loss.\n"
     ]
    }
   ],
   "source": [
    "# 2024-01-03_1221_VGG16_BN_Attention\n",
    "command = 'python ../train_cv.py \\\n",
    "                    --train_path \"../datasets/challenge2/train\" \\\n",
    "                    --train_masks_path \"../datasets_masks/challenge2/train\" \\\n",
    "                    --valid_path \"../datasets/challenge2/val\" \\\n",
    "                    --valid_masks_path \"../datasets_masks/challenge2/val\"\\\n",
    "                    --experiment_name \"ClassifierSegExperimentCV\" \\\n",
    "                    --network_name \"VGG16_BN_Attention\" \\\n",
    "                    --max_epochs \"50\" \\\n",
    "                    --base_lr \"0.00001\" \\\n",
    "                    --num_folds \"5\" \\\n",
    "                    --batch_size \"32\" \\\n",
    "                    --verbose \"1\" \\\n",
    "                    --focal_loss \\\n",
    "                    --multi'\n",
    "\n",
    "# run the function to excute the command\n",
    "_ = execute_cmd_realtime(command, log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excuting inference script...\n",
      "Namespace(test_path='../datasets/challenge2/val', output='outputs', experiment_name='ClassifierSegExperimentCV', network_name='VGG16_BN_Attention', max_epochs=50, batch_size=32, base_lr=1e-05, img_size=224, seed=42, timeframe='2024-01-03_1221', verbose=2, multi=True, report=True, ensemble=True)\n",
      "Constructed output path: outputs/ClassifierSegExperimentCV_224_epo50_bs32_lr1e-05_s42/2024-01-03_1221_VGG16_BN_Attention. Searching for models...\n",
      "Found 5 models. Starting loading the models.\n",
      "Loading data with 3 class labels from ../datasets/challenge2/val path...\n",
      "Dataset labels: {'mel': 0, 'bcc': 1, 'scc': 2} dictionary.\n",
      "Loading the data from ../datasets/challenge2/val\n",
      "Dataset length: 1270\n",
      "Using VGG16_BN_Attention with configurations: num_classes='3', normalize_attn='False'\n",
      "Using VGG16_BN_Attention with configurations: num_classes='3', normalize_attn='False'\n",
      "Using VGG16_BN_Attention with configurations: num_classes='3', normalize_attn='False'\n",
      "Using VGG16_BN_Attention with configurations: num_classes='3', normalize_attn='False'\n",
      "Using VGG16_BN_Attention with configurations: num_classes='3', normalize_attn='False'\n",
      "\n",
      "Inference:   0%|          | 0/40 [00:00<?, ?it/s]\n",
      "Inference:   2%|▎         | 1/40 [00:06<03:55,  6.03s/it]\n",
      "Inference:   5%|▌         | 2/40 [00:06<01:51,  2.93s/it]\n",
      "Inference:   8%|▊         | 3/40 [00:07<01:11,  1.94s/it]\n",
      "Inference:  10%|█         | 4/40 [00:08<00:52,  1.47s/it]\n",
      "Inference:  12%|█▎        | 5/40 [00:09<00:42,  1.21s/it]\n",
      "Inference:  15%|█▌        | 6/40 [00:09<00:35,  1.05s/it]\n",
      "Inference:  18%|█▊        | 7/40 [00:10<00:31,  1.05it/s]\n",
      "Inference:  20%|██        | 8/40 [00:11<00:28,  1.13it/s]\n",
      "Inference:  22%|██▎       | 9/40 [00:12<00:26,  1.19it/s]\n",
      "Inference:  25%|██▌       | 10/40 [00:12<00:24,  1.23it/s]\n",
      "Inference:  28%|██▊       | 11/40 [00:13<00:23,  1.26it/s]\n",
      "Inference:  30%|███       | 12/40 [00:14<00:21,  1.28it/s]\n",
      "Inference:  32%|███▎      | 13/40 [00:15<00:20,  1.30it/s]\n",
      "Inference:  35%|███▌      | 14/40 [00:15<00:19,  1.31it/s]\n",
      "Inference:  38%|███▊      | 15/40 [00:16<00:19,  1.31it/s]\n",
      "Inference:  40%|████      | 16/40 [00:17<00:18,  1.32it/s]\n",
      "Inference:  42%|████▎     | 17/40 [00:18<00:17,  1.32it/s]\n",
      "Inference:  45%|████▌     | 18/40 [00:18<00:16,  1.33it/s]\n",
      "Inference:  48%|████▊     | 19/40 [00:19<00:15,  1.33it/s]\n",
      "Inference:  50%|█████     | 20/40 [00:20<00:15,  1.33it/s]\n",
      "Inference:  52%|█████▎    | 21/40 [00:21<00:14,  1.33it/s]\n",
      "Inference:  55%|█████▌    | 22/40 [00:21<00:13,  1.33it/s]\n",
      "Inference:  57%|█████▊    | 23/40 [00:22<00:12,  1.33it/s]\n",
      "Inference:  60%|██████    | 24/40 [00:23<00:12,  1.33it/s]\n",
      "Inference:  62%|██████▎   | 25/40 [00:24<00:11,  1.33it/s]\n",
      "Inference:  65%|██████▌   | 26/40 [00:24<00:10,  1.33it/s]\n",
      "Inference:  68%|██████▊   | 27/40 [00:25<00:09,  1.33it/s]\n",
      "Inference:  70%|███████   | 28/40 [00:26<00:09,  1.33it/s]\n",
      "Inference:  72%|███████▎  | 29/40 [00:27<00:08,  1.33it/s]\n",
      "Inference:  75%|███████▌  | 30/40 [00:27<00:07,  1.33it/s]\n",
      "Inference:  78%|███████▊  | 31/40 [00:28<00:06,  1.33it/s]\n",
      "Inference:  80%|████████  | 32/40 [00:29<00:06,  1.33it/s]\n",
      "Inference:  82%|████████▎ | 33/40 [00:30<00:05,  1.33it/s]\n",
      "Inference:  85%|████████▌ | 34/40 [00:30<00:04,  1.34it/s]\n",
      "Inference:  88%|████████▊ | 35/40 [00:31<00:03,  1.34it/s]\n",
      "Inference:  90%|█████████ | 36/40 [00:32<00:02,  1.34it/s]\n",
      "Inference:  92%|█████████▎| 37/40 [00:33<00:02,  1.34it/s]\n",
      "Inference:  95%|█████████▌| 38/40 [00:33<00:01,  1.34it/s]\n",
      "Inference:  98%|█████████▊| 39/40 [00:34<00:00,  1.34it/s]\n",
      "Inference: 100%|██████████| 40/40 [00:36<00:00,  1.10s/it]\n",
      "Inference: 100%|██████████| 40/40 [00:36<00:00,  1.10it/s]\n",
      "Results exported to: outputs/ClassifierSegExperimentCV_224_epo50_bs32_lr1e-05_s42/2024-01-03_1221_VGG16_BN_Attention/ClassifierSegExperimentCV_224_epo50_bs32_lr1e-05_s42_2024-01-03_1221_VGG16_BN_Attention.csv\n",
      "Computing AUC scores for each class...\n",
      "Figure(1500x600)\n",
      "Majority vote AUC: 0.99855\n",
      "Majority vote AUC Scores: [0.99859733 0.99887633 0.99816363]\n",
      "Majority vote accuracy: 0.974015748031496\n",
      "Majority vote kappa: 0.9532099890142279\n",
      "Target 0 - Precision: 0.98519, Recall: 0.98083, F-score: 0.98300, Sensitivity: 0.9808259587020649, Specificity: 0.9831081081081081, Support: 678\n",
      "Target 1 - Precision: 0.97024, Recall: 0.98193, F-score: 0.97605, Sensitivity: 0.9819277108433735, Specificity: 0.9805699481865285, Support: 498\n",
      "Target 2 - Precision: 0.91209, Recall: 0.88298, F-score: 0.89730, Sensitivity: 0.8829787234042553, Specificity: 0.9931972789115646, Support: 94\n",
      "(   {   'accuracy': 0.974015748031496,\n",
      "        'auc': 0.9985457622357509,\n",
      "        'auc_scores': [   0.9985973252013075,\n",
      "                          0.9988763343529559,\n",
      "                          0.9981636271529889],\n",
      "        'fscore': [0.9830007390983, 0.9760479041916169, 0.8972972972972972],\n",
      "        'kappa': 0.9532099890142279,\n",
      "        'precision': [   0.9851851851851852,\n",
      "                         0.9702380952380952,\n",
      "                         0.9120879120879121],\n",
      "        'recall': [0.9808259587020649, 0.9819277108433735, 0.8829787234042553],\n",
      "        'sensitivity': [   0.9808259587020649,\n",
      "                           0.9819277108433735,\n",
      "                           0.8829787234042553],\n",
      "        'specificity': [   0.9831081081081081,\n",
      "                           0.9805699481865285,\n",
      "                           0.9931972789115646],\n",
      "        'support': [678, 498, 94]},)\n"
     ]
    }
   ],
   "source": [
    "command = 'python ../inference.py --test_path \"../datasets/challenge2/val\" \\\n",
    "                    --experiment_name \"ClassifierSegExperimentCV\" \\\n",
    "                    --network_name \"VGG16_BN_Attention\" \\\n",
    "                    --max_epochs \"50\" \\\n",
    "                    --base_lr \"0.00001\" \\\n",
    "                    --batch_size \"32\" \\\n",
    "                    --timeframe \"2024-01-03_1221\" \\\n",
    "                    --verbose \"2\" \\\n",
    "                    --multi \\\n",
    "                    --ensemble \\\n",
    "                    --report'\n",
    "\n",
    "# run the function to excute the command\n",
    "_ = execute_cmd_realtime(command, log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excuting inference script...\n",
      "Namespace(test_path='../datasets/challenge2/val', output='outputs', experiment_name='ClassifierSegExperimentCV', network_name='VGG16_BN_Attention', max_epochs=50, batch_size=32, base_lr=1e-05, img_size=224, seed=42, timeframe='2024-01-03_1221', verbose=2, multi=True, report=True, ensemble=True, combination_strategy='majority_vote')\n",
      "Constructed output path: outputs/ClassifierSegExperimentCV_224_epo50_bs32_lr1e-05_s42/2024-01-03_1221_VGG16_BN_Attention. Searching for models...\n",
      "Found 5 models.\n",
      "Loading data with 3 class labels from ../datasets/challenge2/val path...\n",
      "Dataset labels: {'mel': 0, 'bcc': 1, 'scc': 2} dictionary.\n",
      "Loading the data from ../datasets/challenge2/val\n",
      "Dataset length: 1270\n",
      "Using VGG16_BN_Attention with configurations: num_classes='3', normalize_attn='False'\n",
      "Using VGG16_BN_Attention with configurations: num_classes='3', normalize_attn='False'\n",
      "Using VGG16_BN_Attention with configurations: num_classes='3', normalize_attn='False'\n",
      "Using VGG16_BN_Attention with configurations: num_classes='3', normalize_attn='False'\n",
      "Using VGG16_BN_Attention with configurations: num_classes='3', normalize_attn='False'\n",
      "\n",
      "Inference:   0%|          | 0/40 [00:00<?, ?it/s]\n",
      "Inference:   2%|▎         | 1/40 [02:41<1:45:08, 161.74s/it]\n",
      "Inference:   5%|▌         | 2/40 [02:42<42:25, 66.99s/it]   \n",
      "Inference:   8%|▊         | 3/40 [02:43<22:38, 36.72s/it]\n",
      "Inference:  10%|█         | 4/40 [02:43<13:31, 22.54s/it]\n",
      "Inference:  12%|█▎        | 5/40 [02:44<08:37, 14.77s/it]\n",
      "Inference:  15%|█▌        | 6/40 [02:45<05:39,  9.98s/it]\n",
      "Inference:  18%|█▊        | 7/40 [02:46<03:48,  6.94s/it]\n",
      "Inference:  20%|██        | 8/40 [02:47<02:39,  4.99s/it]\n",
      "Inference:  22%|██▎       | 9/40 [02:47<01:53,  3.65s/it]\n",
      "Inference:  25%|██▌       | 10/40 [02:48<01:21,  2.73s/it]\n",
      "Inference:  28%|██▊       | 11/40 [02:49<01:00,  2.10s/it]\n",
      "Inference:  30%|███       | 12/40 [02:49<00:46,  1.66s/it]\n",
      "Inference:  32%|███▎      | 13/40 [02:50<00:36,  1.37s/it]\n",
      "Inference:  35%|███▌      | 14/40 [02:51<00:30,  1.16s/it]\n",
      "Inference:  38%|███▊      | 15/40 [02:51<00:25,  1.00s/it]\n",
      "Inference:  40%|████      | 16/40 [02:52<00:21,  1.11it/s]\n",
      "Inference:  42%|████▎     | 17/40 [02:53<00:19,  1.21it/s]\n",
      "Inference:  45%|████▌     | 18/40 [02:53<00:17,  1.29it/s]\n",
      "Inference:  48%|████▊     | 19/40 [02:54<00:15,  1.37it/s]\n",
      "Inference:  50%|█████     | 20/40 [02:55<00:14,  1.43it/s]\n",
      "Inference:  52%|█████▎    | 21/40 [02:55<00:12,  1.47it/s]\n",
      "Inference:  55%|█████▌    | 22/40 [02:56<00:11,  1.51it/s]\n",
      "Inference:  57%|█████▊    | 23/40 [02:56<00:11,  1.53it/s]\n",
      "Inference:  60%|██████    | 24/40 [02:57<00:10,  1.55it/s]\n",
      "Inference:  62%|██████▎   | 25/40 [02:58<00:09,  1.57it/s]\n",
      "Inference:  65%|██████▌   | 26/40 [02:58<00:08,  1.58it/s]\n",
      "Inference:  68%|██████▊   | 27/40 [02:59<00:08,  1.59it/s]\n",
      "Inference:  70%|███████   | 28/40 [03:00<00:07,  1.59it/s]\n",
      "Inference:  72%|███████▎  | 29/40 [03:00<00:06,  1.60it/s]\n",
      "Inference:  75%|███████▌  | 30/40 [03:01<00:06,  1.60it/s]\n",
      "Inference:  78%|███████▊  | 31/40 [03:01<00:05,  1.60it/s]\n",
      "Inference:  80%|████████  | 32/40 [03:02<00:05,  1.60it/s]\n",
      "Inference:  82%|████████▎ | 33/40 [03:03<00:04,  1.60it/s]\n",
      "Inference:  85%|████████▌ | 34/40 [03:03<00:03,  1.60it/s]\n",
      "Inference:  88%|████████▊ | 35/40 [03:04<00:03,  1.60it/s]\n",
      "Inference:  90%|█████████ | 36/40 [03:04<00:02,  1.60it/s]\n",
      "Inference:  92%|█████████▎| 37/40 [03:05<00:01,  1.61it/s]\n",
      "Inference:  95%|█████████▌| 38/40 [03:06<00:01,  1.61it/s]\n",
      "Inference:  98%|█████████▊| 39/40 [03:06<00:00,  1.61it/s]\n",
      "Inference: 100%|██████████| 40/40 [03:08<00:00,  1.05s/it]\n",
      "Inference: 100%|██████████| 40/40 [03:08<00:00,  4.72s/it]\n",
      "all_predictions shape: (5, 1270)\n",
      "all_probabilities shape: (5, 1270, 3)\n",
      "Combination strategy is majority_vote. Computing the majority vote...\n",
      "Average probabilities: [[0.04913265 0.6069339  0.34393343]\n",
      " [0.0473896  0.92489797 0.0277124 ]\n",
      " [0.02488191 0.8969777  0.07814036]\n",
      " ...\n",
      " [0.21942496 0.2071921  0.573383  ]\n",
      " [0.01205697 0.25897747 0.72896564]\n",
      " [0.19626656 0.33717182 0.46656165]]\n",
      "Results exported to: outputs/ClassifierSegExperimentCV_224_epo50_bs32_lr1e-05_s42/2024-01-03_1221_VGG16_BN_Attention/val_ClassifierSegExperimentCV_224_epo50_bs32_lr1e-05_s42_2024-01-03_1221_VGG16_BN_Attention.csv\n",
      "Computing AUC scores for each class...\n",
      "Figure(1500x600)\n",
      "Majority vote AUC: 0.99855\n",
      "Majority vote AUC Scores: [0.99859733 0.99887894 0.99816363]\n",
      "Majority vote accuracy: 0.974015748031496\n",
      "Majority vote kappa: 0.9532099890142279\n",
      "Target 0 - Precision: 0.98519, Recall: 0.98083, F-score: 0.98300, Sensitivity: 0.9808259587020649, Specificity: 0.9831081081081081, Support: 678\n",
      "Target 1 - Precision: 0.97024, Recall: 0.98193, F-score: 0.97605, Sensitivity: 0.9819277108433735, Specificity: 0.9805699481865285, Support: 498\n",
      "Target 2 - Precision: 0.91209, Recall: 0.88298, F-score: 0.89730, Sensitivity: 0.8829787234042553, Specificity: 0.9931972789115646, Support: 94\n",
      "(   {   'accuracy': 0.974015748031496,\n",
      "        'auc': 0.998546629261713,\n",
      "        'auc_scores': [   0.9985973252013075,\n",
      "                          0.9988789354308425,\n",
      "                          0.9981636271529889],\n",
      "        'fscore': [0.9830007390983, 0.9760479041916169, 0.8972972972972972],\n",
      "        'kappa': 0.9532099890142279,\n",
      "        'precision': [   0.9851851851851852,\n",
      "                         0.9702380952380952,\n",
      "                         0.9120879120879121],\n",
      "        'recall': [0.9808259587020649, 0.9819277108433735, 0.8829787234042553],\n",
      "        'sensitivity': [   0.9808259587020649,\n",
      "                           0.9819277108433735,\n",
      "                           0.8829787234042553],\n",
      "        'specificity': [   0.9831081081081081,\n",
      "                           0.9805699481865285,\n",
      "                           0.9931972789115646],\n",
      "        'support': [678, 498, 94]},)\n"
     ]
    }
   ],
   "source": [
    "command = 'python ../inference.py --test_path \"../datasets/challenge2/val\" \\\n",
    "                    --experiment_name \"ClassifierSegExperimentCV\" \\\n",
    "                    --network_name \"VGG16_BN_Attention\" \\\n",
    "                    --max_epochs \"50\" \\\n",
    "                    --base_lr \"0.00001\" \\\n",
    "                    --batch_size \"32\" \\\n",
    "                    --timeframe \"2024-01-03_1221\" \\\n",
    "                    --verbose \"2\" \\\n",
    "                    --multi \\\n",
    "                    --ensemble \\\n",
    "                    --report \\\n",
    "                    --combination_strategy \"majority_vote\"'\n",
    "\n",
    "# # run the function to excute the command\n",
    "_ = execute_cmd_realtime(command, log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excuting inference script...\n",
      "Namespace(test_path='../datasets/challenge2/val', output='outputs', experiment_name='ClassifierSegExperimentCV', network_name='VGG16_BN_Attention', max_epochs=50, batch_size=32, base_lr=1e-05, img_size=224, seed=42, timeframe='2024-01-03_1221', verbose=2, multi=True, report=True, ensemble=True, combination_strategy='weighted_voting')\n",
      "Constructed output path: outputs/ClassifierSegExperimentCV_224_epo50_bs32_lr1e-05_s42/2024-01-03_1221_VGG16_BN_Attention. Searching for models...\n",
      "Found 5 models.\n",
      "Loading data with 3 class labels from ../datasets/challenge2/val path...\n",
      "Dataset labels: {'mel': 0, 'bcc': 1, 'scc': 2} dictionary.\n",
      "Loading the data from ../datasets/challenge2/val\n",
      "Dataset length: 1270\n",
      "Combination strategy is weighted_voting. Loading validation data to obtain the weights...\n",
      "args.val_path: \n",
      "Loading data with 3 class labels from ../datasets/challenge2/val path...\n",
      "Dataset _val_labels: {'mel': 0, 'bcc': 1, 'scc': 2} dictionary.\n",
      "Loading the data from ../datasets/challenge2/val\n",
      "Dataset `val_dataset` length: 1270\n",
      "Using VGG16_BN_Attention with configurations: num_classes='3', normalize_attn='False'\n",
      "Using VGG16_BN_Attention with configurations: num_classes='3', normalize_attn='False'\n",
      "Using VGG16_BN_Attention with configurations: num_classes='3', normalize_attn='False'\n",
      "Using VGG16_BN_Attention with configurations: num_classes='3', normalize_attn='False'\n",
      "Using VGG16_BN_Attention with configurations: num_classes='3', normalize_attn='False'\n",
      "\n",
      "Inference:   0%|          | 0/40 [00:00<?, ?it/s]\n",
      "Inference:   2%|▎         | 1/40 [03:09<2:03:18, 189.70s/it]\n",
      "Inference:   5%|▌         | 2/40 [03:10<49:42, 78.48s/it]   \n",
      "Inference:   8%|▊         | 3/40 [03:10<26:28, 42.94s/it]\n",
      "Inference:  10%|█         | 4/40 [03:11<15:44, 26.24s/it]\n",
      "Inference:  12%|█▎        | 5/40 [03:12<09:55, 17.02s/it]\n",
      "Inference:  15%|█▌        | 6/40 [03:12<06:29, 11.45s/it]\n",
      "Inference:  18%|█▊        | 7/40 [03:13<04:21,  7.92s/it]\n",
      "Inference:  20%|██        | 8/40 [03:14<02:59,  5.61s/it]\n",
      "Inference:  22%|██▎       | 9/40 [03:14<02:05,  4.05s/it]\n",
      "Inference:  25%|██▌       | 10/40 [03:15<01:29,  2.99s/it]\n",
      "Inference:  28%|██▊       | 11/40 [03:16<01:05,  2.27s/it]\n",
      "Inference:  30%|███       | 12/40 [03:16<00:49,  1.77s/it]\n",
      "Inference:  32%|███▎      | 13/40 [03:17<00:38,  1.42s/it]\n",
      "Inference:  35%|███▌      | 14/40 [03:17<00:30,  1.18s/it]\n",
      "Inference:  38%|███▊      | 15/40 [03:18<00:25,  1.01s/it]\n",
      "Inference:  40%|████      | 16/40 [03:19<00:21,  1.12it/s]\n",
      "Inference:  42%|████▎     | 17/40 [03:19<00:18,  1.23it/s]\n",
      "Inference:  45%|████▌     | 18/40 [03:20<00:16,  1.33it/s]\n",
      "Inference:  48%|████▊     | 19/40 [03:21<00:14,  1.40it/s]\n",
      "Inference:  50%|█████     | 20/40 [03:21<00:13,  1.46it/s]\n",
      "Inference:  52%|█████▎    | 21/40 [03:22<00:12,  1.50it/s]\n",
      "Inference:  55%|█████▌    | 22/40 [03:22<00:11,  1.53it/s]\n",
      "Inference:  57%|█████▊    | 23/40 [03:23<00:10,  1.56it/s]\n",
      "Inference:  60%|██████    | 24/40 [03:24<00:10,  1.58it/s]\n",
      "Inference:  62%|██████▎   | 25/40 [03:24<00:09,  1.59it/s]\n",
      "Inference:  65%|██████▌   | 26/40 [03:25<00:08,  1.60it/s]\n",
      "Inference:  68%|██████▊   | 27/40 [03:26<00:08,  1.60it/s]\n",
      "Inference:  70%|███████   | 28/40 [03:26<00:07,  1.61it/s]\n",
      "Inference:  72%|███████▎  | 29/40 [03:27<00:06,  1.61it/s]\n",
      "Inference:  75%|███████▌  | 30/40 [03:27<00:06,  1.61it/s]\n",
      "Inference:  78%|███████▊  | 31/40 [03:28<00:05,  1.61it/s]\n",
      "Inference:  80%|████████  | 32/40 [03:29<00:04,  1.61it/s]\n",
      "Inference:  82%|████████▎ | 33/40 [03:29<00:04,  1.61it/s]\n",
      "Inference:  85%|████████▌ | 34/40 [03:30<00:03,  1.62it/s]\n",
      "Inference:  88%|████████▊ | 35/40 [03:30<00:03,  1.62it/s]\n",
      "Inference:  90%|█████████ | 36/40 [03:31<00:02,  1.62it/s]\n",
      "Inference:  92%|█████████▎| 37/40 [03:32<00:01,  1.62it/s]\n",
      "Inference:  95%|█████████▌| 38/40 [03:32<00:01,  1.62it/s]\n",
      "Inference:  98%|█████████▊| 39/40 [03:33<00:00,  1.62it/s]\n",
      "Inference: 100%|██████████| 40/40 [03:35<00:00,  1.03s/it]\n",
      "Inference: 100%|██████████| 40/40 [03:35<00:00,  5.39s/it]\n",
      "all_predictions shape: (5, 1270)\n",
      "all_probabilities shape: (5, 1270, 3)\n",
      "Combination strategy is weighted_voting. Computing the weighted voting...\n",
      "\n",
      "Calculating Accuracies:   0%|          | 0/5 [00:00<?, ?it/s]\n",
      "Calculating Accuracies:  20%|██        | 1/5 [00:13<00:54, 13.61s/it]\n",
      "Calculating Accuracies:  40%|████      | 2/5 [00:24<00:35, 11.97s/it]\n",
      "Calculating Accuracies:  60%|██████    | 3/5 [00:35<00:23, 11.69s/it]\n",
      "Calculating Accuracies:  80%|████████  | 4/5 [00:46<00:11, 11.26s/it]\n",
      "Calculating Accuracies: 100%|██████████| 5/5 [00:57<00:00, 11.08s/it]\n",
      "Calculating Accuracies: 100%|██████████| 5/5 [00:57<00:00, 11.43s/it]\n",
      "Validation accuracies: [0.968503937007874, 0.9732283464566929, 0.9511811023622048, 0.9433070866141732, 0.974015748031496]\n",
      "Validation weights: [0.20134228187919462, 0.20232443935177605, 0.1977410378130627, 0.19610410869209363, 0.20248813226387297]\n",
      "Results exported to: outputs/ClassifierSegExperimentCV_224_epo50_bs32_lr1e-05_s42/2024-01-03_1221_VGG16_BN_Attention/val_ClassifierSegExperimentCV_224_epo50_bs32_lr1e-05_s42_2024-01-03_1221_VGG16_BN_Attention.csv\n",
      "Computing AUC scores for each class...\n",
      "Figure(1500x600)\n",
      "Majority vote AUC: 0.99857\n",
      "Majority vote AUC Scores: [0.99862224 0.99888674 0.99819981]\n",
      "Majority vote accuracy: 0.9732283464566929\n",
      "Majority vote kappa: 0.9518017957682021\n",
      "Target 0 - Precision: 0.98516, Recall: 0.97935, F-score: 0.98225, Sensitivity: 0.9793510324483776, Specificity: 0.9831081081081081, Support: 678\n",
      "Target 1 - Precision: 0.96634, Recall: 0.97992, F-score: 0.97308, Sensitivity: 0.9799196787148594, Specificity: 0.977979274611399, Support: 498\n",
      "Target 2 - Precision: 0.92308, Recall: 0.89362, F-score: 0.90811, Sensitivity: 0.8936170212765957, Specificity: 0.9940476190476191, Support: 94\n",
      "(   {   'accuracy': 0.9732283464566929,\n",
      "        'auc': 0.998569596666755,\n",
      "        'auc_scores': [   0.9986222394961333,\n",
      "                          0.9988867386645025,\n",
      "                          0.9981998118396295],\n",
      "        'fscore': [0.9822485207100592, 0.9730807577268196, 0.908108108108108],\n",
      "        'kappa': 0.9518017957682021,\n",
      "        'precision': [   0.9851632047477745,\n",
      "                         0.9663366336633663,\n",
      "                         0.9230769230769231],\n",
      "        'recall': [0.9793510324483776, 0.9799196787148594, 0.8936170212765957],\n",
      "        'sensitivity': [   0.9793510324483776,\n",
      "                           0.9799196787148594,\n",
      "                           0.8936170212765957],\n",
      "        'specificity': [   0.9831081081081081,\n",
      "                           0.977979274611399,\n",
      "                           0.9940476190476191],\n",
      "        'support': [678, 498, 94]},)\n"
     ]
    }
   ],
   "source": [
    "command = 'python ../inference.py --test_path \"../datasets/challenge2/val\" \\\n",
    "                    --experiment_name \"ClassifierSegExperimentCV\" \\\n",
    "                    --network_name \"VGG16_BN_Attention\" \\\n",
    "                    --max_epochs \"50\" \\\n",
    "                    --base_lr \"0.00001\" \\\n",
    "                    --batch_size \"32\" \\\n",
    "                    --timeframe \"2024-01-03_1221\" \\\n",
    "                    --verbose \"2\" \\\n",
    "                    --multi \\\n",
    "                    --ensemble \\\n",
    "                    --report \\\n",
    "                    --combination_strategy \"weighted_voting\"'\n",
    "\n",
    "# # run the function to excute the command\n",
    "_ = execute_cmd_realtime(command, log=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
