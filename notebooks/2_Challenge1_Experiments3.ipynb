{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from utils.utils import excute_cmd, execute_cmd_realtime\n",
    "\n",
    "# To allow auto reload to this notebook after modifying any external file imported\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying to train a single model with SGD optimizer and LambdaLR scheduler from the best experiment previously to see if it improves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excuting training pipeline with 50 epochs...\n",
      "Loading data with 2 class labels...\n",
      "Loading the data from ../datasets/challenge1/train\n",
      "Loading the data from ../datasets/challenge1/val\n",
      "Using segmentation masks for training...\n",
      "train_images: 15195, train_masks: 15195, train_labels: 15195\n",
      "Class weights: [0.98349515 1.01706827]\n",
      "Creating a classifier experiment using VGG16_BN_Attention network.\n",
      "Using VGG16_BN_Attention with configurations: num_classes='2', normalize_attn='False'\n",
      "Using cross entropy loss.\n",
      "Experiment with SGD and LambdaLR.\n",
      "Experiment started.\n",
      "Epoch: 1 Train batch 10 loss: 0.6949501037597656, 2.1% complete\n",
      "Epoch: 1 Train batch 20 loss: 0.6991674900054932, 4.2% complete\n",
      "Epoch: 1 Train batch 30 loss: 0.6963611245155334, 6.3% complete\n",
      "Epoch: 1 Train batch 40 loss: 0.6963446736335754, 8.4% complete\n",
      "Epoch: 1 Train batch 50 loss: 0.6965965628623962, 10.5% complete\n",
      "Epoch: 1 Train batch 60 loss: 0.6936805844306946, 12.6% complete\n",
      "Epoch: 1 Train batch 70 loss: 0.6944960951805115, 14.7% complete\n",
      "Epoch: 1 Train batch 80 loss: 0.6943013072013855, 16.8% complete\n",
      "Epoch: 1 Train batch 90 loss: 0.6943228244781494, 18.9% complete\n",
      "Epoch: 1 Train batch 100 loss: 0.6996123194694519, 21.1% complete\n",
      "Epoch: 1 Train batch 110 loss: 0.6958595514297485, 23.2% complete\n",
      "Epoch: 1 Train batch 120 loss: 0.6945757269859314, 25.3% complete\n",
      "Epoch: 1 Train batch 130 loss: 0.6925545334815979, 27.4% complete\n",
      "Epoch: 1 Train batch 140 loss: 0.6969977617263794, 29.5% complete\n",
      "Epoch: 1 Train batch 150 loss: 0.6966641545295715, 31.6% complete\n",
      "Epoch: 1 Train batch 160 loss: 0.6941817402839661, 33.7% complete\n",
      "Epoch: 1 Train batch 170 loss: 0.7027118802070618, 35.8% complete\n",
      "Epoch: 1 Train batch 180 loss: 0.6952530741691589, 37.9% complete\n",
      "Epoch: 1 Train batch 190 loss: 0.6954317092895508, 40.0% complete\n",
      "Epoch: 1 Train batch 200 loss: 0.6951591968536377, 42.1% complete\n",
      "Epoch: 1 Train batch 210 loss: 0.701127827167511, 44.2% complete\n",
      "Epoch: 1 Train batch 220 loss: 0.6971688270568848, 46.3% complete\n",
      "Epoch: 1 Train batch 230 loss: 0.6944609880447388, 48.4% complete\n",
      "Epoch: 1 Train batch 240 loss: 0.6969264149665833, 50.5% complete\n",
      "Epoch: 1 Train batch 250 loss: 0.6932153701782227, 52.6% complete\n",
      "Epoch: 1 Train batch 260 loss: 0.688480794429779, 54.7% complete\n",
      "Epoch: 1 Train batch 270 loss: 0.6939364075660706, 56.8% complete\n",
      "Epoch: 1 Train batch 280 loss: 0.69746333360672, 58.9% complete\n",
      "Epoch: 1 Train batch 290 loss: 0.6946479082107544, 61.1% complete\n",
      "Epoch: 1 Train batch 300 loss: 0.6924940347671509, 63.2% complete\n",
      "Epoch: 1 Train batch 310 loss: 0.6964120864868164, 65.3% complete\n",
      "Epoch: 1 Train batch 320 loss: 0.6988946795463562, 67.4% complete\n",
      "Epoch: 1 Train batch 330 loss: 0.6918536424636841, 69.5% complete\n",
      "Epoch: 1 Train batch 340 loss: 0.6949617862701416, 71.6% complete\n",
      "Epoch: 1 Train batch 350 loss: 0.695599377155304, 73.7% complete\n",
      "Epoch: 1 Train batch 360 loss: 0.6963077783584595, 75.8% complete\n",
      "Epoch: 1 Train batch 370 loss: 0.6923949718475342, 77.9% complete\n",
      "Epoch: 1 Train batch 380 loss: 0.6959608197212219, 80.0% complete\n",
      "Epoch: 1 Train batch 390 loss: 0.6897802352905273, 82.1% complete\n",
      "Epoch: 1 Train batch 400 loss: 0.6955030560493469, 84.2% complete\n",
      "Epoch: 1 Train batch 410 loss: 0.69248366355896, 86.3% complete\n",
      "Epoch: 1 Train batch 420 loss: 0.6929942965507507, 88.4% complete\n",
      "Epoch: 1 Train batch 430 loss: 0.6977800130844116, 90.5% complete\n",
      "Epoch: 1 Train batch 440 loss: 0.692645251750946, 92.6% complete\n",
      "Epoch: 1 Train batch 450 loss: 0.695700466632843, 94.7% complete\n",
      "Epoch: 1 Train batch 460 loss: 0.6881633400917053, 96.8% complete\n",
      "Epoch: 1 Train batch 470 loss: 0.6949775218963623, 98.9% complete\n",
      "Batch 1. Data shape torch.Size([32, 3, 224, 224]) Loss 0.69808030128479\n",
      "Batch 2. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6929469108581543\n",
      "Batch 3. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6901112198829651\n",
      "Batch 4. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6928767561912537\n",
      "Batch 5. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6944321990013123\n",
      "Batch 6. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6892076134681702\n",
      "Batch 7. Data shape torch.Size([32, 3, 224, 224]) Loss 0.688446044921875\n",
      "Batch 8. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6960989832878113\n",
      "Batch 9. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6900762319564819\n",
      "Batch 10. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6990967988967896\n",
      "Batch 11. Data shape torch.Size([32, 3, 224, 224]) Loss 0.695228636264801\n",
      "Batch 12. Data shape torch.Size([32, 3, 224, 224]) Loss 0.689795196056366\n",
      "Batch 13. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6922817230224609\n",
      "Batch 14. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6945227980613708\n",
      "Batch 15. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6936906576156616\n",
      "Batch 16. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6891553401947021\n",
      "Batch 17. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6998292803764343\n",
      "Batch 18. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6947243809700012\n",
      "Batch 19. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6932777762413025\n",
      "Batch 20. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6943346261978149\n",
      "Batch 21. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6952276825904846\n",
      "Batch 22. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6899311542510986\n",
      "Batch 23. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6950329542160034\n",
      "Batch 24. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6977478265762329\n",
      "Batch 25. Data shape torch.Size([32, 3, 224, 224]) Loss 0.694485604763031\n",
      "Batch 26. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6959171891212463\n",
      "Batch 27. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6927075982093811\n",
      "Batch 28. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6973069906234741\n",
      "Batch 29. Data shape torch.Size([32, 3, 224, 224]) Loss 0.691970944404602\n",
      "Batch 30. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6979798078536987\n",
      "Batch 31. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6929810047149658\n",
      "Batch 32. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6925107836723328\n",
      "Batch 33. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6915185451507568\n",
      "Batch 34. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6910032629966736\n",
      "Batch 35. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6997767686843872\n",
      "Batch 36. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6915391087532043\n",
      "Batch 37. Data shape torch.Size([32, 3, 224, 224]) Loss 0.695377767086029\n",
      "Batch 38. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6978981494903564\n",
      "Batch 39. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6955864429473877\n",
      "Batch 40. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6947413086891174\n",
      "Batch 41. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6911803483963013\n",
      "Batch 42. Data shape torch.Size([32, 3, 224, 224]) Loss 0.705431342124939\n",
      "Batch 43. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6877930164337158\n",
      "Batch 44. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6977282762527466\n",
      "Batch 45. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6925523281097412\n",
      "Batch 46. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6961861848831177\n",
      "Batch 47. Data shape torch.Size([32, 3, 224, 224]) Loss 0.7006648778915405\n",
      "Batch 48. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6995553970336914\n",
      "Batch 49. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6897892355918884\n",
      "Batch 50. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6997541189193726\n",
      "Batch 51. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6994706988334656\n",
      "Batch 52. Data shape torch.Size([32, 3, 224, 224]) Loss 0.699613630771637\n",
      "Batch 53. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6953859925270081\n",
      "Batch 54. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6928935647010803\n",
      "Batch 55. Data shape torch.Size([32, 3, 224, 224]) Loss 0.692085862159729\n",
      "Batch 56. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6963219046592712\n",
      "Batch 57. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6949809193611145\n",
      "Batch 58. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6938514113426208\n",
      "Batch 59. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6900783181190491\n",
      "Batch 60. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6923807263374329\n",
      "Batch 61. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6936094760894775\n",
      "Batch 62. Data shape torch.Size([32, 3, 224, 224]) Loss 0.694673478603363\n",
      "Batch 63. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6966214179992676\n",
      "Batch 64. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6924242973327637\n",
      "Batch 65. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6929114460945129\n",
      "Batch 66. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6962836980819702\n",
      "Batch 67. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6949814558029175\n",
      "Batch 68. Data shape torch.Size([32, 3, 224, 224]) Loss 0.690642774105072\n",
      "Batch 69. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6955451965332031\n",
      "Batch 70. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6946393847465515\n",
      "Batch 71. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6948891878128052\n",
      "Batch 72. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6913657784461975\n",
      "Batch 73. Data shape torch.Size([32, 3, 224, 224]) Loss 0.691481351852417\n",
      "Batch 74. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6850810050964355\n",
      "Batch 75. Data shape torch.Size([32, 3, 224, 224]) Loss 0.685627818107605\n",
      "Batch 76. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6898425221443176\n",
      "Batch 77. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6916284561157227\n",
      "Batch 78. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6969307661056519\n",
      "Batch 79. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6915763020515442\n",
      "Batch 80. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6887819766998291\n",
      "Batch 81. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6932969689369202\n",
      "Batch 82. Data shape torch.Size([32, 3, 224, 224]) Loss 0.689312756061554\n",
      "Batch 83. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6965072154998779\n",
      "Batch 84. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6942301392555237\n",
      "Batch 85. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6994002461433411\n",
      "Batch 86. Data shape torch.Size([32, 3, 224, 224]) Loss 0.690222978591919\n",
      "Batch 87. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6977099180221558\n",
      "Batch 88. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6996574401855469\n",
      "Batch 89. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6962903738021851\n",
      "Batch 90. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6894201040267944\n",
      "Batch 91. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6983347535133362\n",
      "Batch 92. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6931358575820923\n",
      "Batch 93. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6977533102035522\n",
      "Batch 94. Data shape torch.Size([32, 3, 224, 224]) Loss 0.69109708070755\n",
      "Batch 95. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6914467215538025\n",
      "Batch 96. Data shape torch.Size([32, 3, 224, 224]) Loss 0.693080723285675\n",
      "Batch 97. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6966498494148254\n",
      "Batch 98. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6936917901039124\n",
      "Batch 99. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6983819007873535\n",
      "Batch 100. Data shape torch.Size([32, 3, 224, 224]) Loss 0.694112241268158\n",
      "Batch 101. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6932507157325745\n",
      "Batch 102. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6939354538917542\n",
      "Batch 103. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6884522438049316\n",
      "Batch 104. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6931772232055664\n",
      "Batch 105. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6951119303703308\n",
      "Batch 106. Data shape torch.Size([32, 3, 224, 224]) Loss 0.698487401008606\n",
      "Batch 107. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6914952993392944\n",
      "Batch 108. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6930727362632751\n",
      "Batch 109. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6943265795707703\n",
      "Batch 110. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6906464695930481\n",
      "Batch 111. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6940614581108093\n",
      "Batch 112. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6987903118133545\n",
      "Batch 113. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6947522759437561\n",
      "Batch 114. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6953887343406677\n",
      "Batch 115. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6926652789115906\n",
      "Batch 116. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6965234875679016\n",
      "Batch 117. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6941475868225098\n",
      "Batch 118. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6932940483093262\n",
      "Batch 119. Data shape torch.Size([20, 3, 224, 224]) Loss 0.7001967430114746\n",
      "Valid loss improved from inf to 0.694136. Saving model ...\n",
      "Epoch: 01/50 | time: 27.0m 7.981s | lr: 1.0000e-05 | train/loss: 0.69529 | val/loss: 0.69414 | val/accuracy: 0.46733 | val/AUC: 0.47279 | val/Kappa: -0.05382\n",
      "Epoch: 2 Train batch 10 loss: 0.6949657201766968, 2.1% complete\n",
      "Epoch: 2 Train batch 20 loss: 0.697910726070404, 4.2% complete\n",
      "Epoch: 2 Train batch 30 loss: 0.6899524927139282, 6.3% complete\n",
      "Epoch: 2 Train batch 40 loss: 0.6949832439422607, 8.4% complete\n",
      "Epoch: 2 Train batch 50 loss: 0.6883676052093506, 10.5% complete\n",
      "Epoch: 2 Train batch 60 loss: 0.6980019211769104, 12.6% complete\n",
      "Epoch: 2 Train batch 70 loss: 0.6936399936676025, 14.7% complete\n",
      "Epoch: 2 Train batch 80 loss: 0.6946806907653809, 16.8% complete\n",
      "Epoch: 2 Train batch 90 loss: 0.69141685962677, 18.9% complete\n",
      "Epoch: 2 Train batch 100 loss: 0.6926144361495972, 21.1% complete\n",
      "Epoch: 2 Train batch 110 loss: 0.6918652653694153, 23.2% complete\n",
      "Epoch: 2 Train batch 120 loss: 0.6891540288925171, 25.3% complete\n",
      "Epoch: 2 Train batch 130 loss: 0.6935312151908875, 27.4% complete\n",
      "Epoch: 2 Train batch 140 loss: 0.6961435675621033, 29.5% complete\n",
      "Epoch: 2 Train batch 150 loss: 0.685667097568512, 31.6% complete\n",
      "Epoch: 2 Train batch 160 loss: 0.6952170729637146, 33.7% complete\n",
      "Epoch: 2 Train batch 170 loss: 0.6967149376869202, 35.8% complete\n",
      "Epoch: 2 Train batch 180 loss: 0.6877838969230652, 37.9% complete\n",
      "Epoch: 2 Train batch 190 loss: 0.6968656182289124, 40.0% complete\n",
      "Epoch: 2 Train batch 200 loss: 0.6900330781936646, 42.1% complete\n",
      "Epoch: 2 Train batch 210 loss: 0.6941052079200745, 44.2% complete\n",
      "Epoch: 2 Train batch 220 loss: 0.693253755569458, 46.3% complete\n",
      "Epoch: 2 Train batch 230 loss: 0.6972804069519043, 48.4% complete\n",
      "Epoch: 2 Train batch 240 loss: 0.6910268068313599, 50.5% complete\n",
      "Epoch: 2 Train batch 250 loss: 0.6914128661155701, 52.6% complete\n",
      "Epoch: 2 Train batch 260 loss: 0.6987751722335815, 54.7% complete\n",
      "Epoch: 2 Train batch 270 loss: 0.6911911368370056, 56.8% complete\n",
      "Epoch: 2 Train batch 280 loss: 0.6886422038078308, 58.9% complete\n",
      "Epoch: 2 Train batch 290 loss: 0.6956083178520203, 61.1% complete\n",
      "Epoch: 2 Train batch 300 loss: 0.6961415410041809, 63.2% complete\n",
      "Epoch: 2 Train batch 310 loss: 0.6924036145210266, 65.3% complete\n",
      "Epoch: 2 Train batch 320 loss: 0.6975553631782532, 67.4% complete\n",
      "Epoch: 2 Train batch 330 loss: 0.6934897303581238, 69.5% complete\n",
      "Epoch: 2 Train batch 340 loss: 0.6889137625694275, 71.6% complete\n",
      "Epoch: 2 Train batch 350 loss: 0.6897859573364258, 73.7% complete\n",
      "Epoch: 2 Train batch 360 loss: 0.6954703330993652, 75.8% complete\n",
      "Epoch: 2 Train batch 370 loss: 0.6930968761444092, 77.9% complete\n",
      "Epoch: 2 Train batch 380 loss: 0.6860414147377014, 80.0% complete\n",
      "Epoch: 2 Train batch 390 loss: 0.6870099902153015, 82.1% complete\n",
      "Epoch: 2 Train batch 400 loss: 0.6920807361602783, 84.2% complete\n",
      "Epoch: 2 Train batch 410 loss: 0.6913372278213501, 86.3% complete\n",
      "Epoch: 2 Train batch 420 loss: 0.6858553886413574, 88.4% complete\n",
      "Epoch: 2 Train batch 430 loss: 0.6907376646995544, 90.5% complete\n",
      "Epoch: 2 Train batch 440 loss: 0.6915134787559509, 92.6% complete\n",
      "Epoch: 2 Train batch 450 loss: 0.6895086765289307, 94.7% complete\n",
      "Epoch: 2 Train batch 460 loss: 0.6908020377159119, 96.8% complete\n",
      "Epoch: 2 Train batch 470 loss: 0.6951623558998108, 98.9% complete\n",
      "Batch 1. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6877375245094299\n",
      "Batch 2. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6982614398002625\n",
      "Batch 3. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6945582628250122\n",
      "Batch 4. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6967904567718506\n",
      "Batch 5. Data shape torch.Size([32, 3, 224, 224]) Loss 0.689651608467102\n",
      "Batch 6. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6985648274421692\n",
      "Batch 7. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6883624792098999\n",
      "Batch 8. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6886011958122253\n",
      "Batch 9. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6958768367767334\n",
      "Batch 10. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6879343390464783\n",
      "Batch 11. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6946642398834229\n",
      "Batch 12. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6930307149887085\n",
      "Batch 13. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6941114068031311\n",
      "Batch 14. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6878354549407959\n",
      "Batch 15. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6849074959754944\n",
      "Batch 16. Data shape torch.Size([32, 3, 224, 224]) Loss 0.692774772644043\n",
      "Batch 17. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6985137462615967\n",
      "Batch 18. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6895207166671753\n",
      "Batch 19. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6957743167877197\n",
      "Batch 20. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6910343170166016\n",
      "Batch 21. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6907320022583008\n",
      "Batch 22. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6935903429985046\n",
      "Batch 23. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6831029057502747\n",
      "Batch 24. Data shape torch.Size([32, 3, 224, 224]) Loss 0.7025302052497864\n",
      "Batch 25. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6895536184310913\n",
      "Batch 26. Data shape torch.Size([32, 3, 224, 224]) Loss 0.693213939666748\n",
      "Batch 27. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6946829557418823\n",
      "Batch 28. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6907458305358887\n",
      "Batch 29. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6892987489700317\n",
      "Batch 30. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6917579174041748\n",
      "Batch 31. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6959323883056641\n",
      "Batch 32. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6882972121238708\n",
      "Batch 33. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6883575916290283\n",
      "Batch 34. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6909770965576172\n",
      "Batch 35. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6970776319503784\n",
      "Batch 36. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6886854767799377\n",
      "Batch 37. Data shape torch.Size([32, 3, 224, 224]) Loss 0.697006106376648\n",
      "Batch 38. Data shape torch.Size([32, 3, 224, 224]) Loss 0.690301239490509\n",
      "Batch 39. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6874632239341736\n",
      "Batch 40. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6896020770072937\n",
      "Batch 41. Data shape torch.Size([32, 3, 224, 224]) Loss 0.695898175239563\n",
      "Batch 42. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6955431699752808\n",
      "Batch 43. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6874560713768005\n",
      "Batch 44. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6883666515350342\n",
      "Batch 45. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6978013515472412\n",
      "Batch 46. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6940919160842896\n",
      "Batch 47. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6931597590446472\n",
      "Batch 48. Data shape torch.Size([32, 3, 224, 224]) Loss 0.683825671672821\n",
      "Batch 49. Data shape torch.Size([32, 3, 224, 224]) Loss 0.694553017616272\n",
      "Batch 50. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6972057819366455\n",
      "Batch 51. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6909065246582031\n",
      "Batch 52. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6947816014289856\n",
      "Batch 53. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6906819939613342\n",
      "Batch 54. Data shape torch.Size([32, 3, 224, 224]) Loss 0.690628170967102\n",
      "Batch 55. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6898771524429321\n",
      "Batch 56. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6905328035354614\n",
      "Batch 57. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6925801634788513\n",
      "Batch 58. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6908769011497498\n",
      "Batch 59. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6913272142410278\n",
      "Batch 60. Data shape torch.Size([32, 3, 224, 224]) Loss 0.687349796295166\n",
      "Batch 61. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6978094577789307\n",
      "Batch 62. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6931671500205994\n",
      "Batch 63. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6934884786605835\n",
      "Batch 64. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6901597380638123\n",
      "Batch 65. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6993043422698975\n",
      "Batch 66. Data shape torch.Size([32, 3, 224, 224]) Loss 0.693330705165863\n",
      "Batch 67. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6911240816116333\n",
      "Batch 68. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6956099271774292\n",
      "Batch 69. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6958609819412231\n",
      "Batch 70. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6893874406814575\n",
      "Batch 71. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6904392242431641\n",
      "Batch 72. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6956645250320435\n",
      "Batch 73. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6935542225837708\n",
      "Batch 74. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6870361566543579\n",
      "Batch 75. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6903398633003235\n",
      "Batch 76. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6924005150794983\n",
      "Batch 77. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6925700902938843\n",
      "Batch 78. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6924752593040466\n",
      "Batch 79. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6966760158538818\n",
      "Batch 80. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6899024844169617\n",
      "Batch 81. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6935352683067322\n",
      "Batch 82. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6885846257209778\n",
      "Batch 83. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6938932538032532\n",
      "Batch 84. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6946568489074707\n",
      "Batch 85. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6898583769798279\n",
      "Batch 86. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6909123659133911\n",
      "Batch 87. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6907803416252136\n",
      "Batch 88. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6915454864501953\n",
      "Batch 89. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6878184080123901\n",
      "Batch 90. Data shape torch.Size([32, 3, 224, 224]) Loss 0.690146267414093\n",
      "Batch 91. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6946476697921753\n",
      "Batch 92. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6950666904449463\n",
      "Batch 93. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6906300783157349\n",
      "Batch 94. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6862592101097107\n",
      "Batch 95. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6893225312232971\n",
      "Batch 96. Data shape torch.Size([32, 3, 224, 224]) Loss 0.688021183013916\n",
      "Batch 97. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6884389519691467\n",
      "Batch 98. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6970983743667603\n",
      "Batch 99. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6910978555679321\n",
      "Batch 100. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6883796453475952\n",
      "Batch 101. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6918501853942871\n",
      "Batch 102. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6918522119522095\n",
      "Batch 103. Data shape torch.Size([32, 3, 224, 224]) Loss 0.691611111164093\n",
      "Batch 104. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6877503395080566\n",
      "Batch 105. Data shape torch.Size([32, 3, 224, 224]) Loss 0.692582368850708\n",
      "Batch 106. Data shape torch.Size([32, 3, 224, 224]) Loss 0.699181079864502\n",
      "Batch 107. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6964316368103027\n",
      "Batch 108. Data shape torch.Size([32, 3, 224, 224]) Loss 0.688313364982605\n",
      "Batch 109. Data shape torch.Size([32, 3, 224, 224]) Loss 0.692075252532959\n",
      "Batch 110. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6867581605911255\n",
      "Batch 111. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6911451816558838\n",
      "Batch 112. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6924400329589844\n",
      "Batch 113. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6910275220870972\n",
      "Batch 114. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6917960047721863\n",
      "Batch 115. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6844390630722046\n",
      "Batch 116. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6961967349052429\n",
      "Batch 117. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6952580809593201\n",
      "Batch 118. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6926749348640442\n",
      "Batch 119. Data shape torch.Size([20, 3, 224, 224]) Loss 0.6864222288131714\n",
      "Valid loss improved from 0.694136 to 0.691930. Saving model ...\n",
      "Epoch: 02/50 | time: 22.0m 19.54s | lr: 1.0000e-05 | train/loss: 0.69325 | val/loss: 0.69193 | val/accuracy: 0.51370 | val/AUC: 0.52024 | val/Kappa: 0.03995\n",
      "Epoch: 3 Train batch 10 loss: 0.6900138854980469, 2.1% complete\n",
      "Epoch: 3 Train batch 20 loss: 0.6960821747779846, 4.2% complete\n",
      "Epoch: 3 Train batch 30 loss: 0.6951135993003845, 6.3% complete\n",
      "Epoch: 3 Train batch 40 loss: 0.6903766989707947, 8.4% complete\n",
      "Epoch: 3 Train batch 50 loss: 0.6951578259468079, 10.5% complete\n",
      "Epoch: 3 Train batch 60 loss: 0.6883491277694702, 12.6% complete\n",
      "Epoch: 3 Train batch 70 loss: 0.6906885504722595, 14.7% complete\n",
      "Epoch: 3 Train batch 80 loss: 0.6899921298027039, 16.8% complete\n",
      "Epoch: 3 Train batch 90 loss: 0.692928671836853, 18.9% complete\n",
      "Epoch: 3 Train batch 100 loss: 0.6887103319168091, 21.1% complete\n",
      "Epoch: 3 Train batch 110 loss: 0.689619779586792, 23.2% complete\n",
      "Epoch: 3 Train batch 120 loss: 0.6909356117248535, 25.3% complete\n",
      "Epoch: 3 Train batch 130 loss: 0.6923046708106995, 27.4% complete\n",
      "Epoch: 3 Train batch 140 loss: 0.691642701625824, 29.5% complete\n",
      "Epoch: 3 Train batch 150 loss: 0.6871117949485779, 31.6% complete\n",
      "Epoch: 3 Train batch 160 loss: 0.6953610181808472, 33.7% complete\n",
      "Epoch: 3 Train batch 170 loss: 0.6903499364852905, 35.8% complete\n",
      "Epoch: 3 Train batch 180 loss: 0.6884944438934326, 37.9% complete\n",
      "Epoch: 3 Train batch 190 loss: 0.6961864233016968, 40.0% complete\n",
      "Epoch: 3 Train batch 200 loss: 0.6890383362770081, 42.1% complete\n",
      "Epoch: 3 Train batch 210 loss: 0.6880179047584534, 44.2% complete\n",
      "Epoch: 3 Train batch 220 loss: 0.695220410823822, 46.3% complete\n",
      "Epoch: 3 Train batch 230 loss: 0.6937192678451538, 48.4% complete\n",
      "Epoch: 3 Train batch 240 loss: 0.6938390731811523, 50.5% complete\n",
      "Epoch: 3 Train batch 250 loss: 0.6900628209114075, 52.6% complete\n",
      "Epoch: 3 Train batch 260 loss: 0.6846348643302917, 54.7% complete\n",
      "Epoch: 3 Train batch 270 loss: 0.6898705959320068, 56.8% complete\n",
      "Epoch: 3 Train batch 280 loss: 0.6898962259292603, 58.9% complete\n",
      "Epoch: 3 Train batch 290 loss: 0.694849967956543, 61.1% complete\n",
      "Epoch: 3 Train batch 300 loss: 0.6907373666763306, 63.2% complete\n",
      "Epoch: 3 Train batch 310 loss: 0.6949901580810547, 65.3% complete\n",
      "Epoch: 3 Train batch 320 loss: 0.6901375651359558, 67.4% complete\n",
      "Epoch: 3 Train batch 330 loss: 0.6888434886932373, 69.5% complete\n",
      "Epoch: 3 Train batch 340 loss: 0.6904564499855042, 71.6% complete\n",
      "Epoch: 3 Train batch 350 loss: 0.6923253536224365, 73.7% complete\n",
      "Epoch: 3 Train batch 360 loss: 0.6857531070709229, 75.8% complete\n",
      "Epoch: 3 Train batch 370 loss: 0.6935567855834961, 77.9% complete\n",
      "Epoch: 3 Train batch 380 loss: 0.6969266533851624, 80.0% complete\n",
      "Epoch: 3 Train batch 390 loss: 0.6853651404380798, 82.1% complete\n",
      "Epoch: 3 Train batch 400 loss: 0.6920762658119202, 84.2% complete\n",
      "Epoch: 3 Train batch 410 loss: 0.6882662773132324, 86.3% complete\n",
      "Epoch: 3 Train batch 420 loss: 0.6901096105575562, 88.4% complete\n",
      "Epoch: 3 Train batch 430 loss: 0.6925219893455505, 90.5% complete\n",
      "Epoch: 3 Train batch 440 loss: 0.6931850910186768, 92.6% complete\n",
      "Epoch: 3 Train batch 450 loss: 0.6879172325134277, 94.7% complete\n",
      "Epoch: 3 Train batch 460 loss: 0.6908910274505615, 96.8% complete\n",
      "Epoch: 3 Train batch 470 loss: 0.6869809627532959, 98.9% complete\n",
      "Batch 1. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6871665120124817\n",
      "Batch 2. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6845142841339111\n",
      "Batch 3. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6874653100967407\n",
      "Batch 4. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6870421171188354\n",
      "Batch 5. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6919590830802917\n",
      "Batch 6. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6899572014808655\n",
      "Batch 7. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6889066100120544\n",
      "Batch 8. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6900439262390137\n",
      "Batch 9. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6881294846534729\n",
      "Batch 10. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6887246966362\n",
      "Batch 11. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6874573826789856\n",
      "Batch 12. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6916384696960449\n",
      "Batch 13. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6904780864715576\n",
      "Batch 14. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6886535882949829\n",
      "Batch 15. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6931474208831787\n",
      "Batch 16. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6865030527114868\n",
      "Batch 17. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6883741617202759\n",
      "Batch 18. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6908737421035767\n",
      "Batch 19. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6853022575378418\n",
      "Batch 20. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6895244121551514\n",
      "Batch 21. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6866488456726074\n",
      "Batch 22. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6892180442810059\n",
      "Batch 23. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6871818900108337\n",
      "Batch 24. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6891287565231323\n",
      "Batch 25. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6919636726379395\n",
      "Batch 26. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6883426904678345\n",
      "Batch 27. Data shape torch.Size([32, 3, 224, 224]) Loss 0.68776935338974\n",
      "Batch 28. Data shape torch.Size([32, 3, 224, 224]) Loss 0.7028600573539734\n",
      "Batch 29. Data shape torch.Size([32, 3, 224, 224]) Loss 0.685626745223999\n",
      "Batch 30. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6840718984603882\n",
      "Batch 31. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6844215393066406\n",
      "Batch 32. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6986223459243774\n",
      "Batch 33. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6914942264556885\n",
      "Batch 34. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6927727460861206\n",
      "Batch 35. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6938541531562805\n",
      "Batch 36. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6928947567939758\n",
      "Batch 37. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6904086470603943\n",
      "Batch 38. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6984315514564514\n",
      "Batch 39. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6874649524688721\n",
      "Batch 40. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6935167908668518\n",
      "Batch 41. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6913918852806091\n",
      "Batch 42. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6868126392364502\n",
      "Batch 43. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6883037686347961\n",
      "Batch 44. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6883454918861389\n",
      "Batch 45. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6975218653678894\n",
      "Batch 46. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6902669072151184\n",
      "Batch 47. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6912757754325867\n",
      "Batch 48. Data shape torch.Size([32, 3, 224, 224]) Loss 0.691937267780304\n",
      "Batch 49. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6908349990844727\n",
      "Batch 50. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6952217221260071\n",
      "Batch 51. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6929620504379272\n",
      "Batch 52. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6898717880249023\n",
      "Batch 53. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6904113292694092\n",
      "Batch 54. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6877574920654297\n",
      "Batch 55. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6906797885894775\n",
      "Batch 56. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6901310682296753\n",
      "Batch 57. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6941927671432495\n",
      "Batch 58. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6884695291519165\n",
      "Batch 59. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6957800388336182\n",
      "Batch 60. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6955232620239258\n",
      "Batch 61. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6860144138336182\n",
      "Batch 62. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6920374035835266\n",
      "Batch 63. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6898266673088074\n",
      "Batch 64. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6915997266769409\n",
      "Batch 65. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6874155402183533\n",
      "Batch 66. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6960873007774353\n",
      "Batch 67. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6857964396476746\n",
      "Batch 68. Data shape torch.Size([32, 3, 224, 224]) Loss 0.688244640827179\n",
      "Batch 69. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6934069395065308\n",
      "Batch 70. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6827691793441772\n",
      "Batch 71. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6870272755622864\n",
      "Batch 72. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6916473507881165\n",
      "Batch 73. Data shape torch.Size([32, 3, 224, 224]) Loss 0.694679319858551\n",
      "Batch 74. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6864221692085266\n",
      "Batch 75. Data shape torch.Size([32, 3, 224, 224]) Loss 0.696499764919281\n",
      "Batch 76. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6886611580848694\n",
      "Batch 77. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6917679905891418\n",
      "Batch 78. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6900373697280884\n",
      "Batch 79. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6913610696792603\n",
      "Batch 80. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6859627366065979\n",
      "Batch 81. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6897160410881042\n",
      "Batch 82. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6898487210273743\n",
      "Batch 83. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6913701891899109\n",
      "Batch 84. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6886423826217651\n",
      "Batch 85. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6921284794807434\n",
      "Batch 86. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6874959468841553\n",
      "Batch 87. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6826417446136475\n",
      "Batch 88. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6947455406188965\n",
      "Batch 89. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6931965947151184\n",
      "Batch 90. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6885225772857666\n",
      "Batch 91. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6868215203285217\n",
      "Batch 92. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6870922446250916\n",
      "Batch 93. Data shape torch.Size([32, 3, 224, 224]) Loss 0.687242329120636\n",
      "Batch 94. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6796525716781616\n",
      "Batch 95. Data shape torch.Size([32, 3, 224, 224]) Loss 0.690183699131012\n",
      "Batch 96. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6911824941635132\n",
      "Batch 97. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6864956617355347\n",
      "Batch 98. Data shape torch.Size([32, 3, 224, 224]) Loss 0.694017231464386\n",
      "Batch 99. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6903373003005981\n",
      "Batch 100. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6909381151199341\n",
      "Batch 101. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6901951432228088\n",
      "Batch 102. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6904945373535156\n",
      "Batch 103. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6876328587532043\n",
      "Batch 104. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6940647959709167\n",
      "Batch 105. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6926425695419312\n",
      "Batch 106. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6803593635559082\n",
      "Batch 107. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6853857636451721\n",
      "Batch 108. Data shape torch.Size([32, 3, 224, 224]) Loss 0.685504674911499\n",
      "Batch 109. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6871524453163147\n",
      "Batch 110. Data shape torch.Size([32, 3, 224, 224]) Loss 0.690761923789978\n",
      "Batch 111. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6909105181694031\n",
      "Batch 112. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6922769546508789\n",
      "Batch 113. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6905789971351624\n",
      "Batch 114. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6917043924331665\n",
      "Batch 115. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6914380788803101\n",
      "Batch 116. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6912755966186523\n",
      "Batch 117. Data shape torch.Size([32, 3, 224, 224]) Loss 0.691213846206665\n",
      "Batch 118. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6943206787109375\n",
      "Batch 119. Data shape torch.Size([20, 3, 224, 224]) Loss 0.6932908296585083\n",
      "Valid loss improved from 0.691930 to 0.690008. Saving model ...\n",
      "Epoch: 03/50 | time: 21.0m 48.52s | lr: 1.0000e-05 | train/loss: 0.69116 | val/loss: 0.69001 | val/accuracy: 0.54162 | val/AUC: 0.54829 | val/Kappa: 0.09529\n",
      "Epoch: 4 Train batch 10 loss: 0.6869142651557922, 2.1% complete\n",
      "Epoch: 4 Train batch 20 loss: 0.6925090551376343, 4.2% complete\n",
      "Epoch: 4 Train batch 30 loss: 0.6933083534240723, 6.3% complete\n",
      "Epoch: 4 Train batch 40 loss: 0.6903722882270813, 8.4% complete\n",
      "Epoch: 4 Train batch 50 loss: 0.6933197379112244, 10.5% complete\n",
      "Epoch: 4 Train batch 60 loss: 0.6911295652389526, 12.6% complete\n",
      "Epoch: 4 Train batch 70 loss: 0.6910462379455566, 14.7% complete\n",
      "Epoch: 4 Train batch 80 loss: 0.6853429675102234, 16.8% complete\n",
      "Epoch: 4 Train batch 90 loss: 0.6898279190063477, 18.9% complete\n",
      "Epoch: 4 Train batch 100 loss: 0.6867640018463135, 21.1% complete\n",
      "Epoch: 4 Train batch 110 loss: 0.689440131187439, 23.2% complete\n",
      "Epoch: 4 Train batch 120 loss: 0.6818050146102905, 25.3% complete\n",
      "Epoch: 4 Train batch 130 loss: 0.6875535249710083, 27.4% complete\n",
      "Epoch: 4 Train batch 140 loss: 0.6914276480674744, 29.5% complete\n",
      "Epoch: 4 Train batch 150 loss: 0.6920457482337952, 31.6% complete\n",
      "Epoch: 4 Train batch 160 loss: 0.6940659284591675, 33.7% complete\n",
      "Epoch: 4 Train batch 170 loss: 0.6906894445419312, 35.8% complete\n",
      "Epoch: 4 Train batch 180 loss: 0.6858968734741211, 37.9% complete\n",
      "Epoch: 4 Train batch 190 loss: 0.6909315586090088, 40.0% complete\n",
      "Epoch: 4 Train batch 200 loss: 0.6888630986213684, 42.1% complete\n",
      "Epoch: 4 Train batch 210 loss: 0.6895638704299927, 44.2% complete\n",
      "Epoch: 4 Train batch 220 loss: 0.6903693079948425, 46.3% complete\n",
      "Epoch: 4 Train batch 230 loss: 0.6926416754722595, 48.4% complete\n",
      "Epoch: 4 Train batch 240 loss: 0.6934577822685242, 50.5% complete\n",
      "Epoch: 4 Train batch 250 loss: 0.6910039782524109, 52.6% complete\n",
      "Epoch: 4 Train batch 260 loss: 0.6899117231369019, 54.7% complete\n",
      "Epoch: 4 Train batch 270 loss: 0.6894254684448242, 56.8% complete\n",
      "Epoch: 4 Train batch 280 loss: 0.6887597441673279, 58.9% complete\n",
      "Epoch: 4 Train batch 290 loss: 0.6844168305397034, 61.1% complete\n",
      "Epoch: 4 Train batch 300 loss: 0.6953835487365723, 63.2% complete\n",
      "Epoch: 4 Train batch 310 loss: 0.6827507019042969, 65.3% complete\n",
      "Epoch: 4 Train batch 320 loss: 0.6957966089248657, 67.4% complete\n",
      "Epoch: 4 Train batch 330 loss: 0.6875172257423401, 69.5% complete\n",
      "Epoch: 4 Train batch 340 loss: 0.6879481077194214, 71.6% complete\n",
      "Epoch: 4 Train batch 350 loss: 0.6882045269012451, 73.7% complete\n",
      "Epoch: 4 Train batch 360 loss: 0.6821405291557312, 75.8% complete\n",
      "Epoch: 4 Train batch 370 loss: 0.6861941814422607, 77.9% complete\n",
      "Epoch: 4 Train batch 380 loss: 0.6961001753807068, 80.0% complete\n",
      "Epoch: 4 Train batch 390 loss: 0.6893991827964783, 82.1% complete\n",
      "Epoch: 4 Train batch 400 loss: 0.692029595375061, 84.2% complete\n",
      "Epoch: 4 Train batch 410 loss: 0.6917918920516968, 86.3% complete\n",
      "Epoch: 4 Train batch 420 loss: 0.6858351826667786, 88.4% complete\n",
      "Epoch: 4 Train batch 430 loss: 0.6898220181465149, 90.5% complete\n",
      "Epoch: 4 Train batch 440 loss: 0.6877620816230774, 92.6% complete\n",
      "Epoch: 4 Train batch 450 loss: 0.6892971396446228, 94.7% complete\n",
      "Epoch: 4 Train batch 460 loss: 0.6823880672454834, 96.8% complete\n",
      "Epoch: 4 Train batch 470 loss: 0.686281144618988, 98.9% complete\n",
      "Batch 1. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6862637996673584\n",
      "Batch 2. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6851722598075867\n",
      "Batch 3. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6843600273132324\n",
      "Batch 4. Data shape torch.Size([32, 3, 224, 224]) Loss 0.684586226940155\n",
      "Batch 5. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6837623119354248\n",
      "Batch 6. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6805050373077393\n",
      "Batch 7. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6838973164558411\n",
      "Batch 8. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6846014857292175\n",
      "Batch 9. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6873753070831299\n",
      "Batch 10. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6883151531219482\n",
      "Batch 11. Data shape torch.Size([32, 3, 224, 224]) Loss 0.679010272026062\n",
      "Batch 12. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6801841259002686\n",
      "Batch 13. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6867326498031616\n",
      "Batch 14. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6833131313323975\n",
      "Batch 15. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6868278980255127\n",
      "Batch 16. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6937424540519714\n",
      "Batch 17. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6862021088600159\n",
      "Batch 18. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6855193376541138\n",
      "Batch 19. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6845843195915222\n",
      "Batch 20. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6944225430488586\n",
      "Batch 21. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6808972954750061\n",
      "Batch 22. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6790598630905151\n",
      "Batch 23. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6853554248809814\n",
      "Batch 24. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6901758909225464\n",
      "Batch 25. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6905087232589722\n",
      "Batch 26. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6844971776008606\n",
      "Batch 27. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6791237592697144\n",
      "Batch 28. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6907626390457153\n",
      "Batch 29. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6877489686012268\n",
      "Batch 30. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6855986714363098\n",
      "Batch 31. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6904234886169434\n",
      "Batch 32. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6890529990196228\n",
      "Batch 33. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6971439123153687\n",
      "Batch 34. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6801307797431946\n",
      "Batch 35. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6833593249320984\n",
      "Batch 36. Data shape torch.Size([32, 3, 224, 224]) Loss 0.691662609577179\n",
      "Batch 37. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6918678283691406\n",
      "Batch 38. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6886219382286072\n",
      "Batch 39. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6934922337532043\n",
      "Batch 40. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6918789148330688\n",
      "Batch 41. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6963346600532532\n",
      "Batch 42. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6888418197631836\n",
      "Batch 43. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6957423686981201\n",
      "Batch 44. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6847147345542908\n",
      "Batch 45. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6921776533126831\n",
      "Batch 46. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6786385774612427\n",
      "Batch 47. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6884236335754395\n",
      "Batch 48. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6932443380355835\n",
      "Batch 49. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6941147446632385\n",
      "Batch 50. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6932435035705566\n",
      "Batch 51. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6856203675270081\n",
      "Batch 52. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6867206692695618\n",
      "Batch 53. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6830792427062988\n",
      "Batch 54. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6855325698852539\n",
      "Batch 55. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6874402165412903\n",
      "Batch 56. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6907500624656677\n",
      "Batch 57. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6849045753479004\n",
      "Batch 58. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6831960678100586\n",
      "Batch 59. Data shape torch.Size([32, 3, 224, 224]) Loss 0.687995433807373\n",
      "Batch 60. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6937578320503235\n",
      "Batch 61. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6881735920906067\n",
      "Batch 62. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6881933808326721\n",
      "Batch 63. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6935247778892517\n",
      "Batch 64. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6924124360084534\n",
      "Batch 65. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6836005449295044\n",
      "Batch 66. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6934705972671509\n",
      "Batch 67. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6851816177368164\n",
      "Batch 68. Data shape torch.Size([32, 3, 224, 224]) Loss 0.685908854007721\n",
      "Batch 69. Data shape torch.Size([32, 3, 224, 224]) Loss 0.695531964302063\n",
      "Batch 70. Data shape torch.Size([32, 3, 224, 224]) Loss 0.691766083240509\n",
      "Batch 71. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6802875995635986\n",
      "Batch 72. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6839075684547424\n",
      "Batch 73. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6925559639930725\n",
      "Batch 74. Data shape torch.Size([32, 3, 224, 224]) Loss 0.682207465171814\n",
      "Batch 75. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6892314553260803\n",
      "Batch 76. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6974176168441772\n",
      "Batch 77. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6959956884384155\n",
      "Batch 78. Data shape torch.Size([32, 3, 224, 224]) Loss 0.685691237449646\n",
      "Batch 79. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6932852864265442\n",
      "Batch 80. Data shape torch.Size([32, 3, 224, 224]) Loss 0.682732343673706\n",
      "Batch 81. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6900319457054138\n",
      "Batch 82. Data shape torch.Size([32, 3, 224, 224]) Loss 0.692328929901123\n",
      "Batch 83. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6823179721832275\n",
      "Batch 84. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6924684047698975\n",
      "Batch 85. Data shape torch.Size([32, 3, 224, 224]) Loss 0.685957133769989\n",
      "Batch 86. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6818233728408813\n",
      "Batch 87. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6803492307662964\n",
      "Batch 88. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6957337856292725\n",
      "Batch 89. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6813545823097229\n",
      "Batch 90. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6887027621269226\n",
      "Batch 91. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6884804368019104\n",
      "Batch 92. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6877945065498352\n",
      "Batch 93. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6901280283927917\n",
      "Batch 94. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6938402652740479\n",
      "Batch 95. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6893600821495056\n",
      "Batch 96. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6927054524421692\n",
      "Batch 97. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6868563294410706\n",
      "Batch 98. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6906454563140869\n",
      "Batch 99. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6862825751304626\n",
      "Batch 100. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6924461126327515\n",
      "Batch 101. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6776158809661865\n",
      "Batch 102. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6854791641235352\n",
      "Batch 103. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6835498213768005\n",
      "Batch 104. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6870189905166626\n",
      "Batch 105. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6905513405799866\n",
      "Batch 106. Data shape torch.Size([32, 3, 224, 224]) Loss 0.689942479133606\n",
      "Batch 107. Data shape torch.Size([32, 3, 224, 224]) Loss 0.685499906539917\n",
      "Batch 108. Data shape torch.Size([32, 3, 224, 224]) Loss 0.690311074256897\n",
      "Batch 109. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6873349547386169\n",
      "Batch 110. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6928653717041016\n",
      "Batch 111. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6879388093948364\n",
      "Batch 112. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6792528629302979\n",
      "Batch 113. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6864175796508789\n",
      "Batch 114. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6872639060020447\n",
      "Batch 115. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6890828013420105\n",
      "Batch 116. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6845197081565857\n",
      "Batch 117. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6966823935508728\n",
      "Batch 118. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6902315616607666\n",
      "Batch 119. Data shape torch.Size([20, 3, 224, 224]) Loss 0.6946316957473755\n",
      "Valid loss improved from 0.690008 to 0.687833. Saving model ...\n",
      "Epoch: 04/50 | time: 21.0m 45.29s | lr: 1.0000e-05 | train/loss: 0.68941 | val/loss: 0.68783 | val/accuracy: 0.54953 | val/AUC: 0.55646 | val/Kappa: 0.11135\n",
      "Epoch: 5 Train batch 10 loss: 0.6894952654838562, 2.1% complete\n",
      "Epoch: 5 Train batch 20 loss: 0.6911712288856506, 4.2% complete\n",
      "Epoch: 5 Train batch 30 loss: 0.6797646284103394, 6.3% complete\n",
      "Epoch: 5 Train batch 40 loss: 0.6795128583908081, 8.4% complete\n",
      "Epoch: 5 Train batch 50 loss: 0.6863475441932678, 10.5% complete\n",
      "Epoch: 5 Train batch 60 loss: 0.6852169036865234, 12.6% complete\n",
      "Epoch: 5 Train batch 70 loss: 0.6849697828292847, 14.7% complete\n",
      "Epoch: 5 Train batch 80 loss: 0.6939582228660583, 16.8% complete\n",
      "Epoch: 5 Train batch 90 loss: 0.6932491660118103, 18.9% complete\n",
      "Epoch: 5 Train batch 100 loss: 0.6884307861328125, 21.1% complete\n",
      "Epoch: 5 Train batch 110 loss: 0.6793898344039917, 23.2% complete\n",
      "Epoch: 5 Train batch 120 loss: 0.6842661499977112, 25.3% complete\n",
      "Epoch: 5 Train batch 130 loss: 0.6836556792259216, 27.4% complete\n",
      "Epoch: 5 Train batch 140 loss: 0.6911585330963135, 29.5% complete\n",
      "Epoch: 5 Train batch 150 loss: 0.6878278851509094, 31.6% complete\n",
      "Epoch: 5 Train batch 160 loss: 0.6857024431228638, 33.7% complete\n",
      "Epoch: 5 Train batch 170 loss: 0.6852495670318604, 35.8% complete\n",
      "Epoch: 5 Train batch 180 loss: 0.6858307123184204, 37.9% complete\n",
      "Epoch: 5 Train batch 190 loss: 0.6805894374847412, 40.0% complete\n",
      "Epoch: 5 Train batch 200 loss: 0.6815568208694458, 42.1% complete\n",
      "Epoch: 5 Train batch 210 loss: 0.6866058111190796, 44.2% complete\n",
      "Epoch: 5 Train batch 220 loss: 0.6890782117843628, 46.3% complete\n",
      "Epoch: 5 Train batch 230 loss: 0.6879879832267761, 48.4% complete\n",
      "Epoch: 5 Train batch 240 loss: 0.6924843788146973, 50.5% complete\n",
      "Epoch: 5 Train batch 250 loss: 0.6837086081504822, 52.6% complete\n",
      "Epoch: 5 Train batch 260 loss: 0.6860676407814026, 54.7% complete\n",
      "Epoch: 5 Train batch 270 loss: 0.6904939413070679, 56.8% complete\n",
      "Epoch: 5 Train batch 280 loss: 0.6814454197883606, 58.9% complete\n",
      "Epoch: 5 Train batch 290 loss: 0.6877859830856323, 61.1% complete\n",
      "Epoch: 5 Train batch 300 loss: 0.6814643740653992, 63.2% complete\n",
      "Epoch: 5 Train batch 310 loss: 0.6876825094223022, 65.3% complete\n",
      "Epoch: 5 Train batch 320 loss: 0.6899335384368896, 67.4% complete\n",
      "Epoch: 5 Train batch 330 loss: 0.6944183111190796, 69.5% complete\n",
      "Epoch: 5 Train batch 340 loss: 0.6903312802314758, 71.6% complete\n",
      "Epoch: 5 Train batch 350 loss: 0.6960797905921936, 73.7% complete\n",
      "Epoch: 5 Train batch 360 loss: 0.6899754405021667, 75.8% complete\n",
      "Epoch: 5 Train batch 370 loss: 0.6927540898323059, 77.9% complete\n",
      "Epoch: 5 Train batch 380 loss: 0.680867075920105, 80.0% complete\n",
      "Epoch: 5 Train batch 390 loss: 0.6900060176849365, 82.1% complete\n",
      "Epoch: 5 Train batch 400 loss: 0.6846952438354492, 84.2% complete\n",
      "Epoch: 5 Train batch 410 loss: 0.6994261145591736, 86.3% complete\n",
      "Epoch: 5 Train batch 420 loss: 0.693123996257782, 88.4% complete\n",
      "Epoch: 5 Train batch 430 loss: 0.6878559589385986, 90.5% complete\n",
      "Epoch: 5 Train batch 440 loss: 0.6847488284111023, 92.6% complete\n",
      "Epoch: 5 Train batch 450 loss: 0.6893418431282043, 94.7% complete\n",
      "Epoch: 5 Train batch 460 loss: 0.6812702417373657, 96.8% complete\n",
      "Epoch: 5 Train batch 470 loss: 0.6865672469139099, 98.9% complete\n",
      "Batch 1. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6775310635566711\n",
      "Batch 2. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6886559724807739\n",
      "Batch 3. Data shape torch.Size([32, 3, 224, 224]) Loss 0.685035228729248\n",
      "Batch 4. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6826618909835815\n",
      "Batch 5. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6834276914596558\n",
      "Batch 6. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6998785138130188\n",
      "Batch 7. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6853165030479431\n",
      "Batch 8. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6890008449554443\n",
      "Batch 9. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6788941025733948\n",
      "Batch 10. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6944295763969421\n",
      "Batch 11. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6890125274658203\n",
      "Batch 12. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6895538568496704\n",
      "Batch 13. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6832144260406494\n",
      "Batch 14. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6854372620582581\n",
      "Batch 15. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6888514757156372\n",
      "Batch 16. Data shape torch.Size([32, 3, 224, 224]) Loss 0.680679202079773\n",
      "Batch 17. Data shape torch.Size([32, 3, 224, 224]) Loss 0.679680347442627\n",
      "Batch 18. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6836779713630676\n",
      "Batch 19. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6856868267059326\n",
      "Batch 20. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6831303238868713\n",
      "Batch 21. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6946911811828613\n",
      "Batch 22. Data shape torch.Size([32, 3, 224, 224]) Loss 0.677699863910675\n",
      "Batch 23. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6839025616645813\n",
      "Batch 24. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6823095083236694\n",
      "Batch 25. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6845335364341736\n",
      "Batch 26. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6953101754188538\n",
      "Batch 27. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6913723945617676\n",
      "Batch 28. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6914616227149963\n",
      "Batch 29. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6861973404884338\n",
      "Batch 30. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6850686073303223\n",
      "Batch 31. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6814788579940796\n",
      "Batch 32. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6816786527633667\n",
      "Batch 33. Data shape torch.Size([32, 3, 224, 224]) Loss 0.686720609664917\n",
      "Batch 34. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6794425845146179\n",
      "Batch 35. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6887350082397461\n",
      "Batch 36. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6696204543113708\n",
      "Batch 37. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6827024221420288\n",
      "Batch 38. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6886698007583618\n",
      "Batch 39. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6884045004844666\n",
      "Batch 40. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6803646683692932\n",
      "Batch 41. Data shape torch.Size([32, 3, 224, 224]) Loss 0.685296356678009\n",
      "Batch 42. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6887356638908386\n",
      "Batch 43. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6843467354774475\n",
      "Batch 44. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6860999464988708\n",
      "Batch 45. Data shape torch.Size([32, 3, 224, 224]) Loss 0.685627818107605\n",
      "Batch 46. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6861461997032166\n",
      "Batch 47. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6852518916130066\n",
      "Batch 48. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6855814456939697\n",
      "Batch 49. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6914663910865784\n",
      "Batch 50. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6881241202354431\n",
      "Batch 51. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6864556670188904\n",
      "Batch 52. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6801835298538208\n",
      "Batch 53. Data shape torch.Size([32, 3, 224, 224]) Loss 0.683117151260376\n",
      "Batch 54. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6908652782440186\n",
      "Batch 55. Data shape torch.Size([32, 3, 224, 224]) Loss 0.694878101348877\n",
      "Batch 56. Data shape torch.Size([32, 3, 224, 224]) Loss 0.685187041759491\n",
      "Batch 57. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6834033727645874\n",
      "Batch 58. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6835698485374451\n",
      "Batch 59. Data shape torch.Size([32, 3, 224, 224]) Loss 0.685073971748352\n",
      "Batch 60. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6857988834381104\n",
      "Batch 61. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6936095952987671\n",
      "Batch 62. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6841766834259033\n",
      "Batch 63. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6877189874649048\n",
      "Batch 64. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6826680302619934\n",
      "Batch 65. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6861636638641357\n",
      "Batch 66. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6893043518066406\n",
      "Batch 67. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6868618726730347\n",
      "Batch 68. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6895691156387329\n",
      "Batch 69. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6882774233818054\n",
      "Batch 70. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6805412769317627\n",
      "Batch 71. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6827215552330017\n",
      "Batch 72. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6815075278282166\n",
      "Batch 73. Data shape torch.Size([32, 3, 224, 224]) Loss 0.686735212802887\n",
      "Batch 74. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6886127591133118\n",
      "Batch 75. Data shape torch.Size([32, 3, 224, 224]) Loss 0.689228892326355\n",
      "Batch 76. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6895303130149841\n",
      "Batch 77. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6940007209777832\n",
      "Batch 78. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6827822327613831\n",
      "Batch 79. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6861810684204102\n",
      "Batch 80. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6828464269638062\n",
      "Batch 81. Data shape torch.Size([32, 3, 224, 224]) Loss 0.688838005065918\n",
      "Batch 82. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6925670504570007\n",
      "Batch 83. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6941190361976624\n",
      "Batch 84. Data shape torch.Size([32, 3, 224, 224]) Loss 0.689916729927063\n",
      "Batch 85. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6828287839889526\n",
      "Batch 86. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6899093389511108\n",
      "Batch 87. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6878589391708374\n",
      "Batch 88. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6874822378158569\n",
      "Batch 89. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6906057000160217\n",
      "Batch 90. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6819290518760681\n",
      "Batch 91. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6811909079551697\n",
      "Batch 92. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6830395460128784\n",
      "Batch 93. Data shape torch.Size([32, 3, 224, 224]) Loss 0.682315468788147\n",
      "Batch 94. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6887408494949341\n",
      "Batch 95. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6852357387542725\n",
      "Batch 96. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6872107982635498\n",
      "Batch 97. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6899110674858093\n",
      "Batch 98. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6851869225502014\n",
      "Batch 99. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6852918863296509\n",
      "Batch 100. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6931328773498535\n",
      "Batch 101. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6925619840621948\n",
      "Batch 102. Data shape torch.Size([32, 3, 224, 224]) Loss 0.691676676273346\n",
      "Batch 103. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6870136857032776\n",
      "Batch 104. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6845273971557617\n",
      "Batch 105. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6835437417030334\n",
      "Batch 106. Data shape torch.Size([32, 3, 224, 224]) Loss 0.682643711566925\n",
      "Batch 107. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6850250363349915\n",
      "Batch 108. Data shape torch.Size([32, 3, 224, 224]) Loss 0.684890627861023\n",
      "Batch 109. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6876415610313416\n",
      "Batch 110. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6823568940162659\n",
      "Batch 111. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6900203824043274\n",
      "Batch 112. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6873824000358582\n",
      "Batch 113. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6816923022270203\n",
      "Batch 114. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6877049803733826\n",
      "Batch 115. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6854411363601685\n",
      "Batch 116. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6920993328094482\n",
      "Batch 117. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6781538724899292\n",
      "Batch 118. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6816614866256714\n",
      "Batch 119. Data shape torch.Size([20, 3, 224, 224]) Loss 0.6794850826263428\n",
      "Valid loss improved from 0.687833 to 0.686094. Saving model ...\n",
      "Epoch: 05/50 | time: 21.0m 17.69s | lr: 1.0000e-05 | train/loss: 0.68754 | val/loss: 0.68609 | val/accuracy: 0.57007 | val/AUC: 0.57678 | val/Kappa: 0.15149\n",
      "Epoch: 6 Train batch 10 loss: 0.6841521859169006, 2.1% complete\n",
      "Epoch: 6 Train batch 20 loss: 0.6851537823677063, 4.2% complete\n",
      "Epoch: 6 Train batch 30 loss: 0.688173770904541, 6.3% complete\n",
      "Epoch: 6 Train batch 40 loss: 0.6887103915214539, 8.4% complete\n",
      "Epoch: 6 Train batch 50 loss: 0.6767289042472839, 10.5% complete\n",
      "Epoch: 6 Train batch 60 loss: 0.6919489502906799, 12.6% complete\n",
      "Epoch: 6 Train batch 70 loss: 0.6788318157196045, 14.7% complete\n",
      "Epoch: 6 Train batch 80 loss: 0.6765003204345703, 16.8% complete\n",
      "Epoch: 6 Train batch 90 loss: 0.6879277229309082, 18.9% complete\n",
      "Epoch: 6 Train batch 100 loss: 0.6861507296562195, 21.1% complete\n",
      "Epoch: 6 Train batch 110 loss: 0.6879438161849976, 23.2% complete\n",
      "Epoch: 6 Train batch 120 loss: 0.68431556224823, 25.3% complete\n",
      "Epoch: 6 Train batch 130 loss: 0.6880907416343689, 27.4% complete\n",
      "Epoch: 6 Train batch 140 loss: 0.6880379319190979, 29.5% complete\n",
      "Epoch: 6 Train batch 150 loss: 0.6847065687179565, 31.6% complete\n",
      "Epoch: 6 Train batch 160 loss: 0.6912437081336975, 33.7% complete\n",
      "Epoch: 6 Train batch 170 loss: 0.6847919821739197, 35.8% complete\n",
      "Epoch: 6 Train batch 180 loss: 0.6846174597740173, 37.9% complete\n",
      "Epoch: 6 Train batch 190 loss: 0.6879213452339172, 40.0% complete\n",
      "Epoch: 6 Train batch 200 loss: 0.6812562346458435, 42.1% complete\n",
      "Epoch: 6 Train batch 210 loss: 0.6913594603538513, 44.2% complete\n",
      "Epoch: 6 Train batch 220 loss: 0.6843400597572327, 46.3% complete\n",
      "Epoch: 6 Train batch 230 loss: 0.6840587854385376, 48.4% complete\n",
      "Epoch: 6 Train batch 240 loss: 0.6859837174415588, 50.5% complete\n",
      "Epoch: 6 Train batch 250 loss: 0.6885299682617188, 52.6% complete\n",
      "Epoch: 6 Train batch 260 loss: 0.6905643343925476, 54.7% complete\n",
      "Epoch: 6 Train batch 270 loss: 0.6825897097587585, 56.8% complete\n",
      "Epoch: 6 Train batch 280 loss: 0.685008704662323, 58.9% complete\n",
      "Epoch: 6 Train batch 290 loss: 0.6935498714447021, 61.1% complete\n",
      "Epoch: 6 Train batch 300 loss: 0.6842990517616272, 63.2% complete\n",
      "Epoch: 6 Train batch 310 loss: 0.681431770324707, 65.3% complete\n",
      "Epoch: 6 Train batch 320 loss: 0.6792000532150269, 67.4% complete\n",
      "Epoch: 6 Train batch 330 loss: 0.6832799911499023, 69.5% complete\n",
      "Epoch: 6 Train batch 340 loss: 0.6877900958061218, 71.6% complete\n",
      "Epoch: 6 Train batch 350 loss: 0.6858450174331665, 73.7% complete\n",
      "Epoch: 6 Train batch 360 loss: 0.6831001043319702, 75.8% complete\n",
      "Epoch: 6 Train batch 370 loss: 0.6785953640937805, 77.9% complete\n",
      "Epoch: 6 Train batch 380 loss: 0.6883270740509033, 80.0% complete\n",
      "Epoch: 6 Train batch 390 loss: 0.6880955100059509, 82.1% complete\n",
      "Epoch: 6 Train batch 400 loss: 0.6866767406463623, 84.2% complete\n",
      "Epoch: 6 Train batch 410 loss: 0.6824859380722046, 86.3% complete\n",
      "Epoch: 6 Train batch 420 loss: 0.6944481134414673, 88.4% complete\n",
      "Epoch: 6 Train batch 430 loss: 0.680616021156311, 90.5% complete\n",
      "Epoch: 6 Train batch 440 loss: 0.6813099384307861, 92.6% complete\n",
      "Epoch: 6 Train batch 450 loss: 0.6790134906768799, 94.7% complete\n",
      "Epoch: 6 Train batch 460 loss: 0.6811714768409729, 96.8% complete\n",
      "Epoch: 6 Train batch 470 loss: 0.6874675750732422, 98.9% complete\n",
      "Batch 1. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6789686679840088\n",
      "Batch 2. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6809812188148499\n",
      "Batch 3. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6776918768882751\n",
      "Batch 4. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6895204782485962\n",
      "Batch 5. Data shape torch.Size([32, 3, 224, 224]) Loss 0.681178092956543\n",
      "Batch 6. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6768866181373596\n",
      "Batch 7. Data shape torch.Size([32, 3, 224, 224]) Loss 0.679871141910553\n",
      "Batch 8. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6769464015960693\n",
      "Batch 9. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6749619245529175\n",
      "Batch 10. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6851550936698914\n",
      "Batch 11. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6821230053901672\n",
      "Batch 12. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6781417727470398\n",
      "Batch 13. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6894930005073547\n",
      "Batch 14. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6885949373245239\n",
      "Batch 15. Data shape torch.Size([32, 3, 224, 224]) Loss 0.685395359992981\n",
      "Batch 16. Data shape torch.Size([32, 3, 224, 224]) Loss 0.7012264728546143\n",
      "Batch 17. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6839348077774048\n",
      "Batch 18. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6764623522758484\n",
      "Batch 19. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6830391883850098\n",
      "Batch 20. Data shape torch.Size([32, 3, 224, 224]) Loss 0.678000271320343\n",
      "Batch 21. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6765128970146179\n",
      "Batch 22. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6848737001419067\n",
      "Batch 23. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6885672807693481\n",
      "Batch 24. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6808494329452515\n",
      "Batch 25. Data shape torch.Size([32, 3, 224, 224]) Loss 0.681424617767334\n",
      "Batch 26. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6844279170036316\n",
      "Batch 27. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6835460662841797\n",
      "Batch 28. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6846786141395569\n",
      "Batch 29. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6759635806083679\n",
      "Batch 30. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6837221384048462\n",
      "Batch 31. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6804889440536499\n",
      "Batch 32. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6961987018585205\n",
      "Batch 33. Data shape torch.Size([32, 3, 224, 224]) Loss 0.68375563621521\n",
      "Batch 34. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6877435445785522\n",
      "Batch 35. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6746770739555359\n",
      "Batch 36. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6831193566322327\n",
      "Batch 37. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6825321316719055\n",
      "Batch 38. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6814936399459839\n",
      "Batch 39. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6771934628486633\n",
      "Batch 40. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6935430765151978\n",
      "Batch 41. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6871500611305237\n",
      "Batch 42. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6799262166023254\n",
      "Batch 43. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6859542727470398\n",
      "Batch 44. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6818392872810364\n",
      "Batch 45. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6936399340629578\n",
      "Batch 46. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6852611303329468\n",
      "Batch 47. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6777016520500183\n",
      "Batch 48. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6773999929428101\n",
      "Batch 49. Data shape torch.Size([32, 3, 224, 224]) Loss 0.685695469379425\n",
      "Batch 50. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6841296553611755\n",
      "Batch 51. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6897122263908386\n",
      "Batch 52. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6891024112701416\n",
      "Batch 53. Data shape torch.Size([32, 3, 224, 224]) Loss 0.681311845779419\n",
      "Batch 54. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6909207105636597\n",
      "Batch 55. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6919029951095581\n",
      "Batch 56. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6937767863273621\n",
      "Batch 57. Data shape torch.Size([32, 3, 224, 224]) Loss 0.695600152015686\n",
      "Batch 58. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6800185441970825\n",
      "Batch 59. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6914737224578857\n",
      "Batch 60. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6773405075073242\n",
      "Batch 61. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6841192841529846\n",
      "Batch 62. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6820278167724609\n",
      "Batch 63. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6670344471931458\n",
      "Batch 64. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6896040439605713\n",
      "Batch 65. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6897372603416443\n",
      "Batch 66. Data shape torch.Size([32, 3, 224, 224]) Loss 0.69321608543396\n",
      "Batch 67. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6890619397163391\n",
      "Batch 68. Data shape torch.Size([32, 3, 224, 224]) Loss 0.674261748790741\n",
      "Batch 69. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6914120316505432\n",
      "Batch 70. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6805515289306641\n",
      "Batch 71. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6847875714302063\n",
      "Batch 72. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6731780767440796\n",
      "Batch 73. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6801245212554932\n",
      "Batch 74. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6915170550346375\n",
      "Batch 75. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6809327006340027\n",
      "Batch 76. Data shape torch.Size([32, 3, 224, 224]) Loss 0.68362957239151\n",
      "Batch 77. Data shape torch.Size([32, 3, 224, 224]) Loss 0.687028169631958\n",
      "Batch 78. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6837167739868164\n",
      "Batch 79. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6916078925132751\n",
      "Batch 80. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6937299966812134\n",
      "Batch 81. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6966388821601868\n",
      "Batch 82. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6854199171066284\n",
      "Batch 83. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6787403225898743\n",
      "Batch 84. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6847892999649048\n",
      "Batch 85. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6861081123352051\n",
      "Batch 86. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6789128184318542\n",
      "Batch 87. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6791995763778687\n",
      "Batch 88. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6893097758293152\n",
      "Batch 89. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6834599375724792\n",
      "Batch 90. Data shape torch.Size([32, 3, 224, 224]) Loss 0.680259644985199\n",
      "Batch 91. Data shape torch.Size([32, 3, 224, 224]) Loss 0.684288501739502\n",
      "Batch 92. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6801533102989197\n",
      "Batch 93. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6904658079147339\n",
      "Batch 94. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6771017909049988\n",
      "Batch 95. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6844831705093384\n",
      "Batch 96. Data shape torch.Size([32, 3, 224, 224]) Loss 0.68882817029953\n",
      "Batch 97. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6803137063980103\n",
      "Batch 98. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6834632754325867\n",
      "Batch 99. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6901721358299255\n",
      "Batch 100. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6738055348396301\n",
      "Batch 101. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6800184845924377\n",
      "Batch 102. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6930872797966003\n",
      "Batch 103. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6716789603233337\n",
      "Batch 104. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6844668388366699\n",
      "Batch 105. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6902529001235962\n",
      "Batch 106. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6973705291748047\n",
      "Batch 107. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6850016713142395\n",
      "Batch 108. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6793299913406372\n",
      "Batch 109. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6855199933052063\n",
      "Batch 110. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6805925369262695\n",
      "Batch 111. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6908310651779175\n",
      "Batch 112. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6794538497924805\n",
      "Batch 113. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6905469298362732\n",
      "Batch 114. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6773855686187744\n",
      "Batch 115. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6728234887123108\n",
      "Batch 116. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6858571171760559\n",
      "Batch 117. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6815961003303528\n",
      "Batch 118. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6757683157920837\n",
      "Batch 119. Data shape torch.Size([20, 3, 224, 224]) Loss 0.6912241578102112\n",
      "Valid loss improved from 0.686094 to 0.683981. Saving model ...\n",
      "Epoch: 06/50 | time: 21.0m 6.354s | lr: 1.0000e-05 | train/loss: 0.68558 | val/loss: 0.68398 | val/accuracy: 0.59484 | val/AUC: 0.60095 | val/Kappa: 0.19942\n",
      "Epoch: 7 Train batch 10 loss: 0.6849079132080078, 2.1% complete\n",
      "Epoch: 7 Train batch 20 loss: 0.6841874122619629, 4.2% complete\n",
      "Epoch: 7 Train batch 30 loss: 0.6781880855560303, 6.3% complete\n",
      "Epoch: 7 Train batch 40 loss: 0.6837802529335022, 8.4% complete\n",
      "Epoch: 7 Train batch 50 loss: 0.6790937781333923, 10.5% complete\n",
      "Epoch: 7 Train batch 60 loss: 0.680608332157135, 12.6% complete\n",
      "Epoch: 7 Train batch 70 loss: 0.6902684569358826, 14.7% complete\n",
      "Epoch: 7 Train batch 80 loss: 0.6799007058143616, 16.8% complete\n",
      "Epoch: 7 Train batch 90 loss: 0.6851395964622498, 18.9% complete\n",
      "Epoch: 7 Train batch 100 loss: 0.6833048462867737, 21.1% complete\n",
      "Epoch: 7 Train batch 110 loss: 0.6781686544418335, 23.2% complete\n",
      "Epoch: 7 Train batch 120 loss: 0.6776090860366821, 25.3% complete\n",
      "Epoch: 7 Train batch 130 loss: 0.6864341497421265, 27.4% complete\n",
      "Epoch: 7 Train batch 140 loss: 0.6824475526809692, 29.5% complete\n",
      "Epoch: 7 Train batch 150 loss: 0.6867798566818237, 31.6% complete\n",
      "Epoch: 7 Train batch 160 loss: 0.6753407120704651, 33.7% complete\n",
      "Epoch: 7 Train batch 170 loss: 0.6751534938812256, 35.8% complete\n",
      "Epoch: 7 Train batch 180 loss: 0.6756802797317505, 37.9% complete\n",
      "Epoch: 7 Train batch 190 loss: 0.680922269821167, 40.0% complete\n",
      "Epoch: 7 Train batch 200 loss: 0.6897778511047363, 42.1% complete\n",
      "Epoch: 7 Train batch 210 loss: 0.6751516461372375, 44.2% complete\n",
      "Epoch: 7 Train batch 220 loss: 0.6768581867218018, 46.3% complete\n",
      "Epoch: 7 Train batch 230 loss: 0.6843874454498291, 48.4% complete\n",
      "Epoch: 7 Train batch 240 loss: 0.6791403293609619, 50.5% complete\n",
      "Epoch: 7 Train batch 250 loss: 0.6847962737083435, 52.6% complete\n",
      "Epoch: 7 Train batch 260 loss: 0.678534209728241, 54.7% complete\n",
      "Epoch: 7 Train batch 270 loss: 0.6873047351837158, 56.8% complete\n",
      "Epoch: 7 Train batch 280 loss: 0.6753755211830139, 58.9% complete\n",
      "Epoch: 7 Train batch 290 loss: 0.6782099604606628, 61.1% complete\n",
      "Epoch: 7 Train batch 300 loss: 0.6804172992706299, 63.2% complete\n",
      "Epoch: 7 Train batch 310 loss: 0.6915768384933472, 65.3% complete\n",
      "Epoch: 7 Train batch 320 loss: 0.690924882888794, 67.4% complete\n",
      "Epoch: 7 Train batch 330 loss: 0.6777703762054443, 69.5% complete\n",
      "Epoch: 7 Train batch 340 loss: 0.6802257895469666, 71.6% complete\n",
      "Epoch: 7 Train batch 350 loss: 0.6745028495788574, 73.7% complete\n",
      "Epoch: 7 Train batch 360 loss: 0.6766841411590576, 75.8% complete\n",
      "Epoch: 7 Train batch 370 loss: 0.6851482391357422, 77.9% complete\n",
      "Epoch: 7 Train batch 380 loss: 0.6858171820640564, 80.0% complete\n",
      "Epoch: 7 Train batch 390 loss: 0.6970826983451843, 82.1% complete\n",
      "Epoch: 7 Train batch 400 loss: 0.684561550617218, 84.2% complete\n",
      "Epoch: 7 Train batch 410 loss: 0.6792199015617371, 86.3% complete\n",
      "Epoch: 7 Train batch 420 loss: 0.6868374347686768, 88.4% complete\n",
      "Epoch: 7 Train batch 430 loss: 0.6938515305519104, 90.5% complete\n",
      "Epoch: 7 Train batch 440 loss: 0.6789147853851318, 92.6% complete\n",
      "Epoch: 7 Train batch 450 loss: 0.6823226809501648, 94.7% complete\n",
      "Epoch: 7 Train batch 460 loss: 0.6776518225669861, 96.8% complete\n",
      "Epoch: 7 Train batch 470 loss: 0.6831786632537842, 98.9% complete\n",
      "Batch 1. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6837862730026245\n",
      "Batch 2. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6865314245223999\n",
      "Batch 3. Data shape torch.Size([32, 3, 224, 224]) Loss 0.684761106967926\n",
      "Batch 4. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6682886481285095\n",
      "Batch 5. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6792578101158142\n",
      "Batch 6. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6784301400184631\n",
      "Batch 7. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6899307370185852\n",
      "Batch 8. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6732802391052246\n",
      "Batch 9. Data shape torch.Size([32, 3, 224, 224]) Loss 0.686469554901123\n",
      "Batch 10. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6755761504173279\n",
      "Batch 11. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6775780916213989\n",
      "Batch 12. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6878148317337036\n",
      "Batch 13. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6896339654922485\n",
      "Batch 14. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6848940849304199\n",
      "Batch 15. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6835854053497314\n",
      "Batch 16. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6859254240989685\n",
      "Batch 17. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6767702102661133\n",
      "Batch 18. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6897518038749695\n",
      "Batch 19. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6634541153907776\n",
      "Batch 20. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6725067496299744\n",
      "Batch 21. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6866083145141602\n",
      "Batch 22. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6724948883056641\n",
      "Batch 23. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6761072874069214\n",
      "Batch 24. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6816149950027466\n",
      "Batch 25. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6859039664268494\n",
      "Batch 26. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6877470016479492\n",
      "Batch 27. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6904351711273193\n",
      "Batch 28. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6744529604911804\n",
      "Batch 29. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6754364371299744\n",
      "Batch 30. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6819767355918884\n",
      "Batch 31. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6622748374938965\n",
      "Batch 32. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6868533492088318\n",
      "Batch 33. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6842054724693298\n",
      "Batch 34. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6857354044914246\n",
      "Batch 35. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6773004531860352\n",
      "Batch 36. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6810122728347778\n",
      "Batch 37. Data shape torch.Size([32, 3, 224, 224]) Loss 0.692776083946228\n",
      "Batch 38. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6803930401802063\n",
      "Batch 39. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6829222440719604\n",
      "Batch 40. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6909446716308594\n",
      "Batch 41. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6859996318817139\n",
      "Batch 42. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6745314002037048\n",
      "Batch 43. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6846124529838562\n",
      "Batch 44. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6827998757362366\n",
      "Batch 45. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6857238411903381\n",
      "Batch 46. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6783797740936279\n",
      "Batch 47. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6810433864593506\n",
      "Batch 48. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6827157139778137\n",
      "Batch 49. Data shape torch.Size([32, 3, 224, 224]) Loss 0.683674156665802\n",
      "Batch 50. Data shape torch.Size([32, 3, 224, 224]) Loss 0.680607795715332\n",
      "Batch 51. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6784337759017944\n",
      "Batch 52. Data shape torch.Size([32, 3, 224, 224]) Loss 0.682930588722229\n",
      "Batch 53. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6791869401931763\n",
      "Batch 54. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6844986081123352\n",
      "Batch 55. Data shape torch.Size([32, 3, 224, 224]) Loss 0.681547224521637\n",
      "Batch 56. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6823442578315735\n",
      "Batch 57. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6828769445419312\n",
      "Batch 58. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6845487952232361\n",
      "Batch 59. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6835628151893616\n",
      "Batch 60. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6859176158905029\n",
      "Batch 61. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6875411868095398\n",
      "Batch 62. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6932006478309631\n",
      "Batch 63. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6772744655609131\n",
      "Batch 64. Data shape torch.Size([32, 3, 224, 224]) Loss 0.675561249256134\n",
      "Batch 65. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6811721920967102\n",
      "Batch 66. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6880888342857361\n",
      "Batch 67. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6852051019668579\n",
      "Batch 68. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6762809753417969\n",
      "Batch 69. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6803171038627625\n",
      "Batch 70. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6809915900230408\n",
      "Batch 71. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6739967465400696\n",
      "Batch 72. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6806496381759644\n",
      "Batch 73. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6860418319702148\n",
      "Batch 74. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6858659982681274\n",
      "Batch 75. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6784949898719788\n",
      "Batch 76. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6711992621421814\n",
      "Batch 77. Data shape torch.Size([32, 3, 224, 224]) Loss 0.691658079624176\n",
      "Batch 78. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6853675842285156\n",
      "Batch 79. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6705012321472168\n",
      "Batch 80. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6873831152915955\n",
      "Batch 81. Data shape torch.Size([32, 3, 224, 224]) Loss 0.682232677936554\n",
      "Batch 82. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6849895119667053\n",
      "Batch 83. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6896481513977051\n",
      "Batch 84. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6871322989463806\n",
      "Batch 85. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6860567927360535\n",
      "Batch 86. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6768826842308044\n",
      "Batch 87. Data shape torch.Size([32, 3, 224, 224]) Loss 0.689335823059082\n",
      "Batch 88. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6823882460594177\n",
      "Batch 89. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6871898770332336\n",
      "Batch 90. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6871155500411987\n",
      "Batch 91. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6803001761436462\n",
      "Batch 92. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6865718364715576\n",
      "Batch 93. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6889646649360657\n",
      "Batch 94. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6625155210494995\n",
      "Batch 95. Data shape torch.Size([32, 3, 224, 224]) Loss 0.679261326789856\n",
      "Batch 96. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6877744793891907\n",
      "Batch 97. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6768916845321655\n",
      "Batch 98. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6824016571044922\n",
      "Batch 99. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6895281076431274\n",
      "Batch 100. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6766887307167053\n",
      "Batch 101. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6834046244621277\n",
      "Batch 102. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6772965788841248\n",
      "Batch 103. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6797013878822327\n",
      "Batch 104. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6880590915679932\n",
      "Batch 105. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6780078411102295\n",
      "Batch 106. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6862718462944031\n",
      "Batch 107. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6901686191558838\n",
      "Batch 108. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6885212659835815\n",
      "Batch 109. Data shape torch.Size([32, 3, 224, 224]) Loss 0.682449221611023\n",
      "Batch 110. Data shape torch.Size([32, 3, 224, 224]) Loss 0.687936544418335\n",
      "Batch 111. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6843007206916809\n",
      "Batch 112. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6708574295043945\n",
      "Batch 113. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6837310791015625\n",
      "Batch 114. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6774299740791321\n",
      "Batch 115. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6818727850914001\n",
      "Batch 116. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6857905983924866\n",
      "Batch 117. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6811369061470032\n",
      "Batch 118. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6903163194656372\n",
      "Batch 119. Data shape torch.Size([20, 3, 224, 224]) Loss 0.6732767820358276\n",
      "Valid loss improved from 0.683981 to 0.682122. Saving model ...\n",
      "Epoch: 07/50 | time: 20.0m 48.45s | lr: 1.0000e-05 | train/loss: 0.68331 | val/loss: 0.68212 | val/accuracy: 0.61038 | val/AUC: 0.61614 | val/Kappa: 0.22958\n",
      "Epoch: 8 Train batch 10 loss: 0.6855533123016357, 2.1% complete\n",
      "Epoch: 8 Train batch 20 loss: 0.6827408671379089, 4.2% complete\n",
      "Epoch: 8 Train batch 30 loss: 0.6802738308906555, 6.3% complete\n",
      "Epoch: 8 Train batch 40 loss: 0.6819642782211304, 8.4% complete\n",
      "Epoch: 8 Train batch 50 loss: 0.6798608899116516, 10.5% complete\n",
      "Epoch: 8 Train batch 60 loss: 0.6864804029464722, 12.6% complete\n",
      "Epoch: 8 Train batch 70 loss: 0.6755167245864868, 14.7% complete\n",
      "Epoch: 8 Train batch 80 loss: 0.6877266764640808, 16.8% complete\n",
      "Epoch: 8 Train batch 90 loss: 0.6727378964424133, 18.9% complete\n",
      "Epoch: 8 Train batch 100 loss: 0.6851560473442078, 21.1% complete\n",
      "Epoch: 8 Train batch 110 loss: 0.6850100755691528, 23.2% complete\n",
      "Epoch: 8 Train batch 120 loss: 0.6836076974868774, 25.3% complete\n",
      "Epoch: 8 Train batch 130 loss: 0.6890972256660461, 27.4% complete\n",
      "Epoch: 8 Train batch 140 loss: 0.6843426823616028, 29.5% complete\n",
      "Epoch: 8 Train batch 150 loss: 0.6820189952850342, 31.6% complete\n",
      "Epoch: 8 Train batch 160 loss: 0.6895987391471863, 33.7% complete\n",
      "Epoch: 8 Train batch 170 loss: 0.6760681867599487, 35.8% complete\n",
      "Epoch: 8 Train batch 180 loss: 0.6919655203819275, 37.9% complete\n",
      "Epoch: 8 Train batch 190 loss: 0.6790207028388977, 40.0% complete\n",
      "Epoch: 8 Train batch 200 loss: 0.6882443428039551, 42.1% complete\n",
      "Epoch: 8 Train batch 210 loss: 0.6835156679153442, 44.2% complete\n",
      "Epoch: 8 Train batch 220 loss: 0.685380220413208, 46.3% complete\n",
      "Epoch: 8 Train batch 230 loss: 0.6877719163894653, 48.4% complete\n",
      "Epoch: 8 Train batch 240 loss: 0.6731662750244141, 50.5% complete\n",
      "Epoch: 8 Train batch 250 loss: 0.6832050681114197, 52.6% complete\n",
      "Epoch: 8 Train batch 260 loss: 0.6794203519821167, 54.7% complete\n",
      "Epoch: 8 Train batch 270 loss: 0.684273362159729, 56.8% complete\n",
      "Epoch: 8 Train batch 280 loss: 0.679015040397644, 58.9% complete\n",
      "Epoch: 8 Train batch 290 loss: 0.6763783097267151, 61.1% complete\n",
      "Epoch: 8 Train batch 300 loss: 0.6818311810493469, 63.2% complete\n",
      "Epoch: 8 Train batch 310 loss: 0.6825761795043945, 65.3% complete\n",
      "Epoch: 8 Train batch 320 loss: 0.6735376715660095, 67.4% complete\n",
      "Epoch: 8 Train batch 330 loss: 0.6795183420181274, 69.5% complete\n",
      "Epoch: 8 Train batch 340 loss: 0.683933675289154, 71.6% complete\n",
      "Epoch: 8 Train batch 350 loss: 0.6884889602661133, 73.7% complete\n",
      "Epoch: 8 Train batch 360 loss: 0.6848525404930115, 75.8% complete\n",
      "Epoch: 8 Train batch 370 loss: 0.6813283562660217, 77.9% complete\n",
      "Epoch: 8 Train batch 380 loss: 0.6810306906700134, 80.0% complete\n",
      "Epoch: 8 Train batch 390 loss: 0.6663526296615601, 82.1% complete\n",
      "Epoch: 8 Train batch 400 loss: 0.6681106686592102, 84.2% complete\n",
      "Epoch: 8 Train batch 410 loss: 0.6850902438163757, 86.3% complete\n",
      "Epoch: 8 Train batch 420 loss: 0.6831164956092834, 88.4% complete\n",
      "Epoch: 8 Train batch 430 loss: 0.6802972555160522, 90.5% complete\n",
      "Epoch: 8 Train batch 440 loss: 0.6857520937919617, 92.6% complete\n",
      "Epoch: 8 Train batch 450 loss: 0.6792442798614502, 94.7% complete\n",
      "Epoch: 8 Train batch 460 loss: 0.6722228527069092, 96.8% complete\n",
      "Epoch: 8 Train batch 470 loss: 0.6869353652000427, 98.9% complete\n",
      "Batch 1. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6785572171211243\n",
      "Batch 2. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6804519891738892\n",
      "Batch 3. Data shape torch.Size([32, 3, 224, 224]) Loss 0.679879903793335\n",
      "Batch 4. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6824098229408264\n",
      "Batch 5. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6965507864952087\n",
      "Batch 6. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6833167672157288\n",
      "Batch 7. Data shape torch.Size([32, 3, 224, 224]) Loss 0.674553394317627\n",
      "Batch 8. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6817362904548645\n",
      "Batch 9. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6822977662086487\n",
      "Batch 10. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6792280077934265\n",
      "Batch 11. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6695157885551453\n",
      "Batch 12. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6795014142990112\n",
      "Batch 13. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6768222451210022\n",
      "Batch 14. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6840083003044128\n",
      "Batch 15. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6723403930664062\n",
      "Batch 16. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6745080947875977\n",
      "Batch 17. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6809026002883911\n",
      "Batch 18. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6837535500526428\n",
      "Batch 19. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6874448657035828\n",
      "Batch 20. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6789724826812744\n",
      "Batch 21. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6780126690864563\n",
      "Batch 22. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6844906210899353\n",
      "Batch 23. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6730777621269226\n",
      "Batch 24. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6969712972640991\n",
      "Batch 25. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6792672276496887\n",
      "Batch 26. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6924229264259338\n",
      "Batch 27. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6797912120819092\n",
      "Batch 28. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6822938919067383\n",
      "Batch 29. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6756592988967896\n",
      "Batch 30. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6756582856178284\n",
      "Batch 31. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6649192571640015\n",
      "Batch 32. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6780141592025757\n",
      "Batch 33. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6761858463287354\n",
      "Batch 34. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6816196441650391\n",
      "Batch 35. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6834632754325867\n",
      "Batch 36. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6747028231620789\n",
      "Batch 37. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6753890514373779\n",
      "Batch 38. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6787764430046082\n",
      "Batch 39. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6843672394752502\n",
      "Batch 40. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6714616417884827\n",
      "Batch 41. Data shape torch.Size([32, 3, 224, 224]) Loss 0.674589991569519\n",
      "Batch 42. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6820982694625854\n",
      "Batch 43. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6817173957824707\n",
      "Batch 44. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6702101826667786\n",
      "Batch 45. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6762033104896545\n",
      "Batch 46. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6849762797355652\n",
      "Batch 47. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6712791919708252\n",
      "Batch 48. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6785333752632141\n",
      "Batch 49. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6774852275848389\n",
      "Batch 50. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6873472929000854\n",
      "Batch 51. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6769076585769653\n",
      "Batch 52. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6764601469039917\n",
      "Batch 53. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6651073098182678\n",
      "Batch 54. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6803037524223328\n",
      "Batch 55. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6814801096916199\n",
      "Batch 56. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6788514852523804\n",
      "Batch 57. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6817779541015625\n",
      "Batch 58. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6860697865486145\n",
      "Batch 59. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6724454760551453\n",
      "Batch 60. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6852824687957764\n",
      "Batch 61. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6773924827575684\n",
      "Batch 62. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6808215975761414\n",
      "Batch 63. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6698533296585083\n",
      "Batch 64. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6819658875465393\n",
      "Batch 65. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6763577461242676\n",
      "Batch 66. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6809030175209045\n",
      "Batch 67. Data shape torch.Size([32, 3, 224, 224]) Loss 0.679377555847168\n",
      "Batch 68. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6807761192321777\n",
      "Batch 69. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6780191659927368\n",
      "Batch 70. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6733527183532715\n",
      "Batch 71. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6866583824157715\n",
      "Batch 72. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6706914305686951\n",
      "Batch 73. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6774103045463562\n",
      "Batch 74. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6823508739471436\n",
      "Batch 75. Data shape torch.Size([32, 3, 224, 224]) Loss 0.677527129650116\n",
      "Batch 76. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6691522598266602\n",
      "Batch 77. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6715070009231567\n",
      "Batch 78. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6751709580421448\n",
      "Batch 79. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6865100264549255\n",
      "Batch 80. Data shape torch.Size([32, 3, 224, 224]) Loss 0.684270977973938\n",
      "Batch 81. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6810627579689026\n",
      "Batch 82. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6718374490737915\n",
      "Batch 83. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6867359280586243\n",
      "Batch 84. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6727617979049683\n",
      "Batch 85. Data shape torch.Size([32, 3, 224, 224]) Loss 0.688591718673706\n",
      "Batch 86. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6869714856147766\n",
      "Batch 87. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6859888434410095\n",
      "Batch 88. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6887958645820618\n",
      "Batch 89. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6757598519325256\n",
      "Batch 90. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6793834567070007\n",
      "Batch 91. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6835604310035706\n",
      "Batch 92. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6758241653442383\n",
      "Batch 93. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6650781035423279\n",
      "Batch 94. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6882469654083252\n",
      "Batch 95. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6806362271308899\n",
      "Batch 96. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6824578046798706\n",
      "Batch 97. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6853266358375549\n",
      "Batch 98. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6628162860870361\n",
      "Batch 99. Data shape torch.Size([32, 3, 224, 224]) Loss 0.670089840888977\n",
      "Batch 100. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6749463677406311\n",
      "Batch 101. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6766414642333984\n",
      "Batch 102. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6711676716804504\n",
      "Batch 103. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6802344918251038\n",
      "Batch 104. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6742661595344543\n",
      "Batch 105. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6704180836677551\n",
      "Batch 106. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6794073581695557\n",
      "Batch 107. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6851662993431091\n",
      "Batch 108. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6916162371635437\n",
      "Batch 109. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6739274263381958\n",
      "Batch 110. Data shape torch.Size([32, 3, 224, 224]) Loss 0.692228376865387\n",
      "Batch 111. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6795990467071533\n",
      "Batch 112. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6771968603134155\n",
      "Batch 113. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6711530089378357\n",
      "Batch 114. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6696729063987732\n",
      "Batch 115. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6954428553581238\n",
      "Batch 116. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6883676648139954\n",
      "Batch 117. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6923293471336365\n",
      "Batch 118. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6896967887878418\n",
      "Batch 119. Data shape torch.Size([20, 3, 224, 224]) Loss 0.6819067001342773\n",
      "Valid loss improved from 0.682122 to 0.679410. Saving model ...\n",
      "Epoch: 08/50 | time: 20.0m 47.2s | lr: 1.0000e-05 | train/loss: 0.68161 | val/loss: 0.67941 | val/accuracy: 0.62724 | val/AUC: 0.63271 | val/Kappa: 0.26249\n",
      "Epoch: 9 Train batch 10 loss: 0.6751269102096558, 2.1% complete\n",
      "Epoch: 9 Train batch 20 loss: 0.6736435890197754, 4.2% complete\n",
      "Epoch: 9 Train batch 30 loss: 0.674477219581604, 6.3% complete\n",
      "Epoch: 9 Train batch 40 loss: 0.6863787770271301, 8.4% complete\n",
      "Epoch: 9 Train batch 50 loss: 0.6903219819068909, 10.5% complete\n",
      "Epoch: 9 Train batch 60 loss: 0.6857843995094299, 12.6% complete\n",
      "Epoch: 9 Train batch 70 loss: 0.687755286693573, 14.7% complete\n",
      "Epoch: 9 Train batch 80 loss: 0.6729478240013123, 16.8% complete\n",
      "Epoch: 9 Train batch 90 loss: 0.6659550666809082, 18.9% complete\n",
      "Epoch: 9 Train batch 100 loss: 0.67694491147995, 21.1% complete\n",
      "Epoch: 9 Train batch 110 loss: 0.6739040613174438, 23.2% complete\n",
      "Epoch: 9 Train batch 120 loss: 0.6826832294464111, 25.3% complete\n",
      "Epoch: 9 Train batch 130 loss: 0.6880268454551697, 27.4% complete\n",
      "Epoch: 9 Train batch 140 loss: 0.6818469166755676, 29.5% complete\n",
      "Epoch: 9 Train batch 150 loss: 0.6683807373046875, 31.6% complete\n",
      "Epoch: 9 Train batch 160 loss: 0.6848551034927368, 33.7% complete\n",
      "Epoch: 9 Train batch 170 loss: 0.6772677898406982, 35.8% complete\n",
      "Epoch: 9 Train batch 180 loss: 0.6780993938446045, 37.9% complete\n",
      "Epoch: 9 Train batch 190 loss: 0.6759993433952332, 40.0% complete\n",
      "Epoch: 9 Train batch 200 loss: 0.6806325316429138, 42.1% complete\n",
      "Epoch: 9 Train batch 210 loss: 0.677465558052063, 44.2% complete\n",
      "Epoch: 9 Train batch 220 loss: 0.6736788749694824, 46.3% complete\n",
      "Epoch: 9 Train batch 230 loss: 0.6836457252502441, 48.4% complete\n",
      "Epoch: 9 Train batch 240 loss: 0.6768007278442383, 50.5% complete\n",
      "Epoch: 9 Train batch 250 loss: 0.6782054901123047, 52.6% complete\n",
      "Epoch: 9 Train batch 260 loss: 0.672504723072052, 54.7% complete\n",
      "Epoch: 9 Train batch 270 loss: 0.6815356612205505, 56.8% complete\n",
      "Epoch: 9 Train batch 280 loss: 0.6786918044090271, 58.9% complete\n",
      "Epoch: 9 Train batch 290 loss: 0.6795109510421753, 61.1% complete\n",
      "Epoch: 9 Train batch 300 loss: 0.6787663102149963, 63.2% complete\n",
      "Epoch: 9 Train batch 310 loss: 0.6823093891143799, 65.3% complete\n",
      "Epoch: 9 Train batch 320 loss: 0.680281400680542, 67.4% complete\n",
      "Epoch: 9 Train batch 330 loss: 0.6776283979415894, 69.5% complete\n",
      "Epoch: 9 Train batch 340 loss: 0.6796627044677734, 71.6% complete\n",
      "Epoch: 9 Train batch 350 loss: 0.6852080225944519, 73.7% complete\n",
      "Epoch: 9 Train batch 360 loss: 0.6842653751373291, 75.8% complete\n",
      "Epoch: 9 Train batch 370 loss: 0.6898423433303833, 77.9% complete\n",
      "Epoch: 9 Train batch 380 loss: 0.674233078956604, 80.0% complete\n",
      "Epoch: 9 Train batch 390 loss: 0.6951132416725159, 82.1% complete\n",
      "Epoch: 9 Train batch 400 loss: 0.6810140609741211, 84.2% complete\n",
      "Epoch: 9 Train batch 410 loss: 0.6844653487205505, 86.3% complete\n",
      "Epoch: 9 Train batch 420 loss: 0.6813384294509888, 88.4% complete\n",
      "Epoch: 9 Train batch 430 loss: 0.6679860353469849, 90.5% complete\n",
      "Epoch: 9 Train batch 440 loss: 0.673427939414978, 92.6% complete\n",
      "Epoch: 9 Train batch 450 loss: 0.6746556758880615, 94.7% complete\n",
      "Epoch: 9 Train batch 460 loss: 0.6879857182502747, 96.8% complete\n",
      "Epoch: 9 Train batch 470 loss: 0.6644763350486755, 98.9% complete\n",
      "Batch 1. Data shape torch.Size([32, 3, 224, 224]) Loss 0.679593026638031\n",
      "Batch 2. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6657058000564575\n",
      "Batch 3. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6742140054702759\n",
      "Batch 4. Data shape torch.Size([32, 3, 224, 224]) Loss 0.672806978225708\n",
      "Batch 5. Data shape torch.Size([32, 3, 224, 224]) Loss 0.677825391292572\n",
      "Batch 6. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6853975057601929\n",
      "Batch 7. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6763176918029785\n",
      "Batch 8. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6871481537818909\n",
      "Batch 9. Data shape torch.Size([32, 3, 224, 224]) Loss 0.665455162525177\n",
      "Batch 10. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6767244338989258\n",
      "Batch 11. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6713728904724121\n",
      "Batch 12. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6746770143508911\n",
      "Batch 13. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6794562935829163\n",
      "Batch 14. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6725700497627258\n",
      "Batch 15. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6766389012336731\n",
      "Batch 16. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6817576885223389\n",
      "Batch 17. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6770515441894531\n",
      "Batch 18. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6727283000946045\n",
      "Batch 19. Data shape torch.Size([32, 3, 224, 224]) Loss 0.667266309261322\n",
      "Batch 20. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6749067306518555\n",
      "Batch 21. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6824818253517151\n",
      "Batch 22. Data shape torch.Size([32, 3, 224, 224]) Loss 0.671973705291748\n",
      "Batch 23. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6894906163215637\n",
      "Batch 24. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6859225034713745\n",
      "Batch 25. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6719964146614075\n",
      "Batch 26. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6900293827056885\n",
      "Batch 27. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6722995042800903\n",
      "Batch 28. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6866746544837952\n",
      "Batch 29. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6747800707817078\n",
      "Batch 30. Data shape torch.Size([32, 3, 224, 224]) Loss 0.676397979259491\n",
      "Batch 31. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6763442158699036\n",
      "Batch 32. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6746699213981628\n",
      "Batch 33. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6712453365325928\n",
      "Batch 34. Data shape torch.Size([32, 3, 224, 224]) Loss 0.682614266872406\n",
      "Batch 35. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6738349199295044\n",
      "Batch 36. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6809211373329163\n",
      "Batch 37. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6761084794998169\n",
      "Batch 38. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6820830702781677\n",
      "Batch 39. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6826966404914856\n",
      "Batch 40. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6808280348777771\n",
      "Batch 41. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6641178727149963\n",
      "Batch 42. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6740758419036865\n",
      "Batch 43. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6714106798171997\n",
      "Batch 44. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6862117648124695\n",
      "Batch 45. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6785417199134827\n",
      "Batch 46. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6656180620193481\n",
      "Batch 47. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6734321713447571\n",
      "Batch 48. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6650892496109009\n",
      "Batch 49. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6818466782569885\n",
      "Batch 50. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6725125312805176\n",
      "Batch 51. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6834326982498169\n",
      "Batch 52. Data shape torch.Size([32, 3, 224, 224]) Loss 0.66038978099823\n",
      "Batch 53. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6821199655532837\n",
      "Batch 54. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6741056442260742\n",
      "Batch 55. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6874008178710938\n",
      "Batch 56. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6739283800125122\n",
      "Batch 57. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6829251646995544\n",
      "Batch 58. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6859908699989319\n",
      "Batch 59. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6844480633735657\n",
      "Batch 60. Data shape torch.Size([32, 3, 224, 224]) Loss 0.677263617515564\n",
      "Batch 61. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6747643947601318\n",
      "Batch 62. Data shape torch.Size([32, 3, 224, 224]) Loss 0.69255530834198\n",
      "Batch 63. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6824929714202881\n",
      "Batch 64. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6831610202789307\n",
      "Batch 65. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6825747489929199\n",
      "Batch 66. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6767844557762146\n",
      "Batch 67. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6797236800193787\n",
      "Batch 68. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6905929446220398\n",
      "Batch 69. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6733782291412354\n",
      "Batch 70. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6739584803581238\n",
      "Batch 71. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6642489433288574\n",
      "Batch 72. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6768819093704224\n",
      "Batch 73. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6811503171920776\n",
      "Batch 74. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6852402687072754\n",
      "Batch 75. Data shape torch.Size([32, 3, 224, 224]) Loss 0.674066960811615\n",
      "Batch 76. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6732761263847351\n",
      "Batch 77. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6731553077697754\n",
      "Batch 78. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6824468970298767\n",
      "Batch 79. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6794889569282532\n",
      "Batch 80. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6809894442558289\n",
      "Batch 81. Data shape torch.Size([32, 3, 224, 224]) Loss 0.69010329246521\n",
      "Batch 82. Data shape torch.Size([32, 3, 224, 224]) Loss 0.673724353313446\n",
      "Batch 83. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6806451678276062\n",
      "Batch 84. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6840487122535706\n",
      "Batch 85. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6784207820892334\n",
      "Batch 86. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6836146712303162\n",
      "Batch 87. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6769851446151733\n",
      "Batch 88. Data shape torch.Size([32, 3, 224, 224]) Loss 0.666191816329956\n",
      "Batch 89. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6947033405303955\n",
      "Batch 90. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6782996654510498\n",
      "Batch 91. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6688833832740784\n",
      "Batch 92. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6779059767723083\n",
      "Batch 93. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6674830913543701\n",
      "Batch 94. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6724273562431335\n",
      "Batch 95. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6730889081954956\n",
      "Batch 96. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6749935746192932\n",
      "Batch 97. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6771293878555298\n",
      "Batch 98. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6758878231048584\n",
      "Batch 99. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6823047995567322\n",
      "Batch 100. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6982975006103516\n",
      "Batch 101. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6716825366020203\n",
      "Batch 102. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6813615560531616\n",
      "Batch 103. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6832544803619385\n",
      "Batch 104. Data shape torch.Size([32, 3, 224, 224]) Loss 0.683109700679779\n",
      "Batch 105. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6700924038887024\n",
      "Batch 106. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6747198700904846\n",
      "Batch 107. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6795641183853149\n",
      "Batch 108. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6759598255157471\n",
      "Batch 109. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6826524138450623\n",
      "Batch 110. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6909869313240051\n",
      "Batch 111. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6850529909133911\n",
      "Batch 112. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6694515347480774\n",
      "Batch 113. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6801694631576538\n",
      "Batch 114. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6692150235176086\n",
      "Batch 115. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6736816763877869\n",
      "Batch 116. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6779025793075562\n",
      "Batch 117. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6694535613059998\n",
      "Batch 118. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6869384050369263\n",
      "Batch 119. Data shape torch.Size([20, 3, 224, 224]) Loss 0.6680060029029846\n",
      "Valid loss improved from 0.679410 to 0.677708. Saving model ...\n",
      "Epoch: 09/50 | time: 20.0m 55.41s | lr: 1.0000e-05 | train/loss: 0.67939 | val/loss: 0.67771 | val/accuracy: 0.64199 | val/AUC: 0.64711 | val/Kappa: 0.29118\n",
      "Epoch: 10 Train batch 10 loss: 0.6785494089126587, 2.1% complete\n",
      "Epoch: 10 Train batch 20 loss: 0.6772468090057373, 4.2% complete\n",
      "Epoch: 10 Train batch 30 loss: 0.6717948913574219, 6.3% complete\n",
      "Epoch: 10 Train batch 40 loss: 0.6765581965446472, 8.4% complete\n",
      "Epoch: 10 Train batch 50 loss: 0.6703882217407227, 10.5% complete\n",
      "Epoch: 10 Train batch 60 loss: 0.6892967224121094, 12.6% complete\n",
      "Epoch: 10 Train batch 70 loss: 0.6908884644508362, 14.7% complete\n",
      "Epoch: 10 Train batch 80 loss: 0.6877284646034241, 16.8% complete\n",
      "Epoch: 10 Train batch 90 loss: 0.6862788796424866, 18.9% complete\n",
      "Epoch: 10 Train batch 100 loss: 0.6774613857269287, 21.1% complete\n",
      "Epoch: 10 Train batch 110 loss: 0.6730783581733704, 23.2% complete\n",
      "Epoch: 10 Train batch 120 loss: 0.6652513146400452, 25.3% complete\n",
      "Epoch: 10 Train batch 130 loss: 0.6865980625152588, 27.4% complete\n",
      "Epoch: 10 Train batch 140 loss: 0.6807214021682739, 29.5% complete\n",
      "Epoch: 10 Train batch 150 loss: 0.6789340972900391, 31.6% complete\n",
      "Epoch: 10 Train batch 160 loss: 0.6710808873176575, 33.7% complete\n",
      "Epoch: 10 Train batch 170 loss: 0.6833009123802185, 35.8% complete\n",
      "Epoch: 10 Train batch 180 loss: 0.6722346544265747, 37.9% complete\n",
      "Epoch: 10 Train batch 190 loss: 0.6838136315345764, 40.0% complete\n",
      "Epoch: 10 Train batch 200 loss: 0.6835234761238098, 42.1% complete\n",
      "Epoch: 10 Train batch 210 loss: 0.6781479120254517, 44.2% complete\n",
      "Epoch: 10 Train batch 220 loss: 0.6769199371337891, 46.3% complete\n",
      "Epoch: 10 Train batch 230 loss: 0.6681727170944214, 48.4% complete\n",
      "Epoch: 10 Train batch 240 loss: 0.6820386648178101, 50.5% complete\n",
      "Epoch: 10 Train batch 250 loss: 0.682060182094574, 52.6% complete\n",
      "Epoch: 10 Train batch 260 loss: 0.6836849451065063, 54.7% complete\n",
      "Epoch: 10 Train batch 270 loss: 0.6793623566627502, 56.8% complete\n",
      "Epoch: 10 Train batch 280 loss: 0.6853936910629272, 58.9% complete\n",
      "Epoch: 10 Train batch 290 loss: 0.6846514344215393, 61.1% complete\n",
      "Epoch: 10 Train batch 300 loss: 0.6767771244049072, 63.2% complete\n",
      "Epoch: 10 Train batch 310 loss: 0.6713917851448059, 65.3% complete\n",
      "Epoch: 10 Train batch 320 loss: 0.6774420142173767, 67.4% complete\n",
      "Epoch: 10 Train batch 330 loss: 0.6740725040435791, 69.5% complete\n",
      "Epoch: 10 Train batch 340 loss: 0.6780349016189575, 71.6% complete\n",
      "Epoch: 10 Train batch 350 loss: 0.675304114818573, 73.7% complete\n",
      "Epoch: 10 Train batch 360 loss: 0.6846773624420166, 75.8% complete\n",
      "Epoch: 10 Train batch 370 loss: 0.6676821708679199, 77.9% complete\n",
      "Epoch: 10 Train batch 380 loss: 0.6746624112129211, 80.0% complete\n",
      "Epoch: 10 Train batch 390 loss: 0.6776304841041565, 82.1% complete\n",
      "Epoch: 10 Train batch 400 loss: 0.6812106966972351, 84.2% complete\n",
      "Epoch: 10 Train batch 410 loss: 0.6824842691421509, 86.3% complete\n",
      "Epoch: 10 Train batch 420 loss: 0.6802113652229309, 88.4% complete\n",
      "Epoch: 10 Train batch 430 loss: 0.6729943752288818, 90.5% complete\n",
      "Epoch: 10 Train batch 440 loss: 0.6626370549201965, 92.6% complete\n",
      "Epoch: 10 Train batch 450 loss: 0.6809093356132507, 94.7% complete\n",
      "Epoch: 10 Train batch 460 loss: 0.6673612594604492, 96.8% complete\n",
      "Epoch: 10 Train batch 470 loss: 0.676565408706665, 98.9% complete\n",
      "Batch 1. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6600042581558228\n",
      "Batch 2. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6734922528266907\n",
      "Batch 3. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6716962456703186\n",
      "Batch 4. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6708981990814209\n",
      "Batch 5. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6565026640892029\n",
      "Batch 6. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6789520978927612\n",
      "Batch 7. Data shape torch.Size([32, 3, 224, 224]) Loss 0.66581130027771\n",
      "Batch 8. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6771906018257141\n",
      "Batch 9. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6764905452728271\n",
      "Batch 10. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6714979410171509\n",
      "Batch 11. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6779710054397583\n",
      "Batch 12. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6649628281593323\n",
      "Batch 13. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6838547587394714\n",
      "Batch 14. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6746562719345093\n",
      "Batch 15. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6717329025268555\n",
      "Batch 16. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6708300709724426\n",
      "Batch 17. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6671468019485474\n",
      "Batch 18. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6861497759819031\n",
      "Batch 19. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6874978542327881\n",
      "Batch 20. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6617789268493652\n",
      "Batch 21. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6735384464263916\n",
      "Batch 22. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6720589995384216\n",
      "Batch 23. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6680619716644287\n",
      "Batch 24. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6911417841911316\n",
      "Batch 25. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6863992214202881\n",
      "Batch 26. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6726270914077759\n",
      "Batch 27. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6861814856529236\n",
      "Batch 28. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6748580932617188\n",
      "Batch 29. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6762155294418335\n",
      "Batch 30. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6765799522399902\n",
      "Batch 31. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6764456033706665\n",
      "Batch 32. Data shape torch.Size([32, 3, 224, 224]) Loss 0.680370569229126\n",
      "Batch 33. Data shape torch.Size([32, 3, 224, 224]) Loss 0.675421953201294\n",
      "Batch 34. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6698926687240601\n",
      "Batch 35. Data shape torch.Size([32, 3, 224, 224]) Loss 0.686924397945404\n",
      "Batch 36. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6670271158218384\n",
      "Batch 37. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6732567548751831\n",
      "Batch 38. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6704694628715515\n",
      "Batch 39. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6712522506713867\n",
      "Batch 40. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6752089858055115\n",
      "Batch 41. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6697606444358826\n",
      "Batch 42. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6584720015525818\n",
      "Batch 43. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6725374460220337\n",
      "Batch 44. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6827269792556763\n",
      "Batch 45. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6808651089668274\n",
      "Batch 46. Data shape torch.Size([32, 3, 224, 224]) Loss 0.671875536441803\n",
      "Batch 47. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6874861717224121\n",
      "Batch 48. Data shape torch.Size([32, 3, 224, 224]) Loss 0.677800178527832\n",
      "Batch 49. Data shape torch.Size([32, 3, 224, 224]) Loss 0.688602864742279\n",
      "Batch 50. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6757501363754272\n",
      "Batch 51. Data shape torch.Size([32, 3, 224, 224]) Loss 0.67740398645401\n",
      "Batch 52. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6804369688034058\n",
      "Batch 53. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6885693073272705\n",
      "Batch 54. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6650317311286926\n",
      "Batch 55. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6821235418319702\n",
      "Batch 56. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6762384176254272\n",
      "Batch 57. Data shape torch.Size([32, 3, 224, 224]) Loss 0.676469087600708\n",
      "Batch 58. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6848251223564148\n",
      "Batch 59. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6853200197219849\n",
      "Batch 60. Data shape torch.Size([32, 3, 224, 224]) Loss 0.668833315372467\n",
      "Batch 61. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6936486959457397\n",
      "Batch 62. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6816560626029968\n",
      "Batch 63. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6798900961875916\n",
      "Batch 64. Data shape torch.Size([32, 3, 224, 224]) Loss 0.658469021320343\n",
      "Batch 65. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6726611852645874\n",
      "Batch 66. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6871326565742493\n",
      "Batch 67. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6819031238555908\n",
      "Batch 68. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6727015376091003\n",
      "Batch 69. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6772939562797546\n",
      "Batch 70. Data shape torch.Size([32, 3, 224, 224]) Loss 0.664197564125061\n",
      "Batch 71. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6632021069526672\n",
      "Batch 72. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6854280233383179\n",
      "Batch 73. Data shape torch.Size([32, 3, 224, 224]) Loss 0.681740403175354\n",
      "Batch 74. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6946194767951965\n",
      "Batch 75. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6737728118896484\n",
      "Batch 76. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6828383207321167\n",
      "Batch 77. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6650741100311279\n",
      "Batch 78. Data shape torch.Size([32, 3, 224, 224]) Loss 0.664767861366272\n",
      "Batch 79. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6797019839286804\n",
      "Batch 80. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6581200361251831\n",
      "Batch 81. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6849467754364014\n",
      "Batch 82. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6785588264465332\n",
      "Batch 83. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6869692802429199\n",
      "Batch 84. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6650784611701965\n",
      "Batch 85. Data shape torch.Size([32, 3, 224, 224]) Loss 0.681224524974823\n",
      "Batch 86. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6887952089309692\n",
      "Batch 87. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6761205792427063\n",
      "Batch 88. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6781368851661682\n",
      "Batch 89. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6641965508460999\n",
      "Batch 90. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6658775806427002\n",
      "Batch 91. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6767533421516418\n",
      "Batch 92. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6639795899391174\n",
      "Batch 93. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6805606484413147\n",
      "Batch 94. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6706509590148926\n",
      "Batch 95. Data shape torch.Size([32, 3, 224, 224]) Loss 0.674603283405304\n",
      "Batch 96. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6714698076248169\n",
      "Batch 97. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6576073169708252\n",
      "Batch 98. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6673019528388977\n",
      "Batch 99. Data shape torch.Size([32, 3, 224, 224]) Loss 0.669174313545227\n",
      "Batch 100. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6762683391571045\n",
      "Batch 101. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6752573251724243\n",
      "Batch 102. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6731861233711243\n",
      "Batch 103. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6767158508300781\n",
      "Batch 104. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6799051761627197\n",
      "Batch 105. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6770968437194824\n",
      "Batch 106. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6770353317260742\n",
      "Batch 107. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6732115745544434\n",
      "Batch 108. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6908882260322571\n",
      "Batch 109. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6777653694152832\n",
      "Batch 110. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6783801913261414\n",
      "Batch 111. Data shape torch.Size([32, 3, 224, 224]) Loss 0.680018424987793\n",
      "Batch 112. Data shape torch.Size([32, 3, 224, 224]) Loss 0.664320707321167\n",
      "Batch 113. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6654784083366394\n",
      "Batch 114. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6760181188583374\n",
      "Batch 115. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6823840737342834\n",
      "Batch 116. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6800156831741333\n",
      "Batch 117. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6924616098403931\n",
      "Batch 118. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6846176981925964\n",
      "Batch 119. Data shape torch.Size([20, 3, 224, 224]) Loss 0.6918030977249146\n",
      "Valid loss improved from 0.677708 to 0.675780. Saving model ...\n",
      "Epoch: 10/50 | time: 20.0m 58.91s | lr: 1.0000e-05 | train/loss: 0.67765 | val/loss: 0.67578 | val/accuracy: 0.66544 | val/AUC: 0.67006 | val/Kappa: 0.33694\n",
      "Epoch: 11 Train batch 10 loss: 0.6776281595230103, 2.1% complete\n",
      "Epoch: 11 Train batch 20 loss: 0.6812804937362671, 4.2% complete\n",
      "Epoch: 11 Train batch 30 loss: 0.681648313999176, 6.3% complete\n",
      "Epoch: 11 Train batch 40 loss: 0.6894426345825195, 8.4% complete\n",
      "Epoch: 11 Train batch 50 loss: 0.6767638325691223, 10.5% complete\n",
      "Epoch: 11 Train batch 60 loss: 0.6694736480712891, 12.6% complete\n",
      "Epoch: 11 Train batch 70 loss: 0.6843190789222717, 14.7% complete\n",
      "Epoch: 11 Train batch 80 loss: 0.6780579090118408, 16.8% complete\n",
      "Epoch: 11 Train batch 90 loss: 0.6823049187660217, 18.9% complete\n",
      "Epoch: 11 Train batch 100 loss: 0.669991672039032, 21.1% complete\n",
      "Epoch: 11 Train batch 110 loss: 0.6788398027420044, 23.2% complete\n",
      "Epoch: 11 Train batch 120 loss: 0.6888967156410217, 25.3% complete\n",
      "Epoch: 11 Train batch 130 loss: 0.6685497760772705, 27.4% complete\n",
      "Epoch: 11 Train batch 140 loss: 0.6686244010925293, 29.5% complete\n",
      "Epoch: 11 Train batch 150 loss: 0.6808584928512573, 31.6% complete\n",
      "Epoch: 11 Train batch 160 loss: 0.6963285803794861, 33.7% complete\n",
      "Epoch: 11 Train batch 170 loss: 0.6677869558334351, 35.8% complete\n",
      "Epoch: 11 Train batch 180 loss: 0.6800915002822876, 37.9% complete\n",
      "Epoch: 11 Train batch 190 loss: 0.6666963696479797, 40.0% complete\n",
      "Epoch: 11 Train batch 200 loss: 0.6760477423667908, 42.1% complete\n",
      "Epoch: 11 Train batch 210 loss: 0.6691482663154602, 44.2% complete\n",
      "Epoch: 11 Train batch 220 loss: 0.6741508841514587, 46.3% complete\n",
      "Epoch: 11 Train batch 230 loss: 0.6823883056640625, 48.4% complete\n",
      "Epoch: 11 Train batch 240 loss: 0.6626645922660828, 50.5% complete\n",
      "Epoch: 11 Train batch 250 loss: 0.6829402446746826, 52.6% complete\n",
      "Epoch: 11 Train batch 260 loss: 0.6721946001052856, 54.7% complete\n",
      "Epoch: 11 Train batch 270 loss: 0.6697163581848145, 56.8% complete\n",
      "Epoch: 11 Train batch 280 loss: 0.6878358125686646, 58.9% complete\n",
      "Epoch: 11 Train batch 290 loss: 0.6805136799812317, 61.1% complete\n",
      "Epoch: 11 Train batch 300 loss: 0.6640201210975647, 63.2% complete\n",
      "Epoch: 11 Train batch 310 loss: 0.6804357171058655, 65.3% complete\n",
      "Epoch: 11 Train batch 320 loss: 0.6797181963920593, 67.4% complete\n",
      "Epoch: 11 Train batch 330 loss: 0.6629549860954285, 69.5% complete\n",
      "Epoch: 11 Train batch 340 loss: 0.6712761521339417, 71.6% complete\n",
      "Epoch: 11 Train batch 350 loss: 0.6693469882011414, 73.7% complete\n",
      "Epoch: 11 Train batch 360 loss: 0.6765137910842896, 75.8% complete\n",
      "Epoch: 11 Train batch 370 loss: 0.6809333562850952, 77.9% complete\n",
      "Epoch: 11 Train batch 380 loss: 0.6741625666618347, 80.0% complete\n",
      "Epoch: 11 Train batch 390 loss: 0.6802405118942261, 82.1% complete\n",
      "Epoch: 11 Train batch 400 loss: 0.6743175983428955, 84.2% complete\n",
      "Epoch: 11 Train batch 410 loss: 0.6618417501449585, 86.3% complete\n",
      "Epoch: 11 Train batch 420 loss: 0.694340169429779, 88.4% complete\n",
      "Epoch: 11 Train batch 430 loss: 0.6744076013565063, 90.5% complete\n",
      "Epoch: 11 Train batch 440 loss: 0.6791892051696777, 92.6% complete\n",
      "Epoch: 11 Train batch 450 loss: 0.6773326396942139, 94.7% complete\n",
      "Epoch: 11 Train batch 460 loss: 0.678953230381012, 96.8% complete\n",
      "Epoch: 11 Train batch 470 loss: 0.656808614730835, 98.9% complete\n",
      "Batch 1. Data shape torch.Size([32, 3, 224, 224]) Loss 0.672707736492157\n",
      "Batch 2. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6889382600784302\n",
      "Batch 3. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6693833470344543\n",
      "Batch 4. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6813259124755859\n",
      "Batch 5. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6863977909088135\n",
      "Batch 6. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6632854342460632\n",
      "Batch 7. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6851987242698669\n",
      "Batch 8. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6649541854858398\n",
      "Batch 9. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6790550351142883\n",
      "Batch 10. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6670348048210144\n",
      "Batch 11. Data shape torch.Size([32, 3, 224, 224]) Loss 0.668627917766571\n",
      "Batch 12. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6815323233604431\n",
      "Batch 13. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6711775064468384\n",
      "Batch 14. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6684931516647339\n",
      "Batch 15. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6724196076393127\n",
      "Batch 16. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6727666258811951\n",
      "Batch 17. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6808844208717346\n",
      "Batch 18. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6785065531730652\n",
      "Batch 19. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6794889569282532\n",
      "Batch 20. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6762973070144653\n",
      "Batch 21. Data shape torch.Size([32, 3, 224, 224]) Loss 0.669486939907074\n",
      "Batch 22. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6722632646560669\n",
      "Batch 23. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6718387007713318\n",
      "Batch 24. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6741284132003784\n",
      "Batch 25. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6853973865509033\n",
      "Batch 26. Data shape torch.Size([32, 3, 224, 224]) Loss 0.665634036064148\n",
      "Batch 27. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6690938472747803\n",
      "Batch 28. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6757025718688965\n",
      "Batch 29. Data shape torch.Size([32, 3, 224, 224]) Loss 0.664986789226532\n",
      "Batch 30. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6690225601196289\n",
      "Batch 31. Data shape torch.Size([32, 3, 224, 224]) Loss 0.666107177734375\n",
      "Batch 32. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6601026058197021\n",
      "Batch 33. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6661944389343262\n",
      "Batch 34. Data shape torch.Size([32, 3, 224, 224]) Loss 0.675410807132721\n",
      "Batch 35. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6693419218063354\n",
      "Batch 36. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6737523078918457\n",
      "Batch 37. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6715295314788818\n",
      "Batch 38. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6770268082618713\n",
      "Batch 39. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6645904779434204\n",
      "Batch 40. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6560194492340088\n",
      "Batch 41. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6783581972122192\n",
      "Batch 42. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6735369563102722\n",
      "Batch 43. Data shape torch.Size([32, 3, 224, 224]) Loss 0.667504608631134\n",
      "Batch 44. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6597317457199097\n",
      "Batch 45. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6763989925384521\n",
      "Batch 46. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6624906659126282\n",
      "Batch 47. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6819568276405334\n",
      "Batch 48. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6809185743331909\n",
      "Batch 49. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6543079614639282\n",
      "Batch 50. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6878190636634827\n",
      "Batch 51. Data shape torch.Size([32, 3, 224, 224]) Loss 0.676837682723999\n",
      "Batch 52. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6681089997291565\n",
      "Batch 53. Data shape torch.Size([32, 3, 224, 224]) Loss 0.671826183795929\n",
      "Batch 54. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6678155064582825\n",
      "Batch 55. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6782738566398621\n",
      "Batch 56. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6819499135017395\n",
      "Batch 57. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6719419956207275\n",
      "Batch 58. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6676722764968872\n",
      "Batch 59. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6762878894805908\n",
      "Batch 60. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6554161310195923\n",
      "Batch 61. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6637492179870605\n",
      "Batch 62. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6738102436065674\n",
      "Batch 63. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6626144051551819\n",
      "Batch 64. Data shape torch.Size([32, 3, 224, 224]) Loss 0.695213794708252\n",
      "Batch 65. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6607372164726257\n",
      "Batch 66. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6757752895355225\n",
      "Batch 67. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6638385057449341\n",
      "Batch 68. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6712473630905151\n",
      "Batch 69. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6768422722816467\n",
      "Batch 70. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6722205877304077\n",
      "Batch 71. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6669932007789612\n",
      "Batch 72. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6672513484954834\n",
      "Batch 73. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6662411093711853\n",
      "Batch 74. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6634273529052734\n",
      "Batch 75. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6548651456832886\n",
      "Batch 76. Data shape torch.Size([32, 3, 224, 224]) Loss 0.681827187538147\n",
      "Batch 77. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6775652766227722\n",
      "Batch 78. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6737185120582581\n",
      "Batch 79. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6814318299293518\n",
      "Batch 80. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6596933007240295\n",
      "Batch 81. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6783906817436218\n",
      "Batch 82. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6742035746574402\n",
      "Batch 83. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6702407598495483\n",
      "Batch 84. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6753451228141785\n",
      "Batch 85. Data shape torch.Size([32, 3, 224, 224]) Loss 0.664126455783844\n",
      "Batch 86. Data shape torch.Size([32, 3, 224, 224]) Loss 0.671681821346283\n",
      "Batch 87. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6667318940162659\n",
      "Batch 88. Data shape torch.Size([32, 3, 224, 224]) Loss 0.682371199131012\n",
      "Batch 89. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6650652289390564\n",
      "Batch 90. Data shape torch.Size([32, 3, 224, 224]) Loss 0.678187370300293\n",
      "Batch 91. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6547936797142029\n",
      "Batch 92. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6836063265800476\n",
      "Batch 93. Data shape torch.Size([32, 3, 224, 224]) Loss 0.667872965335846\n",
      "Batch 94. Data shape torch.Size([32, 3, 224, 224]) Loss 0.663269579410553\n",
      "Batch 95. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6752905249595642\n",
      "Batch 96. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6745675206184387\n",
      "Batch 97. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6720389127731323\n",
      "Batch 98. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6843770146369934\n",
      "Batch 99. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6857923269271851\n",
      "Batch 100. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6685569882392883\n",
      "Batch 101. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6803173422813416\n",
      "Batch 102. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6698414087295532\n",
      "Batch 103. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6726552248001099\n",
      "Batch 104. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6782978773117065\n",
      "Batch 105. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6760424971580505\n",
      "Batch 106. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6819739937782288\n",
      "Batch 107. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6657164692878723\n",
      "Batch 108. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6698967814445496\n",
      "Batch 109. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6635229587554932\n",
      "Batch 110. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6646742224693298\n",
      "Batch 111. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6681039929389954\n",
      "Batch 112. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6638655662536621\n",
      "Batch 113. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6815167665481567\n",
      "Batch 114. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6836684346199036\n",
      "Batch 115. Data shape torch.Size([32, 3, 224, 224]) Loss 0.676108717918396\n",
      "Batch 116. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6773842573165894\n",
      "Batch 117. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6721180081367493\n",
      "Batch 118. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6670207977294922\n",
      "Batch 119. Data shape torch.Size([20, 3, 224, 224]) Loss 0.6928101181983948\n",
      "Valid loss improved from 0.675780 to 0.672406. Saving model ...\n",
      "Epoch: 11/50 | time: 20.0m 54.42s | lr: 1.0000e-05 | train/loss: 0.67543 | val/loss: 0.67241 | val/accuracy: 0.66834 | val/AUC: 0.67287 | val/Kappa: 0.34256\n",
      "Epoch: 12 Train batch 10 loss: 0.6718349456787109, 2.1% complete\n",
      "Epoch: 12 Train batch 20 loss: 0.6720224022865295, 4.2% complete\n",
      "Epoch: 12 Train batch 30 loss: 0.667937695980072, 6.3% complete\n",
      "Epoch: 12 Train batch 40 loss: 0.6827945709228516, 8.4% complete\n",
      "Epoch: 12 Train batch 50 loss: 0.6711779236793518, 10.5% complete\n",
      "Epoch: 12 Train batch 60 loss: 0.6833466291427612, 12.6% complete\n",
      "Epoch: 12 Train batch 70 loss: 0.6680253148078918, 14.7% complete\n",
      "Epoch: 12 Train batch 80 loss: 0.672709047794342, 16.8% complete\n",
      "Epoch: 12 Train batch 90 loss: 0.6633058190345764, 18.9% complete\n",
      "Epoch: 12 Train batch 100 loss: 0.6844958066940308, 21.1% complete\n",
      "Epoch: 12 Train batch 110 loss: 0.684218168258667, 23.2% complete\n",
      "Epoch: 12 Train batch 120 loss: 0.6774092316627502, 25.3% complete\n",
      "Epoch: 12 Train batch 130 loss: 0.6745261549949646, 27.4% complete\n",
      "Epoch: 12 Train batch 140 loss: 0.6681113243103027, 29.5% complete\n",
      "Epoch: 12 Train batch 150 loss: 0.6754634976387024, 31.6% complete\n",
      "Epoch: 12 Train batch 160 loss: 0.6708731651306152, 33.7% complete\n",
      "Epoch: 12 Train batch 170 loss: 0.6737474799156189, 35.8% complete\n",
      "Epoch: 12 Train batch 180 loss: 0.6803199052810669, 37.9% complete\n",
      "Epoch: 12 Train batch 190 loss: 0.6628389358520508, 40.0% complete\n",
      "Epoch: 12 Train batch 200 loss: 0.6585390567779541, 42.1% complete\n",
      "Epoch: 12 Train batch 210 loss: 0.664417564868927, 44.2% complete\n",
      "Epoch: 12 Train batch 220 loss: 0.6848034262657166, 46.3% complete\n",
      "Epoch: 12 Train batch 230 loss: 0.6896528601646423, 48.4% complete\n",
      "Epoch: 12 Train batch 240 loss: 0.6687331199645996, 50.5% complete\n",
      "Epoch: 12 Train batch 250 loss: 0.6615200638771057, 52.6% complete\n",
      "Epoch: 12 Train batch 260 loss: 0.6738962531089783, 54.7% complete\n",
      "Epoch: 12 Train batch 270 loss: 0.6847849488258362, 56.8% complete\n",
      "Epoch: 12 Train batch 280 loss: 0.6811457872390747, 58.9% complete\n",
      "Epoch: 12 Train batch 290 loss: 0.6626648902893066, 61.1% complete\n",
      "Epoch: 12 Train batch 300 loss: 0.6674731373786926, 63.2% complete\n",
      "Epoch: 12 Train batch 310 loss: 0.6684725880622864, 65.3% complete\n",
      "Epoch: 12 Train batch 320 loss: 0.6666731238365173, 67.4% complete\n",
      "Epoch: 12 Train batch 330 loss: 0.6690493226051331, 69.5% complete\n",
      "Epoch: 12 Train batch 340 loss: 0.6879706978797913, 71.6% complete\n",
      "Epoch: 12 Train batch 350 loss: 0.6651259064674377, 73.7% complete\n",
      "Epoch: 12 Train batch 360 loss: 0.6629722714424133, 75.8% complete\n",
      "Epoch: 12 Train batch 370 loss: 0.6708130240440369, 77.9% complete\n",
      "Epoch: 12 Train batch 380 loss: 0.6627820134162903, 80.0% complete\n",
      "Epoch: 12 Train batch 390 loss: 0.6697069406509399, 82.1% complete\n",
      "Epoch: 12 Train batch 400 loss: 0.6732470989227295, 84.2% complete\n",
      "Epoch: 12 Train batch 410 loss: 0.6620010137557983, 86.3% complete\n",
      "Epoch: 12 Train batch 420 loss: 0.6762583255767822, 88.4% complete\n",
      "Epoch: 12 Train batch 430 loss: 0.6758755445480347, 90.5% complete\n",
      "Epoch: 12 Train batch 440 loss: 0.6729774475097656, 92.6% complete\n",
      "Epoch: 12 Train batch 450 loss: 0.6809714436531067, 94.7% complete\n",
      "Epoch: 12 Train batch 460 loss: 0.7075254917144775, 96.8% complete\n",
      "Epoch: 12 Train batch 470 loss: 0.6812247037887573, 98.9% complete\n",
      "Batch 1. Data shape torch.Size([32, 3, 224, 224]) Loss 0.677998423576355\n",
      "Batch 2. Data shape torch.Size([32, 3, 224, 224]) Loss 0.670388400554657\n",
      "Batch 3. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6654600501060486\n",
      "Batch 4. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6766085028648376\n",
      "Batch 5. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6659200191497803\n",
      "Batch 6. Data shape torch.Size([32, 3, 224, 224]) Loss 0.675674319267273\n",
      "Batch 7. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6699800491333008\n",
      "Batch 8. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6762862205505371\n",
      "Batch 9. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6636255383491516\n",
      "Batch 10. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6806332468986511\n",
      "Batch 11. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6749572157859802\n",
      "Batch 12. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6710663437843323\n",
      "Batch 13. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6707322001457214\n",
      "Batch 14. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6747899055480957\n",
      "Batch 15. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6625373363494873\n",
      "Batch 16. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6879051327705383\n",
      "Batch 17. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6803500652313232\n",
      "Batch 18. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6788262128829956\n",
      "Batch 19. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6736131906509399\n",
      "Batch 20. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6625534892082214\n",
      "Batch 21. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6668499708175659\n",
      "Batch 22. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6685088276863098\n",
      "Batch 23. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6736380457878113\n",
      "Batch 24. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6805232167243958\n",
      "Batch 25. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6691851615905762\n",
      "Batch 26. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6726722121238708\n",
      "Batch 27. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6657044291496277\n",
      "Batch 28. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6582263708114624\n",
      "Batch 29. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6715468764305115\n",
      "Batch 30. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6733612418174744\n",
      "Batch 31. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6622094511985779\n",
      "Batch 32. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6688740253448486\n",
      "Batch 33. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6706547737121582\n",
      "Batch 34. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6724156141281128\n",
      "Batch 35. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6706609725952148\n",
      "Batch 36. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6700364351272583\n",
      "Batch 37. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6764279007911682\n",
      "Batch 38. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6802167296409607\n",
      "Batch 39. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6774507761001587\n",
      "Batch 40. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6717721223831177\n",
      "Batch 41. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6744499802589417\n",
      "Batch 42. Data shape torch.Size([32, 3, 224, 224]) Loss 0.672798752784729\n",
      "Batch 43. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6696896553039551\n",
      "Batch 44. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6801309585571289\n",
      "Batch 45. Data shape torch.Size([32, 3, 224, 224]) Loss 0.670017659664154\n",
      "Batch 46. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6680331826210022\n",
      "Batch 47. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6726950407028198\n",
      "Batch 48. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6601254343986511\n",
      "Batch 49. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6576436758041382\n",
      "Batch 50. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6747488975524902\n",
      "Batch 51. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6782082319259644\n",
      "Batch 52. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6720801591873169\n",
      "Batch 53. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6524178385734558\n",
      "Batch 54. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6631219387054443\n",
      "Batch 55. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6734212636947632\n",
      "Batch 56. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6702566146850586\n",
      "Batch 57. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6690487265586853\n",
      "Batch 58. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6747958064079285\n",
      "Batch 59. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6725553870201111\n",
      "Batch 60. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6695684194564819\n",
      "Batch 61. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6647934317588806\n",
      "Batch 62. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6846770644187927\n",
      "Batch 63. Data shape torch.Size([32, 3, 224, 224]) Loss 0.678837776184082\n",
      "Batch 64. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6788895130157471\n",
      "Batch 65. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6692988276481628\n",
      "Batch 66. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6596949696540833\n",
      "Batch 67. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6780073046684265\n",
      "Batch 68. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6637831330299377\n",
      "Batch 69. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6791499257087708\n",
      "Batch 70. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6583351492881775\n",
      "Batch 71. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6593252420425415\n",
      "Batch 72. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6769576072692871\n",
      "Batch 73. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6724969744682312\n",
      "Batch 74. Data shape torch.Size([32, 3, 224, 224]) Loss 0.7009391188621521\n",
      "Batch 75. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6845107674598694\n",
      "Batch 76. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6842475533485413\n",
      "Batch 77. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6784570813179016\n",
      "Batch 78. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6679993867874146\n",
      "Batch 79. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6811563968658447\n",
      "Batch 80. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6620186567306519\n",
      "Batch 81. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6760244965553284\n",
      "Batch 82. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6760392785072327\n",
      "Batch 83. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6604421138763428\n",
      "Batch 84. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6770317554473877\n",
      "Batch 85. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6642979383468628\n",
      "Batch 86. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6733204126358032\n",
      "Batch 87. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6615053415298462\n",
      "Batch 88. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6640658378601074\n",
      "Batch 89. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6788773536682129\n",
      "Batch 90. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6770711541175842\n",
      "Batch 91. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6559366583824158\n",
      "Batch 92. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6589117050170898\n",
      "Batch 93. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6689254641532898\n",
      "Batch 94. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6774641871452332\n",
      "Batch 95. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6557218432426453\n",
      "Batch 96. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6598778963088989\n",
      "Batch 97. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6670740842819214\n",
      "Batch 98. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6745679378509521\n",
      "Batch 99. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6660900712013245\n",
      "Batch 100. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6656086444854736\n",
      "Batch 101. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6562014818191528\n",
      "Batch 102. Data shape torch.Size([32, 3, 224, 224]) Loss 0.679329514503479\n",
      "Batch 103. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6708257794380188\n",
      "Batch 104. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6581545472145081\n",
      "Batch 105. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6772488951683044\n",
      "Batch 106. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6774842739105225\n",
      "Batch 107. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6563506722450256\n",
      "Batch 108. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6611617803573608\n",
      "Batch 109. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6744739413261414\n",
      "Batch 110. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6739672422409058\n",
      "Batch 111. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6840225458145142\n",
      "Batch 112. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6848055124282837\n",
      "Batch 113. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6739125847816467\n",
      "Batch 114. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6751412153244019\n",
      "Batch 115. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6611849665641785\n",
      "Batch 116. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6552863121032715\n",
      "Batch 117. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6687679290771484\n",
      "Batch 118. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6793193221092224\n",
      "Batch 119. Data shape torch.Size([20, 3, 224, 224]) Loss 0.6603690981864929\n",
      "Valid loss improved from 0.672406 to 0.670984. Saving model ...\n",
      "Epoch: 12/50 | time: 21.0m 3.381s | lr: 1.0000e-05 | train/loss: 0.67321 | val/loss: 0.67098 | val/accuracy: 0.69415 | val/AUC: 0.69777 | val/Kappa: 0.39262\n",
      "Epoch: 13 Train batch 10 loss: 0.6615668535232544, 2.1% complete\n",
      "Epoch: 13 Train batch 20 loss: 0.6754302978515625, 4.2% complete\n",
      "Epoch: 13 Train batch 30 loss: 0.6668461561203003, 6.3% complete\n",
      "Epoch: 13 Train batch 40 loss: 0.6764400005340576, 8.4% complete\n",
      "Epoch: 13 Train batch 50 loss: 0.6809967160224915, 10.5% complete\n",
      "Epoch: 13 Train batch 60 loss: 0.6810833215713501, 12.6% complete\n",
      "Epoch: 13 Train batch 70 loss: 0.6608510613441467, 14.7% complete\n",
      "Epoch: 13 Train batch 80 loss: 0.6656022071838379, 16.8% complete\n",
      "Epoch: 13 Train batch 90 loss: 0.6714102029800415, 18.9% complete\n",
      "Epoch: 13 Train batch 100 loss: 0.6667487621307373, 21.1% complete\n",
      "Epoch: 13 Train batch 110 loss: 0.6632247567176819, 23.2% complete\n",
      "Epoch: 13 Train batch 120 loss: 0.6717545390129089, 25.3% complete\n",
      "Epoch: 13 Train batch 130 loss: 0.6734063029289246, 27.4% complete\n",
      "Epoch: 13 Train batch 140 loss: 0.6747096180915833, 29.5% complete\n",
      "Epoch: 13 Train batch 150 loss: 0.6533153057098389, 31.6% complete\n",
      "Epoch: 13 Train batch 160 loss: 0.679809033870697, 33.7% complete\n",
      "Epoch: 13 Train batch 170 loss: 0.6782960295677185, 35.8% complete\n",
      "Epoch: 13 Train batch 180 loss: 0.6688592433929443, 37.9% complete\n",
      "Epoch: 13 Train batch 190 loss: 0.6746281385421753, 40.0% complete\n",
      "Epoch: 13 Train batch 200 loss: 0.6678861975669861, 42.1% complete\n",
      "Epoch: 13 Train batch 210 loss: 0.6634156107902527, 44.2% complete\n",
      "Epoch: 13 Train batch 220 loss: 0.6538788080215454, 46.3% complete\n",
      "Epoch: 13 Train batch 230 loss: 0.6879552006721497, 48.4% complete\n",
      "Epoch: 13 Train batch 240 loss: 0.6642775535583496, 50.5% complete\n",
      "Epoch: 13 Train batch 250 loss: 0.6722313165664673, 52.6% complete\n",
      "Epoch: 13 Train batch 260 loss: 0.6634896993637085, 54.7% complete\n",
      "Epoch: 13 Train batch 270 loss: 0.6756191253662109, 56.8% complete\n",
      "Epoch: 13 Train batch 280 loss: 0.659132719039917, 58.9% complete\n",
      "Epoch: 13 Train batch 290 loss: 0.6578878164291382, 61.1% complete\n",
      "Epoch: 13 Train batch 300 loss: 0.6562345027923584, 63.2% complete\n",
      "Epoch: 13 Train batch 310 loss: 0.6728273630142212, 65.3% complete\n",
      "Epoch: 13 Train batch 320 loss: 0.670616626739502, 67.4% complete\n",
      "Epoch: 13 Train batch 330 loss: 0.6764186024665833, 69.5% complete\n",
      "Epoch: 13 Train batch 340 loss: 0.6674503087997437, 71.6% complete\n",
      "Epoch: 13 Train batch 350 loss: 0.6605263948440552, 73.7% complete\n",
      "Epoch: 13 Train batch 360 loss: 0.6840783953666687, 75.8% complete\n",
      "Epoch: 13 Train batch 370 loss: 0.6606945395469666, 77.9% complete\n",
      "Epoch: 13 Train batch 380 loss: 0.6733336448669434, 80.0% complete\n",
      "Epoch: 13 Train batch 390 loss: 0.6694666147232056, 82.1% complete\n",
      "Epoch: 13 Train batch 400 loss: 0.6628584265708923, 84.2% complete\n",
      "Epoch: 13 Train batch 410 loss: 0.6750122308731079, 86.3% complete\n",
      "Epoch: 13 Train batch 420 loss: 0.6718487739562988, 88.4% complete\n",
      "Epoch: 13 Train batch 430 loss: 0.6959876418113708, 90.5% complete\n",
      "Epoch: 13 Train batch 440 loss: 0.6578787565231323, 92.6% complete\n",
      "Epoch: 13 Train batch 450 loss: 0.6612525582313538, 94.7% complete\n",
      "Epoch: 13 Train batch 460 loss: 0.6743833422660828, 96.8% complete\n",
      "Epoch: 13 Train batch 470 loss: 0.6729812026023865, 98.9% complete\n",
      "Batch 1. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6721490025520325\n",
      "Batch 2. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6649789214134216\n",
      "Batch 3. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6727615594863892\n",
      "Batch 4. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6919284462928772\n",
      "Batch 5. Data shape torch.Size([32, 3, 224, 224]) Loss 0.672910213470459\n",
      "Batch 6. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6654800176620483\n",
      "Batch 7. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6655526757240295\n",
      "Batch 8. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6641781330108643\n",
      "Batch 9. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6771795153617859\n",
      "Batch 10. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6712573170661926\n",
      "Batch 11. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6753696203231812\n",
      "Batch 12. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6617167592048645\n",
      "Batch 13. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6682425737380981\n",
      "Batch 14. Data shape torch.Size([32, 3, 224, 224]) Loss 0.67441725730896\n",
      "Batch 15. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6754148602485657\n",
      "Batch 16. Data shape torch.Size([32, 3, 224, 224]) Loss 0.655558168888092\n",
      "Batch 17. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6603954434394836\n",
      "Batch 18. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6575626730918884\n",
      "Batch 19. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6712819933891296\n",
      "Batch 20. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6589412689208984\n",
      "Batch 21. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6769328117370605\n",
      "Batch 22. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6804673075675964\n",
      "Batch 23. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6707709431648254\n",
      "Batch 24. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6745781898498535\n",
      "Batch 25. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6719574928283691\n",
      "Batch 26. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6711908578872681\n",
      "Batch 27. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6644043922424316\n",
      "Batch 28. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6851298213005066\n",
      "Batch 29. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6753851175308228\n",
      "Batch 30. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6735460758209229\n",
      "Batch 31. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6781082153320312\n",
      "Batch 32. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6760426759719849\n",
      "Batch 33. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6696203947067261\n",
      "Batch 34. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6586742401123047\n",
      "Batch 35. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6783875226974487\n",
      "Batch 36. Data shape torch.Size([32, 3, 224, 224]) Loss 0.665823757648468\n",
      "Batch 37. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6692133545875549\n",
      "Batch 38. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6495290398597717\n",
      "Batch 39. Data shape torch.Size([32, 3, 224, 224]) Loss 0.686062753200531\n",
      "Batch 40. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6533464193344116\n",
      "Batch 41. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6695336103439331\n",
      "Batch 42. Data shape torch.Size([32, 3, 224, 224]) Loss 0.668574869632721\n",
      "Batch 43. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6642357110977173\n",
      "Batch 44. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6680663824081421\n",
      "Batch 45. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6722527742385864\n",
      "Batch 46. Data shape torch.Size([32, 3, 224, 224]) Loss 0.665486752986908\n",
      "Batch 47. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6637639403343201\n",
      "Batch 48. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6490262150764465\n",
      "Batch 49. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6776525974273682\n",
      "Batch 50. Data shape torch.Size([32, 3, 224, 224]) Loss 0.652154266834259\n",
      "Batch 51. Data shape torch.Size([32, 3, 224, 224]) Loss 0.658561110496521\n",
      "Batch 52. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6717809438705444\n",
      "Batch 53. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6732993721961975\n",
      "Batch 54. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6695590615272522\n",
      "Batch 55. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6681904792785645\n",
      "Batch 56. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6582379937171936\n",
      "Batch 57. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6701514720916748\n",
      "Batch 58. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6677119135856628\n",
      "Batch 59. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6770305037498474\n",
      "Batch 60. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6774846315383911\n",
      "Batch 61. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6689225435256958\n",
      "Batch 62. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6698106527328491\n",
      "Batch 63. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6669915318489075\n",
      "Batch 64. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6547008156776428\n",
      "Batch 65. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6755695343017578\n",
      "Batch 66. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6685746312141418\n",
      "Batch 67. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6714992523193359\n",
      "Batch 68. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6879736185073853\n",
      "Batch 69. Data shape torch.Size([32, 3, 224, 224]) Loss 0.666379988193512\n",
      "Batch 70. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6720679402351379\n",
      "Batch 71. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6709640622138977\n",
      "Batch 72. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6534949541091919\n",
      "Batch 73. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6674313545227051\n",
      "Batch 74. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6725611090660095\n",
      "Batch 75. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6634363532066345\n",
      "Batch 76. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6767910718917847\n",
      "Batch 77. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6721023917198181\n",
      "Batch 78. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6659547686576843\n",
      "Batch 79. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6644193530082703\n",
      "Batch 80. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6675277352333069\n",
      "Batch 81. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6689321994781494\n",
      "Batch 82. Data shape torch.Size([32, 3, 224, 224]) Loss 0.66615229845047\n",
      "Batch 83. Data shape torch.Size([32, 3, 224, 224]) Loss 0.672051727771759\n",
      "Batch 84. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6842641830444336\n",
      "Batch 85. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6651349663734436\n",
      "Batch 86. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6649048328399658\n",
      "Batch 87. Data shape torch.Size([32, 3, 224, 224]) Loss 0.668520450592041\n",
      "Batch 88. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6692669987678528\n",
      "Batch 89. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6499446630477905\n",
      "Batch 90. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6680373549461365\n",
      "Batch 91. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6597039699554443\n",
      "Batch 92. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6657889485359192\n",
      "Batch 93. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6632897853851318\n",
      "Batch 94. Data shape torch.Size([32, 3, 224, 224]) Loss 0.672589123249054\n",
      "Batch 95. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6729140281677246\n",
      "Batch 96. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6607134342193604\n",
      "Batch 97. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6702716946601868\n",
      "Batch 98. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6728870868682861\n",
      "Batch 99. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6701510548591614\n",
      "Batch 100. Data shape torch.Size([32, 3, 224, 224]) Loss 0.669856071472168\n",
      "Batch 101. Data shape torch.Size([32, 3, 224, 224]) Loss 0.664084792137146\n",
      "Batch 102. Data shape torch.Size([32, 3, 224, 224]) Loss 0.654888391494751\n",
      "Batch 103. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6743714809417725\n",
      "Batch 104. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6625730991363525\n",
      "Batch 105. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6831169724464417\n",
      "Batch 106. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6607507467269897\n",
      "Batch 107. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6737533807754517\n",
      "Batch 108. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6706573367118835\n",
      "Batch 109. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6682107448577881\n",
      "Batch 110. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6421079635620117\n",
      "Batch 111. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6724579930305481\n",
      "Batch 112. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6719647645950317\n",
      "Batch 113. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6649148464202881\n",
      "Batch 114. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6638170480728149\n",
      "Batch 115. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6680947542190552\n",
      "Batch 116. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6504614353179932\n",
      "Batch 117. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6655230522155762\n",
      "Batch 118. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6662604212760925\n",
      "Batch 119. Data shape torch.Size([20, 3, 224, 224]) Loss 0.6608433127403259\n",
      "Valid loss improved from 0.670984 to 0.668240. Saving model ...\n",
      "Epoch: 13/50 | time: 20.0m 51.52s | lr: 1.0000e-05 | train/loss: 0.67059 | val/loss: 0.66824 | val/accuracy: 0.70205 | val/AUC: 0.70563 | val/Kappa: 0.40826\n",
      "Epoch: 14 Train batch 10 loss: 0.687544584274292, 2.1% complete\n",
      "Epoch: 14 Train batch 20 loss: 0.6607806086540222, 4.2% complete\n",
      "Epoch: 14 Train batch 30 loss: 0.6723222732543945, 6.3% complete\n",
      "Epoch: 14 Train batch 40 loss: 0.6731020212173462, 8.4% complete\n",
      "Epoch: 14 Train batch 50 loss: 0.6643433570861816, 10.5% complete\n",
      "Epoch: 14 Train batch 60 loss: 0.6838691234588623, 12.6% complete\n",
      "Epoch: 14 Train batch 70 loss: 0.6505158543586731, 14.7% complete\n",
      "Epoch: 14 Train batch 80 loss: 0.6926190257072449, 16.8% complete\n",
      "Epoch: 14 Train batch 90 loss: 0.6745681762695312, 18.9% complete\n",
      "Epoch: 14 Train batch 100 loss: 0.677362322807312, 21.1% complete\n",
      "Epoch: 14 Train batch 110 loss: 0.6745771765708923, 23.2% complete\n",
      "Epoch: 14 Train batch 120 loss: 0.6852851510047913, 25.3% complete\n",
      "Epoch: 14 Train batch 130 loss: 0.6707587242126465, 27.4% complete\n",
      "Epoch: 14 Train batch 140 loss: 0.6629000902175903, 29.5% complete\n",
      "Epoch: 14 Train batch 150 loss: 0.6890856623649597, 31.6% complete\n",
      "Epoch: 14 Train batch 160 loss: 0.6828254461288452, 33.7% complete\n",
      "Epoch: 14 Train batch 170 loss: 0.6734530925750732, 35.8% complete\n",
      "Epoch: 14 Train batch 180 loss: 0.6546084880828857, 37.9% complete\n",
      "Epoch: 14 Train batch 190 loss: 0.6608189940452576, 40.0% complete\n",
      "Epoch: 14 Train batch 200 loss: 0.6618561148643494, 42.1% complete\n",
      "Epoch: 14 Train batch 210 loss: 0.6626248955726624, 44.2% complete\n",
      "Epoch: 14 Train batch 220 loss: 0.6709907650947571, 46.3% complete\n",
      "Epoch: 14 Train batch 230 loss: 0.6774038672447205, 48.4% complete\n",
      "Epoch: 14 Train batch 240 loss: 0.6610673069953918, 50.5% complete\n",
      "Epoch: 14 Train batch 250 loss: 0.6638414859771729, 52.6% complete\n",
      "Epoch: 14 Train batch 260 loss: 0.6789070963859558, 54.7% complete\n",
      "Epoch: 14 Train batch 270 loss: 0.6812412142753601, 56.8% complete\n",
      "Epoch: 14 Train batch 280 loss: 0.6607666015625, 58.9% complete\n",
      "Epoch: 14 Train batch 290 loss: 0.6783027648925781, 61.1% complete\n",
      "Epoch: 14 Train batch 300 loss: 0.6720046997070312, 63.2% complete\n",
      "Epoch: 14 Train batch 310 loss: 0.6573675274848938, 65.3% complete\n",
      "Epoch: 14 Train batch 320 loss: 0.6791331768035889, 67.4% complete\n",
      "Epoch: 14 Train batch 330 loss: 0.6726381182670593, 69.5% complete\n",
      "Epoch: 14 Train batch 340 loss: 0.658241331577301, 71.6% complete\n",
      "Epoch: 14 Train batch 350 loss: 0.669329047203064, 73.7% complete\n",
      "Epoch: 14 Train batch 360 loss: 0.6639711856842041, 75.8% complete\n",
      "Epoch: 14 Train batch 370 loss: 0.6712871789932251, 77.9% complete\n",
      "Epoch: 14 Train batch 380 loss: 0.6456915736198425, 80.0% complete\n",
      "Epoch: 14 Train batch 390 loss: 0.6589377522468567, 82.1% complete\n",
      "Epoch: 14 Train batch 400 loss: 0.6643417477607727, 84.2% complete\n",
      "Epoch: 14 Train batch 410 loss: 0.6585316061973572, 86.3% complete\n",
      "Epoch: 14 Train batch 420 loss: 0.6664320230484009, 88.4% complete\n",
      "Epoch: 14 Train batch 430 loss: 0.6615620255470276, 90.5% complete\n",
      "Epoch: 14 Train batch 440 loss: 0.6652549505233765, 92.6% complete\n",
      "Epoch: 14 Train batch 450 loss: 0.6642187237739563, 94.7% complete\n",
      "Epoch: 14 Train batch 460 loss: 0.6608580350875854, 96.8% complete\n",
      "Epoch: 14 Train batch 470 loss: 0.6856809854507446, 98.9% complete\n",
      "Batch 1. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6609500050544739\n",
      "Batch 2. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6590014100074768\n",
      "Batch 3. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6656008362770081\n",
      "Batch 4. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6720151305198669\n",
      "Batch 5. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6647031903266907\n",
      "Batch 6. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6450567841529846\n",
      "Batch 7. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6545063853263855\n",
      "Batch 8. Data shape torch.Size([32, 3, 224, 224]) Loss 0.656767725944519\n",
      "Batch 9. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6692338585853577\n",
      "Batch 10. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6777629852294922\n",
      "Batch 11. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6495810747146606\n",
      "Batch 12. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6627494096755981\n",
      "Batch 13. Data shape torch.Size([32, 3, 224, 224]) Loss 0.657463014125824\n",
      "Batch 14. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6507344245910645\n",
      "Batch 15. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6756373047828674\n",
      "Batch 16. Data shape torch.Size([32, 3, 224, 224]) Loss 0.667888879776001\n",
      "Batch 17. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6596992611885071\n",
      "Batch 18. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6719982028007507\n",
      "Batch 19. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6494936943054199\n",
      "Batch 20. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6820253133773804\n",
      "Batch 21. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6602464318275452\n",
      "Batch 22. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6594804525375366\n",
      "Batch 23. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6581611037254333\n",
      "Batch 24. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6777966618537903\n",
      "Batch 25. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6656830906867981\n",
      "Batch 26. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6655142903327942\n",
      "Batch 27. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6674495935440063\n",
      "Batch 28. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6526384353637695\n",
      "Batch 29. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6616914868354797\n",
      "Batch 30. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6658459305763245\n",
      "Batch 31. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6644346714019775\n",
      "Batch 32. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6725406646728516\n",
      "Batch 33. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6705595254898071\n",
      "Batch 34. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6459553241729736\n",
      "Batch 35. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6721540093421936\n",
      "Batch 36. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6439762711524963\n",
      "Batch 37. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6674054265022278\n",
      "Batch 38. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6483224630355835\n",
      "Batch 39. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6505036354064941\n",
      "Batch 40. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6509014964103699\n",
      "Batch 41. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6456503868103027\n",
      "Batch 42. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6586458086967468\n",
      "Batch 43. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6808518171310425\n",
      "Batch 44. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6647742986679077\n",
      "Batch 45. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6720693111419678\n",
      "Batch 46. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6607450842857361\n",
      "Batch 47. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6756346821784973\n",
      "Batch 48. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6710374355316162\n",
      "Batch 49. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6695883870124817\n",
      "Batch 50. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6485570669174194\n",
      "Batch 51. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6654038429260254\n",
      "Batch 52. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6614991426467896\n",
      "Batch 53. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6593953967094421\n",
      "Batch 54. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6700840592384338\n",
      "Batch 55. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6584459543228149\n",
      "Batch 56. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6669086217880249\n",
      "Batch 57. Data shape torch.Size([32, 3, 224, 224]) Loss 0.674330472946167\n",
      "Batch 58. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6601834893226624\n",
      "Batch 59. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6547011137008667\n",
      "Batch 60. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6802335381507874\n",
      "Batch 61. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6744963526725769\n",
      "Batch 62. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6604679822921753\n",
      "Batch 63. Data shape torch.Size([32, 3, 224, 224]) Loss 0.672199547290802\n",
      "Batch 64. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6537933945655823\n",
      "Batch 65. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6721193194389343\n",
      "Batch 66. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6716614961624146\n",
      "Batch 67. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6587895154953003\n",
      "Batch 68. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6590967178344727\n",
      "Batch 69. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6699284315109253\n",
      "Batch 70. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6638527512550354\n",
      "Batch 71. Data shape torch.Size([32, 3, 224, 224]) Loss 0.659773051738739\n",
      "Batch 72. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6728602647781372\n",
      "Batch 73. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6710792183876038\n",
      "Batch 74. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6830115914344788\n",
      "Batch 75. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6785503625869751\n",
      "Batch 76. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6782388091087341\n",
      "Batch 77. Data shape torch.Size([32, 3, 224, 224]) Loss 0.671500563621521\n",
      "Batch 78. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6737016439437866\n",
      "Batch 79. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6430415511131287\n",
      "Batch 80. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6664917469024658\n",
      "Batch 81. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6648842096328735\n",
      "Batch 82. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6579676270484924\n",
      "Batch 83. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6751000881195068\n",
      "Batch 84. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6528964638710022\n",
      "Batch 85. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6659649014472961\n",
      "Batch 86. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6947773098945618\n",
      "Batch 87. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6646597981452942\n",
      "Batch 88. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6683127880096436\n",
      "Batch 89. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6740857362747192\n",
      "Batch 90. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6703700423240662\n",
      "Batch 91. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6804580092430115\n",
      "Batch 92. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6774998307228088\n",
      "Batch 93. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6733124852180481\n",
      "Batch 94. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6792161464691162\n",
      "Batch 95. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6833638548851013\n",
      "Batch 96. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6677228808403015\n",
      "Batch 97. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6679214835166931\n",
      "Batch 98. Data shape torch.Size([32, 3, 224, 224]) Loss 0.674302875995636\n",
      "Batch 99. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6669774651527405\n",
      "Batch 100. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6715258359909058\n",
      "Batch 101. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6762850880622864\n",
      "Batch 102. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6770479679107666\n",
      "Batch 103. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6480274796485901\n",
      "Batch 104. Data shape torch.Size([32, 3, 224, 224]) Loss 0.651387095451355\n",
      "Batch 105. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6639630198478699\n",
      "Batch 106. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6683337092399597\n",
      "Batch 107. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6732295751571655\n",
      "Batch 108. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6750942468643188\n",
      "Batch 109. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6533753275871277\n",
      "Batch 110. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6507251262664795\n",
      "Batch 111. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6678506731987\n",
      "Batch 112. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6721193194389343\n",
      "Batch 113. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6547082662582397\n",
      "Batch 114. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6493131518363953\n",
      "Batch 115. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6659690737724304\n",
      "Batch 116. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6610453128814697\n",
      "Batch 117. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6603331565856934\n",
      "Batch 118. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6667025685310364\n",
      "Batch 119. Data shape torch.Size([20, 3, 224, 224]) Loss 0.6759749054908752\n",
      "Valid loss improved from 0.668240 to 0.665297. Saving model ...\n",
      "Epoch: 14/50 | time: 20.0m 59.86s | lr: 1.0000e-05 | train/loss: 0.66873 | val/loss: 0.66530 | val/accuracy: 0.70364 | val/AUC: 0.70707 | val/Kappa: 0.41124\n",
      "Epoch: 15 Train batch 10 loss: 0.6715365052223206, 2.1% complete\n",
      "Epoch: 15 Train batch 20 loss: 0.647415041923523, 4.2% complete\n",
      "Epoch: 15 Train batch 30 loss: 0.6804852485656738, 6.3% complete\n",
      "Epoch: 15 Train batch 40 loss: 0.6628555059432983, 8.4% complete\n",
      "Epoch: 15 Train batch 50 loss: 0.6623338460922241, 10.5% complete\n",
      "Epoch: 15 Train batch 60 loss: 0.6732658743858337, 12.6% complete\n",
      "Epoch: 15 Train batch 70 loss: 0.6629337072372437, 14.7% complete\n",
      "Epoch: 15 Train batch 80 loss: 0.6765801310539246, 16.8% complete\n",
      "Epoch: 15 Train batch 90 loss: 0.6538628935813904, 18.9% complete\n",
      "Epoch: 15 Train batch 100 loss: 0.6577250957489014, 21.1% complete\n",
      "Epoch: 15 Train batch 110 loss: 0.6671119332313538, 23.2% complete\n",
      "Epoch: 15 Train batch 120 loss: 0.655931293964386, 25.3% complete\n",
      "Epoch: 15 Train batch 130 loss: 0.6468123197555542, 27.4% complete\n",
      "Epoch: 15 Train batch 140 loss: 0.6606118679046631, 29.5% complete\n",
      "Epoch: 15 Train batch 150 loss: 0.6629117727279663, 31.6% complete\n",
      "Epoch: 15 Train batch 160 loss: 0.6819391846656799, 33.7% complete\n",
      "Epoch: 15 Train batch 170 loss: 0.6948133707046509, 35.8% complete\n",
      "Epoch: 15 Train batch 180 loss: 0.6608902812004089, 37.9% complete\n",
      "Epoch: 15 Train batch 190 loss: 0.6726872324943542, 40.0% complete\n",
      "Epoch: 15 Train batch 200 loss: 0.6699668169021606, 42.1% complete\n",
      "Epoch: 15 Train batch 210 loss: 0.6825383901596069, 44.2% complete\n",
      "Epoch: 15 Train batch 220 loss: 0.6841748356819153, 46.3% complete\n",
      "Epoch: 15 Train batch 230 loss: 0.67548006772995, 48.4% complete\n",
      "Epoch: 15 Train batch 240 loss: 0.6716514825820923, 50.5% complete\n",
      "Epoch: 15 Train batch 250 loss: 0.6687995195388794, 52.6% complete\n",
      "Epoch: 15 Train batch 260 loss: 0.6726921200752258, 54.7% complete\n",
      "Epoch: 15 Train batch 270 loss: 0.6632280945777893, 56.8% complete\n",
      "Epoch: 15 Train batch 280 loss: 0.6615573167800903, 58.9% complete\n",
      "Epoch: 15 Train batch 290 loss: 0.6679724454879761, 61.1% complete\n",
      "Epoch: 15 Train batch 300 loss: 0.6741832494735718, 63.2% complete\n",
      "Epoch: 15 Train batch 310 loss: 0.6624669432640076, 65.3% complete\n",
      "Epoch: 15 Train batch 320 loss: 0.6624530553817749, 67.4% complete\n",
      "Epoch: 15 Train batch 330 loss: 0.679811418056488, 69.5% complete\n",
      "Epoch: 15 Train batch 340 loss: 0.6594487428665161, 71.6% complete\n",
      "Epoch: 15 Train batch 350 loss: 0.6567394137382507, 73.7% complete\n",
      "Epoch: 15 Train batch 360 loss: 0.6955479979515076, 75.8% complete\n",
      "Epoch: 15 Train batch 370 loss: 0.6823192834854126, 77.9% complete\n",
      "Epoch: 15 Train batch 380 loss: 0.6544340252876282, 80.0% complete\n",
      "Epoch: 15 Train batch 390 loss: 0.6613622307777405, 82.1% complete\n",
      "Epoch: 15 Train batch 400 loss: 0.6669756770133972, 84.2% complete\n",
      "Epoch: 15 Train batch 410 loss: 0.6713382601737976, 86.3% complete\n",
      "Epoch: 15 Train batch 420 loss: 0.6789236664772034, 88.4% complete\n",
      "Epoch: 15 Train batch 430 loss: 0.6662605404853821, 90.5% complete\n",
      "Epoch: 15 Train batch 440 loss: 0.671482503414154, 92.6% complete\n",
      "Epoch: 15 Train batch 450 loss: 0.6766200661659241, 94.7% complete\n",
      "Epoch: 15 Train batch 460 loss: 0.6671817302703857, 96.8% complete\n",
      "Epoch: 15 Train batch 470 loss: 0.6622069478034973, 98.9% complete\n",
      "Batch 1. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6443844437599182\n",
      "Batch 2. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6494031548500061\n",
      "Batch 3. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6515480279922485\n",
      "Batch 4. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6586453318595886\n",
      "Batch 5. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6660709977149963\n",
      "Batch 6. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6611986756324768\n",
      "Batch 7. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6779874563217163\n",
      "Batch 8. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6603139638900757\n",
      "Batch 9. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6636466979980469\n",
      "Batch 10. Data shape torch.Size([32, 3, 224, 224]) Loss 0.661124587059021\n",
      "Batch 11. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6572967767715454\n",
      "Batch 12. Data shape torch.Size([32, 3, 224, 224]) Loss 0.682303249835968\n",
      "Batch 13. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6735759377479553\n",
      "Batch 14. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6459107995033264\n",
      "Batch 15. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6636439561843872\n",
      "Batch 16. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6577557921409607\n",
      "Batch 17. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6593371033668518\n",
      "Batch 18. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6566597819328308\n",
      "Batch 19. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6804468631744385\n",
      "Batch 20. Data shape torch.Size([32, 3, 224, 224]) Loss 0.67080157995224\n",
      "Batch 21. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6623955368995667\n",
      "Batch 22. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6748452186584473\n",
      "Batch 23. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6621683835983276\n",
      "Batch 24. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6686393022537231\n",
      "Batch 25. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6517706513404846\n",
      "Batch 26. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6583618521690369\n",
      "Batch 27. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6628053784370422\n",
      "Batch 28. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6649613976478577\n",
      "Batch 29. Data shape torch.Size([32, 3, 224, 224]) Loss 0.681210458278656\n",
      "Batch 30. Data shape torch.Size([32, 3, 224, 224]) Loss 0.671690821647644\n",
      "Batch 31. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6535536646842957\n",
      "Batch 32. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6669040322303772\n",
      "Batch 33. Data shape torch.Size([32, 3, 224, 224]) Loss 0.668531596660614\n",
      "Batch 34. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6499027609825134\n",
      "Batch 35. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6736448407173157\n",
      "Batch 36. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6533028483390808\n",
      "Batch 37. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6651288866996765\n",
      "Batch 38. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6794212460517883\n",
      "Batch 39. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6823376417160034\n",
      "Batch 40. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6685981750488281\n",
      "Batch 41. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6695510149002075\n",
      "Batch 42. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6761224269866943\n",
      "Batch 43. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6613667607307434\n",
      "Batch 44. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6704868674278259\n",
      "Batch 45. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6678966879844666\n",
      "Batch 46. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6455093622207642\n",
      "Batch 47. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6699439287185669\n",
      "Batch 48. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6609454154968262\n",
      "Batch 49. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6659165620803833\n",
      "Batch 50. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6676983833312988\n",
      "Batch 51. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6521092653274536\n",
      "Batch 52. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6758015751838684\n",
      "Batch 53. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6547846794128418\n",
      "Batch 54. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6534362435340881\n",
      "Batch 55. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6831358075141907\n",
      "Batch 56. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6610552072525024\n",
      "Batch 57. Data shape torch.Size([32, 3, 224, 224]) Loss 0.638461172580719\n",
      "Batch 58. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6848530769348145\n",
      "Batch 59. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6653313636779785\n",
      "Batch 60. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6567288041114807\n",
      "Batch 61. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6552687287330627\n",
      "Batch 62. Data shape torch.Size([32, 3, 224, 224]) Loss 0.663167417049408\n",
      "Batch 63. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6727038025856018\n",
      "Batch 64. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6772781610488892\n",
      "Batch 65. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6696473360061646\n",
      "Batch 66. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6621435880661011\n",
      "Batch 67. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6727217435836792\n",
      "Batch 68. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6556269526481628\n",
      "Batch 69. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6741951704025269\n",
      "Batch 70. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6549808979034424\n",
      "Batch 71. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6735435128211975\n",
      "Batch 72. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6537914872169495\n",
      "Batch 73. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6645059585571289\n",
      "Batch 74. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6657911539077759\n",
      "Batch 75. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6627212166786194\n",
      "Batch 76. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6587116122245789\n",
      "Batch 77. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6623572111129761\n",
      "Batch 78. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6722587943077087\n",
      "Batch 79. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6568630337715149\n",
      "Batch 80. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6546163558959961\n",
      "Batch 81. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6822583675384521\n",
      "Batch 82. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6761991381645203\n",
      "Batch 83. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6697741150856018\n",
      "Batch 84. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6560447216033936\n",
      "Batch 85. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6514861583709717\n",
      "Batch 86. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6486519575119019\n",
      "Batch 87. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6664437651634216\n",
      "Batch 88. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6568151712417603\n",
      "Batch 89. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6661762595176697\n",
      "Batch 90. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6724328398704529\n",
      "Batch 91. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6566752195358276\n",
      "Batch 92. Data shape torch.Size([32, 3, 224, 224]) Loss 0.665942907333374\n",
      "Batch 93. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6463788151741028\n",
      "Batch 94. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6546939611434937\n",
      "Batch 95. Data shape torch.Size([32, 3, 224, 224]) Loss 0.662294864654541\n",
      "Batch 96. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6693453192710876\n",
      "Batch 97. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6556379795074463\n",
      "Batch 98. Data shape torch.Size([32, 3, 224, 224]) Loss 0.672828197479248\n",
      "Batch 99. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6720989942550659\n",
      "Batch 100. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6458423137664795\n",
      "Batch 101. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6699532270431519\n",
      "Batch 102. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6743621230125427\n",
      "Batch 103. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6870880126953125\n",
      "Batch 104. Data shape torch.Size([32, 3, 224, 224]) Loss 0.657220184803009\n",
      "Batch 105. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6667307615280151\n",
      "Batch 106. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6690230965614319\n",
      "Batch 107. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6485111117362976\n",
      "Batch 108. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6443684697151184\n",
      "Batch 109. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6597608923912048\n",
      "Batch 110. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6532086730003357\n",
      "Batch 111. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6622231602668762\n",
      "Batch 112. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6602297425270081\n",
      "Batch 113. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6651785373687744\n",
      "Batch 114. Data shape torch.Size([32, 3, 224, 224]) Loss 0.676978588104248\n",
      "Batch 115. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6535328030586243\n",
      "Batch 116. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6620787978172302\n",
      "Batch 117. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6788402199745178\n",
      "Batch 118. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6625377535820007\n",
      "Batch 119. Data shape torch.Size([20, 3, 224, 224]) Loss 0.6724053621292114\n",
      "Valid loss improved from 0.665297 to 0.663853. Saving model ...\n",
      "Epoch: 15/50 | time: 21.0m 8.45s | lr: 1.0000e-05 | train/loss: 0.66615 | val/loss: 0.66385 | val/accuracy: 0.71575 | val/AUC: 0.71858 | val/Kappa: 0.43462\n",
      "Epoch: 16 Train batch 10 loss: 0.6659788489341736, 2.1% complete\n",
      "Epoch: 16 Train batch 20 loss: 0.6757952570915222, 4.2% complete\n",
      "Epoch: 16 Train batch 30 loss: 0.6536769866943359, 6.3% complete\n",
      "Epoch: 16 Train batch 40 loss: 0.6621876358985901, 8.4% complete\n",
      "Epoch: 16 Train batch 50 loss: 0.6628038883209229, 10.5% complete\n",
      "Epoch: 16 Train batch 60 loss: 0.6533676981925964, 12.6% complete\n",
      "Epoch: 16 Train batch 70 loss: 0.6543635129928589, 14.7% complete\n",
      "Epoch: 16 Train batch 80 loss: 0.6705959439277649, 16.8% complete\n",
      "Epoch: 16 Train batch 90 loss: 0.6609262228012085, 18.9% complete\n",
      "Epoch: 16 Train batch 100 loss: 0.6793039441108704, 21.1% complete\n",
      "Epoch: 16 Train batch 110 loss: 0.6599469184875488, 23.2% complete\n",
      "Epoch: 16 Train batch 120 loss: 0.6622358560562134, 25.3% complete\n",
      "Epoch: 16 Train batch 130 loss: 0.6584722399711609, 27.4% complete\n",
      "Epoch: 16 Train batch 140 loss: 0.649124801158905, 29.5% complete\n",
      "Epoch: 16 Train batch 150 loss: 0.6609674692153931, 31.6% complete\n",
      "Epoch: 16 Train batch 160 loss: 0.6670792102813721, 33.7% complete\n",
      "Epoch: 16 Train batch 170 loss: 0.6673171520233154, 35.8% complete\n",
      "Epoch: 16 Train batch 180 loss: 0.6638115644454956, 37.9% complete\n",
      "Epoch: 16 Train batch 190 loss: 0.6567822694778442, 40.0% complete\n",
      "Epoch: 16 Train batch 200 loss: 0.668746829032898, 42.1% complete\n",
      "Epoch: 16 Train batch 210 loss: 0.662469744682312, 44.2% complete\n",
      "Epoch: 16 Train batch 220 loss: 0.6562597155570984, 46.3% complete\n",
      "Epoch: 16 Train batch 230 loss: 0.6628082394599915, 48.4% complete\n",
      "Epoch: 16 Train batch 240 loss: 0.6617175340652466, 50.5% complete\n",
      "Epoch: 16 Train batch 250 loss: 0.6728978157043457, 52.6% complete\n",
      "Epoch: 16 Train batch 260 loss: 0.6536393761634827, 54.7% complete\n",
      "Epoch: 16 Train batch 270 loss: 0.6599671244621277, 56.8% complete\n",
      "Epoch: 16 Train batch 280 loss: 0.6650242805480957, 58.9% complete\n",
      "Epoch: 16 Train batch 290 loss: 0.672024667263031, 61.1% complete\n",
      "Epoch: 16 Train batch 300 loss: 0.6564194560050964, 63.2% complete\n",
      "Epoch: 16 Train batch 310 loss: 0.6480935215950012, 65.3% complete\n",
      "Epoch: 16 Train batch 320 loss: 0.6526401042938232, 67.4% complete\n",
      "Epoch: 16 Train batch 330 loss: 0.6634779572486877, 69.5% complete\n",
      "Epoch: 16 Train batch 340 loss: 0.6621783971786499, 71.6% complete\n",
      "Epoch: 16 Train batch 350 loss: 0.6567949056625366, 73.7% complete\n",
      "Epoch: 16 Train batch 360 loss: 0.6651372909545898, 75.8% complete\n",
      "Epoch: 16 Train batch 370 loss: 0.6534891724586487, 77.9% complete\n",
      "Epoch: 16 Train batch 380 loss: 0.6579734683036804, 80.0% complete\n",
      "Epoch: 16 Train batch 390 loss: 0.6569011807441711, 82.1% complete\n",
      "Epoch: 16 Train batch 400 loss: 0.6723758578300476, 84.2% complete\n",
      "Epoch: 16 Train batch 410 loss: 0.6602762937545776, 86.3% complete\n",
      "Epoch: 16 Train batch 420 loss: 0.6495286226272583, 88.4% complete\n",
      "Epoch: 16 Train batch 430 loss: 0.6483089327812195, 90.5% complete\n",
      "Epoch: 16 Train batch 440 loss: 0.6779125332832336, 92.6% complete\n",
      "Epoch: 16 Train batch 450 loss: 0.6733344197273254, 94.7% complete\n",
      "Epoch: 16 Train batch 460 loss: 0.6514315009117126, 96.8% complete\n",
      "Epoch: 16 Train batch 470 loss: 0.6571236848831177, 98.9% complete\n",
      "Batch 1. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6520015001296997\n",
      "Batch 2. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6606729030609131\n",
      "Batch 3. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6836174726486206\n",
      "Batch 4. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6513189673423767\n",
      "Batch 5. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6545146703720093\n",
      "Batch 6. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6620900630950928\n",
      "Batch 7. Data shape torch.Size([32, 3, 224, 224]) Loss 0.662818193435669\n",
      "Batch 8. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6598674058914185\n",
      "Batch 9. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6729206442832947\n",
      "Batch 10. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6754792332649231\n",
      "Batch 11. Data shape torch.Size([32, 3, 224, 224]) Loss 0.67071533203125\n",
      "Batch 12. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6390284299850464\n",
      "Batch 13. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6662420034408569\n",
      "Batch 14. Data shape torch.Size([32, 3, 224, 224]) Loss 0.656518280506134\n",
      "Batch 15. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6611203551292419\n",
      "Batch 16. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6677394509315491\n",
      "Batch 17. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6568416357040405\n",
      "Batch 18. Data shape torch.Size([32, 3, 224, 224]) Loss 0.639521598815918\n",
      "Batch 19. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6333392262458801\n",
      "Batch 20. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6594099402427673\n",
      "Batch 21. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6716901063919067\n",
      "Batch 22. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6646720170974731\n",
      "Batch 23. Data shape torch.Size([32, 3, 224, 224]) Loss 0.668488085269928\n",
      "Batch 24. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6508931517601013\n",
      "Batch 25. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6583907604217529\n",
      "Batch 26. Data shape torch.Size([32, 3, 224, 224]) Loss 0.667837381362915\n",
      "Batch 27. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6535462737083435\n",
      "Batch 28. Data shape torch.Size([32, 3, 224, 224]) Loss 0.669306755065918\n",
      "Batch 29. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6703697443008423\n",
      "Batch 30. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6580236554145813\n",
      "Batch 31. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6426091194152832\n",
      "Batch 32. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6368039846420288\n",
      "Batch 33. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6583533883094788\n",
      "Batch 34. Data shape torch.Size([32, 3, 224, 224]) Loss 0.667905867099762\n",
      "Batch 35. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6653909683227539\n",
      "Batch 36. Data shape torch.Size([32, 3, 224, 224]) Loss 0.663578987121582\n",
      "Batch 37. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6799174547195435\n",
      "Batch 38. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6775317192077637\n",
      "Batch 39. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6612721085548401\n",
      "Batch 40. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6523236036300659\n",
      "Batch 41. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6427180171012878\n",
      "Batch 42. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6782491207122803\n",
      "Batch 43. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6648732423782349\n",
      "Batch 44. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6598871350288391\n",
      "Batch 45. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6636147499084473\n",
      "Batch 46. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6591746211051941\n",
      "Batch 47. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6686546206474304\n",
      "Batch 48. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6676677465438843\n",
      "Batch 49. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6476030945777893\n",
      "Batch 50. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6683948636054993\n",
      "Batch 51. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6520522236824036\n",
      "Batch 52. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6654719114303589\n",
      "Batch 53. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6506097912788391\n",
      "Batch 54. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6612889170646667\n",
      "Batch 55. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6555678844451904\n",
      "Batch 56. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6444699168205261\n",
      "Batch 57. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6660804748535156\n",
      "Batch 58. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6553487181663513\n",
      "Batch 59. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6566135287284851\n",
      "Batch 60. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6655756235122681\n",
      "Batch 61. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6663261651992798\n",
      "Batch 62. Data shape torch.Size([32, 3, 224, 224]) Loss 0.654638946056366\n",
      "Batch 63. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6706638336181641\n",
      "Batch 64. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6642272472381592\n",
      "Batch 65. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6587905287742615\n",
      "Batch 66. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6661443710327148\n",
      "Batch 67. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6577417850494385\n",
      "Batch 68. Data shape torch.Size([32, 3, 224, 224]) Loss 0.668179988861084\n",
      "Batch 69. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6857928037643433\n",
      "Batch 70. Data shape torch.Size([32, 3, 224, 224]) Loss 0.654610812664032\n",
      "Batch 71. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6624484658241272\n",
      "Batch 72. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6590560078620911\n",
      "Batch 73. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6575958132743835\n",
      "Batch 74. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6756733059883118\n",
      "Batch 75. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6710286736488342\n",
      "Batch 76. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6578003168106079\n",
      "Batch 77. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6506713628768921\n",
      "Batch 78. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6573308706283569\n",
      "Batch 79. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6690636277198792\n",
      "Batch 80. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6581535935401917\n",
      "Batch 81. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6766893863677979\n",
      "Batch 82. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6778963804244995\n",
      "Batch 83. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6675915718078613\n",
      "Batch 84. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6571981310844421\n",
      "Batch 85. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6598493456840515\n",
      "Batch 86. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6571542024612427\n",
      "Batch 87. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6562744975090027\n",
      "Batch 88. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6412817239761353\n",
      "Batch 89. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6352847218513489\n",
      "Batch 90. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6526500582695007\n",
      "Batch 91. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6567966938018799\n",
      "Batch 92. Data shape torch.Size([32, 3, 224, 224]) Loss 0.660534679889679\n",
      "Batch 93. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6701856851577759\n",
      "Batch 94. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6529707908630371\n",
      "Batch 95. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6768866777420044\n",
      "Batch 96. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6440401673316956\n",
      "Batch 97. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6537191271781921\n",
      "Batch 98. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6550974249839783\n",
      "Batch 99. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6723402738571167\n",
      "Batch 100. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6625393629074097\n",
      "Batch 101. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6779844760894775\n",
      "Batch 102. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6595451235771179\n",
      "Batch 103. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6769383549690247\n",
      "Batch 104. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6555607914924622\n",
      "Batch 105. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6560739278793335\n",
      "Batch 106. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6620895266532898\n",
      "Batch 107. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6534810066223145\n",
      "Batch 108. Data shape torch.Size([32, 3, 224, 224]) Loss 0.676615834236145\n",
      "Batch 109. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6634314656257629\n",
      "Batch 110. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6779338121414185\n",
      "Batch 111. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6497534513473511\n",
      "Batch 112. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6555753946304321\n",
      "Batch 113. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6692975759506226\n",
      "Batch 114. Data shape torch.Size([32, 3, 224, 224]) Loss 0.669442892074585\n",
      "Batch 115. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6408939957618713\n",
      "Batch 116. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6506800651550293\n",
      "Batch 117. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6609339714050293\n",
      "Batch 118. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6849242448806763\n",
      "Batch 119. Data shape torch.Size([20, 3, 224, 224]) Loss 0.6564412713050842\n",
      "Valid loss improved from 0.663853 to 0.661085. Saving model ...\n",
      "Epoch: 16/50 | time: 20.0m 45.29s | lr: 1.0000e-05 | train/loss: 0.66337 | val/loss: 0.66109 | val/accuracy: 0.71575 | val/AUC: 0.71869 | val/Kappa: 0.43475\n",
      "Epoch: 17 Train batch 10 loss: 0.6684619188308716, 2.1% complete\n",
      "Epoch: 17 Train batch 20 loss: 0.6760951280593872, 4.2% complete\n",
      "Epoch: 17 Train batch 30 loss: 0.689520537853241, 6.3% complete\n",
      "Epoch: 17 Train batch 40 loss: 0.6675356030464172, 8.4% complete\n",
      "Epoch: 17 Train batch 50 loss: 0.6546913981437683, 10.5% complete\n",
      "Epoch: 17 Train batch 60 loss: 0.664494514465332, 12.6% complete\n",
      "Epoch: 17 Train batch 70 loss: 0.6491854786872864, 14.7% complete\n",
      "Epoch: 17 Train batch 80 loss: 0.6622671484947205, 16.8% complete\n",
      "Epoch: 17 Train batch 90 loss: 0.656680166721344, 18.9% complete\n",
      "Epoch: 17 Train batch 100 loss: 0.6656226515769958, 21.1% complete\n",
      "Epoch: 17 Train batch 110 loss: 0.6712391972541809, 23.2% complete\n",
      "Epoch: 17 Train batch 120 loss: 0.6768090724945068, 25.3% complete\n",
      "Epoch: 17 Train batch 130 loss: 0.6902791261672974, 27.4% complete\n",
      "Epoch: 17 Train batch 140 loss: 0.6658870577812195, 29.5% complete\n",
      "Epoch: 17 Train batch 150 loss: 0.651814877986908, 31.6% complete\n",
      "Epoch: 17 Train batch 160 loss: 0.6541476845741272, 33.7% complete\n",
      "Epoch: 17 Train batch 170 loss: 0.6452889442443848, 35.8% complete\n",
      "Epoch: 17 Train batch 180 loss: 0.6738443374633789, 37.9% complete\n",
      "Epoch: 17 Train batch 190 loss: 0.658986508846283, 40.0% complete\n",
      "Epoch: 17 Train batch 200 loss: 0.668463945388794, 42.1% complete\n",
      "Epoch: 17 Train batch 210 loss: 0.6738956570625305, 44.2% complete\n",
      "Epoch: 17 Train batch 220 loss: 0.6577823162078857, 46.3% complete\n",
      "Epoch: 17 Train batch 230 loss: 0.65578293800354, 48.4% complete\n",
      "Epoch: 17 Train batch 240 loss: 0.6377980709075928, 50.5% complete\n",
      "Epoch: 17 Train batch 250 loss: 0.6950737237930298, 52.6% complete\n",
      "Epoch: 17 Train batch 260 loss: 0.6551666855812073, 54.7% complete\n",
      "Epoch: 17 Train batch 270 loss: 0.6455663442611694, 56.8% complete\n",
      "Epoch: 17 Train batch 280 loss: 0.6430743336677551, 58.9% complete\n",
      "Epoch: 17 Train batch 290 loss: 0.6614802479743958, 61.1% complete\n",
      "Epoch: 17 Train batch 300 loss: 0.6609862446784973, 63.2% complete\n",
      "Epoch: 17 Train batch 310 loss: 0.6725435853004456, 65.3% complete\n",
      "Epoch: 17 Train batch 320 loss: 0.6714209914207458, 67.4% complete\n",
      "Epoch: 17 Train batch 330 loss: 0.6415220499038696, 69.5% complete\n",
      "Epoch: 17 Train batch 340 loss: 0.6740587949752808, 71.6% complete\n",
      "Epoch: 17 Train batch 350 loss: 0.6504220962524414, 73.7% complete\n",
      "Epoch: 17 Train batch 360 loss: 0.662102222442627, 75.8% complete\n",
      "Epoch: 17 Train batch 370 loss: 0.6730127334594727, 77.9% complete\n",
      "Epoch: 17 Train batch 380 loss: 0.6431220769882202, 80.0% complete\n",
      "Epoch: 17 Train batch 390 loss: 0.6669732332229614, 82.1% complete\n",
      "Epoch: 17 Train batch 400 loss: 0.6482896208763123, 84.2% complete\n",
      "Epoch: 17 Train batch 410 loss: 0.6359614729881287, 86.3% complete\n",
      "Epoch: 17 Train batch 420 loss: 0.6604501008987427, 88.4% complete\n",
      "Epoch: 17 Train batch 430 loss: 0.6610839366912842, 90.5% complete\n",
      "Epoch: 17 Train batch 440 loss: 0.6686884760856628, 92.6% complete\n",
      "Epoch: 17 Train batch 450 loss: 0.6460700035095215, 94.7% complete\n",
      "Epoch: 17 Train batch 460 loss: 0.6484413743019104, 96.8% complete\n",
      "Epoch: 17 Train batch 470 loss: 0.6541721224784851, 98.9% complete\n",
      "Batch 1. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6460548043251038\n",
      "Batch 2. Data shape torch.Size([32, 3, 224, 224]) Loss 0.647964358329773\n",
      "Batch 3. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6618280410766602\n",
      "Batch 4. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6834028959274292\n",
      "Batch 5. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6549893021583557\n",
      "Batch 6. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6497626900672913\n",
      "Batch 7. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6569276452064514\n",
      "Batch 8. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6562955379486084\n",
      "Batch 9. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6600449085235596\n",
      "Batch 10. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6725730895996094\n",
      "Batch 11. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6622446775436401\n",
      "Batch 12. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6569121479988098\n",
      "Batch 13. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6457617878913879\n",
      "Batch 14. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6690236330032349\n",
      "Batch 15. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6623132228851318\n",
      "Batch 16. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6327115297317505\n",
      "Batch 17. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6434895992279053\n",
      "Batch 18. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6634100675582886\n",
      "Batch 19. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6478280425071716\n",
      "Batch 20. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6660371422767639\n",
      "Batch 21. Data shape torch.Size([32, 3, 224, 224]) Loss 0.657375693321228\n",
      "Batch 22. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6427701115608215\n",
      "Batch 23. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6683188676834106\n",
      "Batch 24. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6441332101821899\n",
      "Batch 25. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6761217713356018\n",
      "Batch 26. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6816622018814087\n",
      "Batch 27. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6564575433731079\n",
      "Batch 28. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6619197130203247\n",
      "Batch 29. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6595086455345154\n",
      "Batch 30. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6695127487182617\n",
      "Batch 31. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6676656603813171\n",
      "Batch 32. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6566869616508484\n",
      "Batch 33. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6463632583618164\n",
      "Batch 34. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6453601717948914\n",
      "Batch 35. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6485913395881653\n",
      "Batch 36. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6693443655967712\n",
      "Batch 37. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6616854071617126\n",
      "Batch 38. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6484258770942688\n",
      "Batch 39. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6755645275115967\n",
      "Batch 40. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6518269181251526\n",
      "Batch 41. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6558724045753479\n",
      "Batch 42. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6603531241416931\n",
      "Batch 43. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6358430981636047\n",
      "Batch 44. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6520265340805054\n",
      "Batch 45. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6622282266616821\n",
      "Batch 46. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6554121375083923\n",
      "Batch 47. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6587748527526855\n",
      "Batch 48. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6470760703086853\n",
      "Batch 49. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6659532189369202\n",
      "Batch 50. Data shape torch.Size([32, 3, 224, 224]) Loss 0.662672221660614\n",
      "Batch 51. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6579069495201111\n",
      "Batch 52. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6558941006660461\n",
      "Batch 53. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6690130829811096\n",
      "Batch 54. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6478441953659058\n",
      "Batch 55. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6640756130218506\n",
      "Batch 56. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6529960036277771\n",
      "Batch 57. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6578059196472168\n",
      "Batch 58. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6763834953308105\n",
      "Batch 59. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6543070077896118\n",
      "Batch 60. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6570212841033936\n",
      "Batch 61. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6577094793319702\n",
      "Batch 62. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6528381109237671\n",
      "Batch 63. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6717320680618286\n",
      "Batch 64. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6494420766830444\n",
      "Batch 65. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6500030755996704\n",
      "Batch 66. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6198979616165161\n",
      "Batch 67. Data shape torch.Size([32, 3, 224, 224]) Loss 0.651296854019165\n",
      "Batch 68. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6449667811393738\n",
      "Batch 69. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6546110510826111\n",
      "Batch 70. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6789793372154236\n",
      "Batch 71. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6366913318634033\n",
      "Batch 72. Data shape torch.Size([32, 3, 224, 224]) Loss 0.668344259262085\n",
      "Batch 73. Data shape torch.Size([32, 3, 224, 224]) Loss 0.670609176158905\n",
      "Batch 74. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6581137180328369\n",
      "Batch 75. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6591814160346985\n",
      "Batch 76. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6442738175392151\n",
      "Batch 77. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6670687794685364\n",
      "Batch 78. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6752448081970215\n",
      "Batch 79. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6596940159797668\n",
      "Batch 80. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6790368556976318\n",
      "Batch 81. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6617796421051025\n",
      "Batch 82. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6573591232299805\n",
      "Batch 83. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6437066197395325\n",
      "Batch 84. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6618543863296509\n",
      "Batch 85. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6681757569313049\n",
      "Batch 86. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6583887934684753\n",
      "Batch 87. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6507450938224792\n",
      "Batch 88. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6668270230293274\n",
      "Batch 89. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6475531458854675\n",
      "Batch 90. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6569280028343201\n",
      "Batch 91. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6417169570922852\n",
      "Batch 92. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6613691449165344\n",
      "Batch 93. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6596264839172363\n",
      "Batch 94. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6742734909057617\n",
      "Batch 95. Data shape torch.Size([32, 3, 224, 224]) Loss 0.661652684211731\n",
      "Batch 96. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6580750942230225\n",
      "Batch 97. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6614798903465271\n",
      "Batch 98. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6600045561790466\n",
      "Batch 99. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6540440917015076\n",
      "Batch 100. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6634122133255005\n",
      "Batch 101. Data shape torch.Size([32, 3, 224, 224]) Loss 0.641758918762207\n",
      "Batch 102. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6498369574546814\n",
      "Batch 103. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6491352915763855\n",
      "Batch 104. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6621142625808716\n",
      "Batch 105. Data shape torch.Size([32, 3, 224, 224]) Loss 0.658159077167511\n",
      "Batch 106. Data shape torch.Size([32, 3, 224, 224]) Loss 0.653303861618042\n",
      "Batch 107. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6499784588813782\n",
      "Batch 108. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6661800146102905\n",
      "Batch 109. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6660168766975403\n",
      "Batch 110. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6548353433609009\n",
      "Batch 111. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6496381163597107\n",
      "Batch 112. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6446659564971924\n",
      "Batch 113. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6518958806991577\n",
      "Batch 114. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6352838277816772\n",
      "Batch 115. Data shape torch.Size([32, 3, 224, 224]) Loss 0.660433292388916\n",
      "Batch 116. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6671244502067566\n",
      "Batch 117. Data shape torch.Size([32, 3, 224, 224]) Loss 0.670376718044281\n",
      "Batch 118. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6553425788879395\n",
      "Batch 119. Data shape torch.Size([20, 3, 224, 224]) Loss 0.6654666066169739\n",
      "Valid loss improved from 0.661085 to 0.657551. Saving model ...\n",
      "Epoch: 17/50 | time: 20.0m 46.01s | lr: 1.0000e-05 | train/loss: 0.66055 | val/loss: 0.65755 | val/accuracy: 0.71944 | val/AUC: 0.72216 | val/Kappa: 0.44184\n",
      "Epoch: 18 Train batch 10 loss: 0.6588188409805298, 2.1% complete\n",
      "Epoch: 18 Train batch 20 loss: 0.6589455008506775, 4.2% complete\n",
      "Epoch: 18 Train batch 30 loss: 0.6568538546562195, 6.3% complete\n",
      "Epoch: 18 Train batch 40 loss: 0.6513423323631287, 8.4% complete\n",
      "Epoch: 18 Train batch 50 loss: 0.6318052411079407, 10.5% complete\n",
      "Epoch: 18 Train batch 60 loss: 0.6445358991622925, 12.6% complete\n",
      "Epoch: 18 Train batch 70 loss: 0.6807439923286438, 14.7% complete\n",
      "Epoch: 18 Train batch 80 loss: 0.6410214304924011, 16.8% complete\n",
      "Epoch: 18 Train batch 90 loss: 0.6541323661804199, 18.9% complete\n",
      "Epoch: 18 Train batch 100 loss: 0.6807814836502075, 21.1% complete\n",
      "Epoch: 18 Train batch 110 loss: 0.6633859872817993, 23.2% complete\n",
      "Epoch: 18 Train batch 120 loss: 0.6635407209396362, 25.3% complete\n",
      "Epoch: 18 Train batch 130 loss: 0.6570711135864258, 27.4% complete\n",
      "Epoch: 18 Train batch 140 loss: 0.6648748517036438, 29.5% complete\n",
      "Epoch: 18 Train batch 150 loss: 0.655861496925354, 31.6% complete\n",
      "Epoch: 18 Train batch 160 loss: 0.65360027551651, 33.7% complete\n",
      "Epoch: 18 Train batch 170 loss: 0.6607525944709778, 35.8% complete\n",
      "Epoch: 18 Train batch 180 loss: 0.6720080375671387, 37.9% complete\n",
      "Epoch: 18 Train batch 190 loss: 0.6544303297996521, 40.0% complete\n",
      "Epoch: 18 Train batch 200 loss: 0.663386344909668, 42.1% complete\n",
      "Epoch: 18 Train batch 210 loss: 0.6424343585968018, 44.2% complete\n",
      "Epoch: 18 Train batch 220 loss: 0.6401276588439941, 46.3% complete\n",
      "Epoch: 18 Train batch 230 loss: 0.6674168705940247, 48.4% complete\n",
      "Epoch: 18 Train batch 240 loss: 0.6873918771743774, 50.5% complete\n",
      "Epoch: 18 Train batch 250 loss: 0.6636053919792175, 52.6% complete\n",
      "Epoch: 18 Train batch 260 loss: 0.6753183007240295, 54.7% complete\n",
      "Epoch: 18 Train batch 270 loss: 0.678983211517334, 56.8% complete\n",
      "Epoch: 18 Train batch 280 loss: 0.6383588910102844, 58.9% complete\n",
      "Epoch: 18 Train batch 290 loss: 0.664829432964325, 61.1% complete\n",
      "Epoch: 18 Train batch 300 loss: 0.6401521563529968, 63.2% complete\n",
      "Epoch: 18 Train batch 310 loss: 0.649469792842865, 65.3% complete\n",
      "Epoch: 18 Train batch 320 loss: 0.6429370641708374, 67.4% complete\n",
      "Epoch: 18 Train batch 330 loss: 0.6486437916755676, 69.5% complete\n",
      "Epoch: 18 Train batch 340 loss: 0.6565315127372742, 71.6% complete\n",
      "Epoch: 18 Train batch 350 loss: 0.671191930770874, 73.7% complete\n",
      "Epoch: 18 Train batch 360 loss: 0.64913409948349, 75.8% complete\n",
      "Epoch: 18 Train batch 370 loss: 0.653465986251831, 77.9% complete\n",
      "Epoch: 18 Train batch 380 loss: 0.6451235413551331, 80.0% complete\n",
      "Epoch: 18 Train batch 390 loss: 0.6570664048194885, 82.1% complete\n",
      "Epoch: 18 Train batch 400 loss: 0.6402584910392761, 84.2% complete\n",
      "Epoch: 18 Train batch 410 loss: 0.6641672849655151, 86.3% complete\n",
      "Epoch: 18 Train batch 420 loss: 0.6402353644371033, 88.4% complete\n",
      "Epoch: 18 Train batch 430 loss: 0.6672086119651794, 90.5% complete\n",
      "Epoch: 18 Train batch 440 loss: 0.6321495771408081, 92.6% complete\n",
      "Epoch: 18 Train batch 450 loss: 0.6662172079086304, 94.7% complete\n",
      "Epoch: 18 Train batch 460 loss: 0.6429007053375244, 96.8% complete\n",
      "Epoch: 18 Train batch 470 loss: 0.6490499973297119, 98.9% complete\n",
      "Batch 1. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6634883880615234\n",
      "Batch 2. Data shape torch.Size([32, 3, 224, 224]) Loss 0.656396746635437\n",
      "Batch 3. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6439096927642822\n",
      "Batch 4. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6587451696395874\n",
      "Batch 5. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6575707197189331\n",
      "Batch 6. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6502978205680847\n",
      "Batch 7. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6619032025337219\n",
      "Batch 8. Data shape torch.Size([32, 3, 224, 224]) Loss 0.664371132850647\n",
      "Batch 9. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6504837870597839\n",
      "Batch 10. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6520395278930664\n",
      "Batch 11. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6519153118133545\n",
      "Batch 12. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6570025086402893\n",
      "Batch 13. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6571505069732666\n",
      "Batch 14. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6511527895927429\n",
      "Batch 15. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6507634520530701\n",
      "Batch 16. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6479101181030273\n",
      "Batch 17. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6562405228614807\n",
      "Batch 18. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6466701626777649\n",
      "Batch 19. Data shape torch.Size([32, 3, 224, 224]) Loss 0.646819531917572\n",
      "Batch 20. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6547308564186096\n",
      "Batch 21. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6428724527359009\n",
      "Batch 22. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6463994979858398\n",
      "Batch 23. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6383400559425354\n",
      "Batch 24. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6663041114807129\n",
      "Batch 25. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6476505398750305\n",
      "Batch 26. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6562235951423645\n",
      "Batch 27. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6462715864181519\n",
      "Batch 28. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6744580268859863\n",
      "Batch 29. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6634511351585388\n",
      "Batch 30. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6782824397087097\n",
      "Batch 31. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6782734394073486\n",
      "Batch 32. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6591717600822449\n",
      "Batch 33. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6618462800979614\n",
      "Batch 34. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6493122577667236\n",
      "Batch 35. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6613143682479858\n",
      "Batch 36. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6577003002166748\n",
      "Batch 37. Data shape torch.Size([32, 3, 224, 224]) Loss 0.641478419303894\n",
      "Batch 38. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6446337699890137\n",
      "Batch 39. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6498271226882935\n",
      "Batch 40. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6359694004058838\n",
      "Batch 41. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6566336750984192\n",
      "Batch 42. Data shape torch.Size([32, 3, 224, 224]) Loss 0.656701922416687\n",
      "Batch 43. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6658682823181152\n",
      "Batch 44. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6407678127288818\n",
      "Batch 45. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6671735048294067\n",
      "Batch 46. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6394172310829163\n",
      "Batch 47. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6710546612739563\n",
      "Batch 48. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6260443329811096\n",
      "Batch 49. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6634729504585266\n",
      "Batch 50. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6407630443572998\n",
      "Batch 51. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6444929838180542\n",
      "Batch 52. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6609185934066772\n",
      "Batch 53. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6631743311882019\n",
      "Batch 54. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6534193754196167\n",
      "Batch 55. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6413068175315857\n",
      "Batch 56. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6567509174346924\n",
      "Batch 57. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6707499027252197\n",
      "Batch 58. Data shape torch.Size([32, 3, 224, 224]) Loss 0.649529218673706\n",
      "Batch 59. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6553906798362732\n",
      "Batch 60. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6596165895462036\n",
      "Batch 61. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6548135280609131\n",
      "Batch 62. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6540510058403015\n",
      "Batch 63. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6672158241271973\n",
      "Batch 64. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6656255125999451\n",
      "Batch 65. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6634880304336548\n",
      "Batch 66. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6740845441818237\n",
      "Batch 67. Data shape torch.Size([32, 3, 224, 224]) Loss 0.649512529373169\n",
      "Batch 68. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6393642425537109\n",
      "Batch 69. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6628699898719788\n",
      "Batch 70. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6651299595832825\n",
      "Batch 71. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6614303588867188\n",
      "Batch 72. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6440953612327576\n",
      "Batch 73. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6697881817817688\n",
      "Batch 74. Data shape torch.Size([32, 3, 224, 224]) Loss 0.672170877456665\n",
      "Batch 75. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6766493916511536\n",
      "Batch 76. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6496346592903137\n",
      "Batch 77. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6569079756736755\n",
      "Batch 78. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6577243804931641\n",
      "Batch 79. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6688472628593445\n",
      "Batch 80. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6500260829925537\n",
      "Batch 81. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6597259044647217\n",
      "Batch 82. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6327086091041565\n",
      "Batch 83. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6514589786529541\n",
      "Batch 84. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6773326396942139\n",
      "Batch 85. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6561571359634399\n",
      "Batch 86. Data shape torch.Size([32, 3, 224, 224]) Loss 0.646257758140564\n",
      "Batch 87. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6654030680656433\n",
      "Batch 88. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6355887651443481\n",
      "Batch 89. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6630381345748901\n",
      "Batch 90. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6614663600921631\n",
      "Batch 91. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6616581082344055\n",
      "Batch 92. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6569253206253052\n",
      "Batch 93. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6579664349555969\n",
      "Batch 94. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6594861149787903\n",
      "Batch 95. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6570000052452087\n",
      "Batch 96. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6436091065406799\n",
      "Batch 97. Data shape torch.Size([32, 3, 224, 224]) Loss 0.668936014175415\n",
      "Batch 98. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6555187702178955\n",
      "Batch 99. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6618775725364685\n",
      "Batch 100. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6780069470405579\n",
      "Batch 101. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6514631509780884\n",
      "Batch 102. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6459715366363525\n",
      "Batch 103. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6534399390220642\n",
      "Batch 104. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6479219198226929\n",
      "Batch 105. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6479794383049011\n",
      "Batch 106. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6603320837020874\n",
      "Batch 107. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6602153778076172\n",
      "Batch 108. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6644190549850464\n",
      "Batch 109. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6370862126350403\n",
      "Batch 110. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6483327746391296\n",
      "Batch 111. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6556617021560669\n",
      "Batch 112. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6489953398704529\n",
      "Batch 113. Data shape torch.Size([32, 3, 224, 224]) Loss 0.665676474571228\n",
      "Batch 114. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6445583701133728\n",
      "Batch 115. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6589321494102478\n",
      "Batch 116. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6539568305015564\n",
      "Batch 117. Data shape torch.Size([32, 3, 224, 224]) Loss 0.640947163105011\n",
      "Batch 118. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6429461240768433\n",
      "Batch 119. Data shape torch.Size([20, 3, 224, 224]) Loss 0.6648626327514648\n",
      "Valid loss improved from 0.657551 to 0.655545. Saving model ...\n",
      "Epoch: 18/50 | time: 21.0m 29.19s | lr: 1.0000e-05 | train/loss: 0.65763 | val/loss: 0.65554 | val/accuracy: 0.72787 | val/AUC: 0.73024 | val/Kappa: 0.45823\n",
      "Epoch: 19 Train batch 10 loss: 0.6374760866165161, 2.1% complete\n",
      "Epoch: 19 Train batch 20 loss: 0.6597384214401245, 4.2% complete\n",
      "Epoch: 19 Train batch 30 loss: 0.6685407757759094, 6.3% complete\n",
      "Epoch: 19 Train batch 40 loss: 0.6776129603385925, 8.4% complete\n",
      "Epoch: 19 Train batch 50 loss: 0.6483458280563354, 10.5% complete\n",
      "Epoch: 19 Train batch 60 loss: 0.6426569223403931, 12.6% complete\n",
      "Epoch: 19 Train batch 70 loss: 0.6577883362770081, 14.7% complete\n",
      "Epoch: 19 Train batch 80 loss: 0.655616819858551, 16.8% complete\n",
      "Epoch: 19 Train batch 90 loss: 0.6476500034332275, 18.9% complete\n",
      "Epoch: 19 Train batch 100 loss: 0.6525979042053223, 21.1% complete\n",
      "Epoch: 19 Train batch 110 loss: 0.6461942791938782, 23.2% complete\n",
      "Epoch: 19 Train batch 120 loss: 0.6568121910095215, 25.3% complete\n",
      "Epoch: 19 Train batch 130 loss: 0.6702253818511963, 27.4% complete\n",
      "Epoch: 19 Train batch 140 loss: 0.6407666802406311, 29.5% complete\n",
      "Epoch: 19 Train batch 150 loss: 0.6414602994918823, 31.6% complete\n",
      "Epoch: 19 Train batch 160 loss: 0.6586875915527344, 33.7% complete\n",
      "Epoch: 19 Train batch 170 loss: 0.6641223430633545, 35.8% complete\n",
      "Epoch: 19 Train batch 180 loss: 0.652295708656311, 37.9% complete\n",
      "Epoch: 19 Train batch 190 loss: 0.6611786484718323, 40.0% complete\n",
      "Epoch: 19 Train batch 200 loss: 0.676342785358429, 42.1% complete\n",
      "Epoch: 19 Train batch 210 loss: 0.6426593065261841, 44.2% complete\n",
      "Epoch: 19 Train batch 220 loss: 0.6660486459732056, 46.3% complete\n",
      "Epoch: 19 Train batch 230 loss: 0.6451548337936401, 48.4% complete\n",
      "Epoch: 19 Train batch 240 loss: 0.6745549440383911, 50.5% complete\n",
      "Epoch: 19 Train batch 250 loss: 0.6616666316986084, 52.6% complete\n",
      "Epoch: 19 Train batch 260 loss: 0.6425856947898865, 54.7% complete\n",
      "Epoch: 19 Train batch 270 loss: 0.666495144367218, 56.8% complete\n",
      "Epoch: 19 Train batch 280 loss: 0.6317898035049438, 58.9% complete\n",
      "Epoch: 19 Train batch 290 loss: 0.6857813000679016, 61.1% complete\n",
      "Epoch: 19 Train batch 300 loss: 0.6404023766517639, 63.2% complete\n",
      "Epoch: 19 Train batch 310 loss: 0.6723853349685669, 65.3% complete\n",
      "Epoch: 19 Train batch 320 loss: 0.6858568787574768, 67.4% complete\n",
      "Epoch: 19 Train batch 330 loss: 0.6681044697761536, 69.5% complete\n",
      "Epoch: 19 Train batch 340 loss: 0.6727249622344971, 71.6% complete\n",
      "Epoch: 19 Train batch 350 loss: 0.6754035949707031, 73.7% complete\n",
      "Epoch: 19 Train batch 360 loss: 0.6570691466331482, 75.8% complete\n",
      "Epoch: 19 Train batch 370 loss: 0.6734502911567688, 77.9% complete\n",
      "Epoch: 19 Train batch 380 loss: 0.6360408067703247, 80.0% complete\n",
      "Epoch: 19 Train batch 390 loss: 0.6505610346794128, 82.1% complete\n",
      "Epoch: 19 Train batch 400 loss: 0.6524456739425659, 84.2% complete\n",
      "Epoch: 19 Train batch 410 loss: 0.6620844006538391, 86.3% complete\n",
      "Epoch: 19 Train batch 420 loss: 0.6539091467857361, 88.4% complete\n",
      "Epoch: 19 Train batch 430 loss: 0.6597068905830383, 90.5% complete\n",
      "Epoch: 19 Train batch 440 loss: 0.6276342272758484, 92.6% complete\n",
      "Epoch: 19 Train batch 450 loss: 0.6403911709785461, 94.7% complete\n",
      "Epoch: 19 Train batch 460 loss: 0.6330875158309937, 96.8% complete\n",
      "Epoch: 19 Train batch 470 loss: 0.6357981562614441, 98.9% complete\n",
      "Batch 1. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6616474390029907\n",
      "Batch 2. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6648666262626648\n",
      "Batch 3. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6291725039482117\n",
      "Batch 4. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6542112231254578\n",
      "Batch 5. Data shape torch.Size([32, 3, 224, 224]) Loss 0.650320827960968\n",
      "Batch 6. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6589799523353577\n",
      "Batch 7. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6707834601402283\n",
      "Batch 8. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6539976596832275\n",
      "Batch 9. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6579015851020813\n",
      "Batch 10. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6452260613441467\n",
      "Batch 11. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6567858457565308\n",
      "Batch 12. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6556328535079956\n",
      "Batch 13. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6675293445587158\n",
      "Batch 14. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6426945328712463\n",
      "Batch 15. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6207820773124695\n",
      "Batch 16. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6503345370292664\n",
      "Batch 17. Data shape torch.Size([32, 3, 224, 224]) Loss 0.655569314956665\n",
      "Batch 18. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6462965607643127\n",
      "Batch 19. Data shape torch.Size([32, 3, 224, 224]) Loss 0.63188636302948\n",
      "Batch 20. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6659318804740906\n",
      "Batch 21. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6316820383071899\n",
      "Batch 22. Data shape torch.Size([32, 3, 224, 224]) Loss 0.668441116809845\n",
      "Batch 23. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6264219880104065\n",
      "Batch 24. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6742791533470154\n",
      "Batch 25. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6339015364646912\n",
      "Batch 26. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6518942713737488\n",
      "Batch 27. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6595283150672913\n",
      "Batch 28. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6715399622917175\n",
      "Batch 29. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6473410129547119\n",
      "Batch 30. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6633135080337524\n",
      "Batch 31. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6466168165206909\n",
      "Batch 32. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6642486453056335\n",
      "Batch 33. Data shape torch.Size([32, 3, 224, 224]) Loss 0.649371862411499\n",
      "Batch 34. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6547073125839233\n",
      "Batch 35. Data shape torch.Size([32, 3, 224, 224]) Loss 0.647428035736084\n",
      "Batch 36. Data shape torch.Size([32, 3, 224, 224]) Loss 0.657112717628479\n",
      "Batch 37. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6207258105278015\n",
      "Batch 38. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6603555083274841\n",
      "Batch 39. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6710151433944702\n",
      "Batch 40. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6501467227935791\n",
      "Batch 41. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6620437502861023\n",
      "Batch 42. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6478867530822754\n",
      "Batch 43. Data shape torch.Size([32, 3, 224, 224]) Loss 0.662287712097168\n",
      "Batch 44. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6557079553604126\n",
      "Batch 45. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6379181146621704\n",
      "Batch 46. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6592856049537659\n",
      "Batch 47. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6203509569168091\n",
      "Batch 48. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6575413942337036\n",
      "Batch 49. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6529936790466309\n",
      "Batch 50. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6694625616073608\n",
      "Batch 51. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6386927366256714\n",
      "Batch 52. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6496965885162354\n",
      "Batch 53. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6556395292282104\n",
      "Batch 54. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6540071964263916\n",
      "Batch 55. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6429145932197571\n",
      "Batch 56. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6399413347244263\n",
      "Batch 57. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6467335224151611\n",
      "Batch 58. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6376599669456482\n",
      "Batch 59. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6535018086433411\n",
      "Batch 60. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6577086448669434\n",
      "Batch 61. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6640538573265076\n",
      "Batch 62. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6686490774154663\n",
      "Batch 63. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6433149576187134\n",
      "Batch 64. Data shape torch.Size([32, 3, 224, 224]) Loss 0.650811493396759\n",
      "Batch 65. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6538438200950623\n",
      "Batch 66. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6500297784805298\n",
      "Batch 67. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6584939956665039\n",
      "Batch 68. Data shape torch.Size([32, 3, 224, 224]) Loss 0.672775387763977\n",
      "Batch 69. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6336283087730408\n",
      "Batch 70. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6682031750679016\n",
      "Batch 71. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6479825973510742\n",
      "Batch 72. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6557414531707764\n",
      "Batch 73. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6411466598510742\n",
      "Batch 74. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6462166905403137\n",
      "Batch 75. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6398192644119263\n",
      "Batch 76. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6723565459251404\n",
      "Batch 77. Data shape torch.Size([32, 3, 224, 224]) Loss 0.665120005607605\n",
      "Batch 78. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6490058898925781\n",
      "Batch 79. Data shape torch.Size([32, 3, 224, 224]) Loss 0.644748866558075\n",
      "Batch 80. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6349035501480103\n",
      "Batch 81. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6532313227653503\n",
      "Batch 82. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6532459855079651\n",
      "Batch 83. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6690133213996887\n",
      "Batch 84. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6579119563102722\n",
      "Batch 85. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6506420373916626\n",
      "Batch 86. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6519132852554321\n",
      "Batch 87. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6491069793701172\n",
      "Batch 88. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6485142111778259\n",
      "Batch 89. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6546660661697388\n",
      "Batch 90. Data shape torch.Size([32, 3, 224, 224]) Loss 0.63872230052948\n",
      "Batch 91. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6408321857452393\n",
      "Batch 92. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6504735350608826\n",
      "Batch 93. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6581804156303406\n",
      "Batch 94. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6516303420066833\n",
      "Batch 95. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6555085182189941\n",
      "Batch 96. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6721837520599365\n",
      "Batch 97. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6439141631126404\n",
      "Batch 98. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6330621838569641\n",
      "Batch 99. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6693360209465027\n",
      "Batch 100. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6246588230133057\n",
      "Batch 101. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6532147526741028\n",
      "Batch 102. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6520439982414246\n",
      "Batch 103. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6345544457435608\n",
      "Batch 104. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6369020342826843\n",
      "Batch 105. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6570420861244202\n",
      "Batch 106. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6395962834358215\n",
      "Batch 107. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6621712446212769\n",
      "Batch 108. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6614533066749573\n",
      "Batch 109. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6562694907188416\n",
      "Batch 110. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6647363305091858\n",
      "Batch 111. Data shape torch.Size([32, 3, 224, 224]) Loss 0.64161217212677\n",
      "Batch 112. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6568315029144287\n",
      "Batch 113. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6442757844924927\n",
      "Batch 114. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6455369591712952\n",
      "Batch 115. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6455602645874023\n",
      "Batch 116. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6450142860412598\n",
      "Batch 117. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6488093137741089\n",
      "Batch 118. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6416186094284058\n",
      "Batch 119. Data shape torch.Size([20, 3, 224, 224]) Loss 0.6535182595252991\n",
      "Valid loss improved from 0.655545 to 0.651437. Saving model ...\n",
      "Epoch: 19/50 | time: 21.0m 40.17s | lr: 1.0000e-05 | train/loss: 0.65488 | val/loss: 0.65144 | val/accuracy: 0.74078 | val/AUC: 0.74266 | val/Kappa: 0.48343\n",
      "Epoch: 20 Train batch 10 loss: 0.6522880792617798, 2.1% complete\n",
      "Epoch: 20 Train batch 20 loss: 0.6378263235092163, 4.2% complete\n",
      "Epoch: 20 Train batch 30 loss: 0.679408609867096, 6.3% complete\n",
      "Epoch: 20 Train batch 40 loss: 0.6720899343490601, 8.4% complete\n",
      "Epoch: 20 Train batch 50 loss: 0.6505157947540283, 10.5% complete\n",
      "Epoch: 20 Train batch 60 loss: 0.6445340514183044, 12.6% complete\n",
      "Epoch: 20 Train batch 70 loss: 0.6458578109741211, 14.7% complete\n",
      "Epoch: 20 Train batch 80 loss: 0.6452113389968872, 16.8% complete\n",
      "Epoch: 20 Train batch 90 loss: 0.6717308163642883, 18.9% complete\n",
      "Epoch: 20 Train batch 100 loss: 0.6518601179122925, 21.1% complete\n",
      "Epoch: 20 Train batch 110 loss: 0.6575196981430054, 23.2% complete\n",
      "Epoch: 20 Train batch 120 loss: 0.646514356136322, 25.3% complete\n",
      "Epoch: 20 Train batch 130 loss: 0.6697289943695068, 27.4% complete\n",
      "Epoch: 20 Train batch 140 loss: 0.6690745949745178, 29.5% complete\n",
      "Epoch: 20 Train batch 150 loss: 0.6571162343025208, 31.6% complete\n",
      "Epoch: 20 Train batch 160 loss: 0.6383896470069885, 33.7% complete\n",
      "Epoch: 20 Train batch 170 loss: 0.6414470672607422, 35.8% complete\n",
      "Epoch: 20 Train batch 180 loss: 0.6576629877090454, 37.9% complete\n",
      "Epoch: 20 Train batch 190 loss: 0.6235854029655457, 40.0% complete\n",
      "Epoch: 20 Train batch 200 loss: 0.6578077673912048, 42.1% complete\n",
      "Epoch: 20 Train batch 210 loss: 0.6376626491546631, 44.2% complete\n",
      "Epoch: 20 Train batch 220 loss: 0.6393117904663086, 46.3% complete\n",
      "Epoch: 20 Train batch 230 loss: 0.6465963125228882, 48.4% complete\n",
      "Epoch: 20 Train batch 240 loss: 0.6408662796020508, 50.5% complete\n",
      "Epoch: 20 Train batch 250 loss: 0.6547022461891174, 52.6% complete\n",
      "Epoch: 20 Train batch 260 loss: 0.6534197330474854, 54.7% complete\n",
      "Epoch: 20 Train batch 270 loss: 0.6305372714996338, 56.8% complete\n",
      "Epoch: 20 Train batch 280 loss: 0.6633736491203308, 58.9% complete\n",
      "Epoch: 20 Train batch 290 loss: 0.6525375247001648, 61.1% complete\n",
      "Epoch: 20 Train batch 300 loss: 0.6296614408493042, 63.2% complete\n",
      "Epoch: 20 Train batch 310 loss: 0.6667142510414124, 65.3% complete\n",
      "Epoch: 20 Train batch 320 loss: 0.6483856439590454, 67.4% complete\n",
      "Epoch: 20 Train batch 330 loss: 0.6427879333496094, 69.5% complete\n",
      "Epoch: 20 Train batch 340 loss: 0.6633510589599609, 71.6% complete\n",
      "Epoch: 20 Train batch 350 loss: 0.6631906628608704, 73.7% complete\n",
      "Epoch: 20 Train batch 360 loss: 0.6503274440765381, 75.8% complete\n",
      "Epoch: 20 Train batch 370 loss: 0.6387571096420288, 77.9% complete\n",
      "Epoch: 20 Train batch 380 loss: 0.6382133364677429, 80.0% complete\n",
      "Epoch: 20 Train batch 390 loss: 0.6504706740379333, 82.1% complete\n",
      "Epoch: 20 Train batch 400 loss: 0.6604745388031006, 84.2% complete\n",
      "Epoch: 20 Train batch 410 loss: 0.6322386860847473, 86.3% complete\n",
      "Epoch: 20 Train batch 420 loss: 0.654945969581604, 88.4% complete\n",
      "Epoch: 20 Train batch 430 loss: 0.6396398544311523, 90.5% complete\n",
      "Epoch: 20 Train batch 440 loss: 0.64057856798172, 92.6% complete\n",
      "Epoch: 20 Train batch 450 loss: 0.644926130771637, 94.7% complete\n",
      "Epoch: 20 Train batch 460 loss: 0.6425058245658875, 96.8% complete\n",
      "Epoch: 20 Train batch 470 loss: 0.6402673125267029, 98.9% complete\n",
      "Batch 1. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6437591314315796\n",
      "Batch 2. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6350029110908508\n",
      "Batch 3. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6504528522491455\n",
      "Batch 4. Data shape torch.Size([32, 3, 224, 224]) Loss 0.658050000667572\n",
      "Batch 5. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6643921136856079\n",
      "Batch 6. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6223843097686768\n",
      "Batch 7. Data shape torch.Size([32, 3, 224, 224]) Loss 0.625382661819458\n",
      "Batch 8. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6616330146789551\n",
      "Batch 9. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6590409874916077\n",
      "Batch 10. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6222745180130005\n",
      "Batch 11. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6658287644386292\n",
      "Batch 12. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6352140307426453\n",
      "Batch 13. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6398212909698486\n",
      "Batch 14. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6362901329994202\n",
      "Batch 15. Data shape torch.Size([32, 3, 224, 224]) Loss 0.667123019695282\n",
      "Batch 16. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6058716773986816\n",
      "Batch 17. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6487160325050354\n",
      "Batch 18. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6401123404502869\n",
      "Batch 19. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6337468028068542\n",
      "Batch 20. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6557856202125549\n",
      "Batch 21. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6413566470146179\n",
      "Batch 22. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6446236968040466\n",
      "Batch 23. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6387661695480347\n",
      "Batch 24. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6401065587997437\n",
      "Batch 25. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6081597805023193\n",
      "Batch 26. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6748005151748657\n",
      "Batch 27. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6608242392539978\n",
      "Batch 28. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6423152089118958\n",
      "Batch 29. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6191306114196777\n",
      "Batch 30. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6571279764175415\n",
      "Batch 31. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6352686882019043\n",
      "Batch 32. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6633703708648682\n",
      "Batch 33. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6432101726531982\n",
      "Batch 34. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6676990389823914\n",
      "Batch 35. Data shape torch.Size([32, 3, 224, 224]) Loss 0.636699378490448\n",
      "Batch 36. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6265297532081604\n",
      "Batch 37. Data shape torch.Size([32, 3, 224, 224]) Loss 0.665738046169281\n",
      "Batch 38. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6436920166015625\n",
      "Batch 39. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6584720611572266\n",
      "Batch 40. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6526496410369873\n",
      "Batch 41. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6502677798271179\n",
      "Batch 42. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6383097171783447\n",
      "Batch 43. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6580259799957275\n",
      "Batch 44. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6519078612327576\n",
      "Batch 45. Data shape torch.Size([32, 3, 224, 224]) Loss 0.639595627784729\n",
      "Batch 46. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6386946439743042\n",
      "Batch 47. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6269034147262573\n",
      "Batch 48. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6391886472702026\n",
      "Batch 49. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6547805070877075\n",
      "Batch 50. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6603724360466003\n",
      "Batch 51. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6555652022361755\n",
      "Batch 52. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6460753679275513\n",
      "Batch 53. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6557865142822266\n",
      "Batch 54. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6595848202705383\n",
      "Batch 55. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6188547015190125\n",
      "Batch 56. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6513293981552124\n",
      "Batch 57. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6534802317619324\n",
      "Batch 58. Data shape torch.Size([32, 3, 224, 224]) Loss 0.662753164768219\n",
      "Batch 59. Data shape torch.Size([32, 3, 224, 224]) Loss 0.669327974319458\n",
      "Batch 60. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6412196159362793\n",
      "Batch 61. Data shape torch.Size([32, 3, 224, 224]) Loss 0.649819552898407\n",
      "Batch 62. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6430361866950989\n",
      "Batch 63. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6578114032745361\n",
      "Batch 64. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6588872671127319\n",
      "Batch 65. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6397586464881897\n",
      "Batch 66. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6500185132026672\n",
      "Batch 67. Data shape torch.Size([32, 3, 224, 224]) Loss 0.648596465587616\n",
      "Batch 68. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6584256291389465\n",
      "Batch 69. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6650300621986389\n",
      "Batch 70. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6423836350440979\n",
      "Batch 71. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6395224332809448\n",
      "Batch 72. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6561048030853271\n",
      "Batch 73. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6489127278327942\n",
      "Batch 74. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6407744884490967\n",
      "Batch 75. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6506820917129517\n",
      "Batch 76. Data shape torch.Size([32, 3, 224, 224]) Loss 0.643150269985199\n",
      "Batch 77. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6274203658103943\n",
      "Batch 78. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6423621773719788\n",
      "Batch 79. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6432324051856995\n",
      "Batch 80. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6678574085235596\n",
      "Batch 81. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6897947788238525\n",
      "Batch 82. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6806984543800354\n",
      "Batch 83. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6521987915039062\n",
      "Batch 84. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6588281989097595\n",
      "Batch 85. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6368902921676636\n",
      "Batch 86. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6436949968338013\n",
      "Batch 87. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6379646062850952\n",
      "Batch 88. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6545047163963318\n",
      "Batch 89. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6456666588783264\n",
      "Batch 90. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6554790139198303\n",
      "Batch 91. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6514376997947693\n",
      "Batch 92. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6476103067398071\n",
      "Batch 93. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6368098258972168\n",
      "Batch 94. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6338711977005005\n",
      "Batch 95. Data shape torch.Size([32, 3, 224, 224]) Loss 0.641586184501648\n",
      "Batch 96. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6508634090423584\n",
      "Batch 97. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6424604654312134\n",
      "Batch 98. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6159237623214722\n",
      "Batch 99. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6380285620689392\n",
      "Batch 100. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6179361343383789\n",
      "Batch 101. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6451207399368286\n",
      "Batch 102. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6724446415901184\n",
      "Batch 103. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6531897187232971\n",
      "Batch 104. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6158679127693176\n",
      "Batch 105. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6537453532218933\n",
      "Batch 106. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6486362814903259\n",
      "Batch 107. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6604101657867432\n",
      "Batch 108. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6631807684898376\n",
      "Batch 109. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6436085104942322\n",
      "Batch 110. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6549326777458191\n",
      "Batch 111. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6718260049819946\n",
      "Batch 112. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6646203994750977\n",
      "Batch 113. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6749053597450256\n",
      "Batch 114. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6253201365470886\n",
      "Batch 115. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6576477289199829\n",
      "Batch 116. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6766882538795471\n",
      "Batch 117. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6320939660072327\n",
      "Batch 118. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6342417001724243\n",
      "Batch 119. Data shape torch.Size([20, 3, 224, 224]) Loss 0.642695426940918\n",
      "Valid loss improved from 0.651437 to 0.647569. Saving model ...\n",
      "Epoch: 20/50 | time: 21.0m 48.79s | lr: 1.0000e-05 | train/loss: 0.65190 | val/loss: 0.64757 | val/accuracy: 0.73762 | val/AUC: 0.73977 | val/Kappa: 0.47741\n",
      "Epoch: 21 Train batch 10 loss: 0.6281933784484863, 2.1% complete\n",
      "Epoch: 21 Train batch 20 loss: 0.6556069850921631, 4.2% complete\n",
      "Epoch: 21 Train batch 30 loss: 0.6215245127677917, 6.3% complete\n",
      "Epoch: 21 Train batch 40 loss: 0.6554264426231384, 8.4% complete\n",
      "Epoch: 21 Train batch 50 loss: 0.6407435536384583, 10.5% complete\n",
      "Epoch: 21 Train batch 60 loss: 0.6505833864212036, 12.6% complete\n",
      "Epoch: 21 Train batch 70 loss: 0.653766393661499, 14.7% complete\n",
      "Epoch: 21 Train batch 80 loss: 0.6446714997291565, 16.8% complete\n",
      "Epoch: 21 Train batch 90 loss: 0.6462662816047668, 18.9% complete\n",
      "Epoch: 21 Train batch 100 loss: 0.6331647634506226, 21.1% complete\n",
      "Epoch: 21 Train batch 110 loss: 0.6712731719017029, 23.2% complete\n",
      "Epoch: 21 Train batch 120 loss: 0.64315265417099, 25.3% complete\n",
      "Epoch: 21 Train batch 130 loss: 0.6473268270492554, 27.4% complete\n",
      "Epoch: 21 Train batch 140 loss: 0.6414291858673096, 29.5% complete\n",
      "Epoch: 21 Train batch 150 loss: 0.6549473404884338, 31.6% complete\n",
      "Epoch: 21 Train batch 160 loss: 0.6412680745124817, 33.7% complete\n",
      "Epoch: 21 Train batch 170 loss: 0.6503495573997498, 35.8% complete\n",
      "Epoch: 21 Train batch 180 loss: 0.6337496042251587, 37.9% complete\n",
      "Epoch: 21 Train batch 190 loss: 0.645690381526947, 40.0% complete\n",
      "Epoch: 21 Train batch 200 loss: 0.6449512243270874, 42.1% complete\n",
      "Epoch: 21 Train batch 210 loss: 0.6629070043563843, 44.2% complete\n",
      "Epoch: 21 Train batch 220 loss: 0.6457211375236511, 46.3% complete\n",
      "Epoch: 21 Train batch 230 loss: 0.6326227188110352, 48.4% complete\n",
      "Epoch: 21 Train batch 240 loss: 0.633786141872406, 50.5% complete\n",
      "Epoch: 21 Train batch 250 loss: 0.6509351134300232, 52.6% complete\n",
      "Epoch: 21 Train batch 260 loss: 0.6351315379142761, 54.7% complete\n",
      "Epoch: 21 Train batch 270 loss: 0.6682553291320801, 56.8% complete\n",
      "Epoch: 21 Train batch 280 loss: 0.6574805378913879, 58.9% complete\n",
      "Epoch: 21 Train batch 290 loss: 0.6569548845291138, 61.1% complete\n",
      "Epoch: 21 Train batch 300 loss: 0.6474092602729797, 63.2% complete\n",
      "Epoch: 21 Train batch 310 loss: 0.6159752011299133, 65.3% complete\n",
      "Epoch: 21 Train batch 320 loss: 0.6397513747215271, 67.4% complete\n",
      "Epoch: 21 Train batch 330 loss: 0.6517208814620972, 69.5% complete\n",
      "Epoch: 21 Train batch 340 loss: 0.665052592754364, 71.6% complete\n",
      "Epoch: 21 Train batch 350 loss: 0.6357808709144592, 73.7% complete\n",
      "Epoch: 21 Train batch 360 loss: 0.6285795569419861, 75.8% complete\n",
      "Epoch: 21 Train batch 370 loss: 0.6690386533737183, 77.9% complete\n",
      "Epoch: 21 Train batch 380 loss: 0.6375940442085266, 80.0% complete\n",
      "Epoch: 21 Train batch 390 loss: 0.6280792951583862, 82.1% complete\n",
      "Epoch: 21 Train batch 400 loss: 0.6416800022125244, 84.2% complete\n",
      "Epoch: 21 Train batch 410 loss: 0.650431752204895, 86.3% complete\n",
      "Epoch: 21 Train batch 420 loss: 0.6236142516136169, 88.4% complete\n",
      "Epoch: 21 Train batch 430 loss: 0.638739287853241, 90.5% complete\n",
      "Epoch: 21 Train batch 440 loss: 0.6528230905532837, 92.6% complete\n",
      "Epoch: 21 Train batch 450 loss: 0.6729931235313416, 94.7% complete\n",
      "Epoch: 21 Train batch 460 loss: 0.6544950604438782, 96.8% complete\n",
      "Epoch: 21 Train batch 470 loss: 0.6386091709136963, 98.9% complete\n",
      "Batch 1. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6345272660255432\n",
      "Batch 2. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6423258781433105\n",
      "Batch 3. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6305026412010193\n",
      "Batch 4. Data shape torch.Size([32, 3, 224, 224]) Loss 0.668502688407898\n",
      "Batch 5. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6661393046379089\n",
      "Batch 6. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6368838548660278\n",
      "Batch 7. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6481944918632507\n",
      "Batch 8. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6230708956718445\n",
      "Batch 9. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6419626474380493\n",
      "Batch 10. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6687842011451721\n",
      "Batch 11. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6698882579803467\n",
      "Batch 12. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6583325862884521\n",
      "Batch 13. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6244515776634216\n",
      "Batch 14. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6450857520103455\n",
      "Batch 15. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6423643231391907\n",
      "Batch 16. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6204206943511963\n",
      "Batch 17. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6657435297966003\n",
      "Batch 18. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6381902694702148\n",
      "Batch 19. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6508968472480774\n",
      "Batch 20. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6518424153327942\n",
      "Batch 21. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6146161556243896\n",
      "Batch 22. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6341350078582764\n",
      "Batch 23. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6439945697784424\n",
      "Batch 24. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6501900553703308\n",
      "Batch 25. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6576780676841736\n",
      "Batch 26. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6541995406150818\n",
      "Batch 27. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6444724798202515\n",
      "Batch 28. Data shape torch.Size([32, 3, 224, 224]) Loss 0.660228431224823\n",
      "Batch 29. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6426892876625061\n",
      "Batch 30. Data shape torch.Size([32, 3, 224, 224]) Loss 0.620328426361084\n",
      "Batch 31. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6285973191261292\n",
      "Batch 32. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6486631035804749\n",
      "Batch 33. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6145378947257996\n",
      "Batch 34. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6393003463745117\n",
      "Batch 35. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6296160221099854\n",
      "Batch 36. Data shape torch.Size([32, 3, 224, 224]) Loss 0.639712393283844\n",
      "Batch 37. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6507242918014526\n",
      "Batch 38. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6568157076835632\n",
      "Batch 39. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6330706477165222\n",
      "Batch 40. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6572469472885132\n",
      "Batch 41. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6142627000808716\n",
      "Batch 42. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6531983613967896\n",
      "Batch 43. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6560286283493042\n",
      "Batch 44. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6478810906410217\n",
      "Batch 45. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6458343267440796\n",
      "Batch 46. Data shape torch.Size([32, 3, 224, 224]) Loss 0.662318766117096\n",
      "Batch 47. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6591958999633789\n",
      "Batch 48. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6507322192192078\n",
      "Batch 49. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6406232118606567\n",
      "Batch 50. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6536860466003418\n",
      "Batch 51. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6708875298500061\n",
      "Batch 52. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6466593742370605\n",
      "Batch 53. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6544283628463745\n",
      "Batch 54. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6519683003425598\n",
      "Batch 55. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6226040124893188\n",
      "Batch 56. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6413916349411011\n",
      "Batch 57. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6381548047065735\n",
      "Batch 58. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6429433822631836\n",
      "Batch 59. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6258390545845032\n",
      "Batch 60. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6592097878456116\n",
      "Batch 61. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6526913642883301\n",
      "Batch 62. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6312288045883179\n",
      "Batch 63. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6447698473930359\n",
      "Batch 64. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6488164663314819\n",
      "Batch 65. Data shape torch.Size([32, 3, 224, 224]) Loss 0.630646824836731\n",
      "Batch 66. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6463461518287659\n",
      "Batch 67. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6331974267959595\n",
      "Batch 68. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6619394421577454\n",
      "Batch 69. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6276808977127075\n",
      "Batch 70. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6471070051193237\n",
      "Batch 71. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6481738090515137\n",
      "Batch 72. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6372396945953369\n",
      "Batch 73. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6604583263397217\n",
      "Batch 74. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6319864392280579\n",
      "Batch 75. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6560249924659729\n",
      "Batch 76. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6559110283851624\n",
      "Batch 77. Data shape torch.Size([32, 3, 224, 224]) Loss 0.653977632522583\n",
      "Batch 78. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6424289345741272\n",
      "Batch 79. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6556441187858582\n",
      "Batch 80. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6550074219703674\n",
      "Batch 81. Data shape torch.Size([32, 3, 224, 224]) Loss 0.657493531703949\n",
      "Batch 82. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6576367616653442\n",
      "Batch 83. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6428943276405334\n",
      "Batch 84. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6346173882484436\n",
      "Batch 85. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6293426752090454\n",
      "Batch 86. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6375643610954285\n",
      "Batch 87. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6376078128814697\n",
      "Batch 88. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6244217157363892\n",
      "Batch 89. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6491464972496033\n",
      "Batch 90. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6545096039772034\n",
      "Batch 91. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6484891772270203\n",
      "Batch 92. Data shape torch.Size([32, 3, 224, 224]) Loss 0.629967451095581\n",
      "Batch 93. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6405085921287537\n",
      "Batch 94. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6394251585006714\n",
      "Batch 95. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6517429351806641\n",
      "Batch 96. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6596223711967468\n",
      "Batch 97. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6350082159042358\n",
      "Batch 98. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6292544007301331\n",
      "Batch 99. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6242077350616455\n",
      "Batch 100. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6431442499160767\n",
      "Batch 101. Data shape torch.Size([32, 3, 224, 224]) Loss 0.659135639667511\n",
      "Batch 102. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6647328734397888\n",
      "Batch 103. Data shape torch.Size([32, 3, 224, 224]) Loss 0.654543399810791\n",
      "Batch 104. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6353776454925537\n",
      "Batch 105. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6128328442573547\n",
      "Batch 106. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6545331478118896\n",
      "Batch 107. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6324183940887451\n",
      "Batch 108. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6609013080596924\n",
      "Batch 109. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6302662491798401\n",
      "Batch 110. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6656152009963989\n",
      "Batch 111. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6160286664962769\n",
      "Batch 112. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6427484750747681\n",
      "Batch 113. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6553995609283447\n",
      "Batch 114. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6891598701477051\n",
      "Batch 115. Data shape torch.Size([32, 3, 224, 224]) Loss 0.666458249092102\n",
      "Batch 116. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6464746594429016\n",
      "Batch 117. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6285516023635864\n",
      "Batch 118. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6587710976600647\n",
      "Batch 119. Data shape torch.Size([20, 3, 224, 224]) Loss 0.6287587881088257\n",
      "Valid loss improved from 0.647569 to 0.644852. Saving model ...\n",
      "Epoch: 21/50 | time: 21.0m 59.78s | lr: 1.0000e-05 | train/loss: 0.64834 | val/loss: 0.64485 | val/accuracy: 0.74341 | val/AUC: 0.74496 | val/Kappa: 0.48833\n",
      "Epoch: 22 Train batch 10 loss: 0.626528263092041, 2.1% complete\n",
      "Epoch: 22 Train batch 20 loss: 0.6348832249641418, 4.2% complete\n",
      "Epoch: 22 Train batch 30 loss: 0.6578845977783203, 6.3% complete\n",
      "Epoch: 22 Train batch 40 loss: 0.6280344128608704, 8.4% complete\n",
      "Epoch: 22 Train batch 50 loss: 0.6470038294792175, 10.5% complete\n",
      "Epoch: 22 Train batch 60 loss: 0.683631420135498, 12.6% complete\n",
      "Epoch: 22 Train batch 70 loss: 0.6400507688522339, 14.7% complete\n",
      "Epoch: 22 Train batch 80 loss: 0.6550461649894714, 16.8% complete\n",
      "Epoch: 22 Train batch 90 loss: 0.6028398275375366, 18.9% complete\n",
      "Epoch: 22 Train batch 100 loss: 0.6286150217056274, 21.1% complete\n",
      "Epoch: 22 Train batch 110 loss: 0.6631596088409424, 23.2% complete\n",
      "Epoch: 22 Train batch 120 loss: 0.6141204833984375, 25.3% complete\n",
      "Epoch: 22 Train batch 130 loss: 0.6497664451599121, 27.4% complete\n",
      "Epoch: 22 Train batch 140 loss: 0.6444547176361084, 29.5% complete\n",
      "Epoch: 22 Train batch 150 loss: 0.6257609724998474, 31.6% complete\n",
      "Epoch: 22 Train batch 160 loss: 0.6522775292396545, 33.7% complete\n",
      "Epoch: 22 Train batch 170 loss: 0.624765157699585, 35.8% complete\n",
      "Epoch: 22 Train batch 180 loss: 0.685884416103363, 37.9% complete\n",
      "Epoch: 22 Train batch 190 loss: 0.6125838756561279, 40.0% complete\n",
      "Epoch: 22 Train batch 200 loss: 0.6672698855400085, 42.1% complete\n",
      "Epoch: 22 Train batch 210 loss: 0.6395216584205627, 44.2% complete\n",
      "Epoch: 22 Train batch 220 loss: 0.6512467861175537, 46.3% complete\n",
      "Epoch: 22 Train batch 230 loss: 0.6406518816947937, 48.4% complete\n",
      "Epoch: 22 Train batch 240 loss: 0.6694024205207825, 50.5% complete\n",
      "Epoch: 22 Train batch 250 loss: 0.650015115737915, 52.6% complete\n",
      "Epoch: 22 Train batch 260 loss: 0.6623944044113159, 54.7% complete\n",
      "Epoch: 22 Train batch 270 loss: 0.6524295806884766, 56.8% complete\n",
      "Epoch: 22 Train batch 280 loss: 0.625477135181427, 58.9% complete\n",
      "Epoch: 22 Train batch 290 loss: 0.6407008767127991, 61.1% complete\n",
      "Epoch: 22 Train batch 300 loss: 0.6454736590385437, 63.2% complete\n",
      "Epoch: 22 Train batch 310 loss: 0.6551238894462585, 65.3% complete\n",
      "Epoch: 22 Train batch 320 loss: 0.6580312252044678, 67.4% complete\n",
      "Epoch: 22 Train batch 330 loss: 0.6388062834739685, 69.5% complete\n",
      "Epoch: 22 Train batch 340 loss: 0.6315039992332458, 71.6% complete\n",
      "Epoch: 22 Train batch 350 loss: 0.6482320427894592, 73.7% complete\n",
      "Epoch: 22 Train batch 360 loss: 0.6525803804397583, 75.8% complete\n",
      "Epoch: 22 Train batch 370 loss: 0.6343579292297363, 77.9% complete\n",
      "Epoch: 22 Train batch 380 loss: 0.6430124640464783, 80.0% complete\n",
      "Epoch: 22 Train batch 390 loss: 0.6330305933952332, 82.1% complete\n",
      "Epoch: 22 Train batch 400 loss: 0.6401286125183105, 84.2% complete\n",
      "Epoch: 22 Train batch 410 loss: 0.6310288906097412, 86.3% complete\n",
      "Epoch: 22 Train batch 420 loss: 0.613932728767395, 88.4% complete\n",
      "Epoch: 22 Train batch 430 loss: 0.6583421230316162, 90.5% complete\n",
      "Epoch: 22 Train batch 440 loss: 0.612958550453186, 92.6% complete\n",
      "Epoch: 22 Train batch 450 loss: 0.6608650088310242, 94.7% complete\n",
      "Epoch: 22 Train batch 460 loss: 0.6695623397827148, 96.8% complete\n",
      "Epoch: 22 Train batch 470 loss: 0.6241170167922974, 98.9% complete\n",
      "Batch 1. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6529350876808167\n",
      "Batch 2. Data shape torch.Size([32, 3, 224, 224]) Loss 0.633969783782959\n",
      "Batch 3. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6254186034202576\n",
      "Batch 4. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6421640515327454\n",
      "Batch 5. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6454014778137207\n",
      "Batch 6. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6561883687973022\n",
      "Batch 7. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6426651477813721\n",
      "Batch 8. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6191493272781372\n",
      "Batch 9. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6357860565185547\n",
      "Batch 10. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6195946931838989\n",
      "Batch 11. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6577032804489136\n",
      "Batch 12. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6191300749778748\n",
      "Batch 13. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6375083327293396\n",
      "Batch 14. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6509059071540833\n",
      "Batch 15. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6396562457084656\n",
      "Batch 16. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6561279892921448\n",
      "Batch 17. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6496378183364868\n",
      "Batch 18. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6318037509918213\n",
      "Batch 19. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6294334530830383\n",
      "Batch 20. Data shape torch.Size([32, 3, 224, 224]) Loss 0.65503990650177\n",
      "Batch 21. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6432902216911316\n",
      "Batch 22. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6594579815864563\n",
      "Batch 23. Data shape torch.Size([32, 3, 224, 224]) Loss 0.65943443775177\n",
      "Batch 24. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6483262777328491\n",
      "Batch 25. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6498316526412964\n",
      "Batch 26. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6377114057540894\n",
      "Batch 27. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6347739696502686\n",
      "Batch 28. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6438829898834229\n",
      "Batch 29. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6600537300109863\n",
      "Batch 30. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6203410029411316\n",
      "Batch 31. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6268607974052429\n",
      "Batch 32. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6642307639122009\n",
      "Batch 33. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6516171097755432\n",
      "Batch 34. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6414461731910706\n",
      "Batch 35. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6599329710006714\n",
      "Batch 36. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6277973651885986\n",
      "Batch 37. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6428838968276978\n",
      "Batch 38. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6528568267822266\n",
      "Batch 39. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6406686902046204\n",
      "Batch 40. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6697537899017334\n",
      "Batch 41. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6462432146072388\n",
      "Batch 42. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6569936871528625\n",
      "Batch 43. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6581863760948181\n",
      "Batch 44. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6182665824890137\n",
      "Batch 45. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6311190128326416\n",
      "Batch 46. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6661427617073059\n",
      "Batch 47. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6607252955436707\n",
      "Batch 48. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6424070596694946\n",
      "Batch 49. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6233438849449158\n",
      "Batch 50. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6333494186401367\n",
      "Batch 51. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6313679218292236\n",
      "Batch 52. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6334133148193359\n",
      "Batch 53. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6401088833808899\n",
      "Batch 54. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6174789667129517\n",
      "Batch 55. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6749716997146606\n",
      "Batch 56. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6434818506240845\n",
      "Batch 57. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6381742358207703\n",
      "Batch 58. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6250489950180054\n",
      "Batch 59. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6417492032051086\n",
      "Batch 60. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6358646154403687\n",
      "Batch 61. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6341256499290466\n",
      "Batch 62. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6387685537338257\n",
      "Batch 63. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6388084888458252\n",
      "Batch 64. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6237961649894714\n",
      "Batch 65. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6607794761657715\n",
      "Batch 66. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6569285988807678\n",
      "Batch 67. Data shape torch.Size([32, 3, 224, 224]) Loss 0.67209792137146\n",
      "Batch 68. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6395050287246704\n",
      "Batch 69. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6575933694839478\n",
      "Batch 70. Data shape torch.Size([32, 3, 224, 224]) Loss 0.640608549118042\n",
      "Batch 71. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6591512560844421\n",
      "Batch 72. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6393498778343201\n",
      "Batch 73. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6507778763771057\n",
      "Batch 74. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6181800365447998\n",
      "Batch 75. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6298756003379822\n",
      "Batch 76. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6465083360671997\n",
      "Batch 77. Data shape torch.Size([32, 3, 224, 224]) Loss 0.649811863899231\n",
      "Batch 78. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6194652915000916\n",
      "Batch 79. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6361929774284363\n",
      "Batch 80. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6429368853569031\n",
      "Batch 81. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6635807752609253\n",
      "Batch 82. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6328893899917603\n",
      "Batch 83. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6414476037025452\n",
      "Batch 84. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6239352822303772\n",
      "Batch 85. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6426411867141724\n",
      "Batch 86. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6400636434555054\n",
      "Batch 87. Data shape torch.Size([32, 3, 224, 224]) Loss 0.669237494468689\n",
      "Batch 88. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6153628826141357\n",
      "Batch 89. Data shape torch.Size([32, 3, 224, 224]) Loss 0.597588837146759\n",
      "Batch 90. Data shape torch.Size([32, 3, 224, 224]) Loss 0.655920147895813\n",
      "Batch 91. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6410606503486633\n",
      "Batch 92. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6326728463172913\n",
      "Batch 93. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6250643730163574\n",
      "Batch 94. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6534233093261719\n",
      "Batch 95. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6383224129676819\n",
      "Batch 96. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6400611996650696\n",
      "Batch 97. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6469143033027649\n",
      "Batch 98. Data shape torch.Size([32, 3, 224, 224]) Loss 0.625548779964447\n",
      "Batch 99. Data shape torch.Size([32, 3, 224, 224]) Loss 0.636689305305481\n",
      "Batch 100. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6497310400009155\n",
      "Batch 101. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6408885717391968\n",
      "Batch 102. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6452184319496155\n",
      "Batch 103. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6183621287345886\n",
      "Batch 104. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6472548246383667\n",
      "Batch 105. Data shape torch.Size([32, 3, 224, 224]) Loss 0.635615348815918\n",
      "Batch 106. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6533256769180298\n",
      "Batch 107. Data shape torch.Size([32, 3, 224, 224]) Loss 0.659626841545105\n",
      "Batch 108. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6281205415725708\n",
      "Batch 109. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6403979659080505\n",
      "Batch 110. Data shape torch.Size([32, 3, 224, 224]) Loss 0.648524820804596\n",
      "Batch 111. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6536679863929749\n",
      "Batch 112. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6227110028266907\n",
      "Batch 113. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6388446092605591\n",
      "Batch 114. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6463523507118225\n",
      "Batch 115. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6224374175071716\n",
      "Batch 116. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6306186318397522\n",
      "Batch 117. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6409962177276611\n",
      "Batch 118. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6608832478523254\n",
      "Batch 119. Data shape torch.Size([20, 3, 224, 224]) Loss 0.6513945460319519\n",
      "Valid loss improved from 0.644852 to 0.641735. Saving model ...\n",
      "Epoch: 22/50 | time: 22.0m 25.41s | lr: 1.0000e-05 | train/loss: 0.64505 | val/loss: 0.64174 | val/accuracy: 0.74341 | val/AUC: 0.74488 | val/Kappa: 0.48825\n",
      "Epoch: 23 Train batch 10 loss: 0.6468420028686523, 2.1% complete\n",
      "Epoch: 23 Train batch 20 loss: 0.6401112079620361, 4.2% complete\n",
      "Epoch: 23 Train batch 30 loss: 0.6198909878730774, 6.3% complete\n",
      "Epoch: 23 Train batch 40 loss: 0.6448994874954224, 8.4% complete\n",
      "Epoch: 23 Train batch 50 loss: 0.6539311408996582, 10.5% complete\n",
      "Epoch: 23 Train batch 60 loss: 0.6746068596839905, 12.6% complete\n",
      "Epoch: 23 Train batch 70 loss: 0.6251125931739807, 14.7% complete\n",
      "Epoch: 23 Train batch 80 loss: 0.6583819389343262, 16.8% complete\n",
      "Epoch: 23 Train batch 90 loss: 0.6200425624847412, 18.9% complete\n",
      "Epoch: 23 Train batch 100 loss: 0.634138286113739, 21.1% complete\n",
      "Epoch: 23 Train batch 110 loss: 0.6415435075759888, 23.2% complete\n",
      "Epoch: 23 Train batch 120 loss: 0.6324827075004578, 25.3% complete\n",
      "Epoch: 23 Train batch 130 loss: 0.6701911091804504, 27.4% complete\n",
      "Epoch: 23 Train batch 140 loss: 0.634817898273468, 29.5% complete\n",
      "Epoch: 23 Train batch 150 loss: 0.6563669443130493, 31.6% complete\n",
      "Epoch: 23 Train batch 160 loss: 0.6358493566513062, 33.7% complete\n",
      "Epoch: 23 Train batch 170 loss: 0.6086398363113403, 35.8% complete\n",
      "Epoch: 23 Train batch 180 loss: 0.6719105839729309, 37.9% complete\n",
      "Epoch: 23 Train batch 190 loss: 0.6317915320396423, 40.0% complete\n",
      "Epoch: 23 Train batch 200 loss: 0.6445688605308533, 42.1% complete\n",
      "Epoch: 23 Train batch 210 loss: 0.638840913772583, 44.2% complete\n",
      "Epoch: 23 Train batch 220 loss: 0.6418379545211792, 46.3% complete\n",
      "Epoch: 23 Train batch 230 loss: 0.6243183612823486, 48.4% complete\n",
      "Epoch: 23 Train batch 240 loss: 0.6635938286781311, 50.5% complete\n",
      "Epoch: 23 Train batch 250 loss: 0.6117464303970337, 52.6% complete\n",
      "Epoch: 23 Train batch 260 loss: 0.667389988899231, 54.7% complete\n",
      "Epoch: 23 Train batch 270 loss: 0.6274307370185852, 56.8% complete\n",
      "Epoch: 23 Train batch 280 loss: 0.6342182755470276, 58.9% complete\n",
      "Epoch: 23 Train batch 290 loss: 0.6465726494789124, 61.1% complete\n",
      "Epoch: 23 Train batch 300 loss: 0.6418646574020386, 63.2% complete\n",
      "Epoch: 23 Train batch 310 loss: 0.6064772605895996, 65.3% complete\n",
      "Epoch: 23 Train batch 320 loss: 0.6410062909126282, 67.4% complete\n",
      "Epoch: 23 Train batch 330 loss: 0.6832504272460938, 69.5% complete\n",
      "Epoch: 23 Train batch 340 loss: 0.645168125629425, 71.6% complete\n",
      "Epoch: 23 Train batch 350 loss: 0.6671574711799622, 73.7% complete\n",
      "Epoch: 23 Train batch 360 loss: 0.6512150764465332, 75.8% complete\n",
      "Epoch: 23 Train batch 370 loss: 0.6483145952224731, 77.9% complete\n",
      "Epoch: 23 Train batch 380 loss: 0.6517177820205688, 80.0% complete\n",
      "Epoch: 23 Train batch 390 loss: 0.6504778265953064, 82.1% complete\n",
      "Epoch: 23 Train batch 400 loss: 0.6157763600349426, 84.2% complete\n",
      "Epoch: 23 Train batch 410 loss: 0.626578152179718, 86.3% complete\n",
      "Epoch: 23 Train batch 420 loss: 0.6575084328651428, 88.4% complete\n",
      "Epoch: 23 Train batch 430 loss: 0.6376921534538269, 90.5% complete\n",
      "Epoch: 23 Train batch 440 loss: 0.6400023698806763, 92.6% complete\n",
      "Epoch: 23 Train batch 450 loss: 0.6150830388069153, 94.7% complete\n",
      "Epoch: 23 Train batch 460 loss: 0.6458550095558167, 96.8% complete\n",
      "Epoch: 23 Train batch 470 loss: 0.6422529220581055, 98.9% complete\n",
      "Batch 1. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6252173185348511\n",
      "Batch 2. Data shape torch.Size([32, 3, 224, 224]) Loss 0.645596981048584\n",
      "Batch 3. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6141546368598938\n",
      "Batch 4. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6216655969619751\n",
      "Batch 5. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6607336401939392\n",
      "Batch 6. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6447616815567017\n",
      "Batch 7. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6438226103782654\n",
      "Batch 8. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6504957675933838\n",
      "Batch 9. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6560642123222351\n",
      "Batch 10. Data shape torch.Size([32, 3, 224, 224]) Loss 0.648199200630188\n",
      "Batch 11. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6175088882446289\n",
      "Batch 12. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6281422972679138\n",
      "Batch 13. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6321567893028259\n",
      "Batch 14. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6332468390464783\n",
      "Batch 15. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6366409063339233\n",
      "Batch 16. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6224680542945862\n",
      "Batch 17. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6274803876876831\n",
      "Batch 18. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6421616673469543\n",
      "Batch 19. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6609340906143188\n",
      "Batch 20. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6624342799186707\n",
      "Batch 21. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6313583850860596\n",
      "Batch 22. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6387677788734436\n",
      "Batch 23. Data shape torch.Size([32, 3, 224, 224]) Loss 0.603583574295044\n",
      "Batch 24. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6304881572723389\n",
      "Batch 25. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6275972127914429\n",
      "Batch 26. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6686903834342957\n",
      "Batch 27. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6398095488548279\n",
      "Batch 28. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6363778114318848\n",
      "Batch 29. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6249223947525024\n",
      "Batch 30. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6241731643676758\n",
      "Batch 31. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6334914565086365\n",
      "Batch 32. Data shape torch.Size([32, 3, 224, 224]) Loss 0.613646388053894\n",
      "Batch 33. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6563870310783386\n",
      "Batch 34. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6426650285720825\n",
      "Batch 35. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6316531300544739\n",
      "Batch 36. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6287776231765747\n",
      "Batch 37. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6304217576980591\n",
      "Batch 38. Data shape torch.Size([32, 3, 224, 224]) Loss 0.644576907157898\n",
      "Batch 39. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6625493764877319\n",
      "Batch 40. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6331361532211304\n",
      "Batch 41. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6621640920639038\n",
      "Batch 42. Data shape torch.Size([32, 3, 224, 224]) Loss 0.654528796672821\n",
      "Batch 43. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6134888529777527\n",
      "Batch 44. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6369696259498596\n",
      "Batch 45. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6291718482971191\n",
      "Batch 46. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6134124398231506\n",
      "Batch 47. Data shape torch.Size([32, 3, 224, 224]) Loss 0.641425371170044\n",
      "Batch 48. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6483106017112732\n",
      "Batch 49. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6351470351219177\n",
      "Batch 50. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6107790470123291\n",
      "Batch 51. Data shape torch.Size([32, 3, 224, 224]) Loss 0.65634685754776\n",
      "Batch 52. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6638777852058411\n",
      "Batch 53. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6455003023147583\n",
      "Batch 54. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6450953483581543\n",
      "Batch 55. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6332132816314697\n",
      "Batch 56. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6218932867050171\n",
      "Batch 57. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6511580944061279\n",
      "Batch 58. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6296939253807068\n",
      "Batch 59. Data shape torch.Size([32, 3, 224, 224]) Loss 0.631847083568573\n",
      "Batch 60. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6148462891578674\n",
      "Batch 61. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6546645164489746\n",
      "Batch 62. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6437253355979919\n",
      "Batch 63. Data shape torch.Size([32, 3, 224, 224]) Loss 0.640556275844574\n",
      "Batch 64. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5992693305015564\n",
      "Batch 65. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6353256702423096\n",
      "Batch 66. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6290569305419922\n",
      "Batch 67. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6234337091445923\n",
      "Batch 68. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5989685654640198\n",
      "Batch 69. Data shape torch.Size([32, 3, 224, 224]) Loss 0.60447758436203\n",
      "Batch 70. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6648167967796326\n",
      "Batch 71. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5962602496147156\n",
      "Batch 72. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6377515196800232\n",
      "Batch 73. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6162903308868408\n",
      "Batch 74. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6512137055397034\n",
      "Batch 75. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6516979336738586\n",
      "Batch 76. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6346498131752014\n",
      "Batch 77. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6417323350906372\n",
      "Batch 78. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6294517517089844\n",
      "Batch 79. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6145387291908264\n",
      "Batch 80. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6677598357200623\n",
      "Batch 81. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6338282227516174\n",
      "Batch 82. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6593766808509827\n",
      "Batch 83. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6325347423553467\n",
      "Batch 84. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6528546810150146\n",
      "Batch 85. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6477277278900146\n",
      "Batch 86. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6639595031738281\n",
      "Batch 87. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6354617476463318\n",
      "Batch 88. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6533324122428894\n",
      "Batch 89. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6282471418380737\n",
      "Batch 90. Data shape torch.Size([32, 3, 224, 224]) Loss 0.633697509765625\n",
      "Batch 91. Data shape torch.Size([32, 3, 224, 224]) Loss 0.63067626953125\n",
      "Batch 92. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6448265314102173\n",
      "Batch 93. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6460543870925903\n",
      "Batch 94. Data shape torch.Size([32, 3, 224, 224]) Loss 0.616511344909668\n",
      "Batch 95. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6081181764602661\n",
      "Batch 96. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6889026165008545\n",
      "Batch 97. Data shape torch.Size([32, 3, 224, 224]) Loss 0.661388099193573\n",
      "Batch 98. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6366288065910339\n",
      "Batch 99. Data shape torch.Size([32, 3, 224, 224]) Loss 0.609927237033844\n",
      "Batch 100. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6330854296684265\n",
      "Batch 101. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6456998586654663\n",
      "Batch 102. Data shape torch.Size([32, 3, 224, 224]) Loss 0.630832850933075\n",
      "Batch 103. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6434717178344727\n",
      "Batch 104. Data shape torch.Size([32, 3, 224, 224]) Loss 0.636069655418396\n",
      "Batch 105. Data shape torch.Size([32, 3, 224, 224]) Loss 0.641018271446228\n",
      "Batch 106. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6314404010772705\n",
      "Batch 107. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6406448483467102\n",
      "Batch 108. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6059357523918152\n",
      "Batch 109. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6551979780197144\n",
      "Batch 110. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6243290901184082\n",
      "Batch 111. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6311174035072327\n",
      "Batch 112. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6438915729522705\n",
      "Batch 113. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6575136184692383\n",
      "Batch 114. Data shape torch.Size([32, 3, 224, 224]) Loss 0.630791425704956\n",
      "Batch 115. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6442386507987976\n",
      "Batch 116. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6304892897605896\n",
      "Batch 117. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6406171321868896\n",
      "Batch 118. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6582899689674377\n",
      "Batch 119. Data shape torch.Size([20, 3, 224, 224]) Loss 0.6575880646705627\n",
      "Valid loss improved from 0.641735 to 0.637124. Saving model ...\n",
      "Epoch: 23/50 | time: 22.0m 18.0s | lr: 1.0000e-05 | train/loss: 0.64212 | val/loss: 0.63712 | val/accuracy: 0.75158 | val/AUC: 0.75296 | val/Kappa: 0.50445\n",
      "Epoch: 24 Train batch 10 loss: 0.6167553067207336, 2.1% complete\n",
      "Epoch: 24 Train batch 20 loss: 0.6232957243919373, 4.2% complete\n",
      "Epoch: 24 Train batch 30 loss: 0.636243999004364, 6.3% complete\n",
      "Epoch: 24 Train batch 40 loss: 0.6727275848388672, 8.4% complete\n",
      "Epoch: 24 Train batch 50 loss: 0.6444905400276184, 10.5% complete\n",
      "Epoch: 24 Train batch 60 loss: 0.6387581825256348, 12.6% complete\n",
      "Epoch: 24 Train batch 70 loss: 0.6381010413169861, 14.7% complete\n",
      "Epoch: 24 Train batch 80 loss: 0.6242145299911499, 16.8% complete\n",
      "Epoch: 24 Train batch 90 loss: 0.6749468445777893, 18.9% complete\n",
      "Epoch: 24 Train batch 100 loss: 0.6301878094673157, 21.1% complete\n",
      "Epoch: 24 Train batch 110 loss: 0.6054213643074036, 23.2% complete\n",
      "Epoch: 24 Train batch 120 loss: 0.6345807909965515, 25.3% complete\n",
      "Epoch: 24 Train batch 130 loss: 0.628764271736145, 27.4% complete\n",
      "Epoch: 24 Train batch 140 loss: 0.640048086643219, 29.5% complete\n",
      "Epoch: 24 Train batch 150 loss: 0.6182562708854675, 31.6% complete\n",
      "Epoch: 24 Train batch 160 loss: 0.6463463306427002, 33.7% complete\n",
      "Epoch: 24 Train batch 170 loss: 0.6275134682655334, 35.8% complete\n",
      "Epoch: 24 Train batch 180 loss: 0.6171395182609558, 37.9% complete\n",
      "Epoch: 24 Train batch 190 loss: 0.6277989149093628, 40.0% complete\n",
      "Epoch: 24 Train batch 200 loss: 0.6312723755836487, 42.1% complete\n",
      "Epoch: 24 Train batch 210 loss: 0.6322224736213684, 44.2% complete\n",
      "Epoch: 24 Train batch 220 loss: 0.6258958578109741, 46.3% complete\n",
      "Epoch: 24 Train batch 230 loss: 0.611135721206665, 48.4% complete\n",
      "Epoch: 24 Train batch 240 loss: 0.6396471261978149, 50.5% complete\n",
      "Epoch: 24 Train batch 250 loss: 0.6557412147521973, 52.6% complete\n",
      "Epoch: 24 Train batch 260 loss: 0.6221530437469482, 54.7% complete\n",
      "Epoch: 24 Train batch 270 loss: 0.643101692199707, 56.8% complete\n",
      "Epoch: 24 Train batch 280 loss: 0.6336528062820435, 58.9% complete\n",
      "Epoch: 24 Train batch 290 loss: 0.6418840885162354, 61.1% complete\n",
      "Epoch: 24 Train batch 300 loss: 0.6834310293197632, 63.2% complete\n",
      "Epoch: 24 Train batch 310 loss: 0.6379680633544922, 65.3% complete\n",
      "Epoch: 24 Train batch 320 loss: 0.6705394387245178, 67.4% complete\n",
      "Epoch: 24 Train batch 330 loss: 0.6356201767921448, 69.5% complete\n",
      "Epoch: 24 Train batch 340 loss: 0.6721367835998535, 71.6% complete\n",
      "Epoch: 24 Train batch 350 loss: 0.6312218904495239, 73.7% complete\n",
      "Epoch: 24 Train batch 360 loss: 0.6690375804901123, 75.8% complete\n",
      "Epoch: 24 Train batch 370 loss: 0.6402088403701782, 77.9% complete\n",
      "Epoch: 24 Train batch 380 loss: 0.6320880651473999, 80.0% complete\n",
      "Epoch: 24 Train batch 390 loss: 0.6008719205856323, 82.1% complete\n",
      "Epoch: 24 Train batch 400 loss: 0.6247222423553467, 84.2% complete\n",
      "Epoch: 24 Train batch 410 loss: 0.6429733633995056, 86.3% complete\n",
      "Epoch: 24 Train batch 420 loss: 0.6462664604187012, 88.4% complete\n",
      "Epoch: 24 Train batch 430 loss: 0.6365580558776855, 90.5% complete\n",
      "Epoch: 24 Train batch 440 loss: 0.6160362958908081, 92.6% complete\n",
      "Epoch: 24 Train batch 450 loss: 0.613911509513855, 94.7% complete\n",
      "Epoch: 24 Train batch 460 loss: 0.645060658454895, 96.8% complete\n",
      "Epoch: 24 Train batch 470 loss: 0.6487119793891907, 98.9% complete\n",
      "Batch 1. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6445959806442261\n",
      "Batch 2. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6125545501708984\n",
      "Batch 3. Data shape torch.Size([32, 3, 224, 224]) Loss 0.635619044303894\n",
      "Batch 4. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6237456798553467\n",
      "Batch 5. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6318552494049072\n",
      "Batch 6. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6364797949790955\n",
      "Batch 7. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6201757192611694\n",
      "Batch 8. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6399946808815002\n",
      "Batch 9. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6182448863983154\n",
      "Batch 10. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6281071305274963\n",
      "Batch 11. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6361759305000305\n",
      "Batch 12. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6068685054779053\n",
      "Batch 13. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6141311526298523\n",
      "Batch 14. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6192236542701721\n",
      "Batch 15. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6485562920570374\n",
      "Batch 16. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6187852621078491\n",
      "Batch 17. Data shape torch.Size([32, 3, 224, 224]) Loss 0.618382453918457\n",
      "Batch 18. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6312797665596008\n",
      "Batch 19. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6569463014602661\n",
      "Batch 20. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6344860196113586\n",
      "Batch 21. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6343122124671936\n",
      "Batch 22. Data shape torch.Size([32, 3, 224, 224]) Loss 0.65277498960495\n",
      "Batch 23. Data shape torch.Size([32, 3, 224, 224]) Loss 0.624979555606842\n",
      "Batch 24. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6364678144454956\n",
      "Batch 25. Data shape torch.Size([32, 3, 224, 224]) Loss 0.644048273563385\n",
      "Batch 26. Data shape torch.Size([32, 3, 224, 224]) Loss 0.637863039970398\n",
      "Batch 27. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6212425827980042\n",
      "Batch 28. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6438688039779663\n",
      "Batch 29. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6608054637908936\n",
      "Batch 30. Data shape torch.Size([32, 3, 224, 224]) Loss 0.620399534702301\n",
      "Batch 31. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6331520676612854\n",
      "Batch 32. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6384463310241699\n",
      "Batch 33. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6446754932403564\n",
      "Batch 34. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6368353366851807\n",
      "Batch 35. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6312654614448547\n",
      "Batch 36. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6533983945846558\n",
      "Batch 37. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6479880213737488\n",
      "Batch 38. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6193534135818481\n",
      "Batch 39. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5845634937286377\n",
      "Batch 40. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6256290674209595\n",
      "Batch 41. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6399914622306824\n",
      "Batch 42. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6718961596488953\n",
      "Batch 43. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6090195178985596\n",
      "Batch 44. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6225087642669678\n",
      "Batch 45. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6378037929534912\n",
      "Batch 46. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6256183385848999\n",
      "Batch 47. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6346601843833923\n",
      "Batch 48. Data shape torch.Size([32, 3, 224, 224]) Loss 0.603175699710846\n",
      "Batch 49. Data shape torch.Size([32, 3, 224, 224]) Loss 0.639151394367218\n",
      "Batch 50. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6420980095863342\n",
      "Batch 51. Data shape torch.Size([32, 3, 224, 224]) Loss 0.640916645526886\n",
      "Batch 52. Data shape torch.Size([32, 3, 224, 224]) Loss 0.608969509601593\n",
      "Batch 53. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6404321193695068\n",
      "Batch 54. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6074016094207764\n",
      "Batch 55. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6197814345359802\n",
      "Batch 56. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5987027883529663\n",
      "Batch 57. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6200889348983765\n",
      "Batch 58. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6364001631736755\n",
      "Batch 59. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6575286984443665\n",
      "Batch 60. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6422771215438843\n",
      "Batch 61. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6263256072998047\n",
      "Batch 62. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6252241730690002\n",
      "Batch 63. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6517860889434814\n",
      "Batch 64. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6286969780921936\n",
      "Batch 65. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6421686410903931\n",
      "Batch 66. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6403852701187134\n",
      "Batch 67. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6565839052200317\n",
      "Batch 68. Data shape torch.Size([32, 3, 224, 224]) Loss 0.628774881362915\n",
      "Batch 69. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6176266670227051\n",
      "Batch 70. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6299293637275696\n",
      "Batch 71. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6023766994476318\n",
      "Batch 72. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6470722556114197\n",
      "Batch 73. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6468742489814758\n",
      "Batch 74. Data shape torch.Size([32, 3, 224, 224]) Loss 0.634063720703125\n",
      "Batch 75. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6638692617416382\n",
      "Batch 76. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6041351556777954\n",
      "Batch 77. Data shape torch.Size([32, 3, 224, 224]) Loss 0.638024628162384\n",
      "Batch 78. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5877811908721924\n",
      "Batch 79. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6249681711196899\n",
      "Batch 80. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6614159345626831\n",
      "Batch 81. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6017168760299683\n",
      "Batch 82. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6214482188224792\n",
      "Batch 83. Data shape torch.Size([32, 3, 224, 224]) Loss 0.624374270439148\n",
      "Batch 84. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6336821913719177\n",
      "Batch 85. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6190497279167175\n",
      "Batch 86. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6451114416122437\n",
      "Batch 87. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6369333267211914\n",
      "Batch 88. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6490779519081116\n",
      "Batch 89. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6422690749168396\n",
      "Batch 90. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6049857139587402\n",
      "Batch 91. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6357870101928711\n",
      "Batch 92. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6195623278617859\n",
      "Batch 93. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6267553567886353\n",
      "Batch 94. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6483132243156433\n",
      "Batch 95. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6184539198875427\n",
      "Batch 96. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6442520022392273\n",
      "Batch 97. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6592590808868408\n",
      "Batch 98. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6563228964805603\n",
      "Batch 99. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6819913983345032\n",
      "Batch 100. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6281823515892029\n",
      "Batch 101. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6295612454414368\n",
      "Batch 102. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6400083303451538\n",
      "Batch 103. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6239515542984009\n",
      "Batch 104. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6192823648452759\n",
      "Batch 105. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6088939309120178\n",
      "Batch 106. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6091411709785461\n",
      "Batch 107. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6544737815856934\n",
      "Batch 108. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6608385443687439\n",
      "Batch 109. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6391090154647827\n",
      "Batch 110. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6590781807899475\n",
      "Batch 111. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6148062944412231\n",
      "Batch 112. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6135234832763672\n",
      "Batch 113. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6029224991798401\n",
      "Batch 114. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6541498899459839\n",
      "Batch 115. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6445972323417664\n",
      "Batch 116. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6295106410980225\n",
      "Batch 117. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6279375553131104\n",
      "Batch 118. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6250001192092896\n",
      "Batch 119. Data shape torch.Size([20, 3, 224, 224]) Loss 0.6228201389312744\n",
      "Valid loss improved from 0.637124 to 0.631949. Saving model ...\n",
      "Epoch: 24/50 | time: 22.0m 39.6s | lr: 1.0000e-05 | train/loss: 0.63810 | val/loss: 0.63195 | val/accuracy: 0.75553 | val/AUC: 0.75660 | val/Kappa: 0.51203\n",
      "Epoch: 25 Train batch 10 loss: 0.5939357280731201, 2.1% complete\n",
      "Epoch: 25 Train batch 20 loss: 0.6329869627952576, 4.2% complete\n",
      "Epoch: 25 Train batch 30 loss: 0.6574277877807617, 6.3% complete\n",
      "Epoch: 25 Train batch 40 loss: 0.6044575572013855, 8.4% complete\n",
      "Epoch: 25 Train batch 50 loss: 0.653627872467041, 10.5% complete\n",
      "Epoch: 25 Train batch 60 loss: 0.613430917263031, 12.6% complete\n",
      "Epoch: 25 Train batch 70 loss: 0.6243234872817993, 14.7% complete\n",
      "Epoch: 25 Train batch 80 loss: 0.6338446140289307, 16.8% complete\n",
      "Epoch: 25 Train batch 90 loss: 0.647709310054779, 18.9% complete\n",
      "Epoch: 25 Train batch 100 loss: 0.6348692774772644, 21.1% complete\n",
      "Epoch: 25 Train batch 110 loss: 0.6648485660552979, 23.2% complete\n",
      "Epoch: 25 Train batch 120 loss: 0.6611628532409668, 25.3% complete\n",
      "Epoch: 25 Train batch 130 loss: 0.6025654673576355, 27.4% complete\n",
      "Epoch: 25 Train batch 140 loss: 0.6301915049552917, 29.5% complete\n",
      "Epoch: 25 Train batch 150 loss: 0.6442714929580688, 31.6% complete\n",
      "Epoch: 25 Train batch 160 loss: 0.6460753083229065, 33.7% complete\n",
      "Epoch: 25 Train batch 170 loss: 0.6246635913848877, 35.8% complete\n",
      "Epoch: 25 Train batch 180 loss: 0.6337442994117737, 37.9% complete\n",
      "Epoch: 25 Train batch 190 loss: 0.6305394172668457, 40.0% complete\n",
      "Epoch: 25 Train batch 200 loss: 0.6439015865325928, 42.1% complete\n",
      "Epoch: 25 Train batch 210 loss: 0.6291252374649048, 44.2% complete\n",
      "Epoch: 25 Train batch 220 loss: 0.6168342232704163, 46.3% complete\n",
      "Epoch: 25 Train batch 230 loss: 0.6103945374488831, 48.4% complete\n",
      "Epoch: 25 Train batch 240 loss: 0.6482096314430237, 50.5% complete\n",
      "Epoch: 25 Train batch 250 loss: 0.6342840194702148, 52.6% complete\n",
      "Epoch: 25 Train batch 260 loss: 0.6268081665039062, 54.7% complete\n",
      "Epoch: 25 Train batch 270 loss: 0.6368041634559631, 56.8% complete\n",
      "Epoch: 25 Train batch 280 loss: 0.6336621046066284, 58.9% complete\n",
      "Epoch: 25 Train batch 290 loss: 0.6333641409873962, 61.1% complete\n",
      "Epoch: 25 Train batch 300 loss: 0.6152930855751038, 63.2% complete\n",
      "Epoch: 25 Train batch 310 loss: 0.6362805962562561, 65.3% complete\n",
      "Epoch: 25 Train batch 320 loss: 0.6335853338241577, 67.4% complete\n",
      "Epoch: 25 Train batch 330 loss: 0.6451647877693176, 69.5% complete\n",
      "Epoch: 25 Train batch 340 loss: 0.5961253046989441, 71.6% complete\n",
      "Epoch: 25 Train batch 350 loss: 0.6416539549827576, 73.7% complete\n",
      "Epoch: 25 Train batch 360 loss: 0.6278796195983887, 75.8% complete\n",
      "Epoch: 25 Train batch 370 loss: 0.6487143039703369, 77.9% complete\n",
      "Epoch: 25 Train batch 380 loss: 0.6516242623329163, 80.0% complete\n",
      "Epoch: 25 Train batch 390 loss: 0.6417864561080933, 82.1% complete\n",
      "Epoch: 25 Train batch 400 loss: 0.6509943008422852, 84.2% complete\n",
      "Epoch: 25 Train batch 410 loss: 0.6427249908447266, 86.3% complete\n",
      "Epoch: 25 Train batch 420 loss: 0.602226197719574, 88.4% complete\n",
      "Epoch: 25 Train batch 430 loss: 0.6219378709793091, 90.5% complete\n",
      "Epoch: 25 Train batch 440 loss: 0.6365517377853394, 92.6% complete\n",
      "Epoch: 25 Train batch 450 loss: 0.6722444295883179, 94.7% complete\n",
      "Epoch: 25 Train batch 460 loss: 0.6325016021728516, 96.8% complete\n",
      "Epoch: 25 Train batch 470 loss: 0.6416386365890503, 98.9% complete\n",
      "Batch 1. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6276736855506897\n",
      "Batch 2. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6234731078147888\n",
      "Batch 3. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6104739904403687\n",
      "Batch 4. Data shape torch.Size([32, 3, 224, 224]) Loss 0.645499050617218\n",
      "Batch 5. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6366830468177795\n",
      "Batch 6. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6362293362617493\n",
      "Batch 7. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6227743625640869\n",
      "Batch 8. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6005823612213135\n",
      "Batch 9. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6499499082565308\n",
      "Batch 10. Data shape torch.Size([32, 3, 224, 224]) Loss 0.67032790184021\n",
      "Batch 11. Data shape torch.Size([32, 3, 224, 224]) Loss 0.618665874004364\n",
      "Batch 12. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6017765402793884\n",
      "Batch 13. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6273608803749084\n",
      "Batch 14. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6208125948905945\n",
      "Batch 15. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5872966647148132\n",
      "Batch 16. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6241876482963562\n",
      "Batch 17. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5925893187522888\n",
      "Batch 18. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6402052044868469\n",
      "Batch 19. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6283897161483765\n",
      "Batch 20. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6497511267662048\n",
      "Batch 21. Data shape torch.Size([32, 3, 224, 224]) Loss 0.59585040807724\n",
      "Batch 22. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6379007697105408\n",
      "Batch 23. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6322930455207825\n",
      "Batch 24. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6358016729354858\n",
      "Batch 25. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6277275085449219\n",
      "Batch 26. Data shape torch.Size([32, 3, 224, 224]) Loss 0.641322910785675\n",
      "Batch 27. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6344218254089355\n",
      "Batch 28. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6392367482185364\n",
      "Batch 29. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6355921030044556\n",
      "Batch 30. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6358659863471985\n",
      "Batch 31. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6185963749885559\n",
      "Batch 32. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6001762747764587\n",
      "Batch 33. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6065114140510559\n",
      "Batch 34. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6078474521636963\n",
      "Batch 35. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6631723642349243\n",
      "Batch 36. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6116132140159607\n",
      "Batch 37. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6347565054893494\n",
      "Batch 38. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6406274437904358\n",
      "Batch 39. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6241768598556519\n",
      "Batch 40. Data shape torch.Size([32, 3, 224, 224]) Loss 0.619280219078064\n",
      "Batch 41. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6387073397636414\n",
      "Batch 42. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6184653043746948\n",
      "Batch 43. Data shape torch.Size([32, 3, 224, 224]) Loss 0.642041802406311\n",
      "Batch 44. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6205620765686035\n",
      "Batch 45. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6168831586837769\n",
      "Batch 46. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6248046159744263\n",
      "Batch 47. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6277673840522766\n",
      "Batch 48. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6222618222236633\n",
      "Batch 49. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6032262444496155\n",
      "Batch 50. Data shape torch.Size([32, 3, 224, 224]) Loss 0.617396354675293\n",
      "Batch 51. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6229709386825562\n",
      "Batch 52. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6275678277015686\n",
      "Batch 53. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6348662376403809\n",
      "Batch 54. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6395046710968018\n",
      "Batch 55. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6259783506393433\n",
      "Batch 56. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6586117148399353\n",
      "Batch 57. Data shape torch.Size([32, 3, 224, 224]) Loss 0.638633668422699\n",
      "Batch 58. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5944533944129944\n",
      "Batch 59. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6719361543655396\n",
      "Batch 60. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6444624662399292\n",
      "Batch 61. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6477223038673401\n",
      "Batch 62. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6140648722648621\n",
      "Batch 63. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6522438526153564\n",
      "Batch 64. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6004108786582947\n",
      "Batch 65. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6268178224563599\n",
      "Batch 66. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6305842399597168\n",
      "Batch 67. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6006023287773132\n",
      "Batch 68. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6144816875457764\n",
      "Batch 69. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6064157485961914\n",
      "Batch 70. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6453752517700195\n",
      "Batch 71. Data shape torch.Size([32, 3, 224, 224]) Loss 0.632754921913147\n",
      "Batch 72. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6292590498924255\n",
      "Batch 73. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6024762392044067\n",
      "Batch 74. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6386175155639648\n",
      "Batch 75. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6633592844009399\n",
      "Batch 76. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5965998768806458\n",
      "Batch 77. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6289244890213013\n",
      "Batch 78. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6576541066169739\n",
      "Batch 79. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6543559432029724\n",
      "Batch 80. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6360070705413818\n",
      "Batch 81. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6155340075492859\n",
      "Batch 82. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6260152459144592\n",
      "Batch 83. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6166769862174988\n",
      "Batch 84. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6479331254959106\n",
      "Batch 85. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6041861176490784\n",
      "Batch 86. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6333889961242676\n",
      "Batch 87. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6150603890419006\n",
      "Batch 88. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5885752439498901\n",
      "Batch 89. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6524209976196289\n",
      "Batch 90. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6496139168739319\n",
      "Batch 91. Data shape torch.Size([32, 3, 224, 224]) Loss 0.602023184299469\n",
      "Batch 92. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6162965297698975\n",
      "Batch 93. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6146258115768433\n",
      "Batch 94. Data shape torch.Size([32, 3, 224, 224]) Loss 0.629485011100769\n",
      "Batch 95. Data shape torch.Size([32, 3, 224, 224]) Loss 0.629041850566864\n",
      "Batch 96. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6485857963562012\n",
      "Batch 97. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6519461274147034\n",
      "Batch 98. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6032243967056274\n",
      "Batch 99. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6380028128623962\n",
      "Batch 100. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6406363248825073\n",
      "Batch 101. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6370860934257507\n",
      "Batch 102. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6394436955451965\n",
      "Batch 103. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6201609969139099\n",
      "Batch 104. Data shape torch.Size([32, 3, 224, 224]) Loss 0.607164740562439\n",
      "Batch 105. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6107594966888428\n",
      "Batch 106. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6160738468170166\n",
      "Batch 107. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6309370994567871\n",
      "Batch 108. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6236927509307861\n",
      "Batch 109. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6083366274833679\n",
      "Batch 110. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6497642397880554\n",
      "Batch 111. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6245235800743103\n",
      "Batch 112. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6174919009208679\n",
      "Batch 113. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6435163021087646\n",
      "Batch 114. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6298198699951172\n",
      "Batch 115. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6465404033660889\n",
      "Batch 116. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6117520928382874\n",
      "Batch 117. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6042137742042542\n",
      "Batch 118. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6310673952102661\n",
      "Batch 119. Data shape torch.Size([20, 3, 224, 224]) Loss 0.6018335819244385\n",
      "Valid loss improved from 0.631949 to 0.626931. Saving model ...\n",
      "Epoch: 25/50 | time: 21.0m 43.31s | lr: 1.0000e-05 | train/loss: 0.63419 | val/loss: 0.62693 | val/accuracy: 0.75632 | val/AUC: 0.75743 | val/Kappa: 0.51364\n",
      "Epoch: 26 Train batch 10 loss: 0.6141332983970642, 2.1% complete\n",
      "Epoch: 26 Train batch 20 loss: 0.6551231741905212, 4.2% complete\n",
      "Epoch: 26 Train batch 30 loss: 0.6378108263015747, 6.3% complete\n",
      "Epoch: 26 Train batch 40 loss: 0.6151765584945679, 8.4% complete\n",
      "Epoch: 26 Train batch 50 loss: 0.6124871373176575, 10.5% complete\n",
      "Epoch: 26 Train batch 60 loss: 0.6354967951774597, 12.6% complete\n",
      "Epoch: 26 Train batch 70 loss: 0.6172321438789368, 14.7% complete\n",
      "Epoch: 26 Train batch 80 loss: 0.6223075985908508, 16.8% complete\n",
      "Epoch: 26 Train batch 90 loss: 0.6190711855888367, 18.9% complete\n",
      "Epoch: 26 Train batch 100 loss: 0.674237072467804, 21.1% complete\n",
      "Epoch: 26 Train batch 110 loss: 0.6175355315208435, 23.2% complete\n",
      "Epoch: 26 Train batch 120 loss: 0.6311353445053101, 25.3% complete\n",
      "Epoch: 26 Train batch 130 loss: 0.6288415789604187, 27.4% complete\n",
      "Epoch: 26 Train batch 140 loss: 0.6357719898223877, 29.5% complete\n",
      "Epoch: 26 Train batch 150 loss: 0.6225947737693787, 31.6% complete\n",
      "Epoch: 26 Train batch 160 loss: 0.6257219314575195, 33.7% complete\n",
      "Epoch: 26 Train batch 170 loss: 0.6381088495254517, 35.8% complete\n",
      "Epoch: 26 Train batch 180 loss: 0.6539965867996216, 37.9% complete\n",
      "Epoch: 26 Train batch 190 loss: 0.623840868473053, 40.0% complete\n",
      "Epoch: 26 Train batch 200 loss: 0.6175363659858704, 42.1% complete\n",
      "Epoch: 26 Train batch 210 loss: 0.6143139600753784, 44.2% complete\n",
      "Epoch: 26 Train batch 220 loss: 0.600114643573761, 46.3% complete\n",
      "Epoch: 26 Train batch 230 loss: 0.6231479048728943, 48.4% complete\n",
      "Epoch: 26 Train batch 240 loss: 0.5997766852378845, 50.5% complete\n",
      "Epoch: 26 Train batch 250 loss: 0.6272302865982056, 52.6% complete\n",
      "Epoch: 26 Train batch 260 loss: 0.6306824684143066, 54.7% complete\n",
      "Epoch: 26 Train batch 270 loss: 0.6327577829360962, 56.8% complete\n",
      "Epoch: 26 Train batch 280 loss: 0.6168811321258545, 58.9% complete\n",
      "Epoch: 26 Train batch 290 loss: 0.6733434796333313, 61.1% complete\n",
      "Epoch: 26 Train batch 300 loss: 0.6508504748344421, 63.2% complete\n",
      "Epoch: 26 Train batch 310 loss: 0.6165735721588135, 65.3% complete\n",
      "Epoch: 26 Train batch 320 loss: 0.6460741758346558, 67.4% complete\n",
      "Epoch: 26 Train batch 330 loss: 0.6503710150718689, 69.5% complete\n",
      "Epoch: 26 Train batch 340 loss: 0.6419861912727356, 71.6% complete\n",
      "Epoch: 26 Train batch 350 loss: 0.6564341187477112, 73.7% complete\n",
      "Epoch: 26 Train batch 360 loss: 0.6354258060455322, 75.8% complete\n",
      "Epoch: 26 Train batch 370 loss: 0.6349149346351624, 77.9% complete\n",
      "Epoch: 26 Train batch 380 loss: 0.6449031829833984, 80.0% complete\n",
      "Epoch: 26 Train batch 390 loss: 0.6771659255027771, 82.1% complete\n",
      "Epoch: 26 Train batch 400 loss: 0.6399703025817871, 84.2% complete\n",
      "Epoch: 26 Train batch 410 loss: 0.6632251143455505, 86.3% complete\n",
      "Epoch: 26 Train batch 420 loss: 0.6125738024711609, 88.4% complete\n",
      "Epoch: 26 Train batch 430 loss: 0.6276073455810547, 90.5% complete\n",
      "Epoch: 26 Train batch 440 loss: 0.6555553674697876, 92.6% complete\n",
      "Epoch: 26 Train batch 450 loss: 0.640618622303009, 94.7% complete\n",
      "Epoch: 26 Train batch 460 loss: 0.6019334197044373, 96.8% complete\n",
      "Epoch: 26 Train batch 470 loss: 0.617074191570282, 98.9% complete\n",
      "Batch 1. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6184644103050232\n",
      "Batch 2. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6217827796936035\n",
      "Batch 3. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6501081585884094\n",
      "Batch 4. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6304994225502014\n",
      "Batch 5. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5872975587844849\n",
      "Batch 6. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6050346493721008\n",
      "Batch 7. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6362002491950989\n",
      "Batch 8. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6478080153465271\n",
      "Batch 9. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6590532660484314\n",
      "Batch 10. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6047646403312683\n",
      "Batch 11. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6090047955513\n",
      "Batch 12. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6044687032699585\n",
      "Batch 13. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6158418655395508\n",
      "Batch 14. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6308735013008118\n",
      "Batch 15. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6367210745811462\n",
      "Batch 16. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6099055409431458\n",
      "Batch 17. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5941567420959473\n",
      "Batch 18. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6370255351066589\n",
      "Batch 19. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5996450781822205\n",
      "Batch 20. Data shape torch.Size([32, 3, 224, 224]) Loss 0.618120551109314\n",
      "Batch 21. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6327767372131348\n",
      "Batch 22. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6366663575172424\n",
      "Batch 23. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5982118248939514\n",
      "Batch 24. Data shape torch.Size([32, 3, 224, 224]) Loss 0.693001925945282\n",
      "Batch 25. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5810632705688477\n",
      "Batch 26. Data shape torch.Size([32, 3, 224, 224]) Loss 0.609981894493103\n",
      "Batch 27. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6281034350395203\n",
      "Batch 28. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6513140797615051\n",
      "Batch 29. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6263599395751953\n",
      "Batch 30. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6429468989372253\n",
      "Batch 31. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6812956929206848\n",
      "Batch 32. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6049935221672058\n",
      "Batch 33. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6267024278640747\n",
      "Batch 34. Data shape torch.Size([32, 3, 224, 224]) Loss 0.629524290561676\n",
      "Batch 35. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6047254800796509\n",
      "Batch 36. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6120923161506653\n",
      "Batch 37. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6433975100517273\n",
      "Batch 38. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6214930415153503\n",
      "Batch 39. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6435085535049438\n",
      "Batch 40. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5788896083831787\n",
      "Batch 41. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6479980945587158\n",
      "Batch 42. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6396971344947815\n",
      "Batch 43. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6396127343177795\n",
      "Batch 44. Data shape torch.Size([32, 3, 224, 224]) Loss 0.648211658000946\n",
      "Batch 45. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6286956071853638\n",
      "Batch 46. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6078538298606873\n",
      "Batch 47. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6410633325576782\n",
      "Batch 48. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6187496185302734\n",
      "Batch 49. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6405202746391296\n",
      "Batch 50. Data shape torch.Size([32, 3, 224, 224]) Loss 0.640139102935791\n",
      "Batch 51. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6119027137756348\n",
      "Batch 52. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6150686144828796\n",
      "Batch 53. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6245190501213074\n",
      "Batch 54. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6692600250244141\n",
      "Batch 55. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6191548705101013\n",
      "Batch 56. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6363903284072876\n",
      "Batch 57. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6265323162078857\n",
      "Batch 58. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6129558682441711\n",
      "Batch 59. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6488791704177856\n",
      "Batch 60. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6119006276130676\n",
      "Batch 61. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6160441040992737\n",
      "Batch 62. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6184079647064209\n",
      "Batch 63. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6282749176025391\n",
      "Batch 64. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6284387111663818\n",
      "Batch 65. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6204578876495361\n",
      "Batch 66. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6416621804237366\n",
      "Batch 67. Data shape torch.Size([32, 3, 224, 224]) Loss 0.621666669845581\n",
      "Batch 68. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6368808746337891\n",
      "Batch 69. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6004164218902588\n",
      "Batch 70. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6454537510871887\n",
      "Batch 71. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6255596876144409\n",
      "Batch 72. Data shape torch.Size([32, 3, 224, 224]) Loss 0.622235119342804\n",
      "Batch 73. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6395271420478821\n",
      "Batch 74. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6195665597915649\n",
      "Batch 75. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6310505270957947\n",
      "Batch 76. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6217309832572937\n",
      "Batch 77. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5975090861320496\n",
      "Batch 78. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6061570048332214\n",
      "Batch 79. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6481484174728394\n",
      "Batch 80. Data shape torch.Size([32, 3, 224, 224]) Loss 0.649176299571991\n",
      "Batch 81. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6466382741928101\n",
      "Batch 82. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6111471652984619\n",
      "Batch 83. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6129564642906189\n",
      "Batch 84. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6354827880859375\n",
      "Batch 85. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6378824710845947\n",
      "Batch 86. Data shape torch.Size([32, 3, 224, 224]) Loss 0.629923939704895\n",
      "Batch 87. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6401822566986084\n",
      "Batch 88. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6015044450759888\n",
      "Batch 89. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6157501935958862\n",
      "Batch 90. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6425106525421143\n",
      "Batch 91. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6187885999679565\n",
      "Batch 92. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6300519704818726\n",
      "Batch 93. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6347061991691589\n",
      "Batch 94. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6183079481124878\n",
      "Batch 95. Data shape torch.Size([32, 3, 224, 224]) Loss 0.613269567489624\n",
      "Batch 96. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6779240965843201\n",
      "Batch 97. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6480044722557068\n",
      "Batch 98. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6336801648139954\n",
      "Batch 99. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6389499306678772\n",
      "Batch 100. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6219416856765747\n",
      "Batch 101. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6490622162818909\n",
      "Batch 102. Data shape torch.Size([32, 3, 224, 224]) Loss 0.61447674036026\n",
      "Batch 103. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5892707705497742\n",
      "Batch 104. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6323489546775818\n",
      "Batch 105. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6365035772323608\n",
      "Batch 106. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6206762790679932\n",
      "Batch 107. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6123324632644653\n",
      "Batch 108. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5990177989006042\n",
      "Batch 109. Data shape torch.Size([32, 3, 224, 224]) Loss 0.625289797782898\n",
      "Batch 110. Data shape torch.Size([32, 3, 224, 224]) Loss 0.588901937007904\n",
      "Batch 111. Data shape torch.Size([32, 3, 224, 224]) Loss 0.614921510219574\n",
      "Batch 112. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6392951011657715\n",
      "Batch 113. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6320448517799377\n",
      "Batch 114. Data shape torch.Size([32, 3, 224, 224]) Loss 0.651482880115509\n",
      "Batch 115. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6532357335090637\n",
      "Batch 116. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6076234579086304\n",
      "Batch 117. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6062676310539246\n",
      "Batch 118. Data shape torch.Size([32, 3, 224, 224]) Loss 0.626323938369751\n",
      "Batch 119. Data shape torch.Size([20, 3, 224, 224]) Loss 0.6708449125289917\n",
      "Valid loss improved from 0.626931 to 0.626814. Saving model ...\n",
      "Epoch: 26/50 | time: 22.0m 0.593s | lr: 1.0000e-05 | train/loss: 0.63094 | val/loss: 0.62681 | val/accuracy: 0.75869 | val/AUC: 0.75949 | val/Kappa: 0.51808\n",
      "Epoch: 27 Train batch 10 loss: 0.6321060657501221, 2.1% complete\n",
      "Epoch: 27 Train batch 20 loss: 0.6195598840713501, 4.2% complete\n",
      "Epoch: 27 Train batch 30 loss: 0.6187120676040649, 6.3% complete\n",
      "Epoch: 27 Train batch 40 loss: 0.6625655889511108, 8.4% complete\n",
      "Epoch: 27 Train batch 50 loss: 0.6159182786941528, 10.5% complete\n",
      "Epoch: 27 Train batch 60 loss: 0.6534802317619324, 12.6% complete\n",
      "Epoch: 27 Train batch 70 loss: 0.6283653974533081, 14.7% complete\n",
      "Epoch: 27 Train batch 80 loss: 0.6455008387565613, 16.8% complete\n",
      "Epoch: 27 Train batch 90 loss: 0.6069584488868713, 18.9% complete\n",
      "Epoch: 27 Train batch 100 loss: 0.594327986240387, 21.1% complete\n",
      "Epoch: 27 Train batch 110 loss: 0.6481520533561707, 23.2% complete\n",
      "Epoch: 27 Train batch 120 loss: 0.6474547982215881, 25.3% complete\n",
      "Epoch: 27 Train batch 130 loss: 0.650933027267456, 27.4% complete\n",
      "Epoch: 27 Train batch 140 loss: 0.6150625944137573, 29.5% complete\n",
      "Epoch: 27 Train batch 150 loss: 0.5952431559562683, 31.6% complete\n",
      "Epoch: 27 Train batch 160 loss: 0.6582200527191162, 33.7% complete\n",
      "Epoch: 27 Train batch 170 loss: 0.679175853729248, 35.8% complete\n",
      "Epoch: 27 Train batch 180 loss: 0.6349254250526428, 37.9% complete\n",
      "Epoch: 27 Train batch 190 loss: 0.6292020082473755, 40.0% complete\n",
      "Epoch: 27 Train batch 200 loss: 0.6382055282592773, 42.1% complete\n",
      "Epoch: 27 Train batch 210 loss: 0.6309879422187805, 44.2% complete\n",
      "Epoch: 27 Train batch 220 loss: 0.6263329386711121, 46.3% complete\n",
      "Epoch: 27 Train batch 230 loss: 0.6393252611160278, 48.4% complete\n",
      "Epoch: 27 Train batch 240 loss: 0.6172366142272949, 50.5% complete\n",
      "Epoch: 27 Train batch 250 loss: 0.638387143611908, 52.6% complete\n",
      "Epoch: 27 Train batch 260 loss: 0.6421051621437073, 54.7% complete\n",
      "Epoch: 27 Train batch 270 loss: 0.6219279170036316, 56.8% complete\n",
      "Epoch: 27 Train batch 280 loss: 0.6269216537475586, 58.9% complete\n",
      "Epoch: 27 Train batch 290 loss: 0.6425833106040955, 61.1% complete\n",
      "Epoch: 27 Train batch 300 loss: 0.6043203473091125, 63.2% complete\n",
      "Epoch: 27 Train batch 310 loss: 0.6249179244041443, 65.3% complete\n",
      "Epoch: 27 Train batch 320 loss: 0.660808801651001, 67.4% complete\n",
      "Epoch: 27 Train batch 330 loss: 0.610114574432373, 69.5% complete\n",
      "Epoch: 27 Train batch 340 loss: 0.5766782164573669, 71.6% complete\n",
      "Epoch: 27 Train batch 350 loss: 0.6561192274093628, 73.7% complete\n",
      "Epoch: 27 Train batch 360 loss: 0.6375259757041931, 75.8% complete\n",
      "Epoch: 27 Train batch 370 loss: 0.6527998447418213, 77.9% complete\n",
      "Epoch: 27 Train batch 380 loss: 0.6076921820640564, 80.0% complete\n",
      "Epoch: 27 Train batch 390 loss: 0.5999599695205688, 82.1% complete\n",
      "Epoch: 27 Train batch 400 loss: 0.6457834243774414, 84.2% complete\n",
      "Epoch: 27 Train batch 410 loss: 0.6274176836013794, 86.3% complete\n",
      "Epoch: 27 Train batch 420 loss: 0.6232886910438538, 88.4% complete\n",
      "Epoch: 27 Train batch 430 loss: 0.6079736351966858, 90.5% complete\n",
      "Epoch: 27 Train batch 440 loss: 0.6500113010406494, 92.6% complete\n",
      "Epoch: 27 Train batch 450 loss: 0.6144717931747437, 94.7% complete\n",
      "Epoch: 27 Train batch 460 loss: 0.6116086840629578, 96.8% complete\n",
      "Epoch: 27 Train batch 470 loss: 0.6353445649147034, 98.9% complete\n",
      "Batch 1. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5969907641410828\n",
      "Batch 2. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5716260075569153\n",
      "Batch 3. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6513498425483704\n",
      "Batch 4. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6344720125198364\n",
      "Batch 5. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6411110162734985\n",
      "Batch 6. Data shape torch.Size([32, 3, 224, 224]) Loss 0.586909830570221\n",
      "Batch 7. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6446965932846069\n",
      "Batch 8. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5989170074462891\n",
      "Batch 9. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6120034456253052\n",
      "Batch 10. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6321219801902771\n",
      "Batch 11. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6282885074615479\n",
      "Batch 12. Data shape torch.Size([32, 3, 224, 224]) Loss 0.624489963054657\n",
      "Batch 13. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5922264456748962\n",
      "Batch 14. Data shape torch.Size([32, 3, 224, 224]) Loss 0.626178503036499\n",
      "Batch 15. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6260106563568115\n",
      "Batch 16. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6356728672981262\n",
      "Batch 17. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5761753916740417\n",
      "Batch 18. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6154495477676392\n",
      "Batch 19. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6218779683113098\n",
      "Batch 20. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6512036919593811\n",
      "Batch 21. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6572654843330383\n",
      "Batch 22. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6266714930534363\n",
      "Batch 23. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6383809447288513\n",
      "Batch 24. Data shape torch.Size([32, 3, 224, 224]) Loss 0.651171863079071\n",
      "Batch 25. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5819845795631409\n",
      "Batch 26. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5789723992347717\n",
      "Batch 27. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6175183653831482\n",
      "Batch 28. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6450377702713013\n",
      "Batch 29. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6298940181732178\n",
      "Batch 30. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6308441162109375\n",
      "Batch 31. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6208655834197998\n",
      "Batch 32. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5947715044021606\n",
      "Batch 33. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6184684634208679\n",
      "Batch 34. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6317225694656372\n",
      "Batch 35. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5548421740531921\n",
      "Batch 36. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6317421197891235\n",
      "Batch 37. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5974223017692566\n",
      "Batch 38. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6174484491348267\n",
      "Batch 39. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6280889511108398\n",
      "Batch 40. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5909924507141113\n",
      "Batch 41. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6093413233757019\n",
      "Batch 42. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5851538181304932\n",
      "Batch 43. Data shape torch.Size([32, 3, 224, 224]) Loss 0.616098940372467\n",
      "Batch 44. Data shape torch.Size([32, 3, 224, 224]) Loss 0.628308117389679\n",
      "Batch 45. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6648589968681335\n",
      "Batch 46. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6175487041473389\n",
      "Batch 47. Data shape torch.Size([32, 3, 224, 224]) Loss 0.601574718952179\n",
      "Batch 48. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6275992393493652\n",
      "Batch 49. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6542777419090271\n",
      "Batch 50. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6336684226989746\n",
      "Batch 51. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6296482682228088\n",
      "Batch 52. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6178907155990601\n",
      "Batch 53. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6495242118835449\n",
      "Batch 54. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5949769616127014\n",
      "Batch 55. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6223334670066833\n",
      "Batch 56. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6680656671524048\n",
      "Batch 57. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6006350517272949\n",
      "Batch 58. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6045830845832825\n",
      "Batch 59. Data shape torch.Size([32, 3, 224, 224]) Loss 0.633856475353241\n",
      "Batch 60. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6147611737251282\n",
      "Batch 61. Data shape torch.Size([32, 3, 224, 224]) Loss 0.627436101436615\n",
      "Batch 62. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6448284983634949\n",
      "Batch 63. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5957577228546143\n",
      "Batch 64. Data shape torch.Size([32, 3, 224, 224]) Loss 0.613945722579956\n",
      "Batch 65. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6111351847648621\n",
      "Batch 66. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6370839476585388\n",
      "Batch 67. Data shape torch.Size([32, 3, 224, 224]) Loss 0.641340970993042\n",
      "Batch 68. Data shape torch.Size([32, 3, 224, 224]) Loss 0.594413161277771\n",
      "Batch 69. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6205549836158752\n",
      "Batch 70. Data shape torch.Size([32, 3, 224, 224]) Loss 0.597983181476593\n",
      "Batch 71. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6437283158302307\n",
      "Batch 72. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6230557560920715\n",
      "Batch 73. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5910349488258362\n",
      "Batch 74. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5852357745170593\n",
      "Batch 75. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6198060512542725\n",
      "Batch 76. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6232227087020874\n",
      "Batch 77. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6426995396614075\n",
      "Batch 78. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6138697862625122\n",
      "Batch 79. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6539584398269653\n",
      "Batch 80. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6258700489997864\n",
      "Batch 81. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6506670713424683\n",
      "Batch 82. Data shape torch.Size([32, 3, 224, 224]) Loss 0.605022668838501\n",
      "Batch 83. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6140620708465576\n",
      "Batch 84. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6253600120544434\n",
      "Batch 85. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6449039578437805\n",
      "Batch 86. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6213526129722595\n",
      "Batch 87. Data shape torch.Size([32, 3, 224, 224]) Loss 0.622765064239502\n",
      "Batch 88. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6305240988731384\n",
      "Batch 89. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6155794262886047\n",
      "Batch 90. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6107035279273987\n",
      "Batch 91. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6183895468711853\n",
      "Batch 92. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6250364780426025\n",
      "Batch 93. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6314457654953003\n",
      "Batch 94. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6362923979759216\n",
      "Batch 95. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6092841029167175\n",
      "Batch 96. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6015015244483948\n",
      "Batch 97. Data shape torch.Size([32, 3, 224, 224]) Loss 0.609427809715271\n",
      "Batch 98. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6099833846092224\n",
      "Batch 99. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6000967025756836\n",
      "Batch 100. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6461004018783569\n",
      "Batch 101. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6188437938690186\n",
      "Batch 102. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5984688997268677\n",
      "Batch 103. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6440914869308472\n",
      "Batch 104. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6449818015098572\n",
      "Batch 105. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5918434262275696\n",
      "Batch 106. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6220687627792358\n",
      "Batch 107. Data shape torch.Size([32, 3, 224, 224]) Loss 0.613538920879364\n",
      "Batch 108. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6198763847351074\n",
      "Batch 109. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6004769802093506\n",
      "Batch 110. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5968486666679382\n",
      "Batch 111. Data shape torch.Size([32, 3, 224, 224]) Loss 0.621330201625824\n",
      "Batch 112. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6137080192565918\n",
      "Batch 113. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6037548184394836\n",
      "Batch 114. Data shape torch.Size([32, 3, 224, 224]) Loss 0.595022439956665\n",
      "Batch 115. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5834051370620728\n",
      "Batch 116. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6137476563453674\n",
      "Batch 117. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6171292066574097\n",
      "Batch 118. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6529003977775574\n",
      "Batch 119. Data shape torch.Size([20, 3, 224, 224]) Loss 0.612959086894989\n",
      "Valid loss improved from 0.626814 to 0.619219. Saving model ...\n",
      "Epoch: 27/50 | time: 21.0m 46.1s | lr: 1.0000e-05 | train/loss: 0.62646 | val/loss: 0.61922 | val/accuracy: 0.75896 | val/AUC: 0.75988 | val/Kappa: 0.51872\n",
      "Epoch: 28 Train batch 10 loss: 0.5962247848510742, 2.1% complete\n",
      "Epoch: 28 Train batch 20 loss: 0.6086116433143616, 4.2% complete\n",
      "Epoch: 28 Train batch 30 loss: 0.6305774450302124, 6.3% complete\n",
      "Epoch: 28 Train batch 40 loss: 0.6255887150764465, 8.4% complete\n",
      "Epoch: 28 Train batch 50 loss: 0.6334274411201477, 10.5% complete\n",
      "Epoch: 28 Train batch 60 loss: 0.6262236833572388, 12.6% complete\n",
      "Epoch: 28 Train batch 70 loss: 0.6146107912063599, 14.7% complete\n",
      "Epoch: 28 Train batch 80 loss: 0.6187798976898193, 16.8% complete\n",
      "Epoch: 28 Train batch 90 loss: 0.6139232516288757, 18.9% complete\n",
      "Epoch: 28 Train batch 100 loss: 0.6311130523681641, 21.1% complete\n",
      "Epoch: 28 Train batch 110 loss: 0.6157758235931396, 23.2% complete\n",
      "Epoch: 28 Train batch 120 loss: 0.6169751286506653, 25.3% complete\n",
      "Epoch: 28 Train batch 130 loss: 0.6079108119010925, 27.4% complete\n",
      "Epoch: 28 Train batch 140 loss: 0.6258481740951538, 29.5% complete\n",
      "Epoch: 28 Train batch 150 loss: 0.6316962242126465, 31.6% complete\n",
      "Epoch: 28 Train batch 160 loss: 0.6578238010406494, 33.7% complete\n",
      "Epoch: 28 Train batch 170 loss: 0.6452765464782715, 35.8% complete\n",
      "Epoch: 28 Train batch 180 loss: 0.6071463823318481, 37.9% complete\n",
      "Epoch: 28 Train batch 190 loss: 0.6264268755912781, 40.0% complete\n",
      "Epoch: 28 Train batch 200 loss: 0.6371844410896301, 42.1% complete\n",
      "Epoch: 28 Train batch 210 loss: 0.6396957635879517, 44.2% complete\n",
      "Epoch: 28 Train batch 220 loss: 0.6525944471359253, 46.3% complete\n",
      "Epoch: 28 Train batch 230 loss: 0.6192329525947571, 48.4% complete\n",
      "Epoch: 28 Train batch 240 loss: 0.6651111245155334, 50.5% complete\n",
      "Epoch: 28 Train batch 250 loss: 0.6591137647628784, 52.6% complete\n",
      "Epoch: 28 Train batch 260 loss: 0.6425648331642151, 54.7% complete\n",
      "Epoch: 28 Train batch 270 loss: 0.6233381032943726, 56.8% complete\n",
      "Epoch: 28 Train batch 280 loss: 0.5985342860221863, 58.9% complete\n",
      "Epoch: 28 Train batch 290 loss: 0.6406089067459106, 61.1% complete\n",
      "Epoch: 28 Train batch 300 loss: 0.5972478985786438, 63.2% complete\n",
      "Epoch: 28 Train batch 310 loss: 0.6198244690895081, 65.3% complete\n",
      "Epoch: 28 Train batch 320 loss: 0.6148918867111206, 67.4% complete\n",
      "Epoch: 28 Train batch 330 loss: 0.6483777761459351, 69.5% complete\n",
      "Epoch: 28 Train batch 340 loss: 0.6298808455467224, 71.6% complete\n",
      "Epoch: 28 Train batch 350 loss: 0.6379142999649048, 73.7% complete\n",
      "Epoch: 28 Train batch 360 loss: 0.6198320388793945, 75.8% complete\n",
      "Epoch: 28 Train batch 370 loss: 0.6016755700111389, 77.9% complete\n",
      "Epoch: 28 Train batch 380 loss: 0.6982200741767883, 80.0% complete\n",
      "Epoch: 28 Train batch 390 loss: 0.6613777875900269, 82.1% complete\n",
      "Epoch: 28 Train batch 400 loss: 0.6181745529174805, 84.2% complete\n",
      "Epoch: 28 Train batch 410 loss: 0.5954075455665588, 86.3% complete\n",
      "Epoch: 28 Train batch 420 loss: 0.6201174855232239, 88.4% complete\n",
      "Epoch: 28 Train batch 430 loss: 0.6045230031013489, 90.5% complete\n",
      "Epoch: 28 Train batch 440 loss: 0.6477890014648438, 92.6% complete\n",
      "Epoch: 28 Train batch 450 loss: 0.563621997833252, 94.7% complete\n",
      "Epoch: 28 Train batch 460 loss: 0.6148487329483032, 96.8% complete\n",
      "Epoch: 28 Train batch 470 loss: 0.6194579005241394, 98.9% complete\n",
      "Batch 1. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6213878393173218\n",
      "Batch 2. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5850557684898376\n",
      "Batch 3. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6172892451286316\n",
      "Batch 4. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6059392690658569\n",
      "Batch 5. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6033818125724792\n",
      "Batch 6. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5822346210479736\n",
      "Batch 7. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6222835183143616\n",
      "Batch 8. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6006001830101013\n",
      "Batch 9. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5917328000068665\n",
      "Batch 10. Data shape torch.Size([32, 3, 224, 224]) Loss 0.649161696434021\n",
      "Batch 11. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6302324533462524\n",
      "Batch 12. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6235776543617249\n",
      "Batch 13. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5850189328193665\n",
      "Batch 14. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6178197860717773\n",
      "Batch 15. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5722044706344604\n",
      "Batch 16. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6155591011047363\n",
      "Batch 17. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5881457328796387\n",
      "Batch 18. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6158318519592285\n",
      "Batch 19. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6567589640617371\n",
      "Batch 20. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6266818642616272\n",
      "Batch 21. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6482555270195007\n",
      "Batch 22. Data shape torch.Size([32, 3, 224, 224]) Loss 0.636776328086853\n",
      "Batch 23. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5948222279548645\n",
      "Batch 24. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6185635328292847\n",
      "Batch 25. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5995259881019592\n",
      "Batch 26. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6013761758804321\n",
      "Batch 27. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6380295157432556\n",
      "Batch 28. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6389647722244263\n",
      "Batch 29. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5602814555168152\n",
      "Batch 30. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5901666283607483\n",
      "Batch 31. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6435562968254089\n",
      "Batch 32. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6250450611114502\n",
      "Batch 33. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6442214846611023\n",
      "Batch 34. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6205374598503113\n",
      "Batch 35. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6446888446807861\n",
      "Batch 36. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6203513741493225\n",
      "Batch 37. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6272814273834229\n",
      "Batch 38. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6035971641540527\n",
      "Batch 39. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6211552619934082\n",
      "Batch 40. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6314721703529358\n",
      "Batch 41. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6355186700820923\n",
      "Batch 42. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6536585688591003\n",
      "Batch 43. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6424210071563721\n",
      "Batch 44. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6198038458824158\n",
      "Batch 45. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6239180564880371\n",
      "Batch 46. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5682447552680969\n",
      "Batch 47. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6110707521438599\n",
      "Batch 48. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6268585324287415\n",
      "Batch 49. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6483066082000732\n",
      "Batch 50. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6064240336418152\n",
      "Batch 51. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5918640494346619\n",
      "Batch 52. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6172999143600464\n",
      "Batch 53. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5926772952079773\n",
      "Batch 54. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6084045767784119\n",
      "Batch 55. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6085708141326904\n",
      "Batch 56. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6136744618415833\n",
      "Batch 57. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6621086001396179\n",
      "Batch 58. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6262295246124268\n",
      "Batch 59. Data shape torch.Size([32, 3, 224, 224]) Loss 0.620724081993103\n",
      "Batch 60. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5955678224563599\n",
      "Batch 61. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6230468153953552\n",
      "Batch 62. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5634902715682983\n",
      "Batch 63. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6137369275093079\n",
      "Batch 64. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5885462760925293\n",
      "Batch 65. Data shape torch.Size([32, 3, 224, 224]) Loss 0.621099591255188\n",
      "Batch 66. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6482856273651123\n",
      "Batch 67. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6095854640007019\n",
      "Batch 68. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5800763964653015\n",
      "Batch 69. Data shape torch.Size([32, 3, 224, 224]) Loss 0.656399130821228\n",
      "Batch 70. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6376344561576843\n",
      "Batch 71. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6106818318367004\n",
      "Batch 72. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6337828040122986\n",
      "Batch 73. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6169114112854004\n",
      "Batch 74. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6322664022445679\n",
      "Batch 75. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6216679215431213\n",
      "Batch 76. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6042895317077637\n",
      "Batch 77. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5753816962242126\n",
      "Batch 78. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6492671370506287\n",
      "Batch 79. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6255367994308472\n",
      "Batch 80. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5926677584648132\n",
      "Batch 81. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6328533291816711\n",
      "Batch 82. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6320324540138245\n",
      "Batch 83. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5892040133476257\n",
      "Batch 84. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6075682640075684\n",
      "Batch 85. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6111592054367065\n",
      "Batch 86. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6549946665763855\n",
      "Batch 87. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5789230465888977\n",
      "Batch 88. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6101497411727905\n",
      "Batch 89. Data shape torch.Size([32, 3, 224, 224]) Loss 0.582780659198761\n",
      "Batch 90. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6116580367088318\n",
      "Batch 91. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6010078191757202\n",
      "Batch 92. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6151204705238342\n",
      "Batch 93. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6107128858566284\n",
      "Batch 94. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6101621389389038\n",
      "Batch 95. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5780014395713806\n",
      "Batch 96. Data shape torch.Size([32, 3, 224, 224]) Loss 0.624004065990448\n",
      "Batch 97. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5868922472000122\n",
      "Batch 98. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5969992280006409\n",
      "Batch 99. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5739765763282776\n",
      "Batch 100. Data shape torch.Size([32, 3, 224, 224]) Loss 0.638784646987915\n",
      "Batch 101. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6154893636703491\n",
      "Batch 102. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6229262351989746\n",
      "Batch 103. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6383775472640991\n",
      "Batch 104. Data shape torch.Size([32, 3, 224, 224]) Loss 0.608610987663269\n",
      "Batch 105. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6177164912223816\n",
      "Batch 106. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6100982427597046\n",
      "Batch 107. Data shape torch.Size([32, 3, 224, 224]) Loss 0.589812695980072\n",
      "Batch 108. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6130368709564209\n",
      "Batch 109. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5843364000320435\n",
      "Batch 110. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6138095259666443\n",
      "Batch 111. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5817141532897949\n",
      "Batch 112. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6254117488861084\n",
      "Batch 113. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6281375885009766\n",
      "Batch 114. Data shape torch.Size([32, 3, 224, 224]) Loss 0.60135418176651\n",
      "Batch 115. Data shape torch.Size([32, 3, 224, 224]) Loss 0.622431755065918\n",
      "Batch 116. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6484373807907104\n",
      "Batch 117. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6222456097602844\n",
      "Batch 118. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6095547676086426\n",
      "Batch 119. Data shape torch.Size([20, 3, 224, 224]) Loss 0.6628116369247437\n",
      "Valid loss improved from 0.619219 to 0.614795. Saving model ...\n",
      "Epoch: 28/50 | time: 23.0m 34.71s | lr: 1.0000e-05 | train/loss: 0.62148 | val/loss: 0.61479 | val/accuracy: 0.76159 | val/AUC: 0.76234 | val/Kappa: 0.52382\n",
      "Epoch: 29 Train batch 10 loss: 0.6262354850769043, 2.1% complete\n",
      "Epoch: 29 Train batch 20 loss: 0.6201472282409668, 4.2% complete\n",
      "Epoch: 29 Train batch 30 loss: 0.627376914024353, 6.3% complete\n",
      "Epoch: 29 Train batch 40 loss: 0.5832231640815735, 8.4% complete\n",
      "Epoch: 29 Train batch 50 loss: 0.642901599407196, 10.5% complete\n",
      "Epoch: 29 Train batch 60 loss: 0.605313777923584, 12.6% complete\n",
      "Epoch: 29 Train batch 70 loss: 0.6386017203330994, 14.7% complete\n",
      "Epoch: 29 Train batch 80 loss: 0.6375654935836792, 16.8% complete\n",
      "Epoch: 29 Train batch 90 loss: 0.6151623129844666, 18.9% complete\n",
      "Epoch: 29 Train batch 100 loss: 0.6100279092788696, 21.1% complete\n",
      "Epoch: 29 Train batch 110 loss: 0.6013964414596558, 23.2% complete\n",
      "Epoch: 29 Train batch 120 loss: 0.6342738270759583, 25.3% complete\n",
      "Epoch: 29 Train batch 130 loss: 0.6100569367408752, 27.4% complete\n",
      "Epoch: 29 Train batch 140 loss: 0.6559227705001831, 29.5% complete\n",
      "Epoch: 29 Train batch 150 loss: 0.6126753091812134, 31.6% complete\n",
      "Epoch: 29 Train batch 160 loss: 0.5972286462783813, 33.7% complete\n",
      "Epoch: 29 Train batch 170 loss: 0.6429068446159363, 35.8% complete\n",
      "Epoch: 29 Train batch 180 loss: 0.6263890862464905, 37.9% complete\n",
      "Epoch: 29 Train batch 190 loss: 0.6530343294143677, 40.0% complete\n",
      "Epoch: 29 Train batch 200 loss: 0.628892719745636, 42.1% complete\n",
      "Epoch: 29 Train batch 210 loss: 0.6029459238052368, 44.2% complete\n",
      "Epoch: 29 Train batch 220 loss: 0.6232502460479736, 46.3% complete\n",
      "Epoch: 29 Train batch 230 loss: 0.6367253661155701, 48.4% complete\n",
      "Epoch: 29 Train batch 240 loss: 0.6328755021095276, 50.5% complete\n",
      "Epoch: 29 Train batch 250 loss: 0.6038559079170227, 52.6% complete\n",
      "Epoch: 29 Train batch 260 loss: 0.6416191458702087, 54.7% complete\n",
      "Epoch: 29 Train batch 270 loss: 0.6152586340904236, 56.8% complete\n",
      "Epoch: 29 Train batch 280 loss: 0.5978428721427917, 58.9% complete\n",
      "Epoch: 29 Train batch 290 loss: 0.6200589537620544, 61.1% complete\n",
      "Epoch: 29 Train batch 300 loss: 0.5885677933692932, 63.2% complete\n",
      "Epoch: 29 Train batch 310 loss: 0.6159873008728027, 65.3% complete\n",
      "Epoch: 29 Train batch 320 loss: 0.6266646385192871, 67.4% complete\n",
      "Epoch: 29 Train batch 330 loss: 0.6186487078666687, 69.5% complete\n",
      "Epoch: 29 Train batch 340 loss: 0.6173302531242371, 71.6% complete\n",
      "Epoch: 29 Train batch 350 loss: 0.6263190507888794, 73.7% complete\n",
      "Epoch: 29 Train batch 360 loss: 0.5988409519195557, 75.8% complete\n",
      "Epoch: 29 Train batch 370 loss: 0.618811845779419, 77.9% complete\n",
      "Epoch: 29 Train batch 380 loss: 0.6072251796722412, 80.0% complete\n",
      "Epoch: 29 Train batch 390 loss: 0.5734822750091553, 82.1% complete\n",
      "Epoch: 29 Train batch 400 loss: 0.6001423597335815, 84.2% complete\n",
      "Epoch: 29 Train batch 410 loss: 0.6213468313217163, 86.3% complete\n",
      "Epoch: 29 Train batch 420 loss: 0.6168239712715149, 88.4% complete\n",
      "Epoch: 29 Train batch 430 loss: 0.5800586938858032, 90.5% complete\n",
      "Epoch: 29 Train batch 440 loss: 0.6221698522567749, 92.6% complete\n",
      "Epoch: 29 Train batch 450 loss: 0.5968209505081177, 94.7% complete\n",
      "Epoch: 29 Train batch 460 loss: 0.571377158164978, 96.8% complete\n",
      "Epoch: 29 Train batch 470 loss: 0.6493639349937439, 98.9% complete\n",
      "Batch 1. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6178831458091736\n",
      "Batch 2. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5707364678382874\n",
      "Batch 3. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6098823547363281\n",
      "Batch 4. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6067811250686646\n",
      "Batch 5. Data shape torch.Size([32, 3, 224, 224]) Loss 0.621669590473175\n",
      "Batch 6. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6085415482521057\n",
      "Batch 7. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6339898109436035\n",
      "Batch 8. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6244730949401855\n",
      "Batch 9. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5576896667480469\n",
      "Batch 10. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5986963510513306\n",
      "Batch 11. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6374653577804565\n",
      "Batch 12. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6180123090744019\n",
      "Batch 13. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5945329666137695\n",
      "Batch 14. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5959694385528564\n",
      "Batch 15. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6293719410896301\n",
      "Batch 16. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6379201412200928\n",
      "Batch 17. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6289321780204773\n",
      "Batch 18. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6294248700141907\n",
      "Batch 19. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6204466819763184\n",
      "Batch 20. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6436141729354858\n",
      "Batch 21. Data shape torch.Size([32, 3, 224, 224]) Loss 0.592891275882721\n",
      "Batch 22. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6220223903656006\n",
      "Batch 23. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6215011477470398\n",
      "Batch 24. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5823682546615601\n",
      "Batch 25. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6207633018493652\n",
      "Batch 26. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5455061197280884\n",
      "Batch 27. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6120463013648987\n",
      "Batch 28. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6177108287811279\n",
      "Batch 29. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6070000529289246\n",
      "Batch 30. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5960886478424072\n",
      "Batch 31. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5916404128074646\n",
      "Batch 32. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6264032125473022\n",
      "Batch 33. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5961440205574036\n",
      "Batch 34. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6108188629150391\n",
      "Batch 35. Data shape torch.Size([32, 3, 224, 224]) Loss 0.599561870098114\n",
      "Batch 36. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6111266016960144\n",
      "Batch 37. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6175903677940369\n",
      "Batch 38. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5840378999710083\n",
      "Batch 39. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5914738774299622\n",
      "Batch 40. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5881154537200928\n",
      "Batch 41. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6474197506904602\n",
      "Batch 42. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6381464600563049\n",
      "Batch 43. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6057724356651306\n",
      "Batch 44. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6376716494560242\n",
      "Batch 45. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5829841494560242\n",
      "Batch 46. Data shape torch.Size([32, 3, 224, 224]) Loss 0.628157913684845\n",
      "Batch 47. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6005470752716064\n",
      "Batch 48. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6038415431976318\n",
      "Batch 49. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5747783780097961\n",
      "Batch 50. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5780759453773499\n",
      "Batch 51. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5844544172286987\n",
      "Batch 52. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6075665354728699\n",
      "Batch 53. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6579225063323975\n",
      "Batch 54. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6166833639144897\n",
      "Batch 55. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5907954573631287\n",
      "Batch 56. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6357982158660889\n",
      "Batch 57. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6289516091346741\n",
      "Batch 58. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6015752553939819\n",
      "Batch 59. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6269646286964417\n",
      "Batch 60. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6398840546607971\n",
      "Batch 61. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6427464485168457\n",
      "Batch 62. Data shape torch.Size([32, 3, 224, 224]) Loss 0.603864312171936\n",
      "Batch 63. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5989496111869812\n",
      "Batch 64. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6181214451789856\n",
      "Batch 65. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6241680383682251\n",
      "Batch 66. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5963912606239319\n",
      "Batch 67. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6247121095657349\n",
      "Batch 68. Data shape torch.Size([32, 3, 224, 224]) Loss 0.637697160243988\n",
      "Batch 69. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6173088550567627\n",
      "Batch 70. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6162691712379456\n",
      "Batch 71. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6291044354438782\n",
      "Batch 72. Data shape torch.Size([32, 3, 224, 224]) Loss 0.608707070350647\n",
      "Batch 73. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5957879424095154\n",
      "Batch 74. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5932350754737854\n",
      "Batch 75. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5871885418891907\n",
      "Batch 76. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6441026926040649\n",
      "Batch 77. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5933721661567688\n",
      "Batch 78. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6121701002120972\n",
      "Batch 79. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6246654391288757\n",
      "Batch 80. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5840340256690979\n",
      "Batch 81. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5850480794906616\n",
      "Batch 82. Data shape torch.Size([32, 3, 224, 224]) Loss 0.603154182434082\n",
      "Batch 83. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6302785277366638\n",
      "Batch 84. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6181138753890991\n",
      "Batch 85. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5862540006637573\n",
      "Batch 86. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6278015971183777\n",
      "Batch 87. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5965287685394287\n",
      "Batch 88. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6202677488327026\n",
      "Batch 89. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5680289268493652\n",
      "Batch 90. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6028554439544678\n",
      "Batch 91. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5946983098983765\n",
      "Batch 92. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6266969442367554\n",
      "Batch 93. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6024501919746399\n",
      "Batch 94. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6076103448867798\n",
      "Batch 95. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5722935795783997\n",
      "Batch 96. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6129181385040283\n",
      "Batch 97. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6576778292655945\n",
      "Batch 98. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6398251056671143\n",
      "Batch 99. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6392003893852234\n",
      "Batch 100. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6535946726799011\n",
      "Batch 101. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5909444689750671\n",
      "Batch 102. Data shape torch.Size([32, 3, 224, 224]) Loss 0.603801429271698\n",
      "Batch 103. Data shape torch.Size([32, 3, 224, 224]) Loss 0.599637508392334\n",
      "Batch 104. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5877154469490051\n",
      "Batch 105. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6030348539352417\n",
      "Batch 106. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5905157923698425\n",
      "Batch 107. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6180087327957153\n",
      "Batch 108. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6325251460075378\n",
      "Batch 109. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6211215853691101\n",
      "Batch 110. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6290459036827087\n",
      "Batch 111. Data shape torch.Size([32, 3, 224, 224]) Loss 0.584861159324646\n",
      "Batch 112. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6316514611244202\n",
      "Batch 113. Data shape torch.Size([32, 3, 224, 224]) Loss 0.624137818813324\n",
      "Batch 114. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5823385119438171\n",
      "Batch 115. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5695983171463013\n",
      "Batch 116. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6199912428855896\n",
      "Batch 117. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6363070607185364\n",
      "Batch 118. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5804219841957092\n",
      "Batch 119. Data shape torch.Size([20, 3, 224, 224]) Loss 0.6182249784469604\n",
      "Valid loss improved from 0.614795 to 0.610341. Saving model ...\n",
      "Epoch: 29/50 | time: 22.0m 53.66s | lr: 1.0000e-05 | train/loss: 0.61845 | val/loss: 0.61034 | val/accuracy: 0.76344 | val/AUC: 0.76409 | val/Kappa: 0.52741\n",
      "Epoch: 30 Train batch 10 loss: 0.5813108086585999, 2.1% complete\n",
      "Epoch: 30 Train batch 20 loss: 0.631308913230896, 4.2% complete\n",
      "Epoch: 30 Train batch 30 loss: 0.6482833027839661, 6.3% complete\n",
      "Epoch: 30 Train batch 40 loss: 0.5840458869934082, 8.4% complete\n",
      "Epoch: 30 Train batch 50 loss: 0.6399648785591125, 10.5% complete\n",
      "Epoch: 30 Train batch 60 loss: 0.6340123414993286, 12.6% complete\n",
      "Epoch: 30 Train batch 70 loss: 0.6341467499732971, 14.7% complete\n",
      "Epoch: 30 Train batch 80 loss: 0.6713104844093323, 16.8% complete\n",
      "Epoch: 30 Train batch 90 loss: 0.575318455696106, 18.9% complete\n",
      "Epoch: 30 Train batch 100 loss: 0.5922707319259644, 21.1% complete\n",
      "Epoch: 30 Train batch 110 loss: 0.5670402646064758, 23.2% complete\n",
      "Epoch: 30 Train batch 120 loss: 0.6039475202560425, 25.3% complete\n",
      "Epoch: 30 Train batch 130 loss: 0.6632819771766663, 27.4% complete\n",
      "Epoch: 30 Train batch 140 loss: 0.6820862889289856, 29.5% complete\n",
      "Epoch: 30 Train batch 150 loss: 0.5888976454734802, 31.6% complete\n",
      "Epoch: 30 Train batch 160 loss: 0.6245589852333069, 33.7% complete\n",
      "Epoch: 30 Train batch 170 loss: 0.6260696053504944, 35.8% complete\n",
      "Epoch: 30 Train batch 180 loss: 0.6354068517684937, 37.9% complete\n",
      "Epoch: 30 Train batch 190 loss: 0.6350759267807007, 40.0% complete\n",
      "Epoch: 30 Train batch 200 loss: 0.5915776491165161, 42.1% complete\n",
      "Epoch: 30 Train batch 210 loss: 0.6503089666366577, 44.2% complete\n",
      "Epoch: 30 Train batch 220 loss: 0.6168834567070007, 46.3% complete\n",
      "Epoch: 30 Train batch 230 loss: 0.6413980722427368, 48.4% complete\n",
      "Epoch: 30 Train batch 240 loss: 0.6082240343093872, 50.5% complete\n",
      "Epoch: 30 Train batch 250 loss: 0.5806499123573303, 52.6% complete\n",
      "Epoch: 30 Train batch 260 loss: 0.6208539605140686, 54.7% complete\n",
      "Epoch: 30 Train batch 270 loss: 0.5854287147521973, 56.8% complete\n",
      "Epoch: 30 Train batch 280 loss: 0.6231614351272583, 58.9% complete\n",
      "Epoch: 30 Train batch 290 loss: 0.5965122580528259, 61.1% complete\n",
      "Epoch: 30 Train batch 300 loss: 0.6306864619255066, 63.2% complete\n",
      "Epoch: 30 Train batch 310 loss: 0.57783442735672, 65.3% complete\n",
      "Epoch: 30 Train batch 320 loss: 0.6279311180114746, 67.4% complete\n",
      "Epoch: 30 Train batch 330 loss: 0.6137778759002686, 69.5% complete\n",
      "Epoch: 30 Train batch 340 loss: 0.6392223238945007, 71.6% complete\n",
      "Epoch: 30 Train batch 350 loss: 0.5682307481765747, 73.7% complete\n",
      "Epoch: 30 Train batch 360 loss: 0.6540917754173279, 75.8% complete\n",
      "Epoch: 30 Train batch 370 loss: 0.6635275483131409, 77.9% complete\n",
      "Epoch: 30 Train batch 380 loss: 0.633287787437439, 80.0% complete\n",
      "Epoch: 30 Train batch 390 loss: 0.6065335273742676, 82.1% complete\n",
      "Epoch: 30 Train batch 400 loss: 0.6568225026130676, 84.2% complete\n",
      "Epoch: 30 Train batch 410 loss: 0.6469752788543701, 86.3% complete\n",
      "Epoch: 30 Train batch 420 loss: 0.6078147888183594, 88.4% complete\n",
      "Epoch: 30 Train batch 430 loss: 0.5881831645965576, 90.5% complete\n",
      "Epoch: 30 Train batch 440 loss: 0.6036926507949829, 92.6% complete\n",
      "Epoch: 30 Train batch 450 loss: 0.5834984183311462, 94.7% complete\n",
      "Epoch: 30 Train batch 460 loss: 0.604234516620636, 96.8% complete\n",
      "Epoch: 30 Train batch 470 loss: 0.5757049322128296, 98.9% complete\n",
      "Batch 1. Data shape torch.Size([32, 3, 224, 224]) Loss 0.655299723148346\n",
      "Batch 2. Data shape torch.Size([32, 3, 224, 224]) Loss 0.598821222782135\n",
      "Batch 3. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6330335140228271\n",
      "Batch 4. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5824856758117676\n",
      "Batch 5. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5938456058502197\n",
      "Batch 6. Data shape torch.Size([32, 3, 224, 224]) Loss 0.62904953956604\n",
      "Batch 7. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5865176916122437\n",
      "Batch 8. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6255972385406494\n",
      "Batch 9. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6482710838317871\n",
      "Batch 10. Data shape torch.Size([32, 3, 224, 224]) Loss 0.599583089351654\n",
      "Batch 11. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5863158702850342\n",
      "Batch 12. Data shape torch.Size([32, 3, 224, 224]) Loss 0.62351393699646\n",
      "Batch 13. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6289113163948059\n",
      "Batch 14. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5763065218925476\n",
      "Batch 15. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6054508686065674\n",
      "Batch 16. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5805312991142273\n",
      "Batch 17. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5843662619590759\n",
      "Batch 18. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6152782440185547\n",
      "Batch 19. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5702694654464722\n",
      "Batch 20. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6159271597862244\n",
      "Batch 21. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5773279070854187\n",
      "Batch 22. Data shape torch.Size([32, 3, 224, 224]) Loss 0.605431318283081\n",
      "Batch 23. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5825340151786804\n",
      "Batch 24. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6309623718261719\n",
      "Batch 25. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6452091932296753\n",
      "Batch 26. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5519418120384216\n",
      "Batch 27. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6205264925956726\n",
      "Batch 28. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5942212343215942\n",
      "Batch 29. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6348702907562256\n",
      "Batch 30. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6244329810142517\n",
      "Batch 31. Data shape torch.Size([32, 3, 224, 224]) Loss 0.597037672996521\n",
      "Batch 32. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6204329133033752\n",
      "Batch 33. Data shape torch.Size([32, 3, 224, 224]) Loss 0.632585346698761\n",
      "Batch 34. Data shape torch.Size([32, 3, 224, 224]) Loss 0.590916097164154\n",
      "Batch 35. Data shape torch.Size([32, 3, 224, 224]) Loss 0.580035388469696\n",
      "Batch 36. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5875911116600037\n",
      "Batch 37. Data shape torch.Size([32, 3, 224, 224]) Loss 0.590672492980957\n",
      "Batch 38. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5616616606712341\n",
      "Batch 39. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5900756120681763\n",
      "Batch 40. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6064693331718445\n",
      "Batch 41. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6154734492301941\n",
      "Batch 42. Data shape torch.Size([32, 3, 224, 224]) Loss 0.632301390171051\n",
      "Batch 43. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5897294282913208\n",
      "Batch 44. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6508492231369019\n",
      "Batch 45. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6374735236167908\n",
      "Batch 46. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5698449015617371\n",
      "Batch 47. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6011351346969604\n",
      "Batch 48. Data shape torch.Size([32, 3, 224, 224]) Loss 0.598924994468689\n",
      "Batch 49. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5903946161270142\n",
      "Batch 50. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5902182459831238\n",
      "Batch 51. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5981548428535461\n",
      "Batch 52. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6038762331008911\n",
      "Batch 53. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5902948379516602\n",
      "Batch 54. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5672622323036194\n",
      "Batch 55. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5946308970451355\n",
      "Batch 56. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6231871843338013\n",
      "Batch 57. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6362923383712769\n",
      "Batch 58. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6235983371734619\n",
      "Batch 59. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5903332233428955\n",
      "Batch 60. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6396700739860535\n",
      "Batch 61. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5517857074737549\n",
      "Batch 62. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6219726800918579\n",
      "Batch 63. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6168709397315979\n",
      "Batch 64. Data shape torch.Size([32, 3, 224, 224]) Loss 0.59294593334198\n",
      "Batch 65. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5967394113540649\n",
      "Batch 66. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6058158874511719\n",
      "Batch 67. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5922631621360779\n",
      "Batch 68. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5970205068588257\n",
      "Batch 69. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5989105701446533\n",
      "Batch 70. Data shape torch.Size([32, 3, 224, 224]) Loss 0.633499264717102\n",
      "Batch 71. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5834922194480896\n",
      "Batch 72. Data shape torch.Size([32, 3, 224, 224]) Loss 0.622952401638031\n",
      "Batch 73. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6474592685699463\n",
      "Batch 74. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6301489472389221\n",
      "Batch 75. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6171849370002747\n",
      "Batch 76. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6212136149406433\n",
      "Batch 77. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6034219264984131\n",
      "Batch 78. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5807665586471558\n",
      "Batch 79. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6007742881774902\n",
      "Batch 80. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6336889863014221\n",
      "Batch 81. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5873674750328064\n",
      "Batch 82. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6711013317108154\n",
      "Batch 83. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6135190725326538\n",
      "Batch 84. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6308927536010742\n",
      "Batch 85. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6509290337562561\n",
      "Batch 86. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6242790222167969\n",
      "Batch 87. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6400401592254639\n",
      "Batch 88. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6199220418930054\n",
      "Batch 89. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5618970990180969\n",
      "Batch 90. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6174163222312927\n",
      "Batch 91. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6093146204948425\n",
      "Batch 92. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5777924656867981\n",
      "Batch 93. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6081642508506775\n",
      "Batch 94. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5846169590950012\n",
      "Batch 95. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6391468644142151\n",
      "Batch 96. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5863776206970215\n",
      "Batch 97. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6002459526062012\n",
      "Batch 98. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6278784275054932\n",
      "Batch 99. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6511090993881226\n",
      "Batch 100. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5488532185554504\n",
      "Batch 101. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5784982442855835\n",
      "Batch 102. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5773866176605225\n",
      "Batch 103. Data shape torch.Size([32, 3, 224, 224]) Loss 0.577957272529602\n",
      "Batch 104. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5859207510948181\n",
      "Batch 105. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6008449792861938\n",
      "Batch 106. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5945585370063782\n",
      "Batch 107. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5978623628616333\n",
      "Batch 108. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5488302111625671\n",
      "Batch 109. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6062231659889221\n",
      "Batch 110. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5968611836433411\n",
      "Batch 111. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6242807507514954\n",
      "Batch 112. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6013492345809937\n",
      "Batch 113. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5906785130500793\n",
      "Batch 114. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6001256108283997\n",
      "Batch 115. Data shape torch.Size([32, 3, 224, 224]) Loss 0.59939044713974\n",
      "Batch 116. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6060293316841125\n",
      "Batch 117. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6033436059951782\n",
      "Batch 118. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6055112481117249\n",
      "Batch 119. Data shape torch.Size([20, 3, 224, 224]) Loss 0.6596605777740479\n",
      "Valid loss improved from 0.610341 to 0.605572. Saving model ...\n",
      "Epoch: 30/50 | time: 22.0m 2.354s | lr: 1.0000e-05 | train/loss: 0.61382 | val/loss: 0.60557 | val/accuracy: 0.76159 | val/AUC: 0.76213 | val/Kappa: 0.52362\n",
      "Epoch: 31 Train batch 10 loss: 0.6216958165168762, 2.1% complete\n",
      "Epoch: 31 Train batch 20 loss: 0.6246300339698792, 4.2% complete\n",
      "Epoch: 31 Train batch 30 loss: 0.6132384538650513, 6.3% complete\n",
      "Epoch: 31 Train batch 40 loss: 0.6372911930084229, 8.4% complete\n",
      "Epoch: 31 Train batch 50 loss: 0.6269418597221375, 10.5% complete\n",
      "Epoch: 31 Train batch 60 loss: 0.6003507971763611, 12.6% complete\n",
      "Epoch: 31 Train batch 70 loss: 0.6044778823852539, 14.7% complete\n",
      "Epoch: 31 Train batch 80 loss: 0.5915920734405518, 16.8% complete\n",
      "Epoch: 31 Train batch 90 loss: 0.6080973744392395, 18.9% complete\n",
      "Epoch: 31 Train batch 100 loss: 0.6016637682914734, 21.1% complete\n",
      "Epoch: 31 Train batch 110 loss: 0.6357777714729309, 23.2% complete\n",
      "Epoch: 31 Train batch 120 loss: 0.6273847222328186, 25.3% complete\n",
      "Epoch: 31 Train batch 130 loss: 0.606497049331665, 27.4% complete\n",
      "Epoch: 31 Train batch 140 loss: 0.6008402705192566, 29.5% complete\n",
      "Epoch: 31 Train batch 150 loss: 0.5902573466300964, 31.6% complete\n",
      "Epoch: 31 Train batch 160 loss: 0.5996788740158081, 33.7% complete\n",
      "Epoch: 31 Train batch 170 loss: 0.5995129942893982, 35.8% complete\n",
      "Epoch: 31 Train batch 180 loss: 0.6575139760971069, 37.9% complete\n",
      "Epoch: 31 Train batch 190 loss: 0.6258438229560852, 40.0% complete\n",
      "Epoch: 31 Train batch 200 loss: 0.6241146922111511, 42.1% complete\n",
      "Epoch: 31 Train batch 210 loss: 0.6513147354125977, 44.2% complete\n",
      "Epoch: 31 Train batch 220 loss: 0.5594632029533386, 46.3% complete\n",
      "Epoch: 31 Train batch 230 loss: 0.6160474419593811, 48.4% complete\n",
      "Epoch: 31 Train batch 240 loss: 0.6043906211853027, 50.5% complete\n",
      "Epoch: 31 Train batch 250 loss: 0.5809181332588196, 52.6% complete\n",
      "Epoch: 31 Train batch 260 loss: 0.5742677450180054, 54.7% complete\n",
      "Epoch: 31 Train batch 270 loss: 0.5732116103172302, 56.8% complete\n",
      "Epoch: 31 Train batch 280 loss: 0.6067472100257874, 58.9% complete\n",
      "Epoch: 31 Train batch 290 loss: 0.6605544090270996, 61.1% complete\n",
      "Epoch: 31 Train batch 300 loss: 0.5704845786094666, 63.2% complete\n",
      "Epoch: 31 Train batch 310 loss: 0.5951600670814514, 65.3% complete\n",
      "Epoch: 31 Train batch 320 loss: 0.5880632996559143, 67.4% complete\n",
      "Epoch: 31 Train batch 330 loss: 0.567711591720581, 69.5% complete\n",
      "Epoch: 31 Train batch 340 loss: 0.5922756791114807, 71.6% complete\n",
      "Epoch: 31 Train batch 350 loss: 0.6297516226768494, 73.7% complete\n",
      "Epoch: 31 Train batch 360 loss: 0.6287393569946289, 75.8% complete\n",
      "Epoch: 31 Train batch 370 loss: 0.639414370059967, 77.9% complete\n",
      "Epoch: 31 Train batch 380 loss: 0.5646557807922363, 80.0% complete\n",
      "Epoch: 31 Train batch 390 loss: 0.6100413203239441, 82.1% complete\n",
      "Epoch: 31 Train batch 400 loss: 0.5926493406295776, 84.2% complete\n",
      "Epoch: 31 Train batch 410 loss: 0.611793041229248, 86.3% complete\n",
      "Epoch: 31 Train batch 420 loss: 0.5971938967704773, 88.4% complete\n",
      "Epoch: 31 Train batch 430 loss: 0.602762758731842, 90.5% complete\n",
      "Epoch: 31 Train batch 440 loss: 0.6275206208229065, 92.6% complete\n",
      "Epoch: 31 Train batch 450 loss: 0.5967322587966919, 94.7% complete\n",
      "Epoch: 31 Train batch 460 loss: 0.6256767511367798, 96.8% complete\n",
      "Epoch: 31 Train batch 470 loss: 0.5958389043807983, 98.9% complete\n",
      "Batch 1. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5827564597129822\n",
      "Batch 2. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5872277021408081\n",
      "Batch 3. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6009784936904907\n",
      "Batch 4. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6295115947723389\n",
      "Batch 5. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6041876077651978\n",
      "Batch 6. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5703071355819702\n",
      "Batch 7. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6079176664352417\n",
      "Batch 8. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6186445355415344\n",
      "Batch 9. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5932736396789551\n",
      "Batch 10. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5706335306167603\n",
      "Batch 11. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6070793867111206\n",
      "Batch 12. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6034982204437256\n",
      "Batch 13. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6017876267433167\n",
      "Batch 14. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5955781936645508\n",
      "Batch 15. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6540698409080505\n",
      "Batch 16. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5978817343711853\n",
      "Batch 17. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6119155883789062\n",
      "Batch 18. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5401041507720947\n",
      "Batch 19. Data shape torch.Size([32, 3, 224, 224]) Loss 0.593891978263855\n",
      "Batch 20. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5484198331832886\n",
      "Batch 21. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6006001830101013\n",
      "Batch 22. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6079981327056885\n",
      "Batch 23. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6143039464950562\n",
      "Batch 24. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5907502770423889\n",
      "Batch 25. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6034414768218994\n",
      "Batch 26. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6165119409561157\n",
      "Batch 27. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6073477864265442\n",
      "Batch 28. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6328818798065186\n",
      "Batch 29. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6196489334106445\n",
      "Batch 30. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6202179789543152\n",
      "Batch 31. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5915829539299011\n",
      "Batch 32. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6250985264778137\n",
      "Batch 33. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5851649045944214\n",
      "Batch 34. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6697537899017334\n",
      "Batch 35. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6532235145568848\n",
      "Batch 36. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5967373251914978\n",
      "Batch 37. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5737431049346924\n",
      "Batch 38. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6408486366271973\n",
      "Batch 39. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6081036925315857\n",
      "Batch 40. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5772445201873779\n",
      "Batch 41. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6676174998283386\n",
      "Batch 42. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5839528441429138\n",
      "Batch 43. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5802892446517944\n",
      "Batch 44. Data shape torch.Size([32, 3, 224, 224]) Loss 0.577730119228363\n",
      "Batch 45. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5902665853500366\n",
      "Batch 46. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5885776281356812\n",
      "Batch 47. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5854446291923523\n",
      "Batch 48. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6281140446662903\n",
      "Batch 49. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5928547382354736\n",
      "Batch 50. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5998675227165222\n",
      "Batch 51. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6036182641983032\n",
      "Batch 52. Data shape torch.Size([32, 3, 224, 224]) Loss 0.589164137840271\n",
      "Batch 53. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6043411493301392\n",
      "Batch 54. Data shape torch.Size([32, 3, 224, 224]) Loss 0.60135817527771\n",
      "Batch 55. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5965534448623657\n",
      "Batch 56. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5778679847717285\n",
      "Batch 57. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5996108055114746\n",
      "Batch 58. Data shape torch.Size([32, 3, 224, 224]) Loss 0.576627254486084\n",
      "Batch 59. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5749156475067139\n",
      "Batch 60. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6174591183662415\n",
      "Batch 61. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5865843296051025\n",
      "Batch 62. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5979585647583008\n",
      "Batch 63. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6293051838874817\n",
      "Batch 64. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6082212328910828\n",
      "Batch 65. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6177535653114319\n",
      "Batch 66. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6000699996948242\n",
      "Batch 67. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5754798650741577\n",
      "Batch 68. Data shape torch.Size([32, 3, 224, 224]) Loss 0.611778199672699\n",
      "Batch 69. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5745241641998291\n",
      "Batch 70. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5889650583267212\n",
      "Batch 71. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6341215968132019\n",
      "Batch 72. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5511623024940491\n",
      "Batch 73. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5997694730758667\n",
      "Batch 74. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6419159173965454\n",
      "Batch 75. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6030924320220947\n",
      "Batch 76. Data shape torch.Size([32, 3, 224, 224]) Loss 0.596384584903717\n",
      "Batch 77. Data shape torch.Size([32, 3, 224, 224]) Loss 0.577057957649231\n",
      "Batch 78. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6015433073043823\n",
      "Batch 79. Data shape torch.Size([32, 3, 224, 224]) Loss 0.600255012512207\n",
      "Batch 80. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5627121329307556\n",
      "Batch 81. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5811338424682617\n",
      "Batch 82. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5842016935348511\n",
      "Batch 83. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5737890005111694\n",
      "Batch 84. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5715293884277344\n",
      "Batch 85. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6347757577896118\n",
      "Batch 86. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6361985206604004\n",
      "Batch 87. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6258243322372437\n",
      "Batch 88. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6114163398742676\n",
      "Batch 89. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5702915787696838\n",
      "Batch 90. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6568512320518494\n",
      "Batch 91. Data shape torch.Size([32, 3, 224, 224]) Loss 0.63512122631073\n",
      "Batch 92. Data shape torch.Size([32, 3, 224, 224]) Loss 0.564887285232544\n",
      "Batch 93. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5697180032730103\n",
      "Batch 94. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6310530304908752\n",
      "Batch 95. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5601965188980103\n",
      "Batch 96. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6287473440170288\n",
      "Batch 97. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5794355273246765\n",
      "Batch 98. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5938584208488464\n",
      "Batch 99. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5815171599388123\n",
      "Batch 100. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5656386017799377\n",
      "Batch 101. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6038056015968323\n",
      "Batch 102. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5883973836898804\n",
      "Batch 103. Data shape torch.Size([32, 3, 224, 224]) Loss 0.606886088848114\n",
      "Batch 104. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5950914621353149\n",
      "Batch 105. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5901011824607849\n",
      "Batch 106. Data shape torch.Size([32, 3, 224, 224]) Loss 0.603204607963562\n",
      "Batch 107. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6489752531051636\n",
      "Batch 108. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5515384674072266\n",
      "Batch 109. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5961534976959229\n",
      "Batch 110. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5794785618782043\n",
      "Batch 111. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6288014650344849\n",
      "Batch 112. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6710060238838196\n",
      "Batch 113. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5972470045089722\n",
      "Batch 114. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5966547727584839\n",
      "Batch 115. Data shape torch.Size([32, 3, 224, 224]) Loss 0.600770890712738\n",
      "Batch 116. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6274926066398621\n",
      "Batch 117. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6233993768692017\n",
      "Batch 118. Data shape torch.Size([32, 3, 224, 224]) Loss 0.580755889415741\n",
      "Batch 119. Data shape torch.Size([20, 3, 224, 224]) Loss 0.6471235752105713\n",
      "Valid loss improved from 0.605572 to 0.601200. Saving model ...\n",
      "Epoch: 31/50 | time: 22.0m 52.52s | lr: 1.0000e-05 | train/loss: 0.60980 | val/loss: 0.60120 | val/accuracy: 0.76423 | val/AUC: 0.76451 | val/Kappa: 0.52864\n",
      "Epoch: 32 Train batch 10 loss: 0.6261023879051208, 2.1% complete\n",
      "Epoch: 32 Train batch 20 loss: 0.596878707408905, 4.2% complete\n",
      "Epoch: 32 Train batch 30 loss: 0.6324077844619751, 6.3% complete\n",
      "Epoch: 32 Train batch 40 loss: 0.6358449459075928, 8.4% complete\n",
      "Epoch: 32 Train batch 50 loss: 0.6354562044143677, 10.5% complete\n",
      "Epoch: 32 Train batch 60 loss: 0.6014859676361084, 12.6% complete\n",
      "Epoch: 32 Train batch 70 loss: 0.6000059843063354, 14.7% complete\n",
      "Epoch: 32 Train batch 80 loss: 0.6119692325592041, 16.8% complete\n",
      "Epoch: 32 Train batch 90 loss: 0.5983651280403137, 18.9% complete\n",
      "Epoch: 32 Train batch 100 loss: 0.5835652947425842, 21.1% complete\n",
      "Epoch: 32 Train batch 110 loss: 0.607916533946991, 23.2% complete\n",
      "Epoch: 32 Train batch 120 loss: 0.5929304361343384, 25.3% complete\n",
      "Epoch: 32 Train batch 130 loss: 0.5726231336593628, 27.4% complete\n",
      "Epoch: 32 Train batch 140 loss: 0.6490098237991333, 29.5% complete\n",
      "Epoch: 32 Train batch 150 loss: 0.6216263175010681, 31.6% complete\n",
      "Epoch: 32 Train batch 160 loss: 0.6701664328575134, 33.7% complete\n",
      "Epoch: 32 Train batch 170 loss: 0.5847840309143066, 35.8% complete\n",
      "Epoch: 32 Train batch 180 loss: 0.6373372077941895, 37.9% complete\n",
      "Epoch: 32 Train batch 190 loss: 0.5831440091133118, 40.0% complete\n",
      "Epoch: 32 Train batch 200 loss: 0.6199159026145935, 42.1% complete\n",
      "Epoch: 32 Train batch 210 loss: 0.6476057171821594, 44.2% complete\n",
      "Epoch: 32 Train batch 220 loss: 0.5985621809959412, 46.3% complete\n",
      "Epoch: 32 Train batch 230 loss: 0.6162894368171692, 48.4% complete\n",
      "Epoch: 32 Train batch 240 loss: 0.5918048024177551, 50.5% complete\n",
      "Epoch: 32 Train batch 250 loss: 0.5956915020942688, 52.6% complete\n",
      "Epoch: 32 Train batch 260 loss: 0.6170088052749634, 54.7% complete\n",
      "Epoch: 32 Train batch 270 loss: 0.6225250959396362, 56.8% complete\n",
      "Epoch: 32 Train batch 280 loss: 0.5904123187065125, 58.9% complete\n",
      "Epoch: 32 Train batch 290 loss: 0.5832111239433289, 61.1% complete\n",
      "Epoch: 32 Train batch 300 loss: 0.657516360282898, 63.2% complete\n",
      "Epoch: 32 Train batch 310 loss: 0.6137016415596008, 65.3% complete\n",
      "Epoch: 32 Train batch 320 loss: 0.6247237920761108, 67.4% complete\n",
      "Epoch: 32 Train batch 330 loss: 0.6075500249862671, 69.5% complete\n",
      "Epoch: 32 Train batch 340 loss: 0.6180022358894348, 71.6% complete\n",
      "Epoch: 32 Train batch 350 loss: 0.5798895955085754, 73.7% complete\n",
      "Epoch: 32 Train batch 360 loss: 0.5891114473342896, 75.8% complete\n",
      "Epoch: 32 Train batch 370 loss: 0.6041602492332458, 77.9% complete\n",
      "Epoch: 32 Train batch 380 loss: 0.5875473618507385, 80.0% complete\n",
      "Epoch: 32 Train batch 390 loss: 0.6201643347740173, 82.1% complete\n",
      "Epoch: 32 Train batch 400 loss: 0.6323533058166504, 84.2% complete\n",
      "Epoch: 32 Train batch 410 loss: 0.6622669696807861, 86.3% complete\n",
      "Epoch: 32 Train batch 420 loss: 0.6413775086402893, 88.4% complete\n",
      "Epoch: 32 Train batch 430 loss: 0.6435260772705078, 90.5% complete\n",
      "Epoch: 32 Train batch 440 loss: 0.567313551902771, 92.6% complete\n",
      "Epoch: 32 Train batch 450 loss: 0.6040600538253784, 94.7% complete\n",
      "Epoch: 32 Train batch 460 loss: 0.5889846086502075, 96.8% complete\n",
      "Epoch: 32 Train batch 470 loss: 0.6158103346824646, 98.9% complete\n",
      "Batch 1. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5741515755653381\n",
      "Batch 2. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6557332277297974\n",
      "Batch 3. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6070302128791809\n",
      "Batch 4. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5416452884674072\n",
      "Batch 5. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5753071904182434\n",
      "Batch 6. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6252593994140625\n",
      "Batch 7. Data shape torch.Size([32, 3, 224, 224]) Loss 0.591445803642273\n",
      "Batch 8. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6112316250801086\n",
      "Batch 9. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5909910798072815\n",
      "Batch 10. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6236997842788696\n",
      "Batch 11. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6437370181083679\n",
      "Batch 12. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6216752529144287\n",
      "Batch 13. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5740194320678711\n",
      "Batch 14. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6235328912734985\n",
      "Batch 15. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5755000114440918\n",
      "Batch 16. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6000275611877441\n",
      "Batch 17. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6141330003738403\n",
      "Batch 18. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5733523368835449\n",
      "Batch 19. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6091490983963013\n",
      "Batch 20. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5482475161552429\n",
      "Batch 21. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5801980495452881\n",
      "Batch 22. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5839566588401794\n",
      "Batch 23. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6349381804466248\n",
      "Batch 24. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5751579999923706\n",
      "Batch 25. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6239326596260071\n",
      "Batch 26. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5722336173057556\n",
      "Batch 27. Data shape torch.Size([32, 3, 224, 224]) Loss 0.609199583530426\n",
      "Batch 28. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6014100909233093\n",
      "Batch 29. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6225507259368896\n",
      "Batch 30. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6119460463523865\n",
      "Batch 31. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6175169944763184\n",
      "Batch 32. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5981293320655823\n",
      "Batch 33. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6298023462295532\n",
      "Batch 34. Data shape torch.Size([32, 3, 224, 224]) Loss 0.661370038986206\n",
      "Batch 35. Data shape torch.Size([32, 3, 224, 224]) Loss 0.600128173828125\n",
      "Batch 36. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6048743724822998\n",
      "Batch 37. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5796607136726379\n",
      "Batch 38. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5749093294143677\n",
      "Batch 39. Data shape torch.Size([32, 3, 224, 224]) Loss 0.634378969669342\n",
      "Batch 40. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5648941397666931\n",
      "Batch 41. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6203458905220032\n",
      "Batch 42. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5528051853179932\n",
      "Batch 43. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5712083578109741\n",
      "Batch 44. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5682387948036194\n",
      "Batch 45. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6062166094779968\n",
      "Batch 46. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6325122714042664\n",
      "Batch 47. Data shape torch.Size([32, 3, 224, 224]) Loss 0.602344810962677\n",
      "Batch 48. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6001793742179871\n",
      "Batch 49. Data shape torch.Size([32, 3, 224, 224]) Loss 0.562204897403717\n",
      "Batch 50. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5958693623542786\n",
      "Batch 51. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6363273859024048\n",
      "Batch 52. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6022228002548218\n",
      "Batch 53. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5692701935768127\n",
      "Batch 54. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5700918436050415\n",
      "Batch 55. Data shape torch.Size([32, 3, 224, 224]) Loss 0.596860408782959\n",
      "Batch 56. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5773580074310303\n",
      "Batch 57. Data shape torch.Size([32, 3, 224, 224]) Loss 0.583004355430603\n",
      "Batch 58. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5864521861076355\n",
      "Batch 59. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5581375956535339\n",
      "Batch 60. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6207687854766846\n",
      "Batch 61. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6042826771736145\n",
      "Batch 62. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6108841896057129\n",
      "Batch 63. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5809910893440247\n",
      "Batch 64. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6171918511390686\n",
      "Batch 65. Data shape torch.Size([32, 3, 224, 224]) Loss 0.619806170463562\n",
      "Batch 66. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6252680420875549\n",
      "Batch 67. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5659140348434448\n",
      "Batch 68. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6073412299156189\n",
      "Batch 69. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5656909346580505\n",
      "Batch 70. Data shape torch.Size([32, 3, 224, 224]) Loss 0.611237108707428\n",
      "Batch 71. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5944545269012451\n",
      "Batch 72. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5764762759208679\n",
      "Batch 73. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6225751042366028\n",
      "Batch 74. Data shape torch.Size([32, 3, 224, 224]) Loss 0.613527774810791\n",
      "Batch 75. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5995500683784485\n",
      "Batch 76. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5854554176330566\n",
      "Batch 77. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5988666415214539\n",
      "Batch 78. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5485232472419739\n",
      "Batch 79. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5643218755722046\n",
      "Batch 80. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5718123912811279\n",
      "Batch 81. Data shape torch.Size([32, 3, 224, 224]) Loss 0.602021336555481\n",
      "Batch 82. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5432665944099426\n",
      "Batch 83. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5721491575241089\n",
      "Batch 84. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5849884152412415\n",
      "Batch 85. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6058173179626465\n",
      "Batch 86. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6011223196983337\n",
      "Batch 87. Data shape torch.Size([32, 3, 224, 224]) Loss 0.590395450592041\n",
      "Batch 88. Data shape torch.Size([32, 3, 224, 224]) Loss 0.608210563659668\n",
      "Batch 89. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6158748269081116\n",
      "Batch 90. Data shape torch.Size([32, 3, 224, 224]) Loss 0.592308521270752\n",
      "Batch 91. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6225250363349915\n",
      "Batch 92. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6422513127326965\n",
      "Batch 93. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6350855231285095\n",
      "Batch 94. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5909573435783386\n",
      "Batch 95. Data shape torch.Size([32, 3, 224, 224]) Loss 0.608060359954834\n",
      "Batch 96. Data shape torch.Size([32, 3, 224, 224]) Loss 0.622039794921875\n",
      "Batch 97. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6068482398986816\n",
      "Batch 98. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5586786270141602\n",
      "Batch 99. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5982253551483154\n",
      "Batch 100. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6170234680175781\n",
      "Batch 101. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5500001311302185\n",
      "Batch 102. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6005785465240479\n",
      "Batch 103. Data shape torch.Size([32, 3, 224, 224]) Loss 0.608260989189148\n",
      "Batch 104. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6009657979011536\n",
      "Batch 105. Data shape torch.Size([32, 3, 224, 224]) Loss 0.601805567741394\n",
      "Batch 106. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5844883918762207\n",
      "Batch 107. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6200410723686218\n",
      "Batch 108. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6259452104568481\n",
      "Batch 109. Data shape torch.Size([32, 3, 224, 224]) Loss 0.601021945476532\n",
      "Batch 110. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5933936238288879\n",
      "Batch 111. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6179086565971375\n",
      "Batch 112. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5811443328857422\n",
      "Batch 113. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6352466940879822\n",
      "Batch 114. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5442805886268616\n",
      "Batch 115. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6188511252403259\n",
      "Batch 116. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6056561470031738\n",
      "Batch 117. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5901163816452026\n",
      "Batch 118. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5565685629844666\n",
      "Batch 119. Data shape torch.Size([20, 3, 224, 224]) Loss 0.5205913186073303\n",
      "Valid loss improved from 0.601200 to 0.596911. Saving model ...\n",
      "Epoch: 32/50 | time: 22.0m 9.605s | lr: 1.0000e-05 | train/loss: 0.60599 | val/loss: 0.59691 | val/accuracy: 0.76633 | val/AUC: 0.76629 | val/Kappa: 0.53255\n",
      "Epoch: 33 Train batch 10 loss: 0.6109046339988708, 2.1% complete\n",
      "Epoch: 33 Train batch 20 loss: 0.5552802085876465, 4.2% complete\n",
      "Epoch: 33 Train batch 30 loss: 0.5995469093322754, 6.3% complete\n",
      "Epoch: 33 Train batch 40 loss: 0.60169517993927, 8.4% complete\n",
      "Epoch: 33 Train batch 50 loss: 0.6515110731124878, 10.5% complete\n",
      "Epoch: 33 Train batch 60 loss: 0.6359555125236511, 12.6% complete\n",
      "Epoch: 33 Train batch 70 loss: 0.597171425819397, 14.7% complete\n",
      "Epoch: 33 Train batch 80 loss: 0.6114338636398315, 16.8% complete\n",
      "Epoch: 33 Train batch 90 loss: 0.5760617852210999, 18.9% complete\n",
      "Epoch: 33 Train batch 100 loss: 0.5955202579498291, 21.1% complete\n",
      "Epoch: 33 Train batch 110 loss: 0.6055849194526672, 23.2% complete\n",
      "Epoch: 33 Train batch 120 loss: 0.5981773138046265, 25.3% complete\n",
      "Epoch: 33 Train batch 130 loss: 0.6161878108978271, 27.4% complete\n",
      "Epoch: 33 Train batch 140 loss: 0.6182452440261841, 29.5% complete\n",
      "Epoch: 33 Train batch 150 loss: 0.5887076258659363, 31.6% complete\n",
      "Epoch: 33 Train batch 160 loss: 0.6216134428977966, 33.7% complete\n",
      "Epoch: 33 Train batch 170 loss: 0.6361914873123169, 35.8% complete\n",
      "Epoch: 33 Train batch 180 loss: 0.5746733546257019, 37.9% complete\n",
      "Epoch: 33 Train batch 190 loss: 0.6038373112678528, 40.0% complete\n",
      "Epoch: 33 Train batch 200 loss: 0.5785906910896301, 42.1% complete\n",
      "Epoch: 33 Train batch 210 loss: 0.6283271908760071, 44.2% complete\n",
      "Epoch: 33 Train batch 220 loss: 0.6165098547935486, 46.3% complete\n",
      "Epoch: 33 Train batch 230 loss: 0.5794895887374878, 48.4% complete\n",
      "Epoch: 33 Train batch 240 loss: 0.6157125234603882, 50.5% complete\n",
      "Epoch: 33 Train batch 250 loss: 0.6110445857048035, 52.6% complete\n",
      "Epoch: 33 Train batch 260 loss: 0.6376732587814331, 54.7% complete\n",
      "Epoch: 33 Train batch 270 loss: 0.5906722545623779, 56.8% complete\n",
      "Epoch: 33 Train batch 280 loss: 0.6232144832611084, 58.9% complete\n",
      "Epoch: 33 Train batch 290 loss: 0.6713643670082092, 61.1% complete\n",
      "Epoch: 33 Train batch 300 loss: 0.6351138949394226, 63.2% complete\n",
      "Epoch: 33 Train batch 310 loss: 0.5757038593292236, 65.3% complete\n",
      "Epoch: 33 Train batch 320 loss: 0.5787166357040405, 67.4% complete\n",
      "Epoch: 33 Train batch 330 loss: 0.5749866962432861, 69.5% complete\n",
      "Epoch: 33 Train batch 340 loss: 0.5745983719825745, 71.6% complete\n",
      "Epoch: 33 Train batch 350 loss: 0.6031979322433472, 73.7% complete\n",
      "Epoch: 33 Train batch 360 loss: 0.5926931500434875, 75.8% complete\n",
      "Epoch: 33 Train batch 370 loss: 0.5834768414497375, 77.9% complete\n",
      "Epoch: 33 Train batch 380 loss: 0.5962430238723755, 80.0% complete\n",
      "Epoch: 33 Train batch 390 loss: 0.6476513147354126, 82.1% complete\n",
      "Epoch: 33 Train batch 400 loss: 0.5617196559906006, 84.2% complete\n",
      "Epoch: 33 Train batch 410 loss: 0.6211820244789124, 86.3% complete\n",
      "Epoch: 33 Train batch 420 loss: 0.6218352913856506, 88.4% complete\n",
      "Epoch: 33 Train batch 430 loss: 0.5774555802345276, 90.5% complete\n",
      "Epoch: 33 Train batch 440 loss: 0.5598244071006775, 92.6% complete\n",
      "Epoch: 33 Train batch 450 loss: 0.6196077466011047, 94.7% complete\n",
      "Epoch: 33 Train batch 460 loss: 0.6222561597824097, 96.8% complete\n",
      "Epoch: 33 Train batch 470 loss: 0.585063099861145, 98.9% complete\n",
      "Batch 1. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6006358861923218\n",
      "Batch 2. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6164205074310303\n",
      "Batch 3. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6257805228233337\n",
      "Batch 4. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5961191654205322\n",
      "Batch 5. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5768855810165405\n",
      "Batch 6. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5879164934158325\n",
      "Batch 7. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6178231835365295\n",
      "Batch 8. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5800307989120483\n",
      "Batch 9. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6071796417236328\n",
      "Batch 10. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5876020789146423\n",
      "Batch 11. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6421408653259277\n",
      "Batch 12. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5867986679077148\n",
      "Batch 13. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6325271725654602\n",
      "Batch 14. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6112151741981506\n",
      "Batch 15. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6569811701774597\n",
      "Batch 16. Data shape torch.Size([32, 3, 224, 224]) Loss 0.606421172618866\n",
      "Batch 17. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5963078141212463\n",
      "Batch 18. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5813996195793152\n",
      "Batch 19. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6181604862213135\n",
      "Batch 20. Data shape torch.Size([32, 3, 224, 224]) Loss 0.60170978307724\n",
      "Batch 21. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5659747123718262\n",
      "Batch 22. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5532055497169495\n",
      "Batch 23. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5721793174743652\n",
      "Batch 24. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5844680070877075\n",
      "Batch 25. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6080772280693054\n",
      "Batch 26. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6283610463142395\n",
      "Batch 27. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5907256007194519\n",
      "Batch 28. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5863001346588135\n",
      "Batch 29. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5913019180297852\n",
      "Batch 30. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5435455441474915\n",
      "Batch 31. Data shape torch.Size([32, 3, 224, 224]) Loss 0.580737292766571\n",
      "Batch 32. Data shape torch.Size([32, 3, 224, 224]) Loss 0.569672167301178\n",
      "Batch 33. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5831584334373474\n",
      "Batch 34. Data shape torch.Size([32, 3, 224, 224]) Loss 0.580804705619812\n",
      "Batch 35. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5776512026786804\n",
      "Batch 36. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5893840789794922\n",
      "Batch 37. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6194043159484863\n",
      "Batch 38. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5878994464874268\n",
      "Batch 39. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5977516174316406\n",
      "Batch 40. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5411964654922485\n",
      "Batch 41. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5827509164810181\n",
      "Batch 42. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6201086044311523\n",
      "Batch 43. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6128597259521484\n",
      "Batch 44. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5432109832763672\n",
      "Batch 45. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5129712820053101\n",
      "Batch 46. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5785384774208069\n",
      "Batch 47. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5558063983917236\n",
      "Batch 48. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6420072317123413\n",
      "Batch 49. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5965995788574219\n",
      "Batch 50. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5766922831535339\n",
      "Batch 51. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6238428354263306\n",
      "Batch 52. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6013961434364319\n",
      "Batch 53. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5489333868026733\n",
      "Batch 54. Data shape torch.Size([32, 3, 224, 224]) Loss 0.616145133972168\n",
      "Batch 55. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5803340077400208\n",
      "Batch 56. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5767228603363037\n",
      "Batch 57. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5669368505477905\n",
      "Batch 58. Data shape torch.Size([32, 3, 224, 224]) Loss 0.585225522518158\n",
      "Batch 59. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5972595810890198\n",
      "Batch 60. Data shape torch.Size([32, 3, 224, 224]) Loss 0.622782289981842\n",
      "Batch 61. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5644171237945557\n",
      "Batch 62. Data shape torch.Size([32, 3, 224, 224]) Loss 0.584007203578949\n",
      "Batch 63. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6112648844718933\n",
      "Batch 64. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6219387650489807\n",
      "Batch 65. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5926750898361206\n",
      "Batch 66. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5588915348052979\n",
      "Batch 67. Data shape torch.Size([32, 3, 224, 224]) Loss 0.580079972743988\n",
      "Batch 68. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5876050591468811\n",
      "Batch 69. Data shape torch.Size([32, 3, 224, 224]) Loss 0.592635989189148\n",
      "Batch 70. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5773069858551025\n",
      "Batch 71. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6291024088859558\n",
      "Batch 72. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5577293634414673\n",
      "Batch 73. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5865495800971985\n",
      "Batch 74. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5863633751869202\n",
      "Batch 75. Data shape torch.Size([32, 3, 224, 224]) Loss 0.641679584980011\n",
      "Batch 76. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5454235076904297\n",
      "Batch 77. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6068055629730225\n",
      "Batch 78. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5711820721626282\n",
      "Batch 79. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5373673439025879\n",
      "Batch 80. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5642098188400269\n",
      "Batch 81. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5751116275787354\n",
      "Batch 82. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5880714654922485\n",
      "Batch 83. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6366105675697327\n",
      "Batch 84. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5709065794944763\n",
      "Batch 85. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5872347950935364\n",
      "Batch 86. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5290284156799316\n",
      "Batch 87. Data shape torch.Size([32, 3, 224, 224]) Loss 0.576884925365448\n",
      "Batch 88. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5940392017364502\n",
      "Batch 89. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6578604578971863\n",
      "Batch 90. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5595455765724182\n",
      "Batch 91. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5811792612075806\n",
      "Batch 92. Data shape torch.Size([32, 3, 224, 224]) Loss 0.575207531452179\n",
      "Batch 93. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5805593132972717\n",
      "Batch 94. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6182510852813721\n",
      "Batch 95. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5459871888160706\n",
      "Batch 96. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6402788162231445\n",
      "Batch 97. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5290636420249939\n",
      "Batch 98. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5955509543418884\n",
      "Batch 99. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6154040694236755\n",
      "Batch 100. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5972616076469421\n",
      "Batch 101. Data shape torch.Size([32, 3, 224, 224]) Loss 0.593963623046875\n",
      "Batch 102. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5597385764122009\n",
      "Batch 103. Data shape torch.Size([32, 3, 224, 224]) Loss 0.570759654045105\n",
      "Batch 104. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5585749745368958\n",
      "Batch 105. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5725013017654419\n",
      "Batch 106. Data shape torch.Size([32, 3, 224, 224]) Loss 0.557160496711731\n",
      "Batch 107. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6110683083534241\n",
      "Batch 108. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6106403470039368\n",
      "Batch 109. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6580421924591064\n",
      "Batch 110. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6039647459983826\n",
      "Batch 111. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6214369535446167\n",
      "Batch 112. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6121736168861389\n",
      "Batch 113. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5373085141181946\n",
      "Batch 114. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5760543346405029\n",
      "Batch 115. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5757141709327698\n",
      "Batch 116. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5871513485908508\n",
      "Batch 117. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5800117254257202\n",
      "Batch 118. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5574890971183777\n",
      "Batch 119. Data shape torch.Size([20, 3, 224, 224]) Loss 0.5665675401687622\n",
      "Valid loss improved from 0.596911 to 0.588946. Saving model ...\n",
      "Epoch: 33/50 | time: 22.0m 48.37s | lr: 1.0000e-05 | train/loss: 0.60086 | val/loss: 0.58895 | val/accuracy: 0.76791 | val/AUC: 0.76841 | val/Kappa: 0.53621\n",
      "Epoch: 34 Train batch 10 loss: 0.6195024847984314, 2.1% complete\n",
      "Epoch: 34 Train batch 20 loss: 0.5602407455444336, 4.2% complete\n",
      "Epoch: 34 Train batch 30 loss: 0.6208193898200989, 6.3% complete\n",
      "Epoch: 34 Train batch 40 loss: 0.5858844518661499, 8.4% complete\n",
      "Epoch: 34 Train batch 50 loss: 0.5688555836677551, 10.5% complete\n",
      "Epoch: 34 Train batch 60 loss: 0.6213788986206055, 12.6% complete\n",
      "Epoch: 34 Train batch 70 loss: 0.6267146468162537, 14.7% complete\n",
      "Epoch: 34 Train batch 80 loss: 0.6345888376235962, 16.8% complete\n",
      "Epoch: 34 Train batch 90 loss: 0.6287241578102112, 18.9% complete\n",
      "Epoch: 34 Train batch 100 loss: 0.5619303584098816, 21.1% complete\n",
      "Epoch: 34 Train batch 110 loss: 0.5786479115486145, 23.2% complete\n",
      "Epoch: 34 Train batch 120 loss: 0.5617215037345886, 25.3% complete\n",
      "Epoch: 34 Train batch 130 loss: 0.647820234298706, 27.4% complete\n",
      "Epoch: 34 Train batch 140 loss: 0.6135016083717346, 29.5% complete\n",
      "Epoch: 34 Train batch 150 loss: 0.6257991790771484, 31.6% complete\n",
      "Epoch: 34 Train batch 160 loss: 0.5879788994789124, 33.7% complete\n",
      "Epoch: 34 Train batch 170 loss: 0.5647737383842468, 35.8% complete\n",
      "Epoch: 34 Train batch 180 loss: 0.6093857288360596, 37.9% complete\n",
      "Epoch: 34 Train batch 190 loss: 0.6298637986183167, 40.0% complete\n",
      "Epoch: 34 Train batch 200 loss: 0.6141829490661621, 42.1% complete\n",
      "Epoch: 34 Train batch 210 loss: 0.5636635422706604, 44.2% complete\n",
      "Epoch: 34 Train batch 220 loss: 0.6205267906188965, 46.3% complete\n",
      "Epoch: 34 Train batch 230 loss: 0.5919947028160095, 48.4% complete\n",
      "Epoch: 34 Train batch 240 loss: 0.6037321090698242, 50.5% complete\n",
      "Epoch: 34 Train batch 250 loss: 0.5757541656494141, 52.6% complete\n",
      "Epoch: 34 Train batch 260 loss: 0.6044010519981384, 54.7% complete\n",
      "Epoch: 34 Train batch 270 loss: 0.6225371360778809, 56.8% complete\n",
      "Epoch: 34 Train batch 280 loss: 0.5969416499137878, 58.9% complete\n",
      "Epoch: 34 Train batch 290 loss: 0.5782350897789001, 61.1% complete\n",
      "Epoch: 34 Train batch 300 loss: 0.5552084445953369, 63.2% complete\n",
      "Epoch: 34 Train batch 310 loss: 0.6058637499809265, 65.3% complete\n",
      "Epoch: 34 Train batch 320 loss: 0.6066818833351135, 67.4% complete\n",
      "Epoch: 34 Train batch 330 loss: 0.5477103590965271, 69.5% complete\n",
      "Epoch: 34 Train batch 340 loss: 0.5692307949066162, 71.6% complete\n",
      "Epoch: 34 Train batch 350 loss: 0.5820838212966919, 73.7% complete\n",
      "Epoch: 34 Train batch 360 loss: 0.558811604976654, 75.8% complete\n",
      "Epoch: 34 Train batch 370 loss: 0.6092685461044312, 77.9% complete\n",
      "Epoch: 34 Train batch 380 loss: 0.5811524987220764, 80.0% complete\n",
      "Epoch: 34 Train batch 390 loss: 0.5653963685035706, 82.1% complete\n",
      "Epoch: 34 Train batch 400 loss: 0.609832227230072, 84.2% complete\n",
      "Epoch: 34 Train batch 410 loss: 0.5951942205429077, 86.3% complete\n",
      "Epoch: 34 Train batch 420 loss: 0.6199889779090881, 88.4% complete\n",
      "Epoch: 34 Train batch 430 loss: 0.5709772706031799, 90.5% complete\n",
      "Epoch: 34 Train batch 440 loss: 0.5913538932800293, 92.6% complete\n",
      "Epoch: 34 Train batch 450 loss: 0.5906463861465454, 94.7% complete\n",
      "Epoch: 34 Train batch 460 loss: 0.616296112537384, 96.8% complete\n",
      "Epoch: 34 Train batch 470 loss: 0.5670444369316101, 98.9% complete\n",
      "Batch 1. Data shape torch.Size([32, 3, 224, 224]) Loss 0.582689106464386\n",
      "Batch 2. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5687487125396729\n",
      "Batch 3. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6013838648796082\n",
      "Batch 4. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5560743808746338\n",
      "Batch 5. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6052041053771973\n",
      "Batch 6. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5225322842597961\n",
      "Batch 7. Data shape torch.Size([32, 3, 224, 224]) Loss 0.57355135679245\n",
      "Batch 8. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6198582053184509\n",
      "Batch 9. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5779046416282654\n",
      "Batch 10. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6077979207038879\n",
      "Batch 11. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5311145782470703\n",
      "Batch 12. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5622270703315735\n",
      "Batch 13. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6309770345687866\n",
      "Batch 14. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6370182037353516\n",
      "Batch 15. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5553427338600159\n",
      "Batch 16. Data shape torch.Size([32, 3, 224, 224]) Loss 0.602864146232605\n",
      "Batch 17. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5967549681663513\n",
      "Batch 18. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5475535988807678\n",
      "Batch 19. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5832123160362244\n",
      "Batch 20. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5620285272598267\n",
      "Batch 21. Data shape torch.Size([32, 3, 224, 224]) Loss 0.580210268497467\n",
      "Batch 22. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6024028062820435\n",
      "Batch 23. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5456416010856628\n",
      "Batch 24. Data shape torch.Size([32, 3, 224, 224]) Loss 0.606316328048706\n",
      "Batch 25. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6123886108398438\n",
      "Batch 26. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5966577529907227\n",
      "Batch 27. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5578417778015137\n",
      "Batch 28. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6208111643791199\n",
      "Batch 29. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5352168679237366\n",
      "Batch 30. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5732028484344482\n",
      "Batch 31. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6295469403266907\n",
      "Batch 32. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6020050644874573\n",
      "Batch 33. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6441745758056641\n",
      "Batch 34. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6094732880592346\n",
      "Batch 35. Data shape torch.Size([32, 3, 224, 224]) Loss 0.593450665473938\n",
      "Batch 36. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6452245116233826\n",
      "Batch 37. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6227731108665466\n",
      "Batch 38. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5903914570808411\n",
      "Batch 39. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5794975757598877\n",
      "Batch 40. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5670963525772095\n",
      "Batch 41. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6055420637130737\n",
      "Batch 42. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5938643217086792\n",
      "Batch 43. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6258876323699951\n",
      "Batch 44. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5924082398414612\n",
      "Batch 45. Data shape torch.Size([32, 3, 224, 224]) Loss 0.543194055557251\n",
      "Batch 46. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5903123021125793\n",
      "Batch 47. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6011328101158142\n",
      "Batch 48. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6277610063552856\n",
      "Batch 49. Data shape torch.Size([32, 3, 224, 224]) Loss 0.583810567855835\n",
      "Batch 50. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5731310844421387\n",
      "Batch 51. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6435851454734802\n",
      "Batch 52. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6207142472267151\n",
      "Batch 53. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6506683230400085\n",
      "Batch 54. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5781571865081787\n",
      "Batch 55. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5318012833595276\n",
      "Batch 56. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6243695020675659\n",
      "Batch 57. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5866648554801941\n",
      "Batch 58. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5984419584274292\n",
      "Batch 59. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6371303200721741\n",
      "Batch 60. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6323866248130798\n",
      "Batch 61. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5252190828323364\n",
      "Batch 62. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6123941540718079\n",
      "Batch 63. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5635743737220764\n",
      "Batch 64. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5663812756538391\n",
      "Batch 65. Data shape torch.Size([32, 3, 224, 224]) Loss 0.599472165107727\n",
      "Batch 66. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6145862936973572\n",
      "Batch 67. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5772081017494202\n",
      "Batch 68. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5457656979560852\n",
      "Batch 69. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5930536985397339\n",
      "Batch 70. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5604166984558105\n",
      "Batch 71. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5917374491691589\n",
      "Batch 72. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6022496223449707\n",
      "Batch 73. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6304835081100464\n",
      "Batch 74. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6161127090454102\n",
      "Batch 75. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5604455471038818\n",
      "Batch 76. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5537604689598083\n",
      "Batch 77. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5670390725135803\n",
      "Batch 78. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5774596333503723\n",
      "Batch 79. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5746577382087708\n",
      "Batch 80. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5463865995407104\n",
      "Batch 81. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6196262836456299\n",
      "Batch 82. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5808747410774231\n",
      "Batch 83. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6134786605834961\n",
      "Batch 84. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5942906141281128\n",
      "Batch 85. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5667505860328674\n",
      "Batch 86. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6061232089996338\n",
      "Batch 87. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5758753418922424\n",
      "Batch 88. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5630245208740234\n",
      "Batch 89. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5418668389320374\n",
      "Batch 90. Data shape torch.Size([32, 3, 224, 224]) Loss 0.610397458076477\n",
      "Batch 91. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5609233975410461\n",
      "Batch 92. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6183868646621704\n",
      "Batch 93. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5703325271606445\n",
      "Batch 94. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5673796534538269\n",
      "Batch 95. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5297043323516846\n",
      "Batch 96. Data shape torch.Size([32, 3, 224, 224]) Loss 0.586026132106781\n",
      "Batch 97. Data shape torch.Size([32, 3, 224, 224]) Loss 0.566471517086029\n",
      "Batch 98. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5558599233627319\n",
      "Batch 99. Data shape torch.Size([32, 3, 224, 224]) Loss 0.58848637342453\n",
      "Batch 100. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5519697666168213\n",
      "Batch 101. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6093509197235107\n",
      "Batch 102. Data shape torch.Size([32, 3, 224, 224]) Loss 0.575667679309845\n",
      "Batch 103. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6034930944442749\n",
      "Batch 104. Data shape torch.Size([32, 3, 224, 224]) Loss 0.612593412399292\n",
      "Batch 105. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5591685175895691\n",
      "Batch 106. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5506934523582458\n",
      "Batch 107. Data shape torch.Size([32, 3, 224, 224]) Loss 0.604404091835022\n",
      "Batch 108. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5685123205184937\n",
      "Batch 109. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5865586996078491\n",
      "Batch 110. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5897692441940308\n",
      "Batch 111. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5588106513023376\n",
      "Batch 112. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6292980313301086\n",
      "Batch 113. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5981863737106323\n",
      "Batch 114. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6116164922714233\n",
      "Batch 115. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6144537329673767\n",
      "Batch 116. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5618645548820496\n",
      "Batch 117. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5531060099601746\n",
      "Batch 118. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5680863857269287\n",
      "Batch 119. Data shape torch.Size([20, 3, 224, 224]) Loss 0.5719776749610901\n",
      "Valid loss improved from 0.588946 to 0.587008. Saving model ...\n",
      "Epoch: 34/50 | time: 24.0m 12.82s | lr: 1.0000e-05 | train/loss: 0.59532 | val/loss: 0.58701 | val/accuracy: 0.76844 | val/AUC: 0.76814 | val/Kappa: 0.53652\n",
      "Epoch: 35 Train batch 10 loss: 0.6284293532371521, 2.1% complete\n",
      "Epoch: 35 Train batch 20 loss: 0.5479515790939331, 4.2% complete\n",
      "Epoch: 35 Train batch 30 loss: 0.6056361794471741, 6.3% complete\n",
      "Epoch: 35 Train batch 40 loss: 0.5937780141830444, 8.4% complete\n",
      "Epoch: 35 Train batch 50 loss: 0.5643310546875, 10.5% complete\n",
      "Epoch: 35 Train batch 60 loss: 0.5788019299507141, 12.6% complete\n",
      "Epoch: 35 Train batch 70 loss: 0.5917303562164307, 14.7% complete\n",
      "Epoch: 35 Train batch 80 loss: 0.5716303586959839, 16.8% complete\n",
      "Epoch: 35 Train batch 90 loss: 0.6366211771965027, 18.9% complete\n",
      "Epoch: 35 Train batch 100 loss: 0.6167901158332825, 21.1% complete\n",
      "Epoch: 35 Train batch 110 loss: 0.5696665644645691, 23.2% complete\n",
      "Epoch: 35 Train batch 120 loss: 0.5628862380981445, 25.3% complete\n",
      "Epoch: 35 Train batch 130 loss: 0.5774820446968079, 27.4% complete\n",
      "Epoch: 35 Train batch 140 loss: 0.5827139019966125, 29.5% complete\n",
      "Epoch: 35 Train batch 150 loss: 0.5565215349197388, 31.6% complete\n",
      "Epoch: 35 Train batch 160 loss: 0.5852237939834595, 33.7% complete\n",
      "Epoch: 35 Train batch 170 loss: 0.6463335156440735, 35.8% complete\n",
      "Epoch: 35 Train batch 180 loss: 0.5672739148139954, 37.9% complete\n",
      "Epoch: 35 Train batch 190 loss: 0.5674700736999512, 40.0% complete\n",
      "Epoch: 35 Train batch 200 loss: 0.6070700287818909, 42.1% complete\n",
      "Epoch: 35 Train batch 210 loss: 0.5918689370155334, 44.2% complete\n",
      "Epoch: 35 Train batch 220 loss: 0.6102358102798462, 46.3% complete\n",
      "Epoch: 35 Train batch 230 loss: 0.5451506972312927, 48.4% complete\n",
      "Epoch: 35 Train batch 240 loss: 0.5466521978378296, 50.5% complete\n",
      "Epoch: 35 Train batch 250 loss: 0.5663700699806213, 52.6% complete\n",
      "Epoch: 35 Train batch 260 loss: 0.6526011824607849, 54.7% complete\n",
      "Epoch: 35 Train batch 270 loss: 0.6125515699386597, 56.8% complete\n",
      "Epoch: 35 Train batch 280 loss: 0.5849219560623169, 58.9% complete\n",
      "Epoch: 35 Train batch 290 loss: 0.556128978729248, 61.1% complete\n",
      "Epoch: 35 Train batch 300 loss: 0.6094893217086792, 63.2% complete\n",
      "Epoch: 35 Train batch 310 loss: 0.587064802646637, 65.3% complete\n",
      "Epoch: 35 Train batch 320 loss: 0.618850588798523, 67.4% complete\n",
      "Epoch: 35 Train batch 330 loss: 0.608852207660675, 69.5% complete\n",
      "Epoch: 35 Train batch 340 loss: 0.6011930704116821, 71.6% complete\n",
      "Epoch: 35 Train batch 350 loss: 0.5962197184562683, 73.7% complete\n",
      "Epoch: 35 Train batch 360 loss: 0.5452142357826233, 75.8% complete\n",
      "Epoch: 35 Train batch 370 loss: 0.5749087929725647, 77.9% complete\n",
      "Epoch: 35 Train batch 380 loss: 0.6241599917411804, 80.0% complete\n",
      "Epoch: 35 Train batch 390 loss: 0.6490317583084106, 82.1% complete\n",
      "Epoch: 35 Train batch 400 loss: 0.5624907612800598, 84.2% complete\n",
      "Epoch: 35 Train batch 410 loss: 0.6601031422615051, 86.3% complete\n",
      "Epoch: 35 Train batch 420 loss: 0.641189455986023, 88.4% complete\n",
      "Epoch: 35 Train batch 430 loss: 0.6568760275840759, 90.5% complete\n",
      "Epoch: 35 Train batch 440 loss: 0.5590795278549194, 92.6% complete\n",
      "Epoch: 35 Train batch 450 loss: 0.5717610120773315, 94.7% complete\n",
      "Epoch: 35 Train batch 460 loss: 0.6043625473976135, 96.8% complete\n",
      "Epoch: 35 Train batch 470 loss: 0.545982837677002, 98.9% complete\n",
      "Batch 1. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5755854249000549\n",
      "Batch 2. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5806737542152405\n",
      "Batch 3. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5244541764259338\n",
      "Batch 4. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6057089567184448\n",
      "Batch 5. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5814059376716614\n",
      "Batch 6. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6292307376861572\n",
      "Batch 7. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5608606934547424\n",
      "Batch 8. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5791935920715332\n",
      "Batch 9. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5902693271636963\n",
      "Batch 10. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5830983519554138\n",
      "Batch 11. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6121225953102112\n",
      "Batch 12. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5613139271736145\n",
      "Batch 13. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5658383965492249\n",
      "Batch 14. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5579347610473633\n",
      "Batch 15. Data shape torch.Size([32, 3, 224, 224]) Loss 0.572321355342865\n",
      "Batch 16. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5932076573371887\n",
      "Batch 17. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5867326259613037\n",
      "Batch 18. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5235017538070679\n",
      "Batch 19. Data shape torch.Size([32, 3, 224, 224]) Loss 0.581358790397644\n",
      "Batch 20. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5687640905380249\n",
      "Batch 21. Data shape torch.Size([32, 3, 224, 224]) Loss 0.633948802947998\n",
      "Batch 22. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6138954758644104\n",
      "Batch 23. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5640650391578674\n",
      "Batch 24. Data shape torch.Size([32, 3, 224, 224]) Loss 0.587030291557312\n",
      "Batch 25. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5424434542655945\n",
      "Batch 26. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5890228152275085\n",
      "Batch 27. Data shape torch.Size([32, 3, 224, 224]) Loss 0.580375611782074\n",
      "Batch 28. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5519757866859436\n",
      "Batch 29. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6377103328704834\n",
      "Batch 30. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5735092163085938\n",
      "Batch 31. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5707049369812012\n",
      "Batch 32. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5756665468215942\n",
      "Batch 33. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6160364747047424\n",
      "Batch 34. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5681071877479553\n",
      "Batch 35. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5755984783172607\n",
      "Batch 36. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6160294413566589\n",
      "Batch 37. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5956442952156067\n",
      "Batch 38. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5850656032562256\n",
      "Batch 39. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5875638127326965\n",
      "Batch 40. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5618392825126648\n",
      "Batch 41. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5663777589797974\n",
      "Batch 42. Data shape torch.Size([32, 3, 224, 224]) Loss 0.577189564704895\n",
      "Batch 43. Data shape torch.Size([32, 3, 224, 224]) Loss 0.585599958896637\n",
      "Batch 44. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5530911684036255\n",
      "Batch 45. Data shape torch.Size([32, 3, 224, 224]) Loss 0.572367250919342\n",
      "Batch 46. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5914278626441956\n",
      "Batch 47. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5473626852035522\n",
      "Batch 48. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6250779032707214\n",
      "Batch 49. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5686091184616089\n",
      "Batch 50. Data shape torch.Size([32, 3, 224, 224]) Loss 0.559413731098175\n",
      "Batch 51. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5284267663955688\n",
      "Batch 52. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6242151260375977\n",
      "Batch 53. Data shape torch.Size([32, 3, 224, 224]) Loss 0.548640787601471\n",
      "Batch 54. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5599930286407471\n",
      "Batch 55. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5884323120117188\n",
      "Batch 56. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5090976357460022\n",
      "Batch 57. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5716990232467651\n",
      "Batch 58. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5734843015670776\n",
      "Batch 59. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5640337467193604\n",
      "Batch 60. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5986257791519165\n",
      "Batch 61. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5991091728210449\n",
      "Batch 62. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5554371476173401\n",
      "Batch 63. Data shape torch.Size([32, 3, 224, 224]) Loss 0.566518247127533\n",
      "Batch 64. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5897675156593323\n",
      "Batch 65. Data shape torch.Size([32, 3, 224, 224]) Loss 0.595683217048645\n",
      "Batch 66. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5758552551269531\n",
      "Batch 67. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5583423376083374\n",
      "Batch 68. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5858438611030579\n",
      "Batch 69. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6023686528205872\n",
      "Batch 70. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6368104815483093\n",
      "Batch 71. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5548343062400818\n",
      "Batch 72. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6596890687942505\n",
      "Batch 73. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5683994293212891\n",
      "Batch 74. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5735174417495728\n",
      "Batch 75. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6016436815261841\n",
      "Batch 76. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6007112860679626\n",
      "Batch 77. Data shape torch.Size([32, 3, 224, 224]) Loss 0.608436107635498\n",
      "Batch 78. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6159176826477051\n",
      "Batch 79. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6083940863609314\n",
      "Batch 80. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5835340619087219\n",
      "Batch 81. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6153538227081299\n",
      "Batch 82. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5872441530227661\n",
      "Batch 83. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5617226958274841\n",
      "Batch 84. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5685352683067322\n",
      "Batch 85. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5589408874511719\n",
      "Batch 86. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6054633855819702\n",
      "Batch 87. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6348387002944946\n",
      "Batch 88. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5697274804115295\n",
      "Batch 89. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5966423749923706\n",
      "Batch 90. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6256923675537109\n",
      "Batch 91. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5801407694816589\n",
      "Batch 92. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5784213542938232\n",
      "Batch 93. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6151676177978516\n",
      "Batch 94. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5416451692581177\n",
      "Batch 95. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5730780959129333\n",
      "Batch 96. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6057519316673279\n",
      "Batch 97. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6242502331733704\n",
      "Batch 98. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5681783556938171\n",
      "Batch 99. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5691259503364563\n",
      "Batch 100. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5590763092041016\n",
      "Batch 101. Data shape torch.Size([32, 3, 224, 224]) Loss 0.592278003692627\n",
      "Batch 102. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6646440029144287\n",
      "Batch 103. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6023231148719788\n",
      "Batch 104. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6247730851173401\n",
      "Batch 105. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6024855375289917\n",
      "Batch 106. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5555254220962524\n",
      "Batch 107. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5948840975761414\n",
      "Batch 108. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5839406847953796\n",
      "Batch 109. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6583048701286316\n",
      "Batch 110. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5838893055915833\n",
      "Batch 111. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5700361728668213\n",
      "Batch 112. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5480064749717712\n",
      "Batch 113. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5645794868469238\n",
      "Batch 114. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5596683025360107\n",
      "Batch 115. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5810655355453491\n",
      "Batch 116. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5778177976608276\n",
      "Batch 117. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5759986042976379\n",
      "Batch 118. Data shape torch.Size([32, 3, 224, 224]) Loss 0.567823588848114\n",
      "Batch 119. Data shape torch.Size([20, 3, 224, 224]) Loss 0.5731369256973267\n",
      "Valid loss improved from 0.587008 to 0.583479. Saving model ...\n",
      "Epoch: 35/50 | time: 22.0m 27.9s | lr: 1.0000e-05 | train/loss: 0.59182 | val/loss: 0.58348 | val/accuracy: 0.77081 | val/AUC: 0.77060 | val/Kappa: 0.54135\n",
      "Epoch: 36 Train batch 10 loss: 0.6003760099411011, 2.1% complete\n",
      "Epoch: 36 Train batch 20 loss: 0.5589408278465271, 4.2% complete\n",
      "Epoch: 36 Train batch 30 loss: 0.6042089462280273, 6.3% complete\n",
      "Epoch: 36 Train batch 40 loss: 0.5736240744590759, 8.4% complete\n",
      "Epoch: 36 Train batch 50 loss: 0.5772453546524048, 10.5% complete\n",
      "Epoch: 36 Train batch 60 loss: 0.5496830344200134, 12.6% complete\n",
      "Epoch: 36 Train batch 70 loss: 0.5744467377662659, 14.7% complete\n",
      "Epoch: 36 Train batch 80 loss: 0.5780907273292542, 16.8% complete\n",
      "Epoch: 36 Train batch 90 loss: 0.607490599155426, 18.9% complete\n",
      "Epoch: 36 Train batch 100 loss: 0.5972336530685425, 21.1% complete\n",
      "Epoch: 36 Train batch 110 loss: 0.59774249792099, 23.2% complete\n",
      "Epoch: 36 Train batch 120 loss: 0.6253010630607605, 25.3% complete\n",
      "Epoch: 36 Train batch 130 loss: 0.6491434574127197, 27.4% complete\n",
      "Epoch: 36 Train batch 140 loss: 0.5971057415008545, 29.5% complete\n",
      "Epoch: 36 Train batch 150 loss: 0.5916592478752136, 31.6% complete\n",
      "Epoch: 36 Train batch 160 loss: 0.5890345573425293, 33.7% complete\n",
      "Epoch: 36 Train batch 170 loss: 0.6104540228843689, 35.8% complete\n",
      "Epoch: 36 Train batch 180 loss: 0.6106995344161987, 37.9% complete\n",
      "Epoch: 36 Train batch 190 loss: 0.6208231449127197, 40.0% complete\n",
      "Epoch: 36 Train batch 200 loss: 0.5575194358825684, 42.1% complete\n",
      "Epoch: 36 Train batch 210 loss: 0.6020334362983704, 44.2% complete\n",
      "Epoch: 36 Train batch 220 loss: 0.5761421322822571, 46.3% complete\n",
      "Epoch: 36 Train batch 230 loss: 0.5924908518791199, 48.4% complete\n",
      "Epoch: 36 Train batch 240 loss: 0.5666917562484741, 50.5% complete\n",
      "Epoch: 36 Train batch 250 loss: 0.6162987351417542, 52.6% complete\n",
      "Epoch: 36 Train batch 260 loss: 0.5803706645965576, 54.7% complete\n",
      "Epoch: 36 Train batch 270 loss: 0.5875294804573059, 56.8% complete\n",
      "Epoch: 36 Train batch 280 loss: 0.5196883678436279, 58.9% complete\n",
      "Epoch: 36 Train batch 290 loss: 0.5683902502059937, 61.1% complete\n",
      "Epoch: 36 Train batch 300 loss: 0.5956029891967773, 63.2% complete\n",
      "Epoch: 36 Train batch 310 loss: 0.6029093265533447, 65.3% complete\n",
      "Epoch: 36 Train batch 320 loss: 0.5950685143470764, 67.4% complete\n",
      "Epoch: 36 Train batch 330 loss: 0.5594179630279541, 69.5% complete\n",
      "Epoch: 36 Train batch 340 loss: 0.6016755104064941, 71.6% complete\n",
      "Epoch: 36 Train batch 350 loss: 0.6294542551040649, 73.7% complete\n",
      "Epoch: 36 Train batch 360 loss: 0.5406517386436462, 75.8% complete\n",
      "Epoch: 36 Train batch 370 loss: 0.5486670732498169, 77.9% complete\n",
      "Epoch: 36 Train batch 380 loss: 0.5876997709274292, 80.0% complete\n",
      "Epoch: 36 Train batch 390 loss: 0.6163309812545776, 82.1% complete\n",
      "Epoch: 36 Train batch 400 loss: 0.5534659028053284, 84.2% complete\n",
      "Epoch: 36 Train batch 410 loss: 0.6412913799285889, 86.3% complete\n",
      "Epoch: 36 Train batch 420 loss: 0.5616117119789124, 88.4% complete\n",
      "Epoch: 36 Train batch 430 loss: 0.5597535967826843, 90.5% complete\n",
      "Epoch: 36 Train batch 440 loss: 0.5921226739883423, 92.6% complete\n",
      "Epoch: 36 Train batch 450 loss: 0.5603525042533875, 94.7% complete\n",
      "Epoch: 36 Train batch 460 loss: 0.6125668883323669, 96.8% complete\n",
      "Epoch: 36 Train batch 470 loss: 0.5784093141555786, 98.9% complete\n",
      "Batch 1. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5811338424682617\n",
      "Batch 2. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5781161189079285\n",
      "Batch 3. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5694871544837952\n",
      "Batch 4. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5514585375785828\n",
      "Batch 5. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5951712727546692\n",
      "Batch 6. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5892823338508606\n",
      "Batch 7. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6088634133338928\n",
      "Batch 8. Data shape torch.Size([32, 3, 224, 224]) Loss 0.575373113155365\n",
      "Batch 9. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5382593870162964\n",
      "Batch 10. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5419453978538513\n",
      "Batch 11. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5953693985939026\n",
      "Batch 12. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5751849412918091\n",
      "Batch 13. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5188785195350647\n",
      "Batch 14. Data shape torch.Size([32, 3, 224, 224]) Loss 0.573347806930542\n",
      "Batch 15. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5566288828849792\n",
      "Batch 16. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5483638048171997\n",
      "Batch 17. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5981109142303467\n",
      "Batch 18. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5663740038871765\n",
      "Batch 19. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5501505732536316\n",
      "Batch 20. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5871350765228271\n",
      "Batch 21. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6058304905891418\n",
      "Batch 22. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5516831278800964\n",
      "Batch 23. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6205306649208069\n",
      "Batch 24. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5682551860809326\n",
      "Batch 25. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5655245184898376\n",
      "Batch 26. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5695780515670776\n",
      "Batch 27. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5333037972450256\n",
      "Batch 28. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6213065385818481\n",
      "Batch 29. Data shape torch.Size([32, 3, 224, 224]) Loss 0.642067015171051\n",
      "Batch 30. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5987740159034729\n",
      "Batch 31. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5707659125328064\n",
      "Batch 32. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5552095770835876\n",
      "Batch 33. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6058339476585388\n",
      "Batch 34. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5837724208831787\n",
      "Batch 35. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6202414631843567\n",
      "Batch 36. Data shape torch.Size([32, 3, 224, 224]) Loss 0.567811131477356\n",
      "Batch 37. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5348444581031799\n",
      "Batch 38. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5656951665878296\n",
      "Batch 39. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5614558458328247\n",
      "Batch 40. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6058446168899536\n",
      "Batch 41. Data shape torch.Size([32, 3, 224, 224]) Loss 0.601095974445343\n",
      "Batch 42. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5813807845115662\n",
      "Batch 43. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5056614279747009\n",
      "Batch 44. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5370652079582214\n",
      "Batch 45. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5522855520248413\n",
      "Batch 46. Data shape torch.Size([32, 3, 224, 224]) Loss 0.518007755279541\n",
      "Batch 47. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5635181069374084\n",
      "Batch 48. Data shape torch.Size([32, 3, 224, 224]) Loss 0.564552366733551\n",
      "Batch 49. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5916115045547485\n",
      "Batch 50. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5484574437141418\n",
      "Batch 51. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5716282725334167\n",
      "Batch 52. Data shape torch.Size([32, 3, 224, 224]) Loss 0.620860755443573\n",
      "Batch 53. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5571983456611633\n",
      "Batch 54. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5620189905166626\n",
      "Batch 55. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6245743036270142\n",
      "Batch 56. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5905538201332092\n",
      "Batch 57. Data shape torch.Size([32, 3, 224, 224]) Loss 0.558835506439209\n",
      "Batch 58. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5659981369972229\n",
      "Batch 59. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5769373178482056\n",
      "Batch 60. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5284022688865662\n",
      "Batch 61. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5502276420593262\n",
      "Batch 62. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5384714007377625\n",
      "Batch 63. Data shape torch.Size([32, 3, 224, 224]) Loss 0.596365213394165\n",
      "Batch 64. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5766575336456299\n",
      "Batch 65. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5996232628822327\n",
      "Batch 66. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5893207788467407\n",
      "Batch 67. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5536871552467346\n",
      "Batch 68. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6369374990463257\n",
      "Batch 69. Data shape torch.Size([32, 3, 224, 224]) Loss 0.577177107334137\n",
      "Batch 70. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6335107088088989\n",
      "Batch 71. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5983257293701172\n",
      "Batch 72. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5864707827568054\n",
      "Batch 73. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6034902334213257\n",
      "Batch 74. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6377317905426025\n",
      "Batch 75. Data shape torch.Size([32, 3, 224, 224]) Loss 0.579697847366333\n",
      "Batch 76. Data shape torch.Size([32, 3, 224, 224]) Loss 0.567169189453125\n",
      "Batch 77. Data shape torch.Size([32, 3, 224, 224]) Loss 0.573305070400238\n",
      "Batch 78. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5886189341545105\n",
      "Batch 79. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5828085541725159\n",
      "Batch 80. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6153736710548401\n",
      "Batch 81. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5804187059402466\n",
      "Batch 82. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5985389947891235\n",
      "Batch 83. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5606157183647156\n",
      "Batch 84. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5861871242523193\n",
      "Batch 85. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5396814942359924\n",
      "Batch 86. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5838855504989624\n",
      "Batch 87. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6368798613548279\n",
      "Batch 88. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6506061553955078\n",
      "Batch 89. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5452022552490234\n",
      "Batch 90. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5665117502212524\n",
      "Batch 91. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6132112741470337\n",
      "Batch 92. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5463590025901794\n",
      "Batch 93. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5787385702133179\n",
      "Batch 94. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5520879626274109\n",
      "Batch 95. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5572457909584045\n",
      "Batch 96. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6132616400718689\n",
      "Batch 97. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6054262518882751\n",
      "Batch 98. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5714258551597595\n",
      "Batch 99. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5908849835395813\n",
      "Batch 100. Data shape torch.Size([32, 3, 224, 224]) Loss 0.584212601184845\n",
      "Batch 101. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5239289402961731\n",
      "Batch 102. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5644758343696594\n",
      "Batch 103. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6133304834365845\n",
      "Batch 104. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5635949373245239\n",
      "Batch 105. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5551694631576538\n",
      "Batch 106. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5803397297859192\n",
      "Batch 107. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5915984511375427\n",
      "Batch 108. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5757290720939636\n",
      "Batch 109. Data shape torch.Size([32, 3, 224, 224]) Loss 0.54390949010849\n",
      "Batch 110. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5351722240447998\n",
      "Batch 111. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6036087870597839\n",
      "Batch 112. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5733892917633057\n",
      "Batch 113. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5417014360427856\n",
      "Batch 114. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6362745761871338\n",
      "Batch 115. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5676583647727966\n",
      "Batch 116. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5354948043823242\n",
      "Batch 117. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5783537030220032\n",
      "Batch 118. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6115390658378601\n",
      "Batch 119. Data shape torch.Size([20, 3, 224, 224]) Loss 0.5269995927810669\n",
      "Valid loss improved from 0.583479 to 0.576775. Saving model ...\n",
      "Epoch: 36/50 | time: 22.0m 29.14s | lr: 1.0000e-05 | train/loss: 0.58761 | val/loss: 0.57678 | val/accuracy: 0.77160 | val/AUC: 0.77114 | val/Kappa: 0.54271\n",
      "Epoch: 37 Train batch 10 loss: 0.5903595089912415, 2.1% complete\n",
      "Epoch: 37 Train batch 20 loss: 0.5811398029327393, 4.2% complete\n",
      "Epoch: 37 Train batch 30 loss: 0.5189898610115051, 6.3% complete\n",
      "Epoch: 37 Train batch 40 loss: 0.5948119163513184, 8.4% complete\n",
      "Epoch: 37 Train batch 50 loss: 0.5786263942718506, 10.5% complete\n",
      "Epoch: 37 Train batch 60 loss: 0.5403230786323547, 12.6% complete\n",
      "Epoch: 37 Train batch 70 loss: 0.5707987546920776, 14.7% complete\n",
      "Epoch: 37 Train batch 80 loss: 0.615592896938324, 16.8% complete\n",
      "Epoch: 37 Train batch 90 loss: 0.5752781629562378, 18.9% complete\n",
      "Epoch: 37 Train batch 100 loss: 0.6109989285469055, 21.1% complete\n",
      "Epoch: 37 Train batch 110 loss: 0.5532691478729248, 23.2% complete\n",
      "Epoch: 37 Train batch 120 loss: 0.6385718584060669, 25.3% complete\n",
      "Epoch: 37 Train batch 130 loss: 0.6144204139709473, 27.4% complete\n",
      "Epoch: 37 Train batch 140 loss: 0.5930510759353638, 29.5% complete\n",
      "Epoch: 37 Train batch 150 loss: 0.599764883518219, 31.6% complete\n",
      "Epoch: 37 Train batch 160 loss: 0.5790125727653503, 33.7% complete\n",
      "Epoch: 37 Train batch 170 loss: 0.5376698970794678, 35.8% complete\n",
      "Epoch: 37 Train batch 180 loss: 0.5646863579750061, 37.9% complete\n",
      "Epoch: 37 Train batch 190 loss: 0.5500664710998535, 40.0% complete\n",
      "Epoch: 37 Train batch 200 loss: 0.5365567207336426, 42.1% complete\n",
      "Epoch: 37 Train batch 210 loss: 0.5616355538368225, 44.2% complete\n",
      "Epoch: 37 Train batch 220 loss: 0.5785655975341797, 46.3% complete\n",
      "Epoch: 37 Train batch 230 loss: 0.6290863752365112, 48.4% complete\n",
      "Epoch: 37 Train batch 240 loss: 0.6079336404800415, 50.5% complete\n",
      "Epoch: 37 Train batch 250 loss: 0.6617375016212463, 52.6% complete\n",
      "Epoch: 37 Train batch 260 loss: 0.5807714462280273, 54.7% complete\n",
      "Epoch: 37 Train batch 270 loss: 0.5416730642318726, 56.8% complete\n",
      "Epoch: 37 Train batch 280 loss: 0.568304717540741, 58.9% complete\n",
      "Epoch: 37 Train batch 290 loss: 0.6162147521972656, 61.1% complete\n",
      "Epoch: 37 Train batch 300 loss: 0.5625478625297546, 63.2% complete\n",
      "Epoch: 37 Train batch 310 loss: 0.6429758071899414, 65.3% complete\n",
      "Epoch: 37 Train batch 320 loss: 0.558229386806488, 67.4% complete\n",
      "Epoch: 37 Train batch 330 loss: 0.5822862982749939, 69.5% complete\n",
      "Epoch: 37 Train batch 340 loss: 0.631463885307312, 71.6% complete\n",
      "Epoch: 37 Train batch 350 loss: 0.6454542875289917, 73.7% complete\n",
      "Epoch: 37 Train batch 360 loss: 0.537544846534729, 75.8% complete\n",
      "Epoch: 37 Train batch 370 loss: 0.5746297240257263, 77.9% complete\n",
      "Epoch: 37 Train batch 380 loss: 0.524044930934906, 80.0% complete\n",
      "Epoch: 37 Train batch 390 loss: 0.5868057608604431, 82.1% complete\n",
      "Epoch: 37 Train batch 400 loss: 0.558023989200592, 84.2% complete\n",
      "Epoch: 37 Train batch 410 loss: 0.5638230443000793, 86.3% complete\n",
      "Epoch: 37 Train batch 420 loss: 0.5603623986244202, 88.4% complete\n",
      "Epoch: 37 Train batch 430 loss: 0.6052626967430115, 90.5% complete\n",
      "Epoch: 37 Train batch 440 loss: 0.5386521220207214, 92.6% complete\n",
      "Epoch: 37 Train batch 450 loss: 0.5757119655609131, 94.7% complete\n",
      "Epoch: 37 Train batch 460 loss: 0.6746901273727417, 96.8% complete\n",
      "Epoch: 37 Train batch 470 loss: 0.5255419611930847, 98.9% complete\n",
      "Batch 1. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5554674863815308\n",
      "Batch 2. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5447974801063538\n",
      "Batch 3. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6223945617675781\n",
      "Batch 4. Data shape torch.Size([32, 3, 224, 224]) Loss 0.547542154788971\n",
      "Batch 5. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5710719227790833\n",
      "Batch 6. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5645111203193665\n",
      "Batch 7. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5764502882957458\n",
      "Batch 8. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5368220806121826\n",
      "Batch 9. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5902249217033386\n",
      "Batch 10. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6423998475074768\n",
      "Batch 11. Data shape torch.Size([32, 3, 224, 224]) Loss 0.583058774471283\n",
      "Batch 12. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5826236605644226\n",
      "Batch 13. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5999590754508972\n",
      "Batch 14. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5964076519012451\n",
      "Batch 15. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5439137816429138\n",
      "Batch 16. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5421664118766785\n",
      "Batch 17. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5775831341743469\n",
      "Batch 18. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5519750118255615\n",
      "Batch 19. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5832054018974304\n",
      "Batch 20. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5640966296195984\n",
      "Batch 21. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5938761830329895\n",
      "Batch 22. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5598270893096924\n",
      "Batch 23. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5795414447784424\n",
      "Batch 24. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5797193050384521\n",
      "Batch 25. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5548723936080933\n",
      "Batch 26. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5576702952384949\n",
      "Batch 27. Data shape torch.Size([32, 3, 224, 224]) Loss 0.529464066028595\n",
      "Batch 28. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5550224184989929\n",
      "Batch 29. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5476755499839783\n",
      "Batch 30. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5873814225196838\n",
      "Batch 31. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5471407175064087\n",
      "Batch 32. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5342844724655151\n",
      "Batch 33. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6239304542541504\n",
      "Batch 34. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5931660532951355\n",
      "Batch 35. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5323760509490967\n",
      "Batch 36. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5104230642318726\n",
      "Batch 37. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5728523135185242\n",
      "Batch 38. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5933088064193726\n",
      "Batch 39. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5728712677955627\n",
      "Batch 40. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5998417735099792\n",
      "Batch 41. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5834828615188599\n",
      "Batch 42. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5997464656829834\n",
      "Batch 43. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5574904084205627\n",
      "Batch 44. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5133576393127441\n",
      "Batch 45. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5349693298339844\n",
      "Batch 46. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5878409147262573\n",
      "Batch 47. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5611431002616882\n",
      "Batch 48. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5725511312484741\n",
      "Batch 49. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5585960149765015\n",
      "Batch 50. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5325810313224792\n",
      "Batch 51. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6006984710693359\n",
      "Batch 52. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5626800060272217\n",
      "Batch 53. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5327506065368652\n",
      "Batch 54. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6184143424034119\n",
      "Batch 55. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5678253173828125\n",
      "Batch 56. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5730583667755127\n",
      "Batch 57. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5430582165718079\n",
      "Batch 58. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6265759468078613\n",
      "Batch 59. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5483812689781189\n",
      "Batch 60. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5413788557052612\n",
      "Batch 61. Data shape torch.Size([32, 3, 224, 224]) Loss 0.624352216720581\n",
      "Batch 62. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5673851370811462\n",
      "Batch 63. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5504170656204224\n",
      "Batch 64. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5016509294509888\n",
      "Batch 65. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5717852115631104\n",
      "Batch 66. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5466964244842529\n",
      "Batch 67. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5785300731658936\n",
      "Batch 68. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5471929907798767\n",
      "Batch 69. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5383314490318298\n",
      "Batch 70. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5924105048179626\n",
      "Batch 71. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6004683375358582\n",
      "Batch 72. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5950769186019897\n",
      "Batch 73. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5513636469841003\n",
      "Batch 74. Data shape torch.Size([32, 3, 224, 224]) Loss 0.539365828037262\n",
      "Batch 75. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6111093759536743\n",
      "Batch 76. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5065978169441223\n",
      "Batch 77. Data shape torch.Size([32, 3, 224, 224]) Loss 0.53299880027771\n",
      "Batch 78. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6479095220565796\n",
      "Batch 79. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5861515402793884\n",
      "Batch 80. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5587130784988403\n",
      "Batch 81. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5473535060882568\n",
      "Batch 82. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5956383347511292\n",
      "Batch 83. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5283259153366089\n",
      "Batch 84. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5641221404075623\n",
      "Batch 85. Data shape torch.Size([32, 3, 224, 224]) Loss 0.546913743019104\n",
      "Batch 86. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5414801239967346\n",
      "Batch 87. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5585989952087402\n",
      "Batch 88. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5892171859741211\n",
      "Batch 89. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5335698127746582\n",
      "Batch 90. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5350176692008972\n",
      "Batch 91. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5848732590675354\n",
      "Batch 92. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5650967359542847\n",
      "Batch 93. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6035401225090027\n",
      "Batch 94. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6015697717666626\n",
      "Batch 95. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6149850487709045\n",
      "Batch 96. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6176097989082336\n",
      "Batch 97. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5416064262390137\n",
      "Batch 98. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5833042860031128\n",
      "Batch 99. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5141409635543823\n",
      "Batch 100. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4779050052165985\n",
      "Batch 101. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5863750576972961\n",
      "Batch 102. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5886275768280029\n",
      "Batch 103. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5579730272293091\n",
      "Batch 104. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5560314655303955\n",
      "Batch 105. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5123931169509888\n",
      "Batch 106. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5993244051933289\n",
      "Batch 107. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5871853232383728\n",
      "Batch 108. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5614390969276428\n",
      "Batch 109. Data shape torch.Size([32, 3, 224, 224]) Loss 0.554722785949707\n",
      "Batch 110. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6188976764678955\n",
      "Batch 111. Data shape torch.Size([32, 3, 224, 224]) Loss 0.560377299785614\n",
      "Batch 112. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5847517251968384\n",
      "Batch 113. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5705462098121643\n",
      "Batch 114. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5281524658203125\n",
      "Batch 115. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6068709492683411\n",
      "Batch 116. Data shape torch.Size([32, 3, 224, 224]) Loss 0.562973141670227\n",
      "Batch 117. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5879610180854797\n",
      "Batch 118. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5705914497375488\n",
      "Batch 119. Data shape torch.Size([20, 3, 224, 224]) Loss 0.5694250464439392\n",
      "Valid loss improved from 0.576775 to 0.567870. Saving model ...\n",
      "Epoch: 37/50 | time: 21.0m 43.82s | lr: 1.0000e-05 | train/loss: 0.58348 | val/loss: 0.56787 | val/accuracy: 0.77476 | val/AUC: 0.77470 | val/Kappa: 0.54939\n",
      "Epoch: 38 Train batch 10 loss: 0.5560771822929382, 2.1% complete\n",
      "Epoch: 38 Train batch 20 loss: 0.5688689947128296, 4.2% complete\n",
      "Epoch: 38 Train batch 30 loss: 0.6173723936080933, 6.3% complete\n",
      "Epoch: 38 Train batch 40 loss: 0.5850456357002258, 8.4% complete\n",
      "Epoch: 38 Train batch 50 loss: 0.5946205258369446, 10.5% complete\n",
      "Epoch: 38 Train batch 60 loss: 0.5191285610198975, 12.6% complete\n",
      "Epoch: 38 Train batch 70 loss: 0.6015786528587341, 14.7% complete\n",
      "Epoch: 38 Train batch 80 loss: 0.5932822823524475, 16.8% complete\n",
      "Epoch: 38 Train batch 90 loss: 0.5658104419708252, 18.9% complete\n",
      "Epoch: 38 Train batch 100 loss: 0.6427102088928223, 21.1% complete\n",
      "Epoch: 38 Train batch 110 loss: 0.5665866732597351, 23.2% complete\n",
      "Epoch: 38 Train batch 120 loss: 0.6177985668182373, 25.3% complete\n",
      "Epoch: 38 Train batch 130 loss: 0.555788516998291, 27.4% complete\n",
      "Epoch: 38 Train batch 140 loss: 0.582207441329956, 29.5% complete\n",
      "Epoch: 38 Train batch 150 loss: 0.597980260848999, 31.6% complete\n",
      "Epoch: 38 Train batch 160 loss: 0.5554792881011963, 33.7% complete\n",
      "Epoch: 38 Train batch 170 loss: 0.6266953349113464, 35.8% complete\n",
      "Epoch: 38 Train batch 180 loss: 0.5909743309020996, 37.9% complete\n",
      "Epoch: 38 Train batch 190 loss: 0.5275290012359619, 40.0% complete\n",
      "Epoch: 38 Train batch 200 loss: 0.6018653512001038, 42.1% complete\n",
      "Epoch: 38 Train batch 210 loss: 0.6054991483688354, 44.2% complete\n",
      "Epoch: 38 Train batch 220 loss: 0.5415948629379272, 46.3% complete\n",
      "Epoch: 38 Train batch 230 loss: 0.55269855260849, 48.4% complete\n",
      "Epoch: 38 Train batch 240 loss: 0.5617444515228271, 50.5% complete\n",
      "Epoch: 38 Train batch 250 loss: 0.6581295132637024, 52.6% complete\n",
      "Epoch: 38 Train batch 260 loss: 0.5604067444801331, 54.7% complete\n",
      "Epoch: 38 Train batch 270 loss: 0.5438663959503174, 56.8% complete\n",
      "Epoch: 38 Train batch 280 loss: 0.5514326095581055, 58.9% complete\n",
      "Epoch: 38 Train batch 290 loss: 0.5328419804573059, 61.1% complete\n",
      "Epoch: 38 Train batch 300 loss: 0.5142573714256287, 63.2% complete\n",
      "Epoch: 38 Train batch 310 loss: 0.5474037528038025, 65.3% complete\n",
      "Epoch: 38 Train batch 320 loss: 0.5640642642974854, 67.4% complete\n",
      "Epoch: 38 Train batch 330 loss: 0.5475311875343323, 69.5% complete\n",
      "Epoch: 38 Train batch 340 loss: 0.6466512084007263, 71.6% complete\n",
      "Epoch: 38 Train batch 350 loss: 0.5867894887924194, 73.7% complete\n",
      "Epoch: 38 Train batch 360 loss: 0.5273993611335754, 75.8% complete\n",
      "Epoch: 38 Train batch 370 loss: 0.5089801549911499, 77.9% complete\n",
      "Epoch: 38 Train batch 380 loss: 0.5222676992416382, 80.0% complete\n",
      "Epoch: 38 Train batch 390 loss: 0.5981143116950989, 82.1% complete\n",
      "Epoch: 38 Train batch 400 loss: 0.5809329748153687, 84.2% complete\n",
      "Epoch: 38 Train batch 410 loss: 0.5728858113288879, 86.3% complete\n",
      "Epoch: 38 Train batch 420 loss: 0.5187769532203674, 88.4% complete\n",
      "Epoch: 38 Train batch 430 loss: 0.570511519908905, 90.5% complete\n",
      "Epoch: 38 Train batch 440 loss: 0.49724826216697693, 92.6% complete\n",
      "Epoch: 38 Train batch 450 loss: 0.5715993642807007, 94.7% complete\n",
      "Epoch: 38 Train batch 460 loss: 0.5197305679321289, 96.8% complete\n",
      "Epoch: 38 Train batch 470 loss: 0.5922184586524963, 98.9% complete\n",
      "Batch 1. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5286505818367004\n",
      "Batch 2. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5569881200790405\n",
      "Batch 3. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5375847816467285\n",
      "Batch 4. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5283149480819702\n",
      "Batch 5. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5698710083961487\n",
      "Batch 6. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5666520595550537\n",
      "Batch 7. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5430558323860168\n",
      "Batch 8. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5728950500488281\n",
      "Batch 9. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5350722074508667\n",
      "Batch 10. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5234824419021606\n",
      "Batch 11. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6059672236442566\n",
      "Batch 12. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6040043830871582\n",
      "Batch 13. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5597976446151733\n",
      "Batch 14. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5673783421516418\n",
      "Batch 15. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5447065234184265\n",
      "Batch 16. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6136237978935242\n",
      "Batch 17. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5841489434242249\n",
      "Batch 18. Data shape torch.Size([32, 3, 224, 224]) Loss 0.518054723739624\n",
      "Batch 19. Data shape torch.Size([32, 3, 224, 224]) Loss 0.555912435054779\n",
      "Batch 20. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5290011167526245\n",
      "Batch 21. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6353738307952881\n",
      "Batch 22. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5405182838439941\n",
      "Batch 23. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5763888359069824\n",
      "Batch 24. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5585309267044067\n",
      "Batch 25. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5623435378074646\n",
      "Batch 26. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5595408082008362\n",
      "Batch 27. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5458139777183533\n",
      "Batch 28. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5806280970573425\n",
      "Batch 29. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5709301233291626\n",
      "Batch 30. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5940583944320679\n",
      "Batch 31. Data shape torch.Size([32, 3, 224, 224]) Loss 0.589881956577301\n",
      "Batch 32. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5676177144050598\n",
      "Batch 33. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5633646249771118\n",
      "Batch 34. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5541526079177856\n",
      "Batch 35. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5777948498725891\n",
      "Batch 36. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6111294627189636\n",
      "Batch 37. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5731434226036072\n",
      "Batch 38. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6191874146461487\n",
      "Batch 39. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5996733903884888\n",
      "Batch 40. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5876328349113464\n",
      "Batch 41. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5887601971626282\n",
      "Batch 42. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5912648439407349\n",
      "Batch 43. Data shape torch.Size([32, 3, 224, 224]) Loss 0.509591281414032\n",
      "Batch 44. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6325293779373169\n",
      "Batch 45. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5864869356155396\n",
      "Batch 46. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5002307295799255\n",
      "Batch 47. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5327784419059753\n",
      "Batch 48. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5640560984611511\n",
      "Batch 49. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5555068850517273\n",
      "Batch 50. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5247735977172852\n",
      "Batch 51. Data shape torch.Size([32, 3, 224, 224]) Loss 0.600124716758728\n",
      "Batch 52. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5502020716667175\n",
      "Batch 53. Data shape torch.Size([32, 3, 224, 224]) Loss 0.58591628074646\n",
      "Batch 54. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5898606777191162\n",
      "Batch 55. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5881927609443665\n",
      "Batch 56. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5946133136749268\n",
      "Batch 57. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6141808032989502\n",
      "Batch 58. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6434500217437744\n",
      "Batch 59. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5865121483802795\n",
      "Batch 60. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5516762733459473\n",
      "Batch 61. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5749911665916443\n",
      "Batch 62. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5351721048355103\n",
      "Batch 63. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5496970415115356\n",
      "Batch 64. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5948144793510437\n",
      "Batch 65. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5899834036827087\n",
      "Batch 66. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5998200178146362\n",
      "Batch 67. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5317683219909668\n",
      "Batch 68. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5754954814910889\n",
      "Batch 69. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6066409349441528\n",
      "Batch 70. Data shape torch.Size([32, 3, 224, 224]) Loss 0.578353762626648\n",
      "Batch 71. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5638409852981567\n",
      "Batch 72. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5126823782920837\n",
      "Batch 73. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6364997625350952\n",
      "Batch 74. Data shape torch.Size([32, 3, 224, 224]) Loss 0.553541362285614\n",
      "Batch 75. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5385045409202576\n",
      "Batch 76. Data shape torch.Size([32, 3, 224, 224]) Loss 0.555349588394165\n",
      "Batch 77. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5609073042869568\n",
      "Batch 78. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5450596809387207\n",
      "Batch 79. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5290250778198242\n",
      "Batch 80. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5603289008140564\n",
      "Batch 81. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4945835769176483\n",
      "Batch 82. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5754373073577881\n",
      "Batch 83. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5799095630645752\n",
      "Batch 84. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5349738001823425\n",
      "Batch 85. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5515896081924438\n",
      "Batch 86. Data shape torch.Size([32, 3, 224, 224]) Loss 0.501136064529419\n",
      "Batch 87. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5605286359786987\n",
      "Batch 88. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5745416879653931\n",
      "Batch 89. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6064074635505676\n",
      "Batch 90. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5594871044158936\n",
      "Batch 91. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5327469110488892\n",
      "Batch 92. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5149906277656555\n",
      "Batch 93. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5818201899528503\n",
      "Batch 94. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5556607246398926\n",
      "Batch 95. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5839307308197021\n",
      "Batch 96. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5257379412651062\n",
      "Batch 97. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5652178525924683\n",
      "Batch 98. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5938048362731934\n",
      "Batch 99. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5637722611427307\n",
      "Batch 100. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5671051740646362\n",
      "Batch 101. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5923051834106445\n",
      "Batch 102. Data shape torch.Size([32, 3, 224, 224]) Loss 0.598257839679718\n",
      "Batch 103. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5794174075126648\n",
      "Batch 104. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5550103187561035\n",
      "Batch 105. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6340290904045105\n",
      "Batch 106. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5530984401702881\n",
      "Batch 107. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5275146961212158\n",
      "Batch 108. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5340851545333862\n",
      "Batch 109. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5273538827896118\n",
      "Batch 110. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5332733392715454\n",
      "Batch 111. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6148666739463806\n",
      "Batch 112. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5919623374938965\n",
      "Batch 113. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5675160884857178\n",
      "Batch 114. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5940256118774414\n",
      "Batch 115. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5405403971672058\n",
      "Batch 116. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5437508225440979\n",
      "Batch 117. Data shape torch.Size([32, 3, 224, 224]) Loss 0.638137936592102\n",
      "Batch 118. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5409462451934814\n",
      "Batch 119. Data shape torch.Size([20, 3, 224, 224]) Loss 0.5326544642448425\n",
      "Valid loss improved from 0.567870 to 0.566539. Saving model ...\n",
      "Epoch: 38/50 | time: 22.0m 13.88s | lr: 1.0000e-05 | train/loss: 0.57903 | val/loss: 0.56654 | val/accuracy: 0.77792 | val/AUC: 0.77720 | val/Kappa: 0.55513\n",
      "Epoch: 39 Train batch 10 loss: 0.5377095341682434, 2.1% complete\n",
      "Epoch: 39 Train batch 20 loss: 0.5448891520500183, 4.2% complete\n",
      "Epoch: 39 Train batch 30 loss: 0.553301215171814, 6.3% complete\n",
      "Epoch: 39 Train batch 40 loss: 0.572140097618103, 8.4% complete\n",
      "Epoch: 39 Train batch 50 loss: 0.5921279788017273, 10.5% complete\n",
      "Epoch: 39 Train batch 60 loss: 0.5524609684944153, 12.6% complete\n",
      "Epoch: 39 Train batch 70 loss: 0.5296040177345276, 14.7% complete\n",
      "Epoch: 39 Train batch 80 loss: 0.577304482460022, 16.8% complete\n",
      "Epoch: 39 Train batch 90 loss: 0.5782395005226135, 18.9% complete\n",
      "Epoch: 39 Train batch 100 loss: 0.5925495624542236, 21.1% complete\n",
      "Epoch: 39 Train batch 110 loss: 0.5650346875190735, 23.2% complete\n",
      "Epoch: 39 Train batch 120 loss: 0.608644425868988, 25.3% complete\n",
      "Epoch: 39 Train batch 130 loss: 0.6221606135368347, 27.4% complete\n",
      "Epoch: 39 Train batch 140 loss: 0.5678508877754211, 29.5% complete\n",
      "Epoch: 39 Train batch 150 loss: 0.534176230430603, 31.6% complete\n",
      "Epoch: 39 Train batch 160 loss: 0.5680802464485168, 33.7% complete\n",
      "Epoch: 39 Train batch 170 loss: 0.5427858829498291, 35.8% complete\n",
      "Epoch: 39 Train batch 180 loss: 0.5084925293922424, 37.9% complete\n",
      "Epoch: 39 Train batch 190 loss: 0.578546404838562, 40.0% complete\n",
      "Epoch: 39 Train batch 200 loss: 0.56304532289505, 42.1% complete\n",
      "Epoch: 39 Train batch 210 loss: 0.5347440242767334, 44.2% complete\n",
      "Epoch: 39 Train batch 220 loss: 0.5795448422431946, 46.3% complete\n",
      "Epoch: 39 Train batch 230 loss: 0.6028198003768921, 48.4% complete\n",
      "Epoch: 39 Train batch 240 loss: 0.6124554872512817, 50.5% complete\n",
      "Epoch: 39 Train batch 250 loss: 0.6008847951889038, 52.6% complete\n",
      "Epoch: 39 Train batch 260 loss: 0.5747251510620117, 54.7% complete\n",
      "Epoch: 39 Train batch 270 loss: 0.5871652960777283, 56.8% complete\n",
      "Epoch: 39 Train batch 280 loss: 0.5369151830673218, 58.9% complete\n",
      "Epoch: 39 Train batch 290 loss: 0.6030479073524475, 61.1% complete\n",
      "Epoch: 39 Train batch 300 loss: 0.5615556240081787, 63.2% complete\n",
      "Epoch: 39 Train batch 310 loss: 0.5913069844245911, 65.3% complete\n",
      "Epoch: 39 Train batch 320 loss: 0.5360571146011353, 67.4% complete\n",
      "Epoch: 39 Train batch 330 loss: 0.5707622766494751, 69.5% complete\n",
      "Epoch: 39 Train batch 340 loss: 0.5249105095863342, 71.6% complete\n",
      "Epoch: 39 Train batch 350 loss: 0.6504554152488708, 73.7% complete\n",
      "Epoch: 39 Train batch 360 loss: 0.521037757396698, 75.8% complete\n",
      "Epoch: 39 Train batch 370 loss: 0.5300875902175903, 77.9% complete\n",
      "Epoch: 39 Train batch 380 loss: 0.6059655547142029, 80.0% complete\n",
      "Epoch: 39 Train batch 390 loss: 0.6191530823707581, 82.1% complete\n",
      "Epoch: 39 Train batch 400 loss: 0.5978359580039978, 84.2% complete\n",
      "Epoch: 39 Train batch 410 loss: 0.6064854860305786, 86.3% complete\n",
      "Epoch: 39 Train batch 420 loss: 0.5286937952041626, 88.4% complete\n",
      "Epoch: 39 Train batch 430 loss: 0.6175044178962708, 90.5% complete\n",
      "Epoch: 39 Train batch 440 loss: 0.5654253363609314, 92.6% complete\n",
      "Epoch: 39 Train batch 450 loss: 0.5564472675323486, 94.7% complete\n",
      "Epoch: 39 Train batch 460 loss: 0.6314517855644226, 96.8% complete\n",
      "Epoch: 39 Train batch 470 loss: 0.6039044857025146, 98.9% complete\n",
      "Batch 1. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5217953324317932\n",
      "Batch 2. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5658507943153381\n",
      "Batch 3. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5477513074874878\n",
      "Batch 4. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5061288475990295\n",
      "Batch 5. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5532358884811401\n",
      "Batch 6. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5576487183570862\n",
      "Batch 7. Data shape torch.Size([32, 3, 224, 224]) Loss 0.529212474822998\n",
      "Batch 8. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5582165718078613\n",
      "Batch 9. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5298823118209839\n",
      "Batch 10. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5706320405006409\n",
      "Batch 11. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5381375551223755\n",
      "Batch 12. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6588260531425476\n",
      "Batch 13. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5590745210647583\n",
      "Batch 14. Data shape torch.Size([32, 3, 224, 224]) Loss 0.50459223985672\n",
      "Batch 15. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5259026885032654\n",
      "Batch 16. Data shape torch.Size([32, 3, 224, 224]) Loss 0.596608579158783\n",
      "Batch 17. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5748997330665588\n",
      "Batch 18. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5487441420555115\n",
      "Batch 19. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5655547380447388\n",
      "Batch 20. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5306834578514099\n",
      "Batch 21. Data shape torch.Size([32, 3, 224, 224]) Loss 0.49804601073265076\n",
      "Batch 22. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5282588005065918\n",
      "Batch 23. Data shape torch.Size([32, 3, 224, 224]) Loss 0.49320659041404724\n",
      "Batch 24. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5543025732040405\n",
      "Batch 25. Data shape torch.Size([32, 3, 224, 224]) Loss 0.545265793800354\n",
      "Batch 26. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5564793348312378\n",
      "Batch 27. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5029873847961426\n",
      "Batch 28. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5028836131095886\n",
      "Batch 29. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5633313059806824\n",
      "Batch 30. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5869302153587341\n",
      "Batch 31. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6113623380661011\n",
      "Batch 32. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5682626962661743\n",
      "Batch 33. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5720782279968262\n",
      "Batch 34. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6156331300735474\n",
      "Batch 35. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5843457579612732\n",
      "Batch 36. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5396278500556946\n",
      "Batch 37. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5445138216018677\n",
      "Batch 38. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6027294993400574\n",
      "Batch 39. Data shape torch.Size([32, 3, 224, 224]) Loss 0.645524263381958\n",
      "Batch 40. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6327561140060425\n",
      "Batch 41. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5703015327453613\n",
      "Batch 42. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4851441979408264\n",
      "Batch 43. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5069899559020996\n",
      "Batch 44. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5868017673492432\n",
      "Batch 45. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6259796619415283\n",
      "Batch 46. Data shape torch.Size([32, 3, 224, 224]) Loss 0.552893340587616\n",
      "Batch 47. Data shape torch.Size([32, 3, 224, 224]) Loss 0.621883749961853\n",
      "Batch 48. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6000298857688904\n",
      "Batch 49. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5496630072593689\n",
      "Batch 50. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5532560348510742\n",
      "Batch 51. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5757390260696411\n",
      "Batch 52. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5641867518424988\n",
      "Batch 53. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5456223487854004\n",
      "Batch 54. Data shape torch.Size([32, 3, 224, 224]) Loss 0.49779221415519714\n",
      "Batch 55. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5756518840789795\n",
      "Batch 56. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5400057435035706\n",
      "Batch 57. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5489414930343628\n",
      "Batch 58. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6135614514350891\n",
      "Batch 59. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5893572568893433\n",
      "Batch 60. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5709453225135803\n",
      "Batch 61. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5901036262512207\n",
      "Batch 62. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5463424324989319\n",
      "Batch 63. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5582365393638611\n",
      "Batch 64. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5034400224685669\n",
      "Batch 65. Data shape torch.Size([32, 3, 224, 224]) Loss 0.55865877866745\n",
      "Batch 66. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5496199131011963\n",
      "Batch 67. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5775582194328308\n",
      "Batch 68. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5465223789215088\n",
      "Batch 69. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5489760637283325\n",
      "Batch 70. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5174744725227356\n",
      "Batch 71. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5266627073287964\n",
      "Batch 72. Data shape torch.Size([32, 3, 224, 224]) Loss 0.533544659614563\n",
      "Batch 73. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5403203368186951\n",
      "Batch 74. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5359606146812439\n",
      "Batch 75. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5737972259521484\n",
      "Batch 76. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5974870920181274\n",
      "Batch 77. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5698014497756958\n",
      "Batch 78. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5817769169807434\n",
      "Batch 79. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6033517718315125\n",
      "Batch 80. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6131710410118103\n",
      "Batch 81. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5837255716323853\n",
      "Batch 82. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5717366933822632\n",
      "Batch 83. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5668143630027771\n",
      "Batch 84. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5036961436271667\n",
      "Batch 85. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5831649899482727\n",
      "Batch 86. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5436149835586548\n",
      "Batch 87. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5923137068748474\n",
      "Batch 88. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5444274544715881\n",
      "Batch 89. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6187934279441833\n",
      "Batch 90. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5809757113456726\n",
      "Batch 91. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6068706512451172\n",
      "Batch 92. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5932435989379883\n",
      "Batch 93. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5333258509635925\n",
      "Batch 94. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5644160509109497\n",
      "Batch 95. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5537746548652649\n",
      "Batch 96. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5534521341323853\n",
      "Batch 97. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5599611401557922\n",
      "Batch 98. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5039661526679993\n",
      "Batch 99. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5643333792686462\n",
      "Batch 100. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5632072687149048\n",
      "Batch 101. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5509839653968811\n",
      "Batch 102. Data shape torch.Size([32, 3, 224, 224]) Loss 0.570093035697937\n",
      "Batch 103. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5537092685699463\n",
      "Batch 104. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5318915843963623\n",
      "Batch 105. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5755916833877563\n",
      "Batch 106. Data shape torch.Size([32, 3, 224, 224]) Loss 0.540717601776123\n",
      "Batch 107. Data shape torch.Size([32, 3, 224, 224]) Loss 0.48071539402008057\n",
      "Batch 108. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5831219553947449\n",
      "Batch 109. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6141388416290283\n",
      "Batch 110. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5664132833480835\n",
      "Batch 111. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6159011721611023\n",
      "Batch 112. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5456028580665588\n",
      "Batch 113. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5994294285774231\n",
      "Batch 114. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5932185053825378\n",
      "Batch 115. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5388317108154297\n",
      "Batch 116. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5837309956550598\n",
      "Batch 117. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5205958485603333\n",
      "Batch 118. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5181283950805664\n",
      "Batch 119. Data shape torch.Size([20, 3, 224, 224]) Loss 0.5206085443496704\n",
      "Valid loss improved from 0.566539 to 0.559905. Saving model ...\n",
      "Epoch: 39/50 | time: 23.0m 4.744s | lr: 1.0000e-05 | train/loss: 0.57475 | val/loss: 0.55990 | val/accuracy: 0.77687 | val/AUC: 0.77642 | val/Kappa: 0.55327\n",
      "Epoch: 40 Train batch 10 loss: 0.5500562787055969, 2.1% complete\n",
      "Epoch: 40 Train batch 20 loss: 0.6286823153495789, 4.2% complete\n",
      "Epoch: 40 Train batch 30 loss: 0.6347370147705078, 6.3% complete\n",
      "Epoch: 40 Train batch 40 loss: 0.5648239850997925, 8.4% complete\n",
      "Epoch: 40 Train batch 50 loss: 0.6177594661712646, 10.5% complete\n",
      "Epoch: 40 Train batch 60 loss: 0.5579013824462891, 12.6% complete\n",
      "Epoch: 40 Train batch 70 loss: 0.6164566278457642, 14.7% complete\n",
      "Epoch: 40 Train batch 80 loss: 0.5992633104324341, 16.8% complete\n",
      "Epoch: 40 Train batch 90 loss: 0.520561933517456, 18.9% complete\n",
      "Epoch: 40 Train batch 100 loss: 0.6499091386795044, 21.1% complete\n",
      "Epoch: 40 Train batch 110 loss: 0.5181609988212585, 23.2% complete\n",
      "Epoch: 40 Train batch 120 loss: 0.5266403555870056, 25.3% complete\n",
      "Epoch: 40 Train batch 130 loss: 0.5188329219818115, 27.4% complete\n",
      "Epoch: 40 Train batch 140 loss: 0.5732906460762024, 29.5% complete\n",
      "Epoch: 40 Train batch 150 loss: 0.5144543647766113, 31.6% complete\n",
      "Epoch: 40 Train batch 160 loss: 0.5941872000694275, 33.7% complete\n",
      "Epoch: 40 Train batch 170 loss: 0.611426830291748, 35.8% complete\n",
      "Epoch: 40 Train batch 180 loss: 0.5135226845741272, 37.9% complete\n",
      "Epoch: 40 Train batch 190 loss: 0.5317964553833008, 40.0% complete\n",
      "Epoch: 40 Train batch 200 loss: 0.587735652923584, 42.1% complete\n",
      "Epoch: 40 Train batch 210 loss: 0.545820951461792, 44.2% complete\n",
      "Epoch: 40 Train batch 220 loss: 0.5753768682479858, 46.3% complete\n",
      "Epoch: 40 Train batch 230 loss: 0.6456998586654663, 48.4% complete\n",
      "Epoch: 40 Train batch 240 loss: 0.5691207647323608, 50.5% complete\n",
      "Epoch: 40 Train batch 250 loss: 0.5656942129135132, 52.6% complete\n",
      "Epoch: 40 Train batch 260 loss: 0.5881596207618713, 54.7% complete\n",
      "Epoch: 40 Train batch 270 loss: 0.6059401631355286, 56.8% complete\n",
      "Epoch: 40 Train batch 280 loss: 0.5382096171379089, 58.9% complete\n",
      "Epoch: 40 Train batch 290 loss: 0.6070265173912048, 61.1% complete\n",
      "Epoch: 40 Train batch 300 loss: 0.5210590362548828, 63.2% complete\n",
      "Epoch: 40 Train batch 310 loss: 0.5750818252563477, 65.3% complete\n",
      "Epoch: 40 Train batch 320 loss: 0.5595932006835938, 67.4% complete\n",
      "Epoch: 40 Train batch 330 loss: 0.5216779708862305, 69.5% complete\n",
      "Epoch: 40 Train batch 340 loss: 0.6106904745101929, 71.6% complete\n",
      "Epoch: 40 Train batch 350 loss: 0.5495046377182007, 73.7% complete\n",
      "Epoch: 40 Train batch 360 loss: 0.6004058718681335, 75.8% complete\n",
      "Epoch: 40 Train batch 370 loss: 0.541060209274292, 77.9% complete\n",
      "Epoch: 40 Train batch 380 loss: 0.5943979620933533, 80.0% complete\n",
      "Epoch: 40 Train batch 390 loss: 0.5764090418815613, 82.1% complete\n",
      "Epoch: 40 Train batch 400 loss: 0.5379084944725037, 84.2% complete\n",
      "Epoch: 40 Train batch 410 loss: 0.5811940431594849, 86.3% complete\n",
      "Epoch: 40 Train batch 420 loss: 0.6095618009567261, 88.4% complete\n",
      "Epoch: 40 Train batch 430 loss: 0.6030195355415344, 90.5% complete\n",
      "Epoch: 40 Train batch 440 loss: 0.5998494625091553, 92.6% complete\n",
      "Epoch: 40 Train batch 450 loss: 0.5628457069396973, 94.7% complete\n",
      "Epoch: 40 Train batch 460 loss: 0.5560677647590637, 96.8% complete\n",
      "Epoch: 40 Train batch 470 loss: 0.6082670092582703, 98.9% complete\n",
      "Batch 1. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5774280428886414\n",
      "Batch 2. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5312992334365845\n",
      "Batch 3. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5815315842628479\n",
      "Batch 4. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5629434585571289\n",
      "Batch 5. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5125703811645508\n",
      "Batch 6. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5356217622756958\n",
      "Batch 7. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5384657979011536\n",
      "Batch 8. Data shape torch.Size([32, 3, 224, 224]) Loss 0.49464085698127747\n",
      "Batch 9. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5198962688446045\n",
      "Batch 10. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5791710615158081\n",
      "Batch 11. Data shape torch.Size([32, 3, 224, 224]) Loss 0.528049647808075\n",
      "Batch 12. Data shape torch.Size([32, 3, 224, 224]) Loss 0.514365553855896\n",
      "Batch 13. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5784605145454407\n",
      "Batch 14. Data shape torch.Size([32, 3, 224, 224]) Loss 0.49473273754119873\n",
      "Batch 15. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5508323311805725\n",
      "Batch 16. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5577093958854675\n",
      "Batch 17. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6145056486129761\n",
      "Batch 18. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5445773601531982\n",
      "Batch 19. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6030662655830383\n",
      "Batch 20. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5652492046356201\n",
      "Batch 21. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6023269295692444\n",
      "Batch 22. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5515340566635132\n",
      "Batch 23. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5956050753593445\n",
      "Batch 24. Data shape torch.Size([32, 3, 224, 224]) Loss 0.508713960647583\n",
      "Batch 25. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5256363153457642\n",
      "Batch 26. Data shape torch.Size([32, 3, 224, 224]) Loss 0.49100279808044434\n",
      "Batch 27. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5971118211746216\n",
      "Batch 28. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5713810920715332\n",
      "Batch 29. Data shape torch.Size([32, 3, 224, 224]) Loss 0.43633806705474854\n",
      "Batch 30. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6054514646530151\n",
      "Batch 31. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5665016174316406\n",
      "Batch 32. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5998069643974304\n",
      "Batch 33. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5516505837440491\n",
      "Batch 34. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5645269751548767\n",
      "Batch 35. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5204840898513794\n",
      "Batch 36. Data shape torch.Size([32, 3, 224, 224]) Loss 0.516227126121521\n",
      "Batch 37. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4685957431793213\n",
      "Batch 38. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5087742805480957\n",
      "Batch 39. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5285523533821106\n",
      "Batch 40. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5836519598960876\n",
      "Batch 41. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5705520510673523\n",
      "Batch 42. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5914000868797302\n",
      "Batch 43. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5813809037208557\n",
      "Batch 44. Data shape torch.Size([32, 3, 224, 224]) Loss 0.559005618095398\n",
      "Batch 45. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5702617764472961\n",
      "Batch 46. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6073113679885864\n",
      "Batch 47. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5830221176147461\n",
      "Batch 48. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5635455846786499\n",
      "Batch 49. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4889543652534485\n",
      "Batch 50. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5591761469841003\n",
      "Batch 51. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4968515932559967\n",
      "Batch 52. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5574050545692444\n",
      "Batch 53. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6077922582626343\n",
      "Batch 54. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5181376338005066\n",
      "Batch 55. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5705758929252625\n",
      "Batch 56. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5614764094352722\n",
      "Batch 57. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5394724607467651\n",
      "Batch 58. Data shape torch.Size([32, 3, 224, 224]) Loss 0.563893735408783\n",
      "Batch 59. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6395864486694336\n",
      "Batch 60. Data shape torch.Size([32, 3, 224, 224]) Loss 0.527534008026123\n",
      "Batch 61. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5574328899383545\n",
      "Batch 62. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5538356900215149\n",
      "Batch 63. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5722309350967407\n",
      "Batch 64. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5518949627876282\n",
      "Batch 65. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5469149351119995\n",
      "Batch 66. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5419989824295044\n",
      "Batch 67. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5485731363296509\n",
      "Batch 68. Data shape torch.Size([32, 3, 224, 224]) Loss 0.554216206073761\n",
      "Batch 69. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5471823215484619\n",
      "Batch 70. Data shape torch.Size([32, 3, 224, 224]) Loss 0.539332389831543\n",
      "Batch 71. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5968263149261475\n",
      "Batch 72. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5809571743011475\n",
      "Batch 73. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5589820146560669\n",
      "Batch 74. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5698585510253906\n",
      "Batch 75. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5297062397003174\n",
      "Batch 76. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5631586313247681\n",
      "Batch 77. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4658552408218384\n",
      "Batch 78. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5653127431869507\n",
      "Batch 79. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5900534391403198\n",
      "Batch 80. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5595362782478333\n",
      "Batch 81. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6022789478302002\n",
      "Batch 82. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4785225987434387\n",
      "Batch 83. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5474548935890198\n",
      "Batch 84. Data shape torch.Size([32, 3, 224, 224]) Loss 0.525668740272522\n",
      "Batch 85. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5593591332435608\n",
      "Batch 86. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5609056353569031\n",
      "Batch 87. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5757672190666199\n",
      "Batch 88. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5860334634780884\n",
      "Batch 89. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5624542832374573\n",
      "Batch 90. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5300534963607788\n",
      "Batch 91. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5572668313980103\n",
      "Batch 92. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5978431105613708\n",
      "Batch 93. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5563004612922668\n",
      "Batch 94. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5905026793479919\n",
      "Batch 95. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5980890393257141\n",
      "Batch 96. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5956709980964661\n",
      "Batch 97. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6097440123558044\n",
      "Batch 98. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5773130059242249\n",
      "Batch 99. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5054905414581299\n",
      "Batch 100. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5879940986633301\n",
      "Batch 101. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5343044400215149\n",
      "Batch 102. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5186204314231873\n",
      "Batch 103. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5798810720443726\n",
      "Batch 104. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5420961380004883\n",
      "Batch 105. Data shape torch.Size([32, 3, 224, 224]) Loss 0.597500205039978\n",
      "Batch 106. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5283752083778381\n",
      "Batch 107. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5807161927223206\n",
      "Batch 108. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5900912284851074\n",
      "Batch 109. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5349066257476807\n",
      "Batch 110. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5243796110153198\n",
      "Batch 111. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5210813879966736\n",
      "Batch 112. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5366898775100708\n",
      "Batch 113. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5513177514076233\n",
      "Batch 114. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5334439873695374\n",
      "Batch 115. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5787562727928162\n",
      "Batch 116. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5615354776382446\n",
      "Batch 117. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5432597994804382\n",
      "Batch 118. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4995250701904297\n",
      "Batch 119. Data shape torch.Size([20, 3, 224, 224]) Loss 0.586746335029602\n",
      "Valid loss improved from 0.559905 to 0.554438. Saving model ...\n",
      "Epoch: 40/50 | time: 22.0m 22.74s | lr: 1.0000e-05 | train/loss: 0.57054 | val/loss: 0.55444 | val/accuracy: 0.77792 | val/AUC: 0.77741 | val/Kappa: 0.55532\n",
      "Epoch: 41 Train batch 10 loss: 0.5913880467414856, 2.1% complete\n",
      "Epoch: 41 Train batch 20 loss: 0.49957945942878723, 4.2% complete\n",
      "Epoch: 41 Train batch 30 loss: 0.5843649506568909, 6.3% complete\n",
      "Epoch: 41 Train batch 40 loss: 0.6080875992774963, 8.4% complete\n",
      "Epoch: 41 Train batch 50 loss: 0.5710867643356323, 10.5% complete\n",
      "Epoch: 41 Train batch 60 loss: 0.5417918562889099, 12.6% complete\n",
      "Epoch: 41 Train batch 70 loss: 0.6494940519332886, 14.7% complete\n",
      "Epoch: 41 Train batch 80 loss: 0.5720716714859009, 16.8% complete\n",
      "Epoch: 41 Train batch 90 loss: 0.5328693389892578, 18.9% complete\n",
      "Epoch: 41 Train batch 100 loss: 0.5571553111076355, 21.1% complete\n",
      "Epoch: 41 Train batch 110 loss: 0.5575919151306152, 23.2% complete\n",
      "Epoch: 41 Train batch 120 loss: 0.6099215745925903, 25.3% complete\n",
      "Epoch: 41 Train batch 130 loss: 0.5774279832839966, 27.4% complete\n",
      "Epoch: 41 Train batch 140 loss: 0.5311890840530396, 29.5% complete\n",
      "Epoch: 41 Train batch 150 loss: 0.5528677105903625, 31.6% complete\n",
      "Epoch: 41 Train batch 160 loss: 0.6094970703125, 33.7% complete\n",
      "Epoch: 41 Train batch 170 loss: 0.5583083629608154, 35.8% complete\n",
      "Epoch: 41 Train batch 180 loss: 0.613437294960022, 37.9% complete\n",
      "Epoch: 41 Train batch 190 loss: 0.6002020835876465, 40.0% complete\n",
      "Epoch: 41 Train batch 200 loss: 0.5393176674842834, 42.1% complete\n",
      "Epoch: 41 Train batch 210 loss: 0.48482128977775574, 44.2% complete\n",
      "Epoch: 41 Train batch 220 loss: 0.5664222240447998, 46.3% complete\n",
      "Epoch: 41 Train batch 230 loss: 0.525942325592041, 48.4% complete\n",
      "Epoch: 41 Train batch 240 loss: 0.54523766040802, 50.5% complete\n",
      "Epoch: 41 Train batch 250 loss: 0.5822646617889404, 52.6% complete\n",
      "Epoch: 41 Train batch 260 loss: 0.5543268322944641, 54.7% complete\n",
      "Epoch: 41 Train batch 270 loss: 0.6475481986999512, 56.8% complete\n",
      "Epoch: 41 Train batch 280 loss: 0.4805855453014374, 58.9% complete\n",
      "Epoch: 41 Train batch 290 loss: 0.5365679860115051, 61.1% complete\n",
      "Epoch: 41 Train batch 300 loss: 0.6216686964035034, 63.2% complete\n",
      "Epoch: 41 Train batch 310 loss: 0.5639622211456299, 65.3% complete\n",
      "Epoch: 41 Train batch 320 loss: 0.6048493981361389, 67.4% complete\n",
      "Epoch: 41 Train batch 330 loss: 0.5294319987297058, 69.5% complete\n",
      "Epoch: 41 Train batch 340 loss: 0.6086392402648926, 71.6% complete\n",
      "Epoch: 41 Train batch 350 loss: 0.5778651237487793, 73.7% complete\n",
      "Epoch: 41 Train batch 360 loss: 0.541854977607727, 75.8% complete\n",
      "Epoch: 41 Train batch 370 loss: 0.5278525352478027, 77.9% complete\n",
      "Epoch: 41 Train batch 380 loss: 0.555892288684845, 80.0% complete\n",
      "Epoch: 41 Train batch 390 loss: 0.6034107804298401, 82.1% complete\n",
      "Epoch: 41 Train batch 400 loss: 0.6168664693832397, 84.2% complete\n",
      "Epoch: 41 Train batch 410 loss: 0.5704646110534668, 86.3% complete\n",
      "Epoch: 41 Train batch 420 loss: 0.6107871532440186, 88.4% complete\n",
      "Epoch: 41 Train batch 430 loss: 0.5556488633155823, 90.5% complete\n",
      "Epoch: 41 Train batch 440 loss: 0.5746436715126038, 92.6% complete\n",
      "Epoch: 41 Train batch 450 loss: 0.582880437374115, 94.7% complete\n",
      "Epoch: 41 Train batch 460 loss: 0.5938686728477478, 96.8% complete\n",
      "Epoch: 41 Train batch 470 loss: 0.5042873620986938, 98.9% complete\n",
      "Batch 1. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5657035708427429\n",
      "Batch 2. Data shape torch.Size([32, 3, 224, 224]) Loss 0.47776004672050476\n",
      "Batch 3. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5345085859298706\n",
      "Batch 4. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5104223489761353\n",
      "Batch 5. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5357878804206848\n",
      "Batch 6. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5864853262901306\n",
      "Batch 7. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5239430665969849\n",
      "Batch 8. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6109049320220947\n",
      "Batch 9. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5654723644256592\n",
      "Batch 10. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6675531268119812\n",
      "Batch 11. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5808555483818054\n",
      "Batch 12. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5187439918518066\n",
      "Batch 13. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5512610077857971\n",
      "Batch 14. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5826458930969238\n",
      "Batch 15. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5117920637130737\n",
      "Batch 16. Data shape torch.Size([32, 3, 224, 224]) Loss 0.513498842716217\n",
      "Batch 17. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5754101276397705\n",
      "Batch 18. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5920388698577881\n",
      "Batch 19. Data shape torch.Size([32, 3, 224, 224]) Loss 0.599205732345581\n",
      "Batch 20. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5354354381561279\n",
      "Batch 21. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5895275473594666\n",
      "Batch 22. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5373693108558655\n",
      "Batch 23. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5195757746696472\n",
      "Batch 24. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5368221402168274\n",
      "Batch 25. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5539758801460266\n",
      "Batch 26. Data shape torch.Size([32, 3, 224, 224]) Loss 0.557130753993988\n",
      "Batch 27. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5449697375297546\n",
      "Batch 28. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5173320770263672\n",
      "Batch 29. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5929567813873291\n",
      "Batch 30. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4930145740509033\n",
      "Batch 31. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4844311475753784\n",
      "Batch 32. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5752297639846802\n",
      "Batch 33. Data shape torch.Size([32, 3, 224, 224]) Loss 0.50491863489151\n",
      "Batch 34. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5372848510742188\n",
      "Batch 35. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5594442486763\n",
      "Batch 36. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4631379246711731\n",
      "Batch 37. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5759546756744385\n",
      "Batch 38. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5778583288192749\n",
      "Batch 39. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5299956202507019\n",
      "Batch 40. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5712097883224487\n",
      "Batch 41. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5614779591560364\n",
      "Batch 42. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5614148378372192\n",
      "Batch 43. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5985015630722046\n",
      "Batch 44. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5007189512252808\n",
      "Batch 45. Data shape torch.Size([32, 3, 224, 224]) Loss 0.48913654685020447\n",
      "Batch 46. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6184794902801514\n",
      "Batch 47. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5783416032791138\n",
      "Batch 48. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5561589002609253\n",
      "Batch 49. Data shape torch.Size([32, 3, 224, 224]) Loss 0.60531085729599\n",
      "Batch 50. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5490306615829468\n",
      "Batch 51. Data shape torch.Size([32, 3, 224, 224]) Loss 0.48954033851623535\n",
      "Batch 52. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5747106671333313\n",
      "Batch 53. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5501224398612976\n",
      "Batch 54. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5638687610626221\n",
      "Batch 55. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5549900531768799\n",
      "Batch 56. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5845903754234314\n",
      "Batch 57. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5594033598899841\n",
      "Batch 58. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5496636629104614\n",
      "Batch 59. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5723161101341248\n",
      "Batch 60. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5566511154174805\n",
      "Batch 61. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5178767442703247\n",
      "Batch 62. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6663680076599121\n",
      "Batch 63. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5201943516731262\n",
      "Batch 64. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6681966781616211\n",
      "Batch 65. Data shape torch.Size([32, 3, 224, 224]) Loss 0.531069278717041\n",
      "Batch 66. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5155189633369446\n",
      "Batch 67. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5666053295135498\n",
      "Batch 68. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5544188618659973\n",
      "Batch 69. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6374446749687195\n",
      "Batch 70. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5727221369743347\n",
      "Batch 71. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5341630578041077\n",
      "Batch 72. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5909104347229004\n",
      "Batch 73. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5498682856559753\n",
      "Batch 74. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5232009887695312\n",
      "Batch 75. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5088167190551758\n",
      "Batch 76. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5459194183349609\n",
      "Batch 77. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5244067907333374\n",
      "Batch 78. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5339778661727905\n",
      "Batch 79. Data shape torch.Size([32, 3, 224, 224]) Loss 0.48986005783081055\n",
      "Batch 80. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5942654013633728\n",
      "Batch 81. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5896970629692078\n",
      "Batch 82. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5135445594787598\n",
      "Batch 83. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5928761959075928\n",
      "Batch 84. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5606983304023743\n",
      "Batch 85. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6120703816413879\n",
      "Batch 86. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5545887351036072\n",
      "Batch 87. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5747581124305725\n",
      "Batch 88. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5569829344749451\n",
      "Batch 89. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5368802547454834\n",
      "Batch 90. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5685718059539795\n",
      "Batch 91. Data shape torch.Size([32, 3, 224, 224]) Loss 0.538406252861023\n",
      "Batch 92. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5289542078971863\n",
      "Batch 93. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5381146669387817\n",
      "Batch 94. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5420052409172058\n",
      "Batch 95. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5522300004959106\n",
      "Batch 96. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5608339905738831\n",
      "Batch 97. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5611802935600281\n",
      "Batch 98. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5457839369773865\n",
      "Batch 99. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5375766754150391\n",
      "Batch 100. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5218392014503479\n",
      "Batch 101. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6284619569778442\n",
      "Batch 102. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5365363359451294\n",
      "Batch 103. Data shape torch.Size([32, 3, 224, 224]) Loss 0.48989182710647583\n",
      "Batch 104. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5231444239616394\n",
      "Batch 105. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4911783039569855\n",
      "Batch 106. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5661363005638123\n",
      "Batch 107. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5580371618270874\n",
      "Batch 108. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5439605116844177\n",
      "Batch 109. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5539242029190063\n",
      "Batch 110. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5013719201087952\n",
      "Batch 111. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5265309810638428\n",
      "Batch 112. Data shape torch.Size([32, 3, 224, 224]) Loss 0.589037299156189\n",
      "Batch 113. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4824642837047577\n",
      "Batch 114. Data shape torch.Size([32, 3, 224, 224]) Loss 0.49196505546569824\n",
      "Batch 115. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5195291638374329\n",
      "Batch 116. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5898486375808716\n",
      "Batch 117. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5926521420478821\n",
      "Batch 118. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5807992219924927\n",
      "Batch 119. Data shape torch.Size([20, 3, 224, 224]) Loss 0.518324077129364\n",
      "Valid loss improved from 0.554438 to 0.551707. Saving model ...\n",
      "Epoch: 41/50 | time: 22.0m 30.23s | lr: 1.0000e-05 | train/loss: 0.56725 | val/loss: 0.55171 | val/accuracy: 0.77845 | val/AUC: 0.77774 | val/Kappa: 0.55619\n",
      "Epoch: 42 Train batch 10 loss: 0.5623258352279663, 2.1% complete\n",
      "Epoch: 42 Train batch 20 loss: 0.5268365740776062, 4.2% complete\n",
      "Epoch: 42 Train batch 30 loss: 0.5800700783729553, 6.3% complete\n",
      "Epoch: 42 Train batch 40 loss: 0.5547114014625549, 8.4% complete\n",
      "Epoch: 42 Train batch 50 loss: 0.5230210423469543, 10.5% complete\n",
      "Epoch: 42 Train batch 60 loss: 0.5316469669342041, 12.6% complete\n",
      "Epoch: 42 Train batch 70 loss: 0.5510648488998413, 14.7% complete\n",
      "Epoch: 42 Train batch 80 loss: 0.5766186118125916, 16.8% complete\n",
      "Epoch: 42 Train batch 90 loss: 0.5085645318031311, 18.9% complete\n",
      "Epoch: 42 Train batch 100 loss: 0.5789192914962769, 21.1% complete\n",
      "Epoch: 42 Train batch 110 loss: 0.6026240587234497, 23.2% complete\n",
      "Epoch: 42 Train batch 120 loss: 0.650629997253418, 25.3% complete\n",
      "Epoch: 42 Train batch 130 loss: 0.5429251194000244, 27.4% complete\n",
      "Epoch: 42 Train batch 140 loss: 0.5918445587158203, 29.5% complete\n",
      "Epoch: 42 Train batch 150 loss: 0.5307318568229675, 31.6% complete\n",
      "Epoch: 42 Train batch 160 loss: 0.5629077553749084, 33.7% complete\n",
      "Epoch: 42 Train batch 170 loss: 0.5381745100021362, 35.8% complete\n",
      "Epoch: 42 Train batch 180 loss: 0.5339733958244324, 37.9% complete\n",
      "Epoch: 42 Train batch 190 loss: 0.5176889896392822, 40.0% complete\n",
      "Epoch: 42 Train batch 200 loss: 0.56642085313797, 42.1% complete\n",
      "Epoch: 42 Train batch 210 loss: 0.5700913667678833, 44.2% complete\n",
      "Epoch: 42 Train batch 220 loss: 0.6084789633750916, 46.3% complete\n",
      "Epoch: 42 Train batch 230 loss: 0.5731620788574219, 48.4% complete\n",
      "Epoch: 42 Train batch 240 loss: 0.5646603107452393, 50.5% complete\n",
      "Epoch: 42 Train batch 250 loss: 0.6024695634841919, 52.6% complete\n",
      "Epoch: 42 Train batch 260 loss: 0.5453294515609741, 54.7% complete\n",
      "Epoch: 42 Train batch 270 loss: 0.6167469024658203, 56.8% complete\n",
      "Epoch: 42 Train batch 280 loss: 0.5117244720458984, 58.9% complete\n",
      "Epoch: 42 Train batch 290 loss: 0.5543180108070374, 61.1% complete\n",
      "Epoch: 42 Train batch 300 loss: 0.6695101857185364, 63.2% complete\n",
      "Epoch: 42 Train batch 310 loss: 0.58234041929245, 65.3% complete\n",
      "Epoch: 42 Train batch 320 loss: 0.5806557536125183, 67.4% complete\n",
      "Epoch: 42 Train batch 330 loss: 0.5779869556427002, 69.5% complete\n",
      "Epoch: 42 Train batch 340 loss: 0.5499238967895508, 71.6% complete\n",
      "Epoch: 42 Train batch 350 loss: 0.6103753447532654, 73.7% complete\n",
      "Epoch: 42 Train batch 360 loss: 0.5626002550125122, 75.8% complete\n",
      "Epoch: 42 Train batch 370 loss: 0.5403289794921875, 77.9% complete\n",
      "Epoch: 42 Train batch 380 loss: 0.5549495220184326, 80.0% complete\n",
      "Epoch: 42 Train batch 390 loss: 0.5474575161933899, 82.1% complete\n",
      "Epoch: 42 Train batch 400 loss: 0.4958997070789337, 84.2% complete\n",
      "Epoch: 42 Train batch 410 loss: 0.5668172836303711, 86.3% complete\n",
      "Epoch: 42 Train batch 420 loss: 0.5622747540473938, 88.4% complete\n",
      "Epoch: 42 Train batch 430 loss: 0.5800329446792603, 90.5% complete\n",
      "Epoch: 42 Train batch 440 loss: 0.6181899309158325, 92.6% complete\n",
      "Epoch: 42 Train batch 450 loss: 0.4804724156856537, 94.7% complete\n",
      "Epoch: 42 Train batch 460 loss: 0.5394251942634583, 96.8% complete\n",
      "Epoch: 42 Train batch 470 loss: 0.5339071750640869, 98.9% complete\n",
      "Batch 1. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5524442791938782\n",
      "Batch 2. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5962945818901062\n",
      "Batch 3. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5505424737930298\n",
      "Batch 4. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5689582228660583\n",
      "Batch 5. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6102776527404785\n",
      "Batch 6. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5607835054397583\n",
      "Batch 7. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5904225707054138\n",
      "Batch 8. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5400915145874023\n",
      "Batch 9. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6140931844711304\n",
      "Batch 10. Data shape torch.Size([32, 3, 224, 224]) Loss 0.49874216318130493\n",
      "Batch 11. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5445566177368164\n",
      "Batch 12. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5082530975341797\n",
      "Batch 13. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5376280546188354\n",
      "Batch 14. Data shape torch.Size([32, 3, 224, 224]) Loss 0.506942629814148\n",
      "Batch 15. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5385301113128662\n",
      "Batch 16. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5802339315414429\n",
      "Batch 17. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5109124183654785\n",
      "Batch 18. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5706784725189209\n",
      "Batch 19. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5292800664901733\n",
      "Batch 20. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5977691411972046\n",
      "Batch 21. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6405819654464722\n",
      "Batch 22. Data shape torch.Size([32, 3, 224, 224]) Loss 0.56025230884552\n",
      "Batch 23. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5121678113937378\n",
      "Batch 24. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5458458065986633\n",
      "Batch 25. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5115513801574707\n",
      "Batch 26. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5131756067276001\n",
      "Batch 27. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5699688792228699\n",
      "Batch 28. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4988805651664734\n",
      "Batch 29. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5597133040428162\n",
      "Batch 30. Data shape torch.Size([32, 3, 224, 224]) Loss 0.569344162940979\n",
      "Batch 31. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5830763578414917\n",
      "Batch 32. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5813948512077332\n",
      "Batch 33. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4951462149620056\n",
      "Batch 34. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5567877292633057\n",
      "Batch 35. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5656249523162842\n",
      "Batch 36. Data shape torch.Size([32, 3, 224, 224]) Loss 0.47922515869140625\n",
      "Batch 37. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5767788290977478\n",
      "Batch 38. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4935218095779419\n",
      "Batch 39. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5933148264884949\n",
      "Batch 40. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5314623117446899\n",
      "Batch 41. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5774094462394714\n",
      "Batch 42. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5427170991897583\n",
      "Batch 43. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5888436436653137\n",
      "Batch 44. Data shape torch.Size([32, 3, 224, 224]) Loss 0.49628040194511414\n",
      "Batch 45. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5416337251663208\n",
      "Batch 46. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6315760016441345\n",
      "Batch 47. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5451079607009888\n",
      "Batch 48. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5806530117988586\n",
      "Batch 49. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5887962579727173\n",
      "Batch 50. Data shape torch.Size([32, 3, 224, 224]) Loss 0.548742413520813\n",
      "Batch 51. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5562388300895691\n",
      "Batch 52. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5599156618118286\n",
      "Batch 53. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5413473844528198\n",
      "Batch 54. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5379207730293274\n",
      "Batch 55. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4771362245082855\n",
      "Batch 56. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5783956050872803\n",
      "Batch 57. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5609955191612244\n",
      "Batch 58. Data shape torch.Size([32, 3, 224, 224]) Loss 0.558121383190155\n",
      "Batch 59. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5551111698150635\n",
      "Batch 60. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5127824544906616\n",
      "Batch 61. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5470892786979675\n",
      "Batch 62. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5754328370094299\n",
      "Batch 63. Data shape torch.Size([32, 3, 224, 224]) Loss 0.583577573299408\n",
      "Batch 64. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5342817306518555\n",
      "Batch 65. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5309010744094849\n",
      "Batch 66. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5986526608467102\n",
      "Batch 67. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6096649169921875\n",
      "Batch 68. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5099053382873535\n",
      "Batch 69. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5857208371162415\n",
      "Batch 70. Data shape torch.Size([32, 3, 224, 224]) Loss 0.46951478719711304\n",
      "Batch 71. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5644680261611938\n",
      "Batch 72. Data shape torch.Size([32, 3, 224, 224]) Loss 0.47045379877090454\n",
      "Batch 73. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5581499338150024\n",
      "Batch 74. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5286329388618469\n",
      "Batch 75. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5805385112762451\n",
      "Batch 76. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5301231741905212\n",
      "Batch 77. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6125815510749817\n",
      "Batch 78. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5761827826499939\n",
      "Batch 79. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5300920009613037\n",
      "Batch 80. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5698361396789551\n",
      "Batch 81. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5345650315284729\n",
      "Batch 82. Data shape torch.Size([32, 3, 224, 224]) Loss 0.48894888162612915\n",
      "Batch 83. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5363202095031738\n",
      "Batch 84. Data shape torch.Size([32, 3, 224, 224]) Loss 0.46935632824897766\n",
      "Batch 85. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5774127244949341\n",
      "Batch 86. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5196905136108398\n",
      "Batch 87. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5667295455932617\n",
      "Batch 88. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5081962943077087\n",
      "Batch 89. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5672152042388916\n",
      "Batch 90. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5206152200698853\n",
      "Batch 91. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5180589556694031\n",
      "Batch 92. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5655099153518677\n",
      "Batch 93. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5496212244033813\n",
      "Batch 94. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5331302881240845\n",
      "Batch 95. Data shape torch.Size([32, 3, 224, 224]) Loss 0.49746349453926086\n",
      "Batch 96. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5401718616485596\n",
      "Batch 97. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5236315727233887\n",
      "Batch 98. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5777386426925659\n",
      "Batch 99. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4725460708141327\n",
      "Batch 100. Data shape torch.Size([32, 3, 224, 224]) Loss 0.555461049079895\n",
      "Batch 101. Data shape torch.Size([32, 3, 224, 224]) Loss 0.566717267036438\n",
      "Batch 102. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5434582233428955\n",
      "Batch 103. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5819483995437622\n",
      "Batch 104. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4895744323730469\n",
      "Batch 105. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5461438298225403\n",
      "Batch 106. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5417558550834656\n",
      "Batch 107. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4401230216026306\n",
      "Batch 108. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5239208936691284\n",
      "Batch 109. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5929343700408936\n",
      "Batch 110. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5071849226951599\n",
      "Batch 111. Data shape torch.Size([32, 3, 224, 224]) Loss 0.551214873790741\n",
      "Batch 112. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5081307291984558\n",
      "Batch 113. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4983442425727844\n",
      "Batch 114. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5449161529541016\n",
      "Batch 115. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5386714935302734\n",
      "Batch 116. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4384514093399048\n",
      "Batch 117. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5638279914855957\n",
      "Batch 118. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5349650979042053\n",
      "Batch 119. Data shape torch.Size([20, 3, 224, 224]) Loss 0.6155573129653931\n",
      "Valid loss improved from 0.551707 to 0.545723. Saving model ...\n",
      "Epoch: 42/50 | time: 23.0m 37.17s | lr: 1.0000e-05 | train/loss: 0.56001 | val/loss: 0.54572 | val/accuracy: 0.77924 | val/AUC: 0.77856 | val/Kappa: 0.55781\n",
      "Epoch: 43 Train batch 10 loss: 0.5882237553596497, 2.1% complete\n",
      "Epoch: 43 Train batch 20 loss: 0.504105269908905, 4.2% complete\n",
      "Epoch: 43 Train batch 30 loss: 0.6083255410194397, 6.3% complete\n",
      "Epoch: 43 Train batch 40 loss: 0.5489797592163086, 8.4% complete\n",
      "Epoch: 43 Train batch 50 loss: 0.6007200479507446, 10.5% complete\n",
      "Epoch: 43 Train batch 60 loss: 0.6161729097366333, 12.6% complete\n",
      "Epoch: 43 Train batch 70 loss: 0.5432825088500977, 14.7% complete\n",
      "Epoch: 43 Train batch 80 loss: 0.5222052931785583, 16.8% complete\n",
      "Epoch: 43 Train batch 90 loss: 0.6174294352531433, 18.9% complete\n",
      "Epoch: 43 Train batch 100 loss: 0.47455382347106934, 21.1% complete\n",
      "Epoch: 43 Train batch 110 loss: 0.5389357805252075, 23.2% complete\n",
      "Epoch: 43 Train batch 120 loss: 0.5687179565429688, 25.3% complete\n",
      "Epoch: 43 Train batch 130 loss: 0.5076791644096375, 27.4% complete\n",
      "Epoch: 43 Train batch 140 loss: 0.577556848526001, 29.5% complete\n",
      "Epoch: 43 Train batch 150 loss: 0.4956682622432709, 31.6% complete\n",
      "Epoch: 43 Train batch 160 loss: 0.5715842843055725, 33.7% complete\n",
      "Epoch: 43 Train batch 170 loss: 0.5165742635726929, 35.8% complete\n",
      "Epoch: 43 Train batch 180 loss: 0.5630446076393127, 37.9% complete\n",
      "Epoch: 43 Train batch 190 loss: 0.6018111109733582, 40.0% complete\n",
      "Epoch: 43 Train batch 200 loss: 0.6515733003616333, 42.1% complete\n",
      "Epoch: 43 Train batch 210 loss: 0.6134995818138123, 44.2% complete\n",
      "Epoch: 43 Train batch 220 loss: 0.5417028665542603, 46.3% complete\n",
      "Epoch: 43 Train batch 230 loss: 0.5640972256660461, 48.4% complete\n",
      "Epoch: 43 Train batch 240 loss: 0.6048906445503235, 50.5% complete\n",
      "Epoch: 43 Train batch 250 loss: 0.5294181704521179, 52.6% complete\n",
      "Epoch: 43 Train batch 260 loss: 0.5731878280639648, 54.7% complete\n",
      "Epoch: 43 Train batch 270 loss: 0.5971289873123169, 56.8% complete\n",
      "Epoch: 43 Train batch 280 loss: 0.5049967169761658, 58.9% complete\n",
      "Epoch: 43 Train batch 290 loss: 0.5824230909347534, 61.1% complete\n",
      "Epoch: 43 Train batch 300 loss: 0.6075568199157715, 63.2% complete\n",
      "Epoch: 43 Train batch 310 loss: 0.5874665975570679, 65.3% complete\n",
      "Epoch: 43 Train batch 320 loss: 0.5294491052627563, 67.4% complete\n",
      "Epoch: 43 Train batch 330 loss: 0.5334401726722717, 69.5% complete\n",
      "Epoch: 43 Train batch 340 loss: 0.5543021559715271, 71.6% complete\n",
      "Epoch: 43 Train batch 350 loss: 0.5369946956634521, 73.7% complete\n",
      "Epoch: 43 Train batch 360 loss: 0.5291846990585327, 75.8% complete\n",
      "Epoch: 43 Train batch 370 loss: 0.5252631306648254, 77.9% complete\n",
      "Epoch: 43 Train batch 380 loss: 0.5912610292434692, 80.0% complete\n",
      "Epoch: 43 Train batch 390 loss: 0.5810438394546509, 82.1% complete\n",
      "Epoch: 43 Train batch 400 loss: 0.4914700388908386, 84.2% complete\n",
      "Epoch: 43 Train batch 410 loss: 0.5642387866973877, 86.3% complete\n",
      "Epoch: 43 Train batch 420 loss: 0.574929416179657, 88.4% complete\n",
      "Epoch: 43 Train batch 430 loss: 0.5840892195701599, 90.5% complete\n",
      "Epoch: 43 Train batch 440 loss: 0.6005319356918335, 92.6% complete\n",
      "Epoch: 43 Train batch 450 loss: 0.6041683554649353, 94.7% complete\n",
      "Epoch: 43 Train batch 460 loss: 0.5557014346122742, 96.8% complete\n",
      "Epoch: 43 Train batch 470 loss: 0.5653910040855408, 98.9% complete\n",
      "Batch 1. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6318684816360474\n",
      "Batch 2. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5946159958839417\n",
      "Batch 3. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4927743971347809\n",
      "Batch 4. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5604929327964783\n",
      "Batch 5. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5094470381736755\n",
      "Batch 6. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5661541223526001\n",
      "Batch 7. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5037775039672852\n",
      "Batch 8. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5686731338500977\n",
      "Batch 9. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5080412030220032\n",
      "Batch 10. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5476687550544739\n",
      "Batch 11. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5609662532806396\n",
      "Batch 12. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4773642420768738\n",
      "Batch 13. Data shape torch.Size([32, 3, 224, 224]) Loss 0.487527459859848\n",
      "Batch 14. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4945537745952606\n",
      "Batch 15. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5473194122314453\n",
      "Batch 16. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4826810657978058\n",
      "Batch 17. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5380236506462097\n",
      "Batch 18. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5184600949287415\n",
      "Batch 19. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5066143274307251\n",
      "Batch 20. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6141970157623291\n",
      "Batch 21. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6053609251976013\n",
      "Batch 22. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5168811678886414\n",
      "Batch 23. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5245188474655151\n",
      "Batch 24. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5190864205360413\n",
      "Batch 25. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5761746764183044\n",
      "Batch 26. Data shape torch.Size([32, 3, 224, 224]) Loss 0.47751519083976746\n",
      "Batch 27. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5272355675697327\n",
      "Batch 28. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5626142621040344\n",
      "Batch 29. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5603069067001343\n",
      "Batch 30. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5275431871414185\n",
      "Batch 31. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5693407654762268\n",
      "Batch 32. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5299750566482544\n",
      "Batch 33. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5824886560440063\n",
      "Batch 34. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5654146075248718\n",
      "Batch 35. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5608450174331665\n",
      "Batch 36. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5648318529129028\n",
      "Batch 37. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5966969132423401\n",
      "Batch 38. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5432002544403076\n",
      "Batch 39. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5414435863494873\n",
      "Batch 40. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5429632663726807\n",
      "Batch 41. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4943661093711853\n",
      "Batch 42. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5178900361061096\n",
      "Batch 43. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5778353810310364\n",
      "Batch 44. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5139780044555664\n",
      "Batch 45. Data shape torch.Size([32, 3, 224, 224]) Loss 0.588704526424408\n",
      "Batch 46. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5389726758003235\n",
      "Batch 47. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5514534711837769\n",
      "Batch 48. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5356248617172241\n",
      "Batch 49. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5586841106414795\n",
      "Batch 50. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6179238557815552\n",
      "Batch 51. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5429273843765259\n",
      "Batch 52. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5938146114349365\n",
      "Batch 53. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5495362281799316\n",
      "Batch 54. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5478413105010986\n",
      "Batch 55. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5909743309020996\n",
      "Batch 56. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6181292533874512\n",
      "Batch 57. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5778633952140808\n",
      "Batch 58. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5906291604042053\n",
      "Batch 59. Data shape torch.Size([32, 3, 224, 224]) Loss 0.574161946773529\n",
      "Batch 60. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5699653625488281\n",
      "Batch 61. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5172871947288513\n",
      "Batch 62. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5229477286338806\n",
      "Batch 63. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5025272965431213\n",
      "Batch 64. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5652331709861755\n",
      "Batch 65. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5182722210884094\n",
      "Batch 66. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5380197167396545\n",
      "Batch 67. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5582026243209839\n",
      "Batch 68. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5297484397888184\n",
      "Batch 69. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5760657787322998\n",
      "Batch 70. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5307626724243164\n",
      "Batch 71. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5308742523193359\n",
      "Batch 72. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5015239119529724\n",
      "Batch 73. Data shape torch.Size([32, 3, 224, 224]) Loss 0.47347649931907654\n",
      "Batch 74. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5127089619636536\n",
      "Batch 75. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5393365621566772\n",
      "Batch 76. Data shape torch.Size([32, 3, 224, 224]) Loss 0.569414496421814\n",
      "Batch 77. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5234640836715698\n",
      "Batch 78. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5708433985710144\n",
      "Batch 79. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5265788435935974\n",
      "Batch 80. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5523367524147034\n",
      "Batch 81. Data shape torch.Size([32, 3, 224, 224]) Loss 0.49534136056900024\n",
      "Batch 82. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5173824429512024\n",
      "Batch 83. Data shape torch.Size([32, 3, 224, 224]) Loss 0.523215651512146\n",
      "Batch 84. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4751264452934265\n",
      "Batch 85. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5099048614501953\n",
      "Batch 86. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5465973615646362\n",
      "Batch 87. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5403775572776794\n",
      "Batch 88. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5958142876625061\n",
      "Batch 89. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5167021155357361\n",
      "Batch 90. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5150244235992432\n",
      "Batch 91. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5062475204467773\n",
      "Batch 92. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5553814768791199\n",
      "Batch 93. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6002985239028931\n",
      "Batch 94. Data shape torch.Size([32, 3, 224, 224]) Loss 0.49733224511146545\n",
      "Batch 95. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5448215007781982\n",
      "Batch 96. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5639174580574036\n",
      "Batch 97. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5733488202095032\n",
      "Batch 98. Data shape torch.Size([32, 3, 224, 224]) Loss 0.571085512638092\n",
      "Batch 99. Data shape torch.Size([32, 3, 224, 224]) Loss 0.49830323457717896\n",
      "Batch 100. Data shape torch.Size([32, 3, 224, 224]) Loss 0.559249758720398\n",
      "Batch 101. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6248393058776855\n",
      "Batch 102. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5057560205459595\n",
      "Batch 103. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6064830422401428\n",
      "Batch 104. Data shape torch.Size([32, 3, 224, 224]) Loss 0.577501118183136\n",
      "Batch 105. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5736390352249146\n",
      "Batch 106. Data shape torch.Size([32, 3, 224, 224]) Loss 0.524043083190918\n",
      "Batch 107. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5604972839355469\n",
      "Batch 108. Data shape torch.Size([32, 3, 224, 224]) Loss 0.563407838344574\n",
      "Batch 109. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5004802942276001\n",
      "Batch 110. Data shape torch.Size([32, 3, 224, 224]) Loss 0.46051737666130066\n",
      "Batch 111. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5897989869117737\n",
      "Batch 112. Data shape torch.Size([32, 3, 224, 224]) Loss 0.599572479724884\n",
      "Batch 113. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5092986226081848\n",
      "Batch 114. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5498833656311035\n",
      "Batch 115. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5602014660835266\n",
      "Batch 116. Data shape torch.Size([32, 3, 224, 224]) Loss 0.460038959980011\n",
      "Batch 117. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4777540862560272\n",
      "Batch 118. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5323920845985413\n",
      "Batch 119. Data shape torch.Size([20, 3, 224, 224]) Loss 0.49672603607177734\n",
      "Valid loss improved from 0.545723 to 0.542814. Saving model ...\n",
      "Epoch: 43/50 | time: 23.0m 9.942s | lr: 1.0000e-05 | train/loss: 0.55691 | val/loss: 0.54281 | val/accuracy: 0.78056 | val/AUC: 0.77969 | val/Kappa: 0.56028\n",
      "Epoch: 44 Train batch 10 loss: 0.5442586541175842, 2.1% complete\n",
      "Epoch: 44 Train batch 20 loss: 0.5753574371337891, 4.2% complete\n",
      "Epoch: 44 Train batch 30 loss: 0.5918959975242615, 6.3% complete\n",
      "Epoch: 44 Train batch 40 loss: 0.4844657778739929, 8.4% complete\n",
      "Epoch: 44 Train batch 50 loss: 0.5335321426391602, 10.5% complete\n",
      "Epoch: 44 Train batch 60 loss: 0.5756479501724243, 12.6% complete\n",
      "Epoch: 44 Train batch 70 loss: 0.628180980682373, 14.7% complete\n",
      "Epoch: 44 Train batch 80 loss: 0.5664356350898743, 16.8% complete\n",
      "Epoch: 44 Train batch 90 loss: 0.5362133383750916, 18.9% complete\n",
      "Epoch: 44 Train batch 100 loss: 0.5500319004058838, 21.1% complete\n",
      "Epoch: 44 Train batch 110 loss: 0.5283040404319763, 23.2% complete\n",
      "Epoch: 44 Train batch 120 loss: 0.6153202652931213, 25.3% complete\n",
      "Epoch: 44 Train batch 130 loss: 0.5901055335998535, 27.4% complete\n",
      "Epoch: 44 Train batch 140 loss: 0.5444015860557556, 29.5% complete\n",
      "Epoch: 44 Train batch 150 loss: 0.5363538861274719, 31.6% complete\n",
      "Epoch: 44 Train batch 160 loss: 0.4655182957649231, 33.7% complete\n",
      "Epoch: 44 Train batch 170 loss: 0.6758356690406799, 35.8% complete\n",
      "Epoch: 44 Train batch 180 loss: 0.5308119058609009, 37.9% complete\n",
      "Epoch: 44 Train batch 190 loss: 0.5166430473327637, 40.0% complete\n",
      "Epoch: 44 Train batch 200 loss: 0.5312941074371338, 42.1% complete\n",
      "Epoch: 44 Train batch 210 loss: 0.5766872763633728, 44.2% complete\n",
      "Epoch: 44 Train batch 220 loss: 0.6816274523735046, 46.3% complete\n",
      "Epoch: 44 Train batch 230 loss: 0.5755902528762817, 48.4% complete\n",
      "Epoch: 44 Train batch 240 loss: 0.5801883339881897, 50.5% complete\n",
      "Epoch: 44 Train batch 250 loss: 0.5650765895843506, 52.6% complete\n",
      "Epoch: 44 Train batch 260 loss: 0.48303595185279846, 54.7% complete\n",
      "Epoch: 44 Train batch 270 loss: 0.5223702788352966, 56.8% complete\n",
      "Epoch: 44 Train batch 280 loss: 0.590501606464386, 58.9% complete\n",
      "Epoch: 44 Train batch 290 loss: 0.4989285171031952, 61.1% complete\n",
      "Epoch: 44 Train batch 300 loss: 0.5057092905044556, 63.2% complete\n",
      "Epoch: 44 Train batch 310 loss: 0.5306311249732971, 65.3% complete\n",
      "Epoch: 44 Train batch 320 loss: 0.5169903635978699, 67.4% complete\n",
      "Epoch: 44 Train batch 330 loss: 0.5746373534202576, 69.5% complete\n",
      "Epoch: 44 Train batch 340 loss: 0.6991952061653137, 71.6% complete\n",
      "Epoch: 44 Train batch 350 loss: 0.5680409669876099, 73.7% complete\n",
      "Epoch: 44 Train batch 360 loss: 0.4895949065685272, 75.8% complete\n",
      "Epoch: 44 Train batch 370 loss: 0.5274884700775146, 77.9% complete\n",
      "Epoch: 44 Train batch 380 loss: 0.5007802844047546, 80.0% complete\n",
      "Epoch: 44 Train batch 390 loss: 0.5308100581169128, 82.1% complete\n",
      "Epoch: 44 Train batch 400 loss: 0.5859237909317017, 84.2% complete\n",
      "Epoch: 44 Train batch 410 loss: 0.4939006567001343, 86.3% complete\n",
      "Epoch: 44 Train batch 420 loss: 0.5464985370635986, 88.4% complete\n",
      "Epoch: 44 Train batch 430 loss: 0.6123663783073425, 90.5% complete\n",
      "Epoch: 44 Train batch 440 loss: 0.5324126482009888, 92.6% complete\n",
      "Epoch: 44 Train batch 450 loss: 0.5401758551597595, 94.7% complete\n",
      "Epoch: 44 Train batch 460 loss: 0.5938422083854675, 96.8% complete\n",
      "Epoch: 44 Train batch 470 loss: 0.5484137535095215, 98.9% complete\n",
      "Batch 1. Data shape torch.Size([32, 3, 224, 224]) Loss 0.595682680606842\n",
      "Batch 2. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5280124545097351\n",
      "Batch 3. Data shape torch.Size([32, 3, 224, 224]) Loss 0.501940906047821\n",
      "Batch 4. Data shape torch.Size([32, 3, 224, 224]) Loss 0.573207676410675\n",
      "Batch 5. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5291693806648254\n",
      "Batch 6. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5528861880302429\n",
      "Batch 7. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5714651346206665\n",
      "Batch 8. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5353591442108154\n",
      "Batch 9. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5199941992759705\n",
      "Batch 10. Data shape torch.Size([32, 3, 224, 224]) Loss 0.51789391040802\n",
      "Batch 11. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5165356993675232\n",
      "Batch 12. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5532308220863342\n",
      "Batch 13. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5416792035102844\n",
      "Batch 14. Data shape torch.Size([32, 3, 224, 224]) Loss 0.509047269821167\n",
      "Batch 15. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5996081233024597\n",
      "Batch 16. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5832620859146118\n",
      "Batch 17. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5628756284713745\n",
      "Batch 18. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5669243931770325\n",
      "Batch 19. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5092278122901917\n",
      "Batch 20. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4797983169555664\n",
      "Batch 21. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5731509327888489\n",
      "Batch 22. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5525793433189392\n",
      "Batch 23. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5733013153076172\n",
      "Batch 24. Data shape torch.Size([32, 3, 224, 224]) Loss 0.525876522064209\n",
      "Batch 25. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5534880757331848\n",
      "Batch 26. Data shape torch.Size([32, 3, 224, 224]) Loss 0.547868549823761\n",
      "Batch 27. Data shape torch.Size([32, 3, 224, 224]) Loss 0.48442965745925903\n",
      "Batch 28. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5185152888298035\n",
      "Batch 29. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5331758260726929\n",
      "Batch 30. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5547211766242981\n",
      "Batch 31. Data shape torch.Size([32, 3, 224, 224]) Loss 0.47112515568733215\n",
      "Batch 32. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5747606754302979\n",
      "Batch 33. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4925363063812256\n",
      "Batch 34. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5107210278511047\n",
      "Batch 35. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5501253008842468\n",
      "Batch 36. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5997825264930725\n",
      "Batch 37. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5788881778717041\n",
      "Batch 38. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5110141634941101\n",
      "Batch 39. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5683836340904236\n",
      "Batch 40. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5268151164054871\n",
      "Batch 41. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5458261370658875\n",
      "Batch 42. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5663009285926819\n",
      "Batch 43. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5254604816436768\n",
      "Batch 44. Data shape torch.Size([32, 3, 224, 224]) Loss 0.565760612487793\n",
      "Batch 45. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5912039279937744\n",
      "Batch 46. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5265762805938721\n",
      "Batch 47. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5104817748069763\n",
      "Batch 48. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5707724094390869\n",
      "Batch 49. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5668730735778809\n",
      "Batch 50. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5371756553649902\n",
      "Batch 51. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5093960762023926\n",
      "Batch 52. Data shape torch.Size([32, 3, 224, 224]) Loss 0.51528000831604\n",
      "Batch 53. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5239409804344177\n",
      "Batch 54. Data shape torch.Size([32, 3, 224, 224]) Loss 0.565318763256073\n",
      "Batch 55. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5000083446502686\n",
      "Batch 56. Data shape torch.Size([32, 3, 224, 224]) Loss 0.479322612285614\n",
      "Batch 57. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5336947441101074\n",
      "Batch 58. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5746201872825623\n",
      "Batch 59. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6589850187301636\n",
      "Batch 60. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5182608366012573\n",
      "Batch 61. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5828989148139954\n",
      "Batch 62. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5270308256149292\n",
      "Batch 63. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5037166476249695\n",
      "Batch 64. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5227328538894653\n",
      "Batch 65. Data shape torch.Size([32, 3, 224, 224]) Loss 0.49630579352378845\n",
      "Batch 66. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5535438656806946\n",
      "Batch 67. Data shape torch.Size([32, 3, 224, 224]) Loss 0.569036066532135\n",
      "Batch 68. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5573400259017944\n",
      "Batch 69. Data shape torch.Size([32, 3, 224, 224]) Loss 0.48284032940864563\n",
      "Batch 70. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5070340633392334\n",
      "Batch 71. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5838476419448853\n",
      "Batch 72. Data shape torch.Size([32, 3, 224, 224]) Loss 0.45161426067352295\n",
      "Batch 73. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5627119541168213\n",
      "Batch 74. Data shape torch.Size([32, 3, 224, 224]) Loss 0.579362690448761\n",
      "Batch 75. Data shape torch.Size([32, 3, 224, 224]) Loss 0.46581560373306274\n",
      "Batch 76. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5733892917633057\n",
      "Batch 77. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5551719665527344\n",
      "Batch 78. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5244763493537903\n",
      "Batch 79. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5674058198928833\n",
      "Batch 80. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5247098207473755\n",
      "Batch 81. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5510683059692383\n",
      "Batch 82. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5545058250427246\n",
      "Batch 83. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5463805794715881\n",
      "Batch 84. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5416744947433472\n",
      "Batch 85. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5800495743751526\n",
      "Batch 86. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5151572823524475\n",
      "Batch 87. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5988101959228516\n",
      "Batch 88. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5407670736312866\n",
      "Batch 89. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5481248497962952\n",
      "Batch 90. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5166299343109131\n",
      "Batch 91. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4428534209728241\n",
      "Batch 92. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5484746694564819\n",
      "Batch 93. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4977344572544098\n",
      "Batch 94. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5093829035758972\n",
      "Batch 95. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5643772482872009\n",
      "Batch 96. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5499671101570129\n",
      "Batch 97. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5424960851669312\n",
      "Batch 98. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5735733509063721\n",
      "Batch 99. Data shape torch.Size([32, 3, 224, 224]) Loss 0.508823573589325\n",
      "Batch 100. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5525357127189636\n",
      "Batch 101. Data shape torch.Size([32, 3, 224, 224]) Loss 0.567650318145752\n",
      "Batch 102. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5268099308013916\n",
      "Batch 103. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5352200269699097\n",
      "Batch 104. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6117051839828491\n",
      "Batch 105. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6491809487342834\n",
      "Batch 106. Data shape torch.Size([32, 3, 224, 224]) Loss 0.45460203289985657\n",
      "Batch 107. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4908917248249054\n",
      "Batch 108. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5531700849533081\n",
      "Batch 109. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4940158724784851\n",
      "Batch 110. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5143210887908936\n",
      "Batch 111. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4922736585140228\n",
      "Batch 112. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4656811058521271\n",
      "Batch 113. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5416215062141418\n",
      "Batch 114. Data shape torch.Size([32, 3, 224, 224]) Loss 0.49047958850860596\n",
      "Batch 115. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5564887523651123\n",
      "Batch 116. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5059981942176819\n",
      "Batch 117. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4583416283130646\n",
      "Batch 118. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5523287653923035\n",
      "Batch 119. Data shape torch.Size([20, 3, 224, 224]) Loss 0.5155568718910217\n",
      "Valid loss improved from 0.542814 to 0.537689. Saving model ...\n",
      "Epoch: 44/50 | time: 23.0m 22.65s | lr: 1.0000e-05 | train/loss: 0.55275 | val/loss: 0.53769 | val/accuracy: 0.78240 | val/AUC: 0.78153 | val/Kappa: 0.56397\n",
      "Epoch: 45 Train batch 10 loss: 0.5094375610351562, 2.1% complete\n",
      "Epoch: 45 Train batch 20 loss: 0.605758011341095, 4.2% complete\n",
      "Epoch: 45 Train batch 30 loss: 0.47027504444122314, 6.3% complete\n",
      "Epoch: 45 Train batch 40 loss: 0.5095967054367065, 8.4% complete\n",
      "Epoch: 45 Train batch 50 loss: 0.5155235528945923, 10.5% complete\n",
      "Epoch: 45 Train batch 60 loss: 0.5114262104034424, 12.6% complete\n",
      "Epoch: 45 Train batch 70 loss: 0.5447064638137817, 14.7% complete\n",
      "Epoch: 45 Train batch 80 loss: 0.5061920881271362, 16.8% complete\n",
      "Epoch: 45 Train batch 90 loss: 0.5866478681564331, 18.9% complete\n",
      "Epoch: 45 Train batch 100 loss: 0.5497236251831055, 21.1% complete\n",
      "Epoch: 45 Train batch 110 loss: 0.4972320795059204, 23.2% complete\n",
      "Epoch: 45 Train batch 120 loss: 0.4695611000061035, 25.3% complete\n",
      "Epoch: 45 Train batch 130 loss: 0.5986132621765137, 27.4% complete\n",
      "Epoch: 45 Train batch 140 loss: 0.5423843264579773, 29.5% complete\n",
      "Epoch: 45 Train batch 150 loss: 0.5298935770988464, 31.6% complete\n",
      "Epoch: 45 Train batch 160 loss: 0.5355772376060486, 33.7% complete\n",
      "Epoch: 45 Train batch 170 loss: 0.502132773399353, 35.8% complete\n",
      "Epoch: 45 Train batch 180 loss: 0.5560034513473511, 37.9% complete\n",
      "Epoch: 45 Train batch 190 loss: 0.5916574597358704, 40.0% complete\n",
      "Epoch: 45 Train batch 200 loss: 0.5905378460884094, 42.1% complete\n",
      "Epoch: 45 Train batch 210 loss: 0.5416250824928284, 44.2% complete\n",
      "Epoch: 45 Train batch 220 loss: 0.48200029134750366, 46.3% complete\n",
      "Epoch: 45 Train batch 230 loss: 0.5863096117973328, 48.4% complete\n",
      "Epoch: 45 Train batch 240 loss: 0.4997635781764984, 50.5% complete\n",
      "Epoch: 45 Train batch 250 loss: 0.5042423009872437, 52.6% complete\n",
      "Epoch: 45 Train batch 260 loss: 0.49858328700065613, 54.7% complete\n",
      "Epoch: 45 Train batch 270 loss: 0.5699177980422974, 56.8% complete\n",
      "Epoch: 45 Train batch 280 loss: 0.501008152961731, 58.9% complete\n",
      "Epoch: 45 Train batch 290 loss: 0.5263461470603943, 61.1% complete\n",
      "Epoch: 45 Train batch 300 loss: 0.5717024803161621, 63.2% complete\n",
      "Epoch: 45 Train batch 310 loss: 0.5173048973083496, 65.3% complete\n",
      "Epoch: 45 Train batch 320 loss: 0.5499382615089417, 67.4% complete\n",
      "Epoch: 45 Train batch 330 loss: 0.5723528265953064, 69.5% complete\n",
      "Epoch: 45 Train batch 340 loss: 0.6452168226242065, 71.6% complete\n",
      "Epoch: 45 Train batch 350 loss: 0.5863757729530334, 73.7% complete\n",
      "Epoch: 45 Train batch 360 loss: 0.5044633746147156, 75.8% complete\n",
      "Epoch: 45 Train batch 370 loss: 0.5338646173477173, 77.9% complete\n",
      "Epoch: 45 Train batch 380 loss: 0.5462163686752319, 80.0% complete\n",
      "Epoch: 45 Train batch 390 loss: 0.48421573638916016, 82.1% complete\n",
      "Epoch: 45 Train batch 400 loss: 0.5620999336242676, 84.2% complete\n",
      "Epoch: 45 Train batch 410 loss: 0.5859516263008118, 86.3% complete\n",
      "Epoch: 45 Train batch 420 loss: 0.5565099120140076, 88.4% complete\n",
      "Epoch: 45 Train batch 430 loss: 0.5447394847869873, 90.5% complete\n",
      "Epoch: 45 Train batch 440 loss: 0.5369687676429749, 92.6% complete\n",
      "Epoch: 45 Train batch 450 loss: 0.5287673473358154, 94.7% complete\n",
      "Epoch: 45 Train batch 460 loss: 0.49026262760162354, 96.8% complete\n",
      "Epoch: 45 Train batch 470 loss: 0.5857110023498535, 98.9% complete\n",
      "Batch 1. Data shape torch.Size([32, 3, 224, 224]) Loss 0.51123046875\n",
      "Batch 2. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5194755792617798\n",
      "Batch 3. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4965662658214569\n",
      "Batch 4. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4648421108722687\n",
      "Batch 5. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4884673058986664\n",
      "Batch 6. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5356314182281494\n",
      "Batch 7. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5803726315498352\n",
      "Batch 8. Data shape torch.Size([32, 3, 224, 224]) Loss 0.509771466255188\n",
      "Batch 9. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5006574988365173\n",
      "Batch 10. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5426134467124939\n",
      "Batch 11. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5575597882270813\n",
      "Batch 12. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5885277986526489\n",
      "Batch 13. Data shape torch.Size([32, 3, 224, 224]) Loss 0.49297472834587097\n",
      "Batch 14. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4612849950790405\n",
      "Batch 15. Data shape torch.Size([32, 3, 224, 224]) Loss 0.46438589692115784\n",
      "Batch 16. Data shape torch.Size([32, 3, 224, 224]) Loss 0.48204129934310913\n",
      "Batch 17. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4491037130355835\n",
      "Batch 18. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5039898157119751\n",
      "Batch 19. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5219359993934631\n",
      "Batch 20. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5700641870498657\n",
      "Batch 21. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5636582374572754\n",
      "Batch 22. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4790691137313843\n",
      "Batch 23. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5325175523757935\n",
      "Batch 24. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5433062314987183\n",
      "Batch 25. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6119251251220703\n",
      "Batch 26. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5077719688415527\n",
      "Batch 27. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4725906252861023\n",
      "Batch 28. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5487745404243469\n",
      "Batch 29. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5193317532539368\n",
      "Batch 30. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5241543054580688\n",
      "Batch 31. Data shape torch.Size([32, 3, 224, 224]) Loss 0.552992582321167\n",
      "Batch 32. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4048576056957245\n",
      "Batch 33. Data shape torch.Size([32, 3, 224, 224]) Loss 0.540880024433136\n",
      "Batch 34. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4973140358924866\n",
      "Batch 35. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6341439485549927\n",
      "Batch 36. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4825492799282074\n",
      "Batch 37. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5759477019309998\n",
      "Batch 38. Data shape torch.Size([32, 3, 224, 224]) Loss 0.531332790851593\n",
      "Batch 39. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4517742991447449\n",
      "Batch 40. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5231020450592041\n",
      "Batch 41. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6072720885276794\n",
      "Batch 42. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5159687995910645\n",
      "Batch 43. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5997092723846436\n",
      "Batch 44. Data shape torch.Size([32, 3, 224, 224]) Loss 0.547626793384552\n",
      "Batch 45. Data shape torch.Size([32, 3, 224, 224]) Loss 0.49991127848625183\n",
      "Batch 46. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5558922290802002\n",
      "Batch 47. Data shape torch.Size([32, 3, 224, 224]) Loss 0.49604278802871704\n",
      "Batch 48. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5445560216903687\n",
      "Batch 49. Data shape torch.Size([32, 3, 224, 224]) Loss 0.47101446986198425\n",
      "Batch 50. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5681574940681458\n",
      "Batch 51. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5230531692504883\n",
      "Batch 52. Data shape torch.Size([32, 3, 224, 224]) Loss 0.49090734124183655\n",
      "Batch 53. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5363791584968567\n",
      "Batch 54. Data shape torch.Size([32, 3, 224, 224]) Loss 0.47673606872558594\n",
      "Batch 55. Data shape torch.Size([32, 3, 224, 224]) Loss 0.593440055847168\n",
      "Batch 56. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5089401602745056\n",
      "Batch 57. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4830526113510132\n",
      "Batch 58. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5021414756774902\n",
      "Batch 59. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5075193643569946\n",
      "Batch 60. Data shape torch.Size([32, 3, 224, 224]) Loss 0.44391196966171265\n",
      "Batch 61. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5433496236801147\n",
      "Batch 62. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5363355875015259\n",
      "Batch 63. Data shape torch.Size([32, 3, 224, 224]) Loss 0.605134904384613\n",
      "Batch 64. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4997948408126831\n",
      "Batch 65. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6611150503158569\n",
      "Batch 66. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4494556486606598\n",
      "Batch 67. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6053728461265564\n",
      "Batch 68. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5150137543678284\n",
      "Batch 69. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5446727871894836\n",
      "Batch 70. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5305532813072205\n",
      "Batch 71. Data shape torch.Size([32, 3, 224, 224]) Loss 0.576323926448822\n",
      "Batch 72. Data shape torch.Size([32, 3, 224, 224]) Loss 0.43017667531967163\n",
      "Batch 73. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5334975719451904\n",
      "Batch 74. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5603184700012207\n",
      "Batch 75. Data shape torch.Size([32, 3, 224, 224]) Loss 0.516880452632904\n",
      "Batch 76. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5453536510467529\n",
      "Batch 77. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5777952671051025\n",
      "Batch 78. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5677365064620972\n",
      "Batch 79. Data shape torch.Size([32, 3, 224, 224]) Loss 0.47546982765197754\n",
      "Batch 80. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5005612969398499\n",
      "Batch 81. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5340259075164795\n",
      "Batch 82. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6056954860687256\n",
      "Batch 83. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5641433596611023\n",
      "Batch 84. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5107606649398804\n",
      "Batch 85. Data shape torch.Size([32, 3, 224, 224]) Loss 0.549973726272583\n",
      "Batch 86. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5985741019248962\n",
      "Batch 87. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5513764023780823\n",
      "Batch 88. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5335453748703003\n",
      "Batch 89. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5068498253822327\n",
      "Batch 90. Data shape torch.Size([32, 3, 224, 224]) Loss 0.49705076217651367\n",
      "Batch 91. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6070734262466431\n",
      "Batch 92. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6112402677536011\n",
      "Batch 93. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5365901589393616\n",
      "Batch 94. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5586095452308655\n",
      "Batch 95. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5834434032440186\n",
      "Batch 96. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5088728666305542\n",
      "Batch 97. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5300554633140564\n",
      "Batch 98. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5288757085800171\n",
      "Batch 99. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4466123580932617\n",
      "Batch 100. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5465239882469177\n",
      "Batch 101. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5404866933822632\n",
      "Batch 102. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5275510549545288\n",
      "Batch 103. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6313602328300476\n",
      "Batch 104. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4910587668418884\n",
      "Batch 105. Data shape torch.Size([32, 3, 224, 224]) Loss 0.589963436126709\n",
      "Batch 106. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4731484353542328\n",
      "Batch 107. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5595946311950684\n",
      "Batch 108. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5601449012756348\n",
      "Batch 109. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5630534291267395\n",
      "Batch 110. Data shape torch.Size([32, 3, 224, 224]) Loss 0.532056987285614\n",
      "Batch 111. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5300314426422119\n",
      "Batch 112. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5002672076225281\n",
      "Batch 113. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4986603558063507\n",
      "Batch 114. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5535244941711426\n",
      "Batch 115. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5591346025466919\n",
      "Batch 116. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5309326648712158\n",
      "Batch 117. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5631882548332214\n",
      "Batch 118. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4764750599861145\n",
      "Batch 119. Data shape torch.Size([20, 3, 224, 224]) Loss 0.5329269766807556\n",
      "Valid loss improved from 0.537689 to 0.530337. Saving model ...\n",
      "Epoch: 45/50 | time: 26.0m 37.31s | lr: 1.0000e-05 | train/loss: 0.54970 | val/loss: 0.53034 | val/accuracy: 0.77950 | val/AUC: 0.77911 | val/Kappa: 0.55859\n",
      "Epoch: 46 Train batch 10 loss: 0.5544986724853516, 2.1% complete\n",
      "Epoch: 46 Train batch 20 loss: 0.5218168497085571, 4.2% complete\n",
      "Epoch: 46 Train batch 30 loss: 0.5284562110900879, 6.3% complete\n",
      "Epoch: 46 Train batch 40 loss: 0.5743823647499084, 8.4% complete\n",
      "Epoch: 46 Train batch 50 loss: 0.5077705979347229, 10.5% complete\n",
      "Epoch: 46 Train batch 60 loss: 0.5268855094909668, 12.6% complete\n",
      "Epoch: 46 Train batch 70 loss: 0.5365331768989563, 14.7% complete\n",
      "Epoch: 46 Train batch 80 loss: 0.5704811215400696, 16.8% complete\n",
      "Epoch: 46 Train batch 90 loss: 0.524394154548645, 18.9% complete\n",
      "Epoch: 46 Train batch 100 loss: 0.4898543357849121, 21.1% complete\n",
      "Epoch: 46 Train batch 110 loss: 0.5227468609809875, 23.2% complete\n",
      "Epoch: 46 Train batch 120 loss: 0.572247326374054, 25.3% complete\n",
      "Epoch: 46 Train batch 130 loss: 0.6026979088783264, 27.4% complete\n",
      "Epoch: 46 Train batch 140 loss: 0.6267476081848145, 29.5% complete\n",
      "Epoch: 46 Train batch 150 loss: 0.5053966045379639, 31.6% complete\n",
      "Epoch: 46 Train batch 160 loss: 0.5103588700294495, 33.7% complete\n",
      "Epoch: 46 Train batch 170 loss: 0.5783175230026245, 35.8% complete\n",
      "Epoch: 46 Train batch 180 loss: 0.48954108357429504, 37.9% complete\n",
      "Epoch: 46 Train batch 190 loss: 0.4865710139274597, 40.0% complete\n",
      "Epoch: 46 Train batch 200 loss: 0.6036964058876038, 42.1% complete\n",
      "Epoch: 46 Train batch 210 loss: 0.5613900423049927, 44.2% complete\n",
      "Epoch: 46 Train batch 220 loss: 0.5456306338310242, 46.3% complete\n",
      "Epoch: 46 Train batch 230 loss: 0.5887048244476318, 48.4% complete\n",
      "Epoch: 46 Train batch 240 loss: 0.5376748442649841, 50.5% complete\n",
      "Epoch: 46 Train batch 250 loss: 0.639120876789093, 52.6% complete\n",
      "Epoch: 46 Train batch 260 loss: 0.5321926474571228, 54.7% complete\n",
      "Epoch: 46 Train batch 270 loss: 0.5875731706619263, 56.8% complete\n",
      "Epoch: 46 Train batch 280 loss: 0.5885955095291138, 58.9% complete\n",
      "Epoch: 46 Train batch 290 loss: 0.535796046257019, 61.1% complete\n",
      "Epoch: 46 Train batch 300 loss: 0.4957781434059143, 63.2% complete\n",
      "Epoch: 46 Train batch 310 loss: 0.5859191417694092, 65.3% complete\n",
      "Epoch: 46 Train batch 320 loss: 0.5939871668815613, 67.4% complete\n",
      "Epoch: 46 Train batch 330 loss: 0.6021374464035034, 69.5% complete\n",
      "Epoch: 46 Train batch 340 loss: 0.543386697769165, 71.6% complete\n",
      "Epoch: 46 Train batch 350 loss: 0.5096480250358582, 73.7% complete\n",
      "Epoch: 46 Train batch 360 loss: 0.5988346338272095, 75.8% complete\n",
      "Epoch: 46 Train batch 370 loss: 0.49433258175849915, 77.9% complete\n",
      "Epoch: 46 Train batch 380 loss: 0.5454137921333313, 80.0% complete\n",
      "Epoch: 46 Train batch 390 loss: 0.5903962254524231, 82.1% complete\n",
      "Epoch: 46 Train batch 400 loss: 0.5572841763496399, 84.2% complete\n",
      "Epoch: 46 Train batch 410 loss: 0.5459169745445251, 86.3% complete\n",
      "Epoch: 46 Train batch 420 loss: 0.5491765141487122, 88.4% complete\n",
      "Epoch: 46 Train batch 430 loss: 0.4657589793205261, 90.5% complete\n",
      "Epoch: 46 Train batch 440 loss: 0.5395248532295227, 92.6% complete\n",
      "Epoch: 46 Train batch 450 loss: 0.5023751258850098, 94.7% complete\n",
      "Epoch: 46 Train batch 460 loss: 0.629216194152832, 96.8% complete\n",
      "Epoch: 46 Train batch 470 loss: 0.548772394657135, 98.9% complete\n",
      "Batch 1. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5239297747612\n",
      "Batch 2. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5628489851951599\n",
      "Batch 3. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5557550191879272\n",
      "Batch 4. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5947319865226746\n",
      "Batch 5. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5321636199951172\n",
      "Batch 6. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5169445276260376\n",
      "Batch 7. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5074528455734253\n",
      "Batch 8. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5225832462310791\n",
      "Batch 9. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5034412741661072\n",
      "Batch 10. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5449551343917847\n",
      "Batch 11. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5259045362472534\n",
      "Batch 12. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4830535352230072\n",
      "Batch 13. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5194976329803467\n",
      "Batch 14. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5254778861999512\n",
      "Batch 15. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4824979305267334\n",
      "Batch 16. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5542726516723633\n",
      "Batch 17. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5361272096633911\n",
      "Batch 18. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5214970707893372\n",
      "Batch 19. Data shape torch.Size([32, 3, 224, 224]) Loss 0.43618136644363403\n",
      "Batch 20. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5272295475006104\n",
      "Batch 21. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5785863995552063\n",
      "Batch 22. Data shape torch.Size([32, 3, 224, 224]) Loss 0.502226710319519\n",
      "Batch 23. Data shape torch.Size([32, 3, 224, 224]) Loss 0.45339593291282654\n",
      "Batch 24. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5750986337661743\n",
      "Batch 25. Data shape torch.Size([32, 3, 224, 224]) Loss 0.516006588935852\n",
      "Batch 26. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5974807143211365\n",
      "Batch 27. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4906785786151886\n",
      "Batch 28. Data shape torch.Size([32, 3, 224, 224]) Loss 0.47341856360435486\n",
      "Batch 29. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4145663380622864\n",
      "Batch 30. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6069537401199341\n",
      "Batch 31. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5566666722297668\n",
      "Batch 32. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5180673003196716\n",
      "Batch 33. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4999595582485199\n",
      "Batch 34. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5467075705528259\n",
      "Batch 35. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4610104560852051\n",
      "Batch 36. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6070971488952637\n",
      "Batch 37. Data shape torch.Size([32, 3, 224, 224]) Loss 0.558294415473938\n",
      "Batch 38. Data shape torch.Size([32, 3, 224, 224]) Loss 0.48465287685394287\n",
      "Batch 39. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5327942371368408\n",
      "Batch 40. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5446869730949402\n",
      "Batch 41. Data shape torch.Size([32, 3, 224, 224]) Loss 0.46563655138015747\n",
      "Batch 42. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5409945845603943\n",
      "Batch 43. Data shape torch.Size([32, 3, 224, 224]) Loss 0.47611290216445923\n",
      "Batch 44. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5195212960243225\n",
      "Batch 45. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5451781749725342\n",
      "Batch 46. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5316674113273621\n",
      "Batch 47. Data shape torch.Size([32, 3, 224, 224]) Loss 0.49310025572776794\n",
      "Batch 48. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4578864872455597\n",
      "Batch 49. Data shape torch.Size([32, 3, 224, 224]) Loss 0.48993006348609924\n",
      "Batch 50. Data shape torch.Size([32, 3, 224, 224]) Loss 0.585252583026886\n",
      "Batch 51. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5334459543228149\n",
      "Batch 52. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5068251490592957\n",
      "Batch 53. Data shape torch.Size([32, 3, 224, 224]) Loss 0.49659717082977295\n",
      "Batch 54. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4555260241031647\n",
      "Batch 55. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4866621494293213\n",
      "Batch 56. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5100981593132019\n",
      "Batch 57. Data shape torch.Size([32, 3, 224, 224]) Loss 0.496501624584198\n",
      "Batch 58. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4966016411781311\n",
      "Batch 59. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4616861641407013\n",
      "Batch 60. Data shape torch.Size([32, 3, 224, 224]) Loss 0.47426992654800415\n",
      "Batch 61. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5229477882385254\n",
      "Batch 62. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5668289065361023\n",
      "Batch 63. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5333860516548157\n",
      "Batch 64. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4891965389251709\n",
      "Batch 65. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5214346647262573\n",
      "Batch 66. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5761563777923584\n",
      "Batch 67. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5390344262123108\n",
      "Batch 68. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5109785795211792\n",
      "Batch 69. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5463829636573792\n",
      "Batch 70. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5208842158317566\n",
      "Batch 71. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5040221810340881\n",
      "Batch 72. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6047558188438416\n",
      "Batch 73. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5223727226257324\n",
      "Batch 74. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5871181488037109\n",
      "Batch 75. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5849727392196655\n",
      "Batch 76. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5219582319259644\n",
      "Batch 77. Data shape torch.Size([32, 3, 224, 224]) Loss 0.586859405040741\n",
      "Batch 78. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4905547499656677\n",
      "Batch 79. Data shape torch.Size([32, 3, 224, 224]) Loss 0.45583611726760864\n",
      "Batch 80. Data shape torch.Size([32, 3, 224, 224]) Loss 0.45413506031036377\n",
      "Batch 81. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5118335485458374\n",
      "Batch 82. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4573931396007538\n",
      "Batch 83. Data shape torch.Size([32, 3, 224, 224]) Loss 0.557411789894104\n",
      "Batch 84. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5650952458381653\n",
      "Batch 85. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5487433671951294\n",
      "Batch 86. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4771873652935028\n",
      "Batch 87. Data shape torch.Size([32, 3, 224, 224]) Loss 0.530745804309845\n",
      "Batch 88. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5361926555633545\n",
      "Batch 89. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5373998880386353\n",
      "Batch 90. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5467392802238464\n",
      "Batch 91. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4705132246017456\n",
      "Batch 92. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5653841495513916\n",
      "Batch 93. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5421624183654785\n",
      "Batch 94. Data shape torch.Size([32, 3, 224, 224]) Loss 0.579770565032959\n",
      "Batch 95. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5098680853843689\n",
      "Batch 96. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5031564831733704\n",
      "Batch 97. Data shape torch.Size([32, 3, 224, 224]) Loss 0.601360559463501\n",
      "Batch 98. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5110817551612854\n",
      "Batch 99. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5691437721252441\n",
      "Batch 100. Data shape torch.Size([32, 3, 224, 224]) Loss 0.522555947303772\n",
      "Batch 101. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5179144740104675\n",
      "Batch 102. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6388662457466125\n",
      "Batch 103. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5580840110778809\n",
      "Batch 104. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4366801381111145\n",
      "Batch 105. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5490497946739197\n",
      "Batch 106. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5745832920074463\n",
      "Batch 107. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5382859706878662\n",
      "Batch 108. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5378271341323853\n",
      "Batch 109. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5496702790260315\n",
      "Batch 110. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5498193502426147\n",
      "Batch 111. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5191841721534729\n",
      "Batch 112. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5919506549835205\n",
      "Batch 113. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6107929348945618\n",
      "Batch 114. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5416985750198364\n",
      "Batch 115. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5822988748550415\n",
      "Batch 116. Data shape torch.Size([32, 3, 224, 224]) Loss 0.47083279490470886\n",
      "Batch 117. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5770972371101379\n",
      "Batch 118. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5411878824234009\n",
      "Batch 119. Data shape torch.Size([20, 3, 224, 224]) Loss 0.5313599109649658\n",
      "Valid loss improved from 0.530337 to 0.527051. Saving model ...\n",
      "Epoch: 46/50 | time: 23.0m 12.69s | lr: 1.0000e-05 | train/loss: 0.54483 | val/loss: 0.52705 | val/accuracy: 0.78267 | val/AUC: 0.78177 | val/Kappa: 0.56448\n",
      "Epoch: 47 Train batch 10 loss: 0.5412002801895142, 2.1% complete\n",
      "Epoch: 47 Train batch 20 loss: 0.48326340317726135, 4.2% complete\n",
      "Epoch: 47 Train batch 30 loss: 0.5198550820350647, 6.3% complete\n",
      "Epoch: 47 Train batch 40 loss: 0.5346153974533081, 8.4% complete\n",
      "Epoch: 47 Train batch 50 loss: 0.5483880639076233, 10.5% complete\n",
      "Epoch: 47 Train batch 60 loss: 0.4712841510772705, 12.6% complete\n",
      "Epoch: 47 Train batch 70 loss: 0.5797226428985596, 14.7% complete\n",
      "Epoch: 47 Train batch 80 loss: 0.502538800239563, 16.8% complete\n",
      "Epoch: 47 Train batch 90 loss: 0.5178276300430298, 18.9% complete\n",
      "Epoch: 47 Train batch 100 loss: 0.4665306806564331, 21.1% complete\n",
      "Epoch: 47 Train batch 110 loss: 0.5806496739387512, 23.2% complete\n",
      "Epoch: 47 Train batch 120 loss: 0.5219966173171997, 25.3% complete\n",
      "Epoch: 47 Train batch 130 loss: 0.48595476150512695, 27.4% complete\n",
      "Epoch: 47 Train batch 140 loss: 0.6217917203903198, 29.5% complete\n",
      "Epoch: 47 Train batch 150 loss: 0.6050944328308105, 31.6% complete\n",
      "Epoch: 47 Train batch 160 loss: 0.5367028713226318, 33.7% complete\n",
      "Epoch: 47 Train batch 170 loss: 0.4977104067802429, 35.8% complete\n",
      "Epoch: 47 Train batch 180 loss: 0.5313623547554016, 37.9% complete\n",
      "Epoch: 47 Train batch 190 loss: 0.5104511976242065, 40.0% complete\n",
      "Epoch: 47 Train batch 200 loss: 0.484161913394928, 42.1% complete\n",
      "Epoch: 47 Train batch 210 loss: 0.5887792706489563, 44.2% complete\n",
      "Epoch: 47 Train batch 220 loss: 0.4352671504020691, 46.3% complete\n",
      "Epoch: 47 Train batch 230 loss: 0.5612733364105225, 48.4% complete\n",
      "Epoch: 47 Train batch 240 loss: 0.5747971534729004, 50.5% complete\n",
      "Epoch: 47 Train batch 250 loss: 0.4855874478816986, 52.6% complete\n",
      "Epoch: 47 Train batch 260 loss: 0.5658519268035889, 54.7% complete\n",
      "Epoch: 47 Train batch 270 loss: 0.6041573882102966, 56.8% complete\n",
      "Epoch: 47 Train batch 280 loss: 0.511596143245697, 58.9% complete\n",
      "Epoch: 47 Train batch 290 loss: 0.4627838432788849, 61.1% complete\n",
      "Epoch: 47 Train batch 300 loss: 0.49420565366744995, 63.2% complete\n",
      "Epoch: 47 Train batch 310 loss: 0.5594800710678101, 65.3% complete\n",
      "Epoch: 47 Train batch 320 loss: 0.5697323679924011, 67.4% complete\n",
      "Epoch: 47 Train batch 330 loss: 0.48077964782714844, 69.5% complete\n",
      "Epoch: 47 Train batch 340 loss: 0.5522353053092957, 71.6% complete\n",
      "Epoch: 47 Train batch 350 loss: 0.5223495364189148, 73.7% complete\n",
      "Epoch: 47 Train batch 360 loss: 0.5131785273551941, 75.8% complete\n",
      "Epoch: 47 Train batch 370 loss: 0.5529977679252625, 77.9% complete\n",
      "Epoch: 47 Train batch 380 loss: 0.5275025963783264, 80.0% complete\n",
      "Epoch: 47 Train batch 390 loss: 0.553950846195221, 82.1% complete\n",
      "Epoch: 47 Train batch 400 loss: 0.5154775381088257, 84.2% complete\n",
      "Epoch: 47 Train batch 410 loss: 0.48449790477752686, 86.3% complete\n",
      "Epoch: 47 Train batch 420 loss: 0.5458092093467712, 88.4% complete\n",
      "Epoch: 47 Train batch 430 loss: 0.5759207606315613, 90.5% complete\n",
      "Epoch: 47 Train batch 440 loss: 0.601495087146759, 92.6% complete\n",
      "Epoch: 47 Train batch 450 loss: 0.5221559405326843, 94.7% complete\n",
      "Epoch: 47 Train batch 460 loss: 0.5635697245597839, 96.8% complete\n",
      "Epoch: 47 Train batch 470 loss: 0.5437492728233337, 98.9% complete\n",
      "Batch 1. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5281476974487305\n",
      "Batch 2. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5606516599655151\n",
      "Batch 3. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5696358680725098\n",
      "Batch 4. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5198728442192078\n",
      "Batch 5. Data shape torch.Size([32, 3, 224, 224]) Loss 0.516167938709259\n",
      "Batch 6. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5744178295135498\n",
      "Batch 7. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5606172680854797\n",
      "Batch 8. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6271488070487976\n",
      "Batch 9. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4573061466217041\n",
      "Batch 10. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5217229723930359\n",
      "Batch 11. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5482183694839478\n",
      "Batch 12. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4754849672317505\n",
      "Batch 13. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5975906848907471\n",
      "Batch 14. Data shape torch.Size([32, 3, 224, 224]) Loss 0.502494752407074\n",
      "Batch 15. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5327624082565308\n",
      "Batch 16. Data shape torch.Size([32, 3, 224, 224]) Loss 0.574808657169342\n",
      "Batch 17. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5308012366294861\n",
      "Batch 18. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5048142075538635\n",
      "Batch 19. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4667728543281555\n",
      "Batch 20. Data shape torch.Size([32, 3, 224, 224]) Loss 0.594953715801239\n",
      "Batch 21. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5228540897369385\n",
      "Batch 22. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5118604898452759\n",
      "Batch 23. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5611253976821899\n",
      "Batch 24. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4937695860862732\n",
      "Batch 25. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5103558897972107\n",
      "Batch 26. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5088810920715332\n",
      "Batch 27. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4799250364303589\n",
      "Batch 28. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5090154409408569\n",
      "Batch 29. Data shape torch.Size([32, 3, 224, 224]) Loss 0.48408618569374084\n",
      "Batch 30. Data shape torch.Size([32, 3, 224, 224]) Loss 0.49972057342529297\n",
      "Batch 31. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5021816492080688\n",
      "Batch 32. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5336848497390747\n",
      "Batch 33. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5036147236824036\n",
      "Batch 34. Data shape torch.Size([32, 3, 224, 224]) Loss 0.576095461845398\n",
      "Batch 35. Data shape torch.Size([32, 3, 224, 224]) Loss 0.46956193447113037\n",
      "Batch 36. Data shape torch.Size([32, 3, 224, 224]) Loss 0.47766372561454773\n",
      "Batch 37. Data shape torch.Size([32, 3, 224, 224]) Loss 0.46959009766578674\n",
      "Batch 38. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5288683176040649\n",
      "Batch 39. Data shape torch.Size([32, 3, 224, 224]) Loss 0.564969539642334\n",
      "Batch 40. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5161324739456177\n",
      "Batch 41. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5281403660774231\n",
      "Batch 42. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4630783498287201\n",
      "Batch 43. Data shape torch.Size([32, 3, 224, 224]) Loss 0.45325297117233276\n",
      "Batch 44. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5640003085136414\n",
      "Batch 45. Data shape torch.Size([32, 3, 224, 224]) Loss 0.48502257466316223\n",
      "Batch 46. Data shape torch.Size([32, 3, 224, 224]) Loss 0.43517711758613586\n",
      "Batch 47. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5028653144836426\n",
      "Batch 48. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5569918751716614\n",
      "Batch 49. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5455312728881836\n",
      "Batch 50. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5964394211769104\n",
      "Batch 51. Data shape torch.Size([32, 3, 224, 224]) Loss 0.41803693771362305\n",
      "Batch 52. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5512822270393372\n",
      "Batch 53. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4584450423717499\n",
      "Batch 54. Data shape torch.Size([32, 3, 224, 224]) Loss 0.521045982837677\n",
      "Batch 55. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4887530505657196\n",
      "Batch 56. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5091069936752319\n",
      "Batch 57. Data shape torch.Size([32, 3, 224, 224]) Loss 0.41970333456993103\n",
      "Batch 58. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5264725685119629\n",
      "Batch 59. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5372555255889893\n",
      "Batch 60. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5251138210296631\n",
      "Batch 61. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5220969319343567\n",
      "Batch 62. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4576132595539093\n",
      "Batch 63. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5643777251243591\n",
      "Batch 64. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4392251670360565\n",
      "Batch 65. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5709635615348816\n",
      "Batch 66. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5226602554321289\n",
      "Batch 67. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5337108969688416\n",
      "Batch 68. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5395959615707397\n",
      "Batch 69. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5142675042152405\n",
      "Batch 70. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5378336906433105\n",
      "Batch 71. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5263084769248962\n",
      "Batch 72. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5407713055610657\n",
      "Batch 73. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5221636891365051\n",
      "Batch 74. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5762163400650024\n",
      "Batch 75. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4359792172908783\n",
      "Batch 76. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5561772584915161\n",
      "Batch 77. Data shape torch.Size([32, 3, 224, 224]) Loss 0.511931300163269\n",
      "Batch 78. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4414212107658386\n",
      "Batch 79. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5347127914428711\n",
      "Batch 80. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5223463177680969\n",
      "Batch 81. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5629115700721741\n",
      "Batch 82. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4738938808441162\n",
      "Batch 83. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4907696545124054\n",
      "Batch 84. Data shape torch.Size([32, 3, 224, 224]) Loss 0.569017767906189\n",
      "Batch 85. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5286126136779785\n",
      "Batch 86. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4361742436885834\n",
      "Batch 87. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5236899256706238\n",
      "Batch 88. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5381724834442139\n",
      "Batch 89. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5142031908035278\n",
      "Batch 90. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5265170335769653\n",
      "Batch 91. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4595535695552826\n",
      "Batch 92. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5357083678245544\n",
      "Batch 93. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5092357993125916\n",
      "Batch 94. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5505853295326233\n",
      "Batch 95. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5544966459274292\n",
      "Batch 96. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5969406962394714\n",
      "Batch 97. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4927537143230438\n",
      "Batch 98. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5125598311424255\n",
      "Batch 99. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5865859389305115\n",
      "Batch 100. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5888291001319885\n",
      "Batch 101. Data shape torch.Size([32, 3, 224, 224]) Loss 0.45449283719062805\n",
      "Batch 102. Data shape torch.Size([32, 3, 224, 224]) Loss 0.48641422390937805\n",
      "Batch 103. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5149275660514832\n",
      "Batch 104. Data shape torch.Size([32, 3, 224, 224]) Loss 0.504839301109314\n",
      "Batch 105. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5565230250358582\n",
      "Batch 106. Data shape torch.Size([32, 3, 224, 224]) Loss 0.44402652978897095\n",
      "Batch 107. Data shape torch.Size([32, 3, 224, 224]) Loss 0.49162909388542175\n",
      "Batch 108. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4766511917114258\n",
      "Batch 109. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4926985502243042\n",
      "Batch 110. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5319814085960388\n",
      "Batch 111. Data shape torch.Size([32, 3, 224, 224]) Loss 0.45109158754348755\n",
      "Batch 112. Data shape torch.Size([32, 3, 224, 224]) Loss 0.56779944896698\n",
      "Batch 113. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5198565721511841\n",
      "Batch 114. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5275269746780396\n",
      "Batch 115. Data shape torch.Size([32, 3, 224, 224]) Loss 0.553169846534729\n",
      "Batch 116. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5465281009674072\n",
      "Batch 117. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5570536851882935\n",
      "Batch 118. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5977003574371338\n",
      "Batch 119. Data shape torch.Size([20, 3, 224, 224]) Loss 0.5724197626113892\n",
      "Valid loss improved from 0.527051 to 0.519689. Saving model ...\n",
      "Epoch: 47/50 | time: 23.0m 2.299s | lr: 1.0000e-05 | train/loss: 0.53952 | val/loss: 0.51969 | val/accuracy: 0.78530 | val/AUC: 0.78460 | val/Kappa: 0.56992\n",
      "Epoch: 48 Train batch 10 loss: 0.5090075135231018, 2.1% complete\n",
      "Epoch: 48 Train batch 20 loss: 0.5255643129348755, 4.2% complete\n",
      "Epoch: 48 Train batch 30 loss: 0.4995766878128052, 6.3% complete\n",
      "Epoch: 48 Train batch 40 loss: 0.6077708601951599, 8.4% complete\n",
      "Epoch: 48 Train batch 50 loss: 0.5092103481292725, 10.5% complete\n",
      "Epoch: 48 Train batch 60 loss: 0.5537666082382202, 12.6% complete\n",
      "Epoch: 48 Train batch 70 loss: 0.4760701060295105, 14.7% complete\n",
      "Epoch: 48 Train batch 80 loss: 0.6109946370124817, 16.8% complete\n",
      "Epoch: 48 Train batch 90 loss: 0.559729278087616, 18.9% complete\n",
      "Epoch: 48 Train batch 100 loss: 0.47802767157554626, 21.1% complete\n",
      "Epoch: 48 Train batch 110 loss: 0.5464010238647461, 23.2% complete\n",
      "Epoch: 48 Train batch 120 loss: 0.5451211333274841, 25.3% complete\n",
      "Epoch: 48 Train batch 130 loss: 0.5673052668571472, 27.4% complete\n",
      "Epoch: 48 Train batch 140 loss: 0.5142908692359924, 29.5% complete\n",
      "Epoch: 48 Train batch 150 loss: 0.5041214227676392, 31.6% complete\n",
      "Epoch: 48 Train batch 160 loss: 0.48165246844291687, 33.7% complete\n",
      "Epoch: 48 Train batch 170 loss: 0.6880967617034912, 35.8% complete\n",
      "Epoch: 48 Train batch 180 loss: 0.5619630813598633, 37.9% complete\n",
      "Epoch: 48 Train batch 190 loss: 0.5019574761390686, 40.0% complete\n",
      "Epoch: 48 Train batch 200 loss: 0.48329243063926697, 42.1% complete\n",
      "Epoch: 48 Train batch 210 loss: 0.5657674074172974, 44.2% complete\n",
      "Epoch: 48 Train batch 220 loss: 0.4794127941131592, 46.3% complete\n",
      "Epoch: 48 Train batch 230 loss: 0.5500785112380981, 48.4% complete\n",
      "Epoch: 48 Train batch 240 loss: 0.47839292883872986, 50.5% complete\n",
      "Epoch: 48 Train batch 250 loss: 0.5026774406433105, 52.6% complete\n",
      "Epoch: 48 Train batch 260 loss: 0.5426636934280396, 54.7% complete\n",
      "Epoch: 48 Train batch 270 loss: 0.5595247149467468, 56.8% complete\n",
      "Epoch: 48 Train batch 280 loss: 0.5108392238616943, 58.9% complete\n",
      "Epoch: 48 Train batch 290 loss: 0.5549373030662537, 61.1% complete\n",
      "Epoch: 48 Train batch 300 loss: 0.5533833503723145, 63.2% complete\n",
      "Epoch: 48 Train batch 310 loss: 0.594943642616272, 65.3% complete\n",
      "Epoch: 48 Train batch 320 loss: 0.4934171736240387, 67.4% complete\n",
      "Epoch: 48 Train batch 330 loss: 0.5081080794334412, 69.5% complete\n",
      "Epoch: 48 Train batch 340 loss: 0.5868975520133972, 71.6% complete\n",
      "Epoch: 48 Train batch 350 loss: 0.578344464302063, 73.7% complete\n",
      "Epoch: 48 Train batch 360 loss: 0.5049285292625427, 75.8% complete\n",
      "Epoch: 48 Train batch 370 loss: 0.5980177521705627, 77.9% complete\n",
      "Epoch: 48 Train batch 380 loss: 0.4248500168323517, 80.0% complete\n",
      "Epoch: 48 Train batch 390 loss: 0.5210952162742615, 82.1% complete\n",
      "Epoch: 48 Train batch 400 loss: 0.5448215007781982, 84.2% complete\n",
      "Epoch: 48 Train batch 410 loss: 0.511188805103302, 86.3% complete\n",
      "Epoch: 48 Train batch 420 loss: 0.5578334927558899, 88.4% complete\n",
      "Epoch: 48 Train batch 430 loss: 0.4727044999599457, 90.5% complete\n",
      "Epoch: 48 Train batch 440 loss: 0.4804825782775879, 92.6% complete\n",
      "Epoch: 48 Train batch 450 loss: 0.47973284125328064, 94.7% complete\n",
      "Epoch: 48 Train batch 460 loss: 0.4762662351131439, 96.8% complete\n",
      "Epoch: 48 Train batch 470 loss: 0.5599701404571533, 98.9% complete\n",
      "Batch 1. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5157767534255981\n",
      "Batch 2. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5749139189720154\n",
      "Batch 3. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5586580634117126\n",
      "Batch 4. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4955752491950989\n",
      "Batch 5. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5156861543655396\n",
      "Batch 6. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4957932233810425\n",
      "Batch 7. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5219289660453796\n",
      "Batch 8. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4784722328186035\n",
      "Batch 9. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5647804737091064\n",
      "Batch 10. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5376774668693542\n",
      "Batch 11. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5692965984344482\n",
      "Batch 12. Data shape torch.Size([32, 3, 224, 224]) Loss 0.532504677772522\n",
      "Batch 13. Data shape torch.Size([32, 3, 224, 224]) Loss 0.49872928857803345\n",
      "Batch 14. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5018977522850037\n",
      "Batch 15. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5146145224571228\n",
      "Batch 16. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5519969463348389\n",
      "Batch 17. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4973517954349518\n",
      "Batch 18. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5180225372314453\n",
      "Batch 19. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6022008657455444\n",
      "Batch 20. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6183185577392578\n",
      "Batch 21. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5124555230140686\n",
      "Batch 22. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5722531676292419\n",
      "Batch 23. Data shape torch.Size([32, 3, 224, 224]) Loss 0.47054073214530945\n",
      "Batch 24. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5808860063552856\n",
      "Batch 25. Data shape torch.Size([32, 3, 224, 224]) Loss 0.49048545956611633\n",
      "Batch 26. Data shape torch.Size([32, 3, 224, 224]) Loss 0.591606080532074\n",
      "Batch 27. Data shape torch.Size([32, 3, 224, 224]) Loss 0.48097336292266846\n",
      "Batch 28. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4708576798439026\n",
      "Batch 29. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5026062726974487\n",
      "Batch 30. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5543882846832275\n",
      "Batch 31. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5289400219917297\n",
      "Batch 32. Data shape torch.Size([32, 3, 224, 224]) Loss 0.472729355096817\n",
      "Batch 33. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5149634480476379\n",
      "Batch 34. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5234190225601196\n",
      "Batch 35. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4883241057395935\n",
      "Batch 36. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5592286586761475\n",
      "Batch 37. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4973261058330536\n",
      "Batch 38. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5591219663619995\n",
      "Batch 39. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5230566263198853\n",
      "Batch 40. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5008559226989746\n",
      "Batch 41. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5439769625663757\n",
      "Batch 42. Data shape torch.Size([32, 3, 224, 224]) Loss 0.48743340373039246\n",
      "Batch 43. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4983604848384857\n",
      "Batch 44. Data shape torch.Size([32, 3, 224, 224]) Loss 0.48840585350990295\n",
      "Batch 45. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5206081867218018\n",
      "Batch 46. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5662677884101868\n",
      "Batch 47. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4758131504058838\n",
      "Batch 48. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4966711103916168\n",
      "Batch 49. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5625554323196411\n",
      "Batch 50. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4691493511199951\n",
      "Batch 51. Data shape torch.Size([32, 3, 224, 224]) Loss 0.592831015586853\n",
      "Batch 52. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5633329749107361\n",
      "Batch 53. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4770888388156891\n",
      "Batch 54. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4752807915210724\n",
      "Batch 55. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5153273344039917\n",
      "Batch 56. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5050422549247742\n",
      "Batch 57. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5417757630348206\n",
      "Batch 58. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4800483286380768\n",
      "Batch 59. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5348131060600281\n",
      "Batch 60. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5132306218147278\n",
      "Batch 61. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5374712347984314\n",
      "Batch 62. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5231447219848633\n",
      "Batch 63. Data shape torch.Size([32, 3, 224, 224]) Loss 0.49265867471694946\n",
      "Batch 64. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5621961951255798\n",
      "Batch 65. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5044710636138916\n",
      "Batch 66. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5457140803337097\n",
      "Batch 67. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5131754279136658\n",
      "Batch 68. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5114607214927673\n",
      "Batch 69. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4667970836162567\n",
      "Batch 70. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5600309371948242\n",
      "Batch 71. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4983918368816376\n",
      "Batch 72. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6069667935371399\n",
      "Batch 73. Data shape torch.Size([32, 3, 224, 224]) Loss 0.493717759847641\n",
      "Batch 74. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6165962815284729\n",
      "Batch 75. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4406830072402954\n",
      "Batch 76. Data shape torch.Size([32, 3, 224, 224]) Loss 0.46459996700286865\n",
      "Batch 77. Data shape torch.Size([32, 3, 224, 224]) Loss 0.521811842918396\n",
      "Batch 78. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5066199898719788\n",
      "Batch 79. Data shape torch.Size([32, 3, 224, 224]) Loss 0.49655279517173767\n",
      "Batch 80. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5232232809066772\n",
      "Batch 81. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6623362302780151\n",
      "Batch 82. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5012947916984558\n",
      "Batch 83. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5526302456855774\n",
      "Batch 84. Data shape torch.Size([32, 3, 224, 224]) Loss 0.45621684193611145\n",
      "Batch 85. Data shape torch.Size([32, 3, 224, 224]) Loss 0.46710270643234253\n",
      "Batch 86. Data shape torch.Size([32, 3, 224, 224]) Loss 0.51060551404953\n",
      "Batch 87. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5545628070831299\n",
      "Batch 88. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5166299939155579\n",
      "Batch 89. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4835994839668274\n",
      "Batch 90. Data shape torch.Size([32, 3, 224, 224]) Loss 0.43185678124427795\n",
      "Batch 91. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5634322166442871\n",
      "Batch 92. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5697818398475647\n",
      "Batch 93. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4899500012397766\n",
      "Batch 94. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4789639115333557\n",
      "Batch 95. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5055109262466431\n",
      "Batch 96. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5654096007347107\n",
      "Batch 97. Data shape torch.Size([32, 3, 224, 224]) Loss 0.560231626033783\n",
      "Batch 98. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5324236154556274\n",
      "Batch 99. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5648055672645569\n",
      "Batch 100. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4507756531238556\n",
      "Batch 101. Data shape torch.Size([32, 3, 224, 224]) Loss 0.49757108092308044\n",
      "Batch 102. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5155482292175293\n",
      "Batch 103. Data shape torch.Size([32, 3, 224, 224]) Loss 0.573009729385376\n",
      "Batch 104. Data shape torch.Size([32, 3, 224, 224]) Loss 0.49578776955604553\n",
      "Batch 105. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4762970507144928\n",
      "Batch 106. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5455524325370789\n",
      "Batch 107. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5352172255516052\n",
      "Batch 108. Data shape torch.Size([32, 3, 224, 224]) Loss 0.616461992263794\n",
      "Batch 109. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5136250257492065\n",
      "Batch 110. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4688851535320282\n",
      "Batch 111. Data shape torch.Size([32, 3, 224, 224]) Loss 0.581433117389679\n",
      "Batch 112. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5390763878822327\n",
      "Batch 113. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4784359633922577\n",
      "Batch 114. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4902960956096649\n",
      "Batch 115. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5443158745765686\n",
      "Batch 116. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5238389372825623\n",
      "Batch 117. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5795205235481262\n",
      "Batch 118. Data shape torch.Size([32, 3, 224, 224]) Loss 0.45930731296539307\n",
      "Batch 119. Data shape torch.Size([20, 3, 224, 224]) Loss 0.6270098686218262\n",
      "EarlyStopping counter: 1 out of 5\n",
      "Epoch: 48/50 | time: 25.0m 7.014s | lr: 1.0000e-05 | train/loss: 0.54056 | val/loss: 0.52296 | val/accuracy: 0.77871 | val/AUC: 0.77754 | val/Kappa: 0.55631\n",
      "Epoch: 49 Train batch 10 loss: 0.5198122262954712, 2.1% complete\n",
      "Epoch: 49 Train batch 20 loss: 0.5103335380554199, 4.2% complete\n",
      "Epoch: 49 Train batch 30 loss: 0.5401625633239746, 6.3% complete\n",
      "Epoch: 49 Train batch 40 loss: 0.6057507991790771, 8.4% complete\n",
      "Epoch: 49 Train batch 50 loss: 0.5466197729110718, 10.5% complete\n",
      "Epoch: 49 Train batch 60 loss: 0.482936292886734, 12.6% complete\n",
      "Epoch: 49 Train batch 70 loss: 0.5705199837684631, 14.7% complete\n",
      "Epoch: 49 Train batch 80 loss: 0.4464742839336395, 16.8% complete\n",
      "Epoch: 49 Train batch 90 loss: 0.5004559755325317, 18.9% complete\n",
      "Epoch: 49 Train batch 100 loss: 0.4660036861896515, 21.1% complete\n",
      "Epoch: 49 Train batch 110 loss: 0.544326901435852, 23.2% complete\n",
      "Epoch: 49 Train batch 120 loss: 0.5356011390686035, 25.3% complete\n",
      "Epoch: 49 Train batch 130 loss: 0.503040075302124, 27.4% complete\n",
      "Epoch: 49 Train batch 140 loss: 0.5220579504966736, 29.5% complete\n",
      "Epoch: 49 Train batch 150 loss: 0.5720649361610413, 31.6% complete\n",
      "Epoch: 49 Train batch 160 loss: 0.5149577260017395, 33.7% complete\n",
      "Epoch: 49 Train batch 170 loss: 0.5191850662231445, 35.8% complete\n",
      "Epoch: 49 Train batch 180 loss: 0.5037767291069031, 37.9% complete\n",
      "Epoch: 49 Train batch 190 loss: 0.4893515706062317, 40.0% complete\n",
      "Epoch: 49 Train batch 200 loss: 0.518707275390625, 42.1% complete\n",
      "Epoch: 49 Train batch 210 loss: 0.5269517302513123, 44.2% complete\n",
      "Epoch: 49 Train batch 220 loss: 0.5241498947143555, 46.3% complete\n",
      "Epoch: 49 Train batch 230 loss: 0.5146530270576477, 48.4% complete\n",
      "Epoch: 49 Train batch 240 loss: 0.525576114654541, 50.5% complete\n",
      "Epoch: 49 Train batch 250 loss: 0.5672058463096619, 52.6% complete\n",
      "Epoch: 49 Train batch 260 loss: 0.5052028298377991, 54.7% complete\n",
      "Epoch: 49 Train batch 270 loss: 0.489342600107193, 56.8% complete\n",
      "Epoch: 49 Train batch 280 loss: 0.4883367717266083, 58.9% complete\n",
      "Epoch: 49 Train batch 290 loss: 0.5071898102760315, 61.1% complete\n",
      "Epoch: 49 Train batch 300 loss: 0.5023735761642456, 63.2% complete\n",
      "Epoch: 49 Train batch 310 loss: 0.5638107061386108, 65.3% complete\n",
      "Epoch: 49 Train batch 320 loss: 0.4910873770713806, 67.4% complete\n",
      "Epoch: 49 Train batch 330 loss: 0.5322864055633545, 69.5% complete\n",
      "Epoch: 49 Train batch 340 loss: 0.531321108341217, 71.6% complete\n",
      "Epoch: 49 Train batch 350 loss: 0.5852547883987427, 73.7% complete\n",
      "Epoch: 49 Train batch 360 loss: 0.5174022912979126, 75.8% complete\n",
      "Epoch: 49 Train batch 370 loss: 0.595543622970581, 77.9% complete\n",
      "Epoch: 49 Train batch 380 loss: 0.5320934057235718, 80.0% complete\n",
      "Epoch: 49 Train batch 390 loss: 0.4556010961532593, 82.1% complete\n",
      "Epoch: 49 Train batch 400 loss: 0.5973705649375916, 84.2% complete\n",
      "Epoch: 49 Train batch 410 loss: 0.48100703954696655, 86.3% complete\n",
      "Epoch: 49 Train batch 420 loss: 0.4972507357597351, 88.4% complete\n",
      "Epoch: 49 Train batch 430 loss: 0.5585770010948181, 90.5% complete\n",
      "Epoch: 49 Train batch 440 loss: 0.43720269203186035, 92.6% complete\n",
      "Epoch: 49 Train batch 450 loss: 0.4738728404045105, 94.7% complete\n",
      "Epoch: 49 Train batch 460 loss: 0.5743523240089417, 96.8% complete\n",
      "Epoch: 49 Train batch 470 loss: 0.5194227695465088, 98.9% complete\n",
      "Batch 1. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5230481624603271\n",
      "Batch 2. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6085737943649292\n",
      "Batch 3. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5301274061203003\n",
      "Batch 4. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5715412497520447\n",
      "Batch 5. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6312621235847473\n",
      "Batch 6. Data shape torch.Size([32, 3, 224, 224]) Loss 0.46040254831314087\n",
      "Batch 7. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5411471724510193\n",
      "Batch 8. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5307484865188599\n",
      "Batch 9. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5858840942382812\n",
      "Batch 10. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5240801572799683\n",
      "Batch 11. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5483445525169373\n",
      "Batch 12. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6039873361587524\n",
      "Batch 13. Data shape torch.Size([32, 3, 224, 224]) Loss 0.49922800064086914\n",
      "Batch 14. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5210830569267273\n",
      "Batch 15. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5045361518859863\n",
      "Batch 16. Data shape torch.Size([32, 3, 224, 224]) Loss 0.48053669929504395\n",
      "Batch 17. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4863833785057068\n",
      "Batch 18. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5058825016021729\n",
      "Batch 19. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5443043112754822\n",
      "Batch 20. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5125570297241211\n",
      "Batch 21. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5712932348251343\n",
      "Batch 22. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5012288689613342\n",
      "Batch 23. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5507438778877258\n",
      "Batch 24. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5029894113540649\n",
      "Batch 25. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5014441609382629\n",
      "Batch 26. Data shape torch.Size([32, 3, 224, 224]) Loss 0.46928107738494873\n",
      "Batch 27. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6327465772628784\n",
      "Batch 28. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5198373198509216\n",
      "Batch 29. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5219821333885193\n",
      "Batch 30. Data shape torch.Size([32, 3, 224, 224]) Loss 0.493818461894989\n",
      "Batch 31. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4965817630290985\n",
      "Batch 32. Data shape torch.Size([32, 3, 224, 224]) Loss 0.482554167509079\n",
      "Batch 33. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5199058055877686\n",
      "Batch 34. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6000761985778809\n",
      "Batch 35. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5140752792358398\n",
      "Batch 36. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4934311807155609\n",
      "Batch 37. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4581557512283325\n",
      "Batch 38. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4842107892036438\n",
      "Batch 39. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6199885606765747\n",
      "Batch 40. Data shape torch.Size([32, 3, 224, 224]) Loss 0.46867120265960693\n",
      "Batch 41. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4296427071094513\n",
      "Batch 42. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5073117613792419\n",
      "Batch 43. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5166731476783752\n",
      "Batch 44. Data shape torch.Size([32, 3, 224, 224]) Loss 0.45560938119888306\n",
      "Batch 45. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5311129689216614\n",
      "Batch 46. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5103240609169006\n",
      "Batch 47. Data shape torch.Size([32, 3, 224, 224]) Loss 0.49245917797088623\n",
      "Batch 48. Data shape torch.Size([32, 3, 224, 224]) Loss 0.48830562829971313\n",
      "Batch 49. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5735508799552917\n",
      "Batch 50. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5180922150611877\n",
      "Batch 51. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5603916645050049\n",
      "Batch 52. Data shape torch.Size([32, 3, 224, 224]) Loss 0.544471263885498\n",
      "Batch 53. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5274585485458374\n",
      "Batch 54. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4200259745121002\n",
      "Batch 55. Data shape torch.Size([32, 3, 224, 224]) Loss 0.43605297803878784\n",
      "Batch 56. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5168665051460266\n",
      "Batch 57. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5747947692871094\n",
      "Batch 58. Data shape torch.Size([32, 3, 224, 224]) Loss 0.45760872960090637\n",
      "Batch 59. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5343983769416809\n",
      "Batch 60. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5266739130020142\n",
      "Batch 61. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5192511677742004\n",
      "Batch 62. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5362980365753174\n",
      "Batch 63. Data shape torch.Size([32, 3, 224, 224]) Loss 0.42782679200172424\n",
      "Batch 64. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5020264387130737\n",
      "Batch 65. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5405350923538208\n",
      "Batch 66. Data shape torch.Size([32, 3, 224, 224]) Loss 0.49497121572494507\n",
      "Batch 67. Data shape torch.Size([32, 3, 224, 224]) Loss 0.47830015420913696\n",
      "Batch 68. Data shape torch.Size([32, 3, 224, 224]) Loss 0.47788548469543457\n",
      "Batch 69. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5033203959465027\n",
      "Batch 70. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4736418128013611\n",
      "Batch 71. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5119550228118896\n",
      "Batch 72. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4641139507293701\n",
      "Batch 73. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5461513996124268\n",
      "Batch 74. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5028151273727417\n",
      "Batch 75. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4955383837223053\n",
      "Batch 76. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5126214027404785\n",
      "Batch 77. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5237996578216553\n",
      "Batch 78. Data shape torch.Size([32, 3, 224, 224]) Loss 0.515266478061676\n",
      "Batch 79. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5023497343063354\n",
      "Batch 80. Data shape torch.Size([32, 3, 224, 224]) Loss 0.47946280241012573\n",
      "Batch 81. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5232608318328857\n",
      "Batch 82. Data shape torch.Size([32, 3, 224, 224]) Loss 0.564548909664154\n",
      "Batch 83. Data shape torch.Size([32, 3, 224, 224]) Loss 0.524447500705719\n",
      "Batch 84. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4090571403503418\n",
      "Batch 85. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5384248495101929\n",
      "Batch 86. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5132299661636353\n",
      "Batch 87. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4948919713497162\n",
      "Batch 88. Data shape torch.Size([32, 3, 224, 224]) Loss 0.48165470361709595\n",
      "Batch 89. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5467299222946167\n",
      "Batch 90. Data shape torch.Size([32, 3, 224, 224]) Loss 0.46356090903282166\n",
      "Batch 91. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5559225678443909\n",
      "Batch 92. Data shape torch.Size([32, 3, 224, 224]) Loss 0.42803990840911865\n",
      "Batch 93. Data shape torch.Size([32, 3, 224, 224]) Loss 0.509289562702179\n",
      "Batch 94. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4992523491382599\n",
      "Batch 95. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5483070611953735\n",
      "Batch 96. Data shape torch.Size([32, 3, 224, 224]) Loss 0.48214560747146606\n",
      "Batch 97. Data shape torch.Size([32, 3, 224, 224]) Loss 0.582651674747467\n",
      "Batch 98. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4911193251609802\n",
      "Batch 99. Data shape torch.Size([32, 3, 224, 224]) Loss 0.46536222100257874\n",
      "Batch 100. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5225508213043213\n",
      "Batch 101. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6141632795333862\n",
      "Batch 102. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5648297667503357\n",
      "Batch 103. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4695472717285156\n",
      "Batch 104. Data shape torch.Size([32, 3, 224, 224]) Loss 0.44412678480148315\n",
      "Batch 105. Data shape torch.Size([32, 3, 224, 224]) Loss 0.47120028734207153\n",
      "Batch 106. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5661168098449707\n",
      "Batch 107. Data shape torch.Size([32, 3, 224, 224]) Loss 0.37725841999053955\n",
      "Batch 108. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5293647050857544\n",
      "Batch 109. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5203691124916077\n",
      "Batch 110. Data shape torch.Size([32, 3, 224, 224]) Loss 0.460114985704422\n",
      "Batch 111. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5588918924331665\n",
      "Batch 112. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5284590721130371\n",
      "Batch 113. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5367129445075989\n",
      "Batch 114. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4709411561489105\n",
      "Batch 115. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5501694679260254\n",
      "Batch 116. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6005951762199402\n",
      "Batch 117. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5621666312217712\n",
      "Batch 118. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5362244844436646\n",
      "Batch 119. Data shape torch.Size([20, 3, 224, 224]) Loss 0.5168573260307312\n",
      "Valid loss improved from 0.519689 to 0.514867. Saving model ...\n",
      "Epoch: 49/50 | time: 26.0m 21.94s | lr: 1.0000e-05 | train/loss: 0.53242 | val/loss: 0.51487 | val/accuracy: 0.78293 | val/AUC: 0.78176 | val/Kappa: 0.56477\n",
      "Epoch: 50 Train batch 10 loss: 0.609705924987793, 2.1% complete\n",
      "Epoch: 50 Train batch 20 loss: 0.5000463724136353, 4.2% complete\n",
      "Epoch: 50 Train batch 30 loss: 0.5672829747200012, 6.3% complete\n",
      "Epoch: 50 Train batch 40 loss: 0.5296696424484253, 8.4% complete\n",
      "Epoch: 50 Train batch 50 loss: 0.4651755392551422, 10.5% complete\n",
      "Epoch: 50 Train batch 60 loss: 0.5777148008346558, 12.6% complete\n",
      "Epoch: 50 Train batch 70 loss: 0.5277262926101685, 14.7% complete\n",
      "Epoch: 50 Train batch 80 loss: 0.47016164660453796, 16.8% complete\n",
      "Epoch: 50 Train batch 90 loss: 0.506770133972168, 18.9% complete\n",
      "Epoch: 50 Train batch 100 loss: 0.5062947869300842, 21.1% complete\n",
      "Epoch: 50 Train batch 110 loss: 0.5002208948135376, 23.2% complete\n",
      "Epoch: 50 Train batch 120 loss: 0.5887061357498169, 25.3% complete\n",
      "Epoch: 50 Train batch 130 loss: 0.515609860420227, 27.4% complete\n",
      "Epoch: 50 Train batch 140 loss: 0.46747684478759766, 29.5% complete\n",
      "Epoch: 50 Train batch 150 loss: 0.526715874671936, 31.6% complete\n",
      "Epoch: 50 Train batch 160 loss: 0.5621505975723267, 33.7% complete\n",
      "Epoch: 50 Train batch 170 loss: 0.594639003276825, 35.8% complete\n",
      "Epoch: 50 Train batch 180 loss: 0.5586285591125488, 37.9% complete\n",
      "Epoch: 50 Train batch 190 loss: 0.49078309535980225, 40.0% complete\n",
      "Epoch: 50 Train batch 200 loss: 0.5559849143028259, 42.1% complete\n",
      "Epoch: 50 Train batch 210 loss: 0.5304766893386841, 44.2% complete\n",
      "Epoch: 50 Train batch 220 loss: 0.5147636532783508, 46.3% complete\n",
      "Epoch: 50 Train batch 230 loss: 0.503023087978363, 48.4% complete\n",
      "Epoch: 50 Train batch 240 loss: 0.5255308747291565, 50.5% complete\n",
      "Epoch: 50 Train batch 250 loss: 0.4900384545326233, 52.6% complete\n",
      "Epoch: 50 Train batch 260 loss: 0.5961930155754089, 54.7% complete\n",
      "Epoch: 50 Train batch 270 loss: 0.5117761492729187, 56.8% complete\n",
      "Epoch: 50 Train batch 280 loss: 0.5600311160087585, 58.9% complete\n",
      "Epoch: 50 Train batch 290 loss: 0.5680063962936401, 61.1% complete\n",
      "Epoch: 50 Train batch 300 loss: 0.49226948618888855, 63.2% complete\n",
      "Epoch: 50 Train batch 310 loss: 0.5628412961959839, 65.3% complete\n",
      "Epoch: 50 Train batch 320 loss: 0.5650914907455444, 67.4% complete\n",
      "Epoch: 50 Train batch 330 loss: 0.5563400387763977, 69.5% complete\n",
      "Epoch: 50 Train batch 340 loss: 0.5719580054283142, 71.6% complete\n",
      "Epoch: 50 Train batch 350 loss: 0.49520057439804077, 73.7% complete\n",
      "Epoch: 50 Train batch 360 loss: 0.4790780544281006, 75.8% complete\n",
      "Epoch: 50 Train batch 370 loss: 0.5721532106399536, 77.9% complete\n",
      "Epoch: 50 Train batch 380 loss: 0.5030083656311035, 80.0% complete\n",
      "Epoch: 50 Train batch 390 loss: 0.4936201870441437, 82.1% complete\n",
      "Epoch: 50 Train batch 400 loss: 0.559626042842865, 84.2% complete\n",
      "Epoch: 50 Train batch 410 loss: 0.5986332297325134, 86.3% complete\n",
      "Epoch: 50 Train batch 420 loss: 0.5006117820739746, 88.4% complete\n",
      "Epoch: 50 Train batch 430 loss: 0.5592697858810425, 90.5% complete\n",
      "Epoch: 50 Train batch 440 loss: 0.5040886998176575, 92.6% complete\n",
      "Epoch: 50 Train batch 450 loss: 0.5196046233177185, 94.7% complete\n",
      "Epoch: 50 Train batch 460 loss: 0.5196621417999268, 96.8% complete\n",
      "Epoch: 50 Train batch 470 loss: 0.541369616985321, 98.9% complete\n",
      "Batch 1. Data shape torch.Size([32, 3, 224, 224]) Loss 0.46237683296203613\n",
      "Batch 2. Data shape torch.Size([32, 3, 224, 224]) Loss 0.49705418944358826\n",
      "Batch 3. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5784835815429688\n",
      "Batch 4. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5553226470947266\n",
      "Batch 5. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5107661485671997\n",
      "Batch 6. Data shape torch.Size([32, 3, 224, 224]) Loss 0.629100501537323\n",
      "Batch 7. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4431648850440979\n",
      "Batch 8. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4483357071876526\n",
      "Batch 9. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4900762736797333\n",
      "Batch 10. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4841237962245941\n",
      "Batch 11. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5426254868507385\n",
      "Batch 12. Data shape torch.Size([32, 3, 224, 224]) Loss 0.49684733152389526\n",
      "Batch 13. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5061423778533936\n",
      "Batch 14. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5322393774986267\n",
      "Batch 15. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4226047694683075\n",
      "Batch 16. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5467511415481567\n",
      "Batch 17. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4589441418647766\n",
      "Batch 18. Data shape torch.Size([32, 3, 224, 224]) Loss 0.48551875352859497\n",
      "Batch 19. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5815895795822144\n",
      "Batch 20. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5627860426902771\n",
      "Batch 21. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5780603289604187\n",
      "Batch 22. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4896922707557678\n",
      "Batch 23. Data shape torch.Size([32, 3, 224, 224]) Loss 0.44582635164260864\n",
      "Batch 24. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5004982352256775\n",
      "Batch 25. Data shape torch.Size([32, 3, 224, 224]) Loss 0.45832690596580505\n",
      "Batch 26. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5380701422691345\n",
      "Batch 27. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5425500869750977\n",
      "Batch 28. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5444425940513611\n",
      "Batch 29. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4016773998737335\n",
      "Batch 30. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5328246355056763\n",
      "Batch 31. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4861091673374176\n",
      "Batch 32. Data shape torch.Size([32, 3, 224, 224]) Loss 0.46298497915267944\n",
      "Batch 33. Data shape torch.Size([32, 3, 224, 224]) Loss 0.566474974155426\n",
      "Batch 34. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5188128352165222\n",
      "Batch 35. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5344669222831726\n",
      "Batch 36. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5322037935256958\n",
      "Batch 37. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5225721001625061\n",
      "Batch 38. Data shape torch.Size([32, 3, 224, 224]) Loss 0.47614771127700806\n",
      "Batch 39. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5191567540168762\n",
      "Batch 40. Data shape torch.Size([32, 3, 224, 224]) Loss 0.48975375294685364\n",
      "Batch 41. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4856627285480499\n",
      "Batch 42. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5654802322387695\n",
      "Batch 43. Data shape torch.Size([32, 3, 224, 224]) Loss 0.480689138174057\n",
      "Batch 44. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4938483238220215\n",
      "Batch 45. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4065363109111786\n",
      "Batch 46. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5322015881538391\n",
      "Batch 47. Data shape torch.Size([32, 3, 224, 224]) Loss 0.558803915977478\n",
      "Batch 48. Data shape torch.Size([32, 3, 224, 224]) Loss 0.583847165107727\n",
      "Batch 49. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5132400393486023\n",
      "Batch 50. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4090517461299896\n",
      "Batch 51. Data shape torch.Size([32, 3, 224, 224]) Loss 0.46691685914993286\n",
      "Batch 52. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6010189652442932\n",
      "Batch 53. Data shape torch.Size([32, 3, 224, 224]) Loss 0.505655825138092\n",
      "Batch 54. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5670914053916931\n",
      "Batch 55. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5693572759628296\n",
      "Batch 56. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5183745622634888\n",
      "Batch 57. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5756860375404358\n",
      "Batch 58. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4582824409008026\n",
      "Batch 59. Data shape torch.Size([32, 3, 224, 224]) Loss 0.425415575504303\n",
      "Batch 60. Data shape torch.Size([32, 3, 224, 224]) Loss 0.49139001965522766\n",
      "Batch 61. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5066884756088257\n",
      "Batch 62. Data shape torch.Size([32, 3, 224, 224]) Loss 0.49059873819351196\n",
      "Batch 63. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4377109706401825\n",
      "Batch 64. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5284519791603088\n",
      "Batch 65. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5038726925849915\n",
      "Batch 66. Data shape torch.Size([32, 3, 224, 224]) Loss 0.42840147018432617\n",
      "Batch 67. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5453805327415466\n",
      "Batch 68. Data shape torch.Size([32, 3, 224, 224]) Loss 0.49126318097114563\n",
      "Batch 69. Data shape torch.Size([32, 3, 224, 224]) Loss 0.475077748298645\n",
      "Batch 70. Data shape torch.Size([32, 3, 224, 224]) Loss 0.44601836800575256\n",
      "Batch 71. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5344781875610352\n",
      "Batch 72. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5049047470092773\n",
      "Batch 73. Data shape torch.Size([32, 3, 224, 224]) Loss 0.49758946895599365\n",
      "Batch 74. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5107211470603943\n",
      "Batch 75. Data shape torch.Size([32, 3, 224, 224]) Loss 0.49150756001472473\n",
      "Batch 76. Data shape torch.Size([32, 3, 224, 224]) Loss 0.513166069984436\n",
      "Batch 77. Data shape torch.Size([32, 3, 224, 224]) Loss 0.42047590017318726\n",
      "Batch 78. Data shape torch.Size([32, 3, 224, 224]) Loss 0.53143709897995\n",
      "Batch 79. Data shape torch.Size([32, 3, 224, 224]) Loss 0.43165209889411926\n",
      "Batch 80. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5683878660202026\n",
      "Batch 81. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4844856858253479\n",
      "Batch 82. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5167027115821838\n",
      "Batch 83. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5354636907577515\n",
      "Batch 84. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4724001884460449\n",
      "Batch 85. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5620922446250916\n",
      "Batch 86. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5590735077857971\n",
      "Batch 87. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5530228614807129\n",
      "Batch 88. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5955690145492554\n",
      "Batch 89. Data shape torch.Size([32, 3, 224, 224]) Loss 0.49687349796295166\n",
      "Batch 90. Data shape torch.Size([32, 3, 224, 224]) Loss 0.522700846195221\n",
      "Batch 91. Data shape torch.Size([32, 3, 224, 224]) Loss 0.47488167881965637\n",
      "Batch 92. Data shape torch.Size([32, 3, 224, 224]) Loss 0.44018951058387756\n",
      "Batch 93. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5071185231208801\n",
      "Batch 94. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5266926884651184\n",
      "Batch 95. Data shape torch.Size([32, 3, 224, 224]) Loss 0.544014036655426\n",
      "Batch 96. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5752605199813843\n",
      "Batch 97. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4851003587245941\n",
      "Batch 98. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5399371981620789\n",
      "Batch 99. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4585767090320587\n",
      "Batch 100. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4325755834579468\n",
      "Batch 101. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5022520422935486\n",
      "Batch 102. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4836984872817993\n",
      "Batch 103. Data shape torch.Size([32, 3, 224, 224]) Loss 0.44851773977279663\n",
      "Batch 104. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5246315002441406\n",
      "Batch 105. Data shape torch.Size([32, 3, 224, 224]) Loss 0.6178652048110962\n",
      "Batch 106. Data shape torch.Size([32, 3, 224, 224]) Loss 0.47474807500839233\n",
      "Batch 107. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4439293444156647\n",
      "Batch 108. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5561621189117432\n",
      "Batch 109. Data shape torch.Size([32, 3, 224, 224]) Loss 0.4546675980091095\n",
      "Batch 110. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5153145790100098\n",
      "Batch 111. Data shape torch.Size([32, 3, 224, 224]) Loss 0.49713820219039917\n",
      "Batch 112. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5416300296783447\n",
      "Batch 113. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5366982221603394\n",
      "Batch 114. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5045722723007202\n",
      "Batch 115. Data shape torch.Size([32, 3, 224, 224]) Loss 0.49038711190223694\n",
      "Batch 116. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5299323797225952\n",
      "Batch 117. Data shape torch.Size([32, 3, 224, 224]) Loss 0.48030224442481995\n",
      "Batch 118. Data shape torch.Size([32, 3, 224, 224]) Loss 0.5482240319252014\n",
      "Batch 119. Data shape torch.Size([20, 3, 224, 224]) Loss 0.5472431778907776\n",
      "Valid loss improved from 0.514867 to 0.507752. Saving model ...\n",
      "Epoch: 50/50 | time: 50.0m 22.19s | lr: 1.0000e-05 | train/loss: 0.53068 | val/loss: 0.50775 | val/accuracy: 0.78583 | val/AUC: 0.78521 | val/Kappa: 0.57105\n",
      "Testing...\n",
      "Test Accuracy: 0.78583\n",
      "Test AUC: 0.78521\n",
      "Test Kappa: 0.57105\n",
      "Target 0 - Precision: 0.77242, Recall: 0.82082, F-score: 0.79588, Sensitivity: 0.8208182288969446, Specificity: 0.749597855227882, Support: 1931\n",
      "Target 1 - Precision: 0.80161, Recall: 0.74960, F-score: 0.77473, Sensitivity: 0.749597855227882, Specificity: 0.8208182288969446, Support: 1865\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.82      0.80      1931\n",
      "           1       0.80      0.75      0.77      1865\n",
      "\n",
      "    accuracy                           0.79      3796\n",
      "   macro avg       0.79      0.79      0.79      3796\n",
      "weighted avg       0.79      0.79      0.79      3796\n",
      "\n",
      "\n",
      "Testing complete.\n",
      "Run complete. Total time: 19:09:17\n"
     ]
    }
   ],
   "source": [
    "# ClassifierSegExperiment_224_epo50_bs32_lr1e-05_s42/2024-01-08_2313_VGG16_BN_Attention\n",
    "# code for this experiment has been removed from the controller as it showed no improvement over the baseline\n",
    "command = 'python ../train.py --train_path \"../datasets/challenge1/train\" \\\n",
    "                        --train_masks_path \"../datasets_masks/challenge1/train\" \\\n",
    "                        --valid_path \"../datasets/challenge1/val\" \\\n",
    "                        --experiment_name \"ClassifierSegExperiment\" \\\n",
    "                        --network_name \"VGG16_BN_Attention\" \\\n",
    "                        --max_epochs \"50\" \\\n",
    "                        --base_lr \"0.00001\" \\\n",
    "                        --batch_size \"32\" \\\n",
    "                        --verbose \"2\"'\n",
    "\n",
    "# run the function to excute the command\n",
    "_ = execute_cmd_realtime(command, log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excuting inference script...\n",
      "Namespace(test_path='../datasets/challenge1/val', output='outputs', experiment_name='HoldoutModelExperiments', network_name='VGG16_BN_Attention', max_epochs=50, batch_size=32, base_lr=1e-05, img_size=224, seed=42, timeframe='2023-12-24_2131+1035', verbose=2, multi=False, report=True, ensemble=True, combination_strategy='majority_vote', upscale_factor=8, gradcam=False)\n",
      "Constructed output path: outputs/HoldoutModelExperiments_224_epo50_bs32_lr1e-05_s42/2023-12-24_2131+1035_VGG16_BN_Attention. Searching for models...\n",
      "Found 6 models.\n",
      "Loading data with 2 class labels from ../datasets/challenge1/val path...\n",
      "Dataset labels: {'nevus': 0, 'others': 1} dictionary.\n",
      "Loading the data from ../datasets/challenge1/val\n",
      "Dataset length: 3796\n",
      "Using VGG16_BN_Attention with configurations: num_classes='2', normalize_attn='False'\n",
      "Using VGG16_BN_Attention with configurations: num_classes='2', normalize_attn='False'\n",
      "Using VGG16_BN_Attention with configurations: num_classes='2', normalize_attn='False'\n",
      "Using VGG16_BN_Attention with configurations: num_classes='2', normalize_attn='False'\n",
      "Using VGG16_BN_Attention with configurations: num_classes='2', normalize_attn='False'\n",
      "Using VGG16_BN_Attention with configurations: num_classes='2', normalize_attn='False'\n",
      "\n",
      "Inference:   0%|          | 0/119 [00:00<?, ?it/s]\n",
      "Inference:   1%|          | 1/119 [00:53<1:45:46, 53.78s/it]\n",
      "Inference:   2%|▏         | 2/119 [00:54<44:11, 22.66s/it]  \n",
      "Inference:   3%|▎         | 3/119 [00:55<24:33, 12.71s/it]\n",
      "Inference:   3%|▎         | 4/119 [00:56<15:23,  8.03s/it]\n",
      "Inference:   4%|▍         | 5/119 [00:57<10:20,  5.45s/it]\n",
      "Inference:   5%|▌         | 6/119 [00:58<07:19,  3.89s/it]\n",
      "Inference:   6%|▌         | 7/119 [00:58<05:22,  2.88s/it]\n",
      "Inference:   7%|▋         | 8/119 [00:59<04:06,  2.22s/it]\n",
      "Inference:   8%|▊         | 9/119 [01:00<03:15,  1.78s/it]\n",
      "Inference:   8%|▊         | 10/119 [01:01<02:40,  1.47s/it]\n",
      "Inference:   9%|▉         | 11/119 [01:02<02:16,  1.26s/it]\n",
      "Inference:  10%|█         | 12/119 [01:02<01:59,  1.11s/it]\n",
      "Inference:  11%|█         | 13/119 [01:03<01:47,  1.01s/it]\n",
      "Inference:  12%|█▏        | 14/119 [01:04<01:38,  1.07it/s]\n",
      "Inference:  13%|█▎        | 15/119 [01:05<01:32,  1.13it/s]\n",
      "Inference:  13%|█▎        | 16/119 [01:05<01:27,  1.17it/s]\n",
      "Inference:  14%|█▍        | 17/119 [01:06<01:24,  1.21it/s]\n",
      "Inference:  15%|█▌        | 18/119 [01:07<01:21,  1.23it/s]\n",
      "Inference:  16%|█▌        | 19/119 [01:08<01:19,  1.25it/s]\n",
      "Inference:  17%|█▋        | 20/119 [01:09<01:18,  1.26it/s]\n",
      "Inference:  18%|█▊        | 21/119 [01:09<01:17,  1.27it/s]\n",
      "Inference:  18%|█▊        | 22/119 [01:10<01:15,  1.28it/s]\n",
      "Inference:  19%|█▉        | 23/119 [01:11<01:14,  1.28it/s]\n",
      "Inference:  20%|██        | 24/119 [01:12<01:13,  1.29it/s]\n",
      "Inference:  21%|██        | 25/119 [01:12<01:12,  1.29it/s]\n",
      "Inference:  22%|██▏       | 26/119 [01:13<01:12,  1.29it/s]\n",
      "Inference:  23%|██▎       | 27/119 [01:14<01:11,  1.29it/s]\n",
      "Inference:  24%|██▎       | 28/119 [01:15<01:10,  1.29it/s]\n",
      "Inference:  24%|██▍       | 29/119 [01:16<01:09,  1.29it/s]\n",
      "Inference:  25%|██▌       | 30/119 [01:16<01:08,  1.29it/s]\n",
      "Inference:  26%|██▌       | 31/119 [01:17<01:08,  1.29it/s]\n",
      "Inference:  27%|██▋       | 32/119 [01:18<01:07,  1.29it/s]\n",
      "Inference:  28%|██▊       | 33/119 [01:19<01:06,  1.29it/s]\n",
      "Inference:  29%|██▊       | 34/119 [01:19<01:05,  1.29it/s]\n",
      "Inference:  29%|██▉       | 35/119 [01:20<01:04,  1.29it/s]\n",
      "Inference:  30%|███       | 36/119 [01:21<01:04,  1.29it/s]\n",
      "Inference:  31%|███       | 37/119 [01:22<01:03,  1.29it/s]\n",
      "Inference:  32%|███▏      | 38/119 [01:22<01:02,  1.29it/s]\n",
      "Inference:  33%|███▎      | 39/119 [01:23<01:02,  1.29it/s]\n",
      "Inference:  34%|███▎      | 40/119 [01:24<01:01,  1.29it/s]\n",
      "Inference:  34%|███▍      | 41/119 [01:25<01:00,  1.29it/s]\n",
      "Inference:  35%|███▌      | 42/119 [01:26<00:59,  1.29it/s]\n",
      "Inference:  36%|███▌      | 43/119 [01:26<00:59,  1.29it/s]\n",
      "Inference:  37%|███▋      | 44/119 [01:27<00:58,  1.29it/s]\n",
      "Inference:  38%|███▊      | 45/119 [01:28<00:57,  1.29it/s]\n",
      "Inference:  39%|███▊      | 46/119 [01:29<00:56,  1.29it/s]\n",
      "Inference:  39%|███▉      | 47/119 [01:29<00:55,  1.29it/s]\n",
      "Inference:  40%|████      | 48/119 [01:30<00:55,  1.29it/s]\n",
      "Inference:  41%|████      | 49/119 [01:31<00:54,  1.29it/s]\n",
      "Inference:  42%|████▏     | 50/119 [01:32<00:53,  1.29it/s]\n",
      "Inference:  43%|████▎     | 51/119 [01:33<00:52,  1.29it/s]\n",
      "Inference:  44%|████▎     | 52/119 [01:33<00:52,  1.29it/s]\n",
      "Inference:  45%|████▍     | 53/119 [01:34<00:51,  1.29it/s]\n",
      "Inference:  45%|████▌     | 54/119 [01:35<00:50,  1.28it/s]\n",
      "Inference:  46%|████▌     | 55/119 [01:36<00:50,  1.27it/s]\n",
      "Inference:  47%|████▋     | 56/119 [01:37<00:49,  1.26it/s]\n",
      "Inference:  48%|████▊     | 57/119 [01:37<00:49,  1.26it/s]\n",
      "Inference:  49%|████▊     | 58/119 [01:38<00:48,  1.26it/s]\n",
      "Inference:  50%|████▉     | 59/119 [01:39<00:47,  1.27it/s]\n",
      "Inference:  50%|█████     | 60/119 [01:40<00:46,  1.27it/s]\n",
      "Inference:  51%|█████▏    | 61/119 [01:40<00:45,  1.26it/s]\n",
      "Inference:  52%|█████▏    | 62/119 [01:41<00:45,  1.26it/s]\n",
      "Inference:  53%|█████▎    | 63/119 [01:42<00:44,  1.26it/s]\n",
      "Inference:  54%|█████▍    | 64/119 [01:43<00:43,  1.27it/s]\n",
      "Inference:  55%|█████▍    | 65/119 [01:44<00:42,  1.27it/s]\n",
      "Inference:  55%|█████▌    | 66/119 [01:44<00:41,  1.27it/s]\n",
      "Inference:  56%|█████▋    | 67/119 [01:45<00:40,  1.28it/s]\n",
      "Inference:  57%|█████▋    | 68/119 [01:46<00:40,  1.27it/s]\n",
      "Inference:  58%|█████▊    | 69/119 [01:47<00:39,  1.28it/s]\n",
      "Inference:  59%|█████▉    | 70/119 [01:48<00:38,  1.28it/s]\n",
      "Inference:  60%|█████▉    | 71/119 [01:48<00:37,  1.28it/s]\n",
      "Inference:  61%|██████    | 72/119 [01:49<00:36,  1.28it/s]\n",
      "Inference:  61%|██████▏   | 73/119 [01:50<00:36,  1.28it/s]\n",
      "Inference:  62%|██████▏   | 74/119 [01:51<00:35,  1.28it/s]\n",
      "Inference:  63%|██████▎   | 75/119 [01:51<00:34,  1.28it/s]\n",
      "Inference:  64%|██████▍   | 76/119 [01:52<00:33,  1.28it/s]\n",
      "Inference:  65%|██████▍   | 77/119 [01:53<00:32,  1.28it/s]\n",
      "Inference:  66%|██████▌   | 78/119 [01:54<00:31,  1.28it/s]\n",
      "Inference:  66%|██████▋   | 79/119 [01:55<00:31,  1.29it/s]\n",
      "Inference:  67%|██████▋   | 80/119 [01:55<00:30,  1.29it/s]\n",
      "Inference:  68%|██████▊   | 81/119 [01:56<00:29,  1.28it/s]\n",
      "Inference:  69%|██████▉   | 82/119 [01:57<00:28,  1.28it/s]\n",
      "Inference:  70%|██████▉   | 83/119 [01:58<00:28,  1.28it/s]\n",
      "Inference:  71%|███████   | 84/119 [01:58<00:27,  1.28it/s]\n",
      "Inference:  71%|███████▏  | 85/119 [01:59<00:26,  1.28it/s]\n",
      "Inference:  72%|███████▏  | 86/119 [02:00<00:25,  1.28it/s]\n",
      "Inference:  73%|███████▎  | 87/119 [02:01<00:24,  1.28it/s]\n",
      "Inference:  74%|███████▍  | 88/119 [02:02<00:24,  1.28it/s]\n",
      "Inference:  75%|███████▍  | 89/119 [02:02<00:23,  1.28it/s]\n",
      "Inference:  76%|███████▌  | 90/119 [02:03<00:22,  1.28it/s]\n",
      "Inference:  76%|███████▋  | 91/119 [02:04<00:21,  1.28it/s]\n",
      "Inference:  77%|███████▋  | 92/119 [02:05<00:21,  1.28it/s]\n",
      "Inference:  78%|███████▊  | 93/119 [02:05<00:20,  1.28it/s]\n",
      "Inference:  79%|███████▉  | 94/119 [02:06<00:19,  1.27it/s]\n",
      "Inference:  80%|███████▉  | 95/119 [02:07<00:18,  1.27it/s]\n",
      "Inference:  81%|████████  | 96/119 [02:08<00:18,  1.27it/s]\n",
      "Inference:  82%|████████▏ | 97/119 [02:09<00:17,  1.27it/s]\n",
      "Inference:  82%|████████▏ | 98/119 [02:09<00:16,  1.28it/s]\n",
      "Inference:  83%|████████▎ | 99/119 [02:10<00:15,  1.28it/s]\n",
      "Inference:  84%|████████▍ | 100/119 [02:11<00:14,  1.28it/s]\n",
      "Inference:  85%|████████▍ | 101/119 [02:12<00:14,  1.28it/s]\n",
      "Inference:  86%|████████▌ | 102/119 [02:13<00:13,  1.28it/s]\n",
      "Inference:  87%|████████▋ | 103/119 [02:13<00:12,  1.28it/s]\n",
      "Inference:  87%|████████▋ | 104/119 [02:14<00:11,  1.28it/s]\n",
      "Inference:  88%|████████▊ | 105/119 [02:15<00:10,  1.28it/s]\n",
      "Inference:  89%|████████▉ | 106/119 [02:16<00:10,  1.28it/s]\n",
      "Inference:  90%|████████▉ | 107/119 [02:16<00:09,  1.28it/s]\n",
      "Inference:  91%|█████████ | 108/119 [02:17<00:08,  1.28it/s]\n",
      "Inference:  92%|█████████▏| 109/119 [02:18<00:07,  1.27it/s]\n",
      "Inference:  92%|█████████▏| 110/119 [02:19<00:07,  1.27it/s]\n",
      "Inference:  93%|█████████▎| 111/119 [02:20<00:06,  1.27it/s]\n",
      "Inference:  94%|█████████▍| 112/119 [02:20<00:05,  1.28it/s]\n",
      "Inference:  95%|█████████▍| 113/119 [02:21<00:04,  1.28it/s]\n",
      "Inference:  96%|█████████▌| 114/119 [02:22<00:03,  1.28it/s]\n",
      "Inference:  97%|█████████▋| 115/119 [02:23<00:03,  1.28it/s]\n",
      "Inference:  97%|█████████▋| 116/119 [02:23<00:02,  1.28it/s]\n",
      "Inference:  98%|█████████▊| 117/119 [02:24<00:01,  1.28it/s]\n",
      "Inference:  99%|█████████▉| 118/119 [02:25<00:00,  1.28it/s]\n",
      "Inference: 100%|██████████| 119/119 [02:27<00:00,  1.07s/it]\n",
      "Inference: 100%|██████████| 119/119 [02:27<00:00,  1.24s/it]\n",
      "all_predictions shape: (6, 3796)\n",
      "all_probabilities shape: (6, 3796, 2)\n",
      "Combination strategy is majority_vote. Computing the majority vote...\n",
      "Average probabilities: [[9.7669601e-01 2.3304075e-02]\n",
      " [9.9944860e-01 5.5136945e-04]\n",
      " [9.9852115e-01 1.4787964e-03]\n",
      " ...\n",
      " [4.6259663e-03 9.9537402e-01]\n",
      " [1.5355277e-01 8.4644723e-01]\n",
      " [6.6968058e-03 9.9330324e-01]]\n",
      "Results exported to: outputs/HoldoutModelExperiments_224_epo50_bs32_lr1e-05_s42/2023-12-24_2131+1035_VGG16_BN_Attention/ch1_majority_vote_val_HoldoutModelExperiments_224_epo50_bs32_lr1e-05_s42_2023-12-24_2131+1035_VGG16_BN_Attention.csv\n",
      "Figure(1500x600)\n",
      "Majority vote AUC: 0.92860\n",
      "Majority vote accuracy: 0.9291359325605901\n",
      "Majority vote kappa: 0.8580820583580212\n",
      "Target 0 - Precision: 0.90656, Recall: 0.95961, F-score: 0.93233, Sensitivity: 0.9596064215432418, Specificity: 0.8975871313672922, Support: 1931\n",
      "Target 1 - Precision: 0.95548, Recall: 0.89759, F-score: 0.92563, Sensitivity: 0.8975871313672922, Specificity: 0.9596064215432418, Support: 1865\n",
      "(   {   'accuracy': 0.9291359325605901,\n",
      "        'auc': 0.9285967764552671,\n",
      "        'fscore': [0.9323270440251572, 0.9256289742880841],\n",
      "        'kappa': 0.8580820583580212,\n",
      "        'precision': [0.9065557729941291, 0.9554794520547946],\n",
      "        'recall': [0.9596064215432418, 0.8975871313672922],\n",
      "        'sensitivity': [0.9596064215432418, 0.8975871313672922],\n",
      "        'specificity': [0.8975871313672922, 0.9596064215432418],\n",
      "        'support': [1931, 1865]},)\n"
     ]
    }
   ],
   "source": [
    "# Inferencing on the holdout model approach\n",
    "# Inferencing on the holdout model approach didn't show any improvement over the best baseline\n",
    "command = 'python ../inference.py --test_path \"../datasets/challenge1/val\" \\\n",
    "                    --experiment_name \"HoldoutModelExperiments\" \\\n",
    "                    --network_name \"VGG16_BN_Attention\" \\\n",
    "                    --max_epochs \"50\" \\\n",
    "                    --base_lr \"0.00001\" \\\n",
    "                    --batch_size \"32\" \\\n",
    "                    --timeframe \"2023-12-24_2131+1035\" \\\n",
    "                    --verbose \"2\" \\\n",
    "                    --ensemble \\\n",
    "                    --report'\n",
    "\n",
    "# run the function to excute the command\n",
    "_ = execute_cmd_realtime(command, log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excuting inference script...\n",
      "Namespace(test_path='../datasets/challenge1/val', output='outputs', experiment_name='BestK3', network_name='VGG16_BN_Attention', max_epochs=50, batch_size=32, base_lr=1e-05, img_size=224, seed=42, timeframe='2023-12-24_2131', verbose=2, multi=False, report=True, ensemble=True, combination_strategy='majority_vote', upscale_factor=8, gradcam=False)\n",
      "Constructed output path: outputs/BestK3_224_epo50_bs32_lr1e-05_s42/2023-12-24_2131_VGG16_BN_Attention. Searching for models...\n",
      "Found 3 models.\n",
      "Loading data with 2 class labels from ../datasets/challenge1/val path...\n",
      "Dataset labels: {'nevus': 0, 'others': 1} dictionary.\n",
      "Loading the data from ../datasets/challenge1/val\n",
      "Dataset length: 3796\n",
      "Using VGG16_BN_Attention with configurations: num_classes='2', normalize_attn='False'\n",
      "Using VGG16_BN_Attention with configurations: num_classes='2', normalize_attn='False'\n",
      "Using VGG16_BN_Attention with configurations: num_classes='2', normalize_attn='False'\n",
      "\n",
      "Inference:   0%|          | 0/119 [00:00<?, ?it/s]\n",
      "Inference:   1%|          | 1/119 [00:51<1:41:07, 51.42s/it]\n",
      "Inference:   2%|▏         | 2/119 [00:51<41:45, 21.42s/it]  \n",
      "Inference:   3%|▎         | 3/119 [00:52<22:51, 11.83s/it]\n",
      "Inference:   3%|▎         | 4/119 [00:52<14:04,  7.34s/it]\n",
      "Inference:   4%|▍         | 5/119 [00:53<09:13,  4.85s/it]\n",
      "Inference:   5%|▌         | 6/119 [00:53<06:18,  3.35s/it]\n",
      "Inference:   6%|▌         | 7/119 [00:54<04:29,  2.40s/it]\n",
      "Inference:   7%|▋         | 8/119 [00:54<03:17,  1.78s/it]\n",
      "Inference:   8%|▊         | 9/119 [00:54<02:30,  1.37s/it]\n",
      "Inference:   8%|▊         | 10/119 [00:55<01:59,  1.09s/it]\n",
      "Inference:   9%|▉         | 11/119 [00:55<01:37,  1.11it/s]\n",
      "Inference:  10%|█         | 12/119 [00:56<01:21,  1.31it/s]\n",
      "Inference:  11%|█         | 13/119 [00:56<01:10,  1.51it/s]\n",
      "Inference:  12%|█▏        | 14/119 [00:57<01:02,  1.68it/s]\n",
      "Inference:  13%|█▎        | 15/119 [00:57<00:56,  1.83it/s]\n",
      "Inference:  13%|█▎        | 16/119 [00:58<00:53,  1.94it/s]\n",
      "Inference:  14%|█▍        | 17/119 [00:58<00:49,  2.05it/s]\n",
      "Inference:  15%|█▌        | 18/119 [00:58<00:46,  2.16it/s]\n",
      "Inference:  16%|█▌        | 19/119 [00:59<00:44,  2.24it/s]\n",
      "Inference:  17%|█▋        | 20/119 [00:59<00:43,  2.29it/s]\n",
      "Inference:  18%|█▊        | 21/119 [01:00<00:42,  2.32it/s]\n",
      "Inference:  18%|█▊        | 22/119 [01:00<00:41,  2.33it/s]\n",
      "Inference:  19%|█▉        | 23/119 [01:01<00:41,  2.33it/s]\n",
      "Inference:  20%|██        | 24/119 [01:01<00:40,  2.35it/s]\n",
      "Inference:  21%|██        | 25/119 [01:01<00:39,  2.36it/s]\n",
      "Inference:  22%|██▏       | 26/119 [01:02<00:39,  2.37it/s]\n",
      "Inference:  23%|██▎       | 27/119 [01:02<00:38,  2.39it/s]\n",
      "Inference:  24%|██▎       | 28/119 [01:03<00:37,  2.41it/s]\n",
      "Inference:  24%|██▍       | 29/119 [01:03<00:37,  2.43it/s]\n",
      "Inference:  25%|██▌       | 30/119 [01:03<00:36,  2.44it/s]\n",
      "Inference:  26%|██▌       | 31/119 [01:04<00:35,  2.45it/s]\n",
      "Inference:  27%|██▋       | 32/119 [01:04<00:35,  2.46it/s]\n",
      "Inference:  28%|██▊       | 33/119 [01:05<00:34,  2.46it/s]\n",
      "Inference:  29%|██▊       | 34/119 [01:05<00:34,  2.47it/s]\n",
      "Inference:  29%|██▉       | 35/119 [01:05<00:33,  2.48it/s]\n",
      "Inference:  30%|███       | 36/119 [01:06<00:33,  2.48it/s]\n",
      "Inference:  31%|███       | 37/119 [01:06<00:32,  2.49it/s]\n",
      "Inference:  32%|███▏      | 38/119 [01:07<00:32,  2.50it/s]\n",
      "Inference:  33%|███▎      | 39/119 [01:07<00:32,  2.50it/s]\n",
      "Inference:  34%|███▎      | 40/119 [01:07<00:31,  2.50it/s]\n",
      "Inference:  34%|███▍      | 41/119 [01:08<00:31,  2.50it/s]\n",
      "Inference:  35%|███▌      | 42/119 [01:08<00:30,  2.49it/s]\n",
      "Inference:  36%|███▌      | 43/119 [01:09<00:30,  2.50it/s]\n",
      "Inference:  37%|███▋      | 44/119 [01:09<00:29,  2.50it/s]\n",
      "Inference:  38%|███▊      | 45/119 [01:09<00:29,  2.51it/s]\n",
      "Inference:  39%|███▊      | 46/119 [01:10<00:29,  2.51it/s]\n",
      "Inference:  39%|███▉      | 47/119 [01:10<00:28,  2.51it/s]\n",
      "Inference:  40%|████      | 48/119 [01:11<00:28,  2.51it/s]\n",
      "Inference:  41%|████      | 49/119 [01:11<00:28,  2.50it/s]\n",
      "Inference:  42%|████▏     | 50/119 [01:11<00:27,  2.51it/s]\n",
      "Inference:  43%|████▎     | 51/119 [01:12<00:27,  2.51it/s]\n",
      "Inference:  44%|████▎     | 52/119 [01:12<00:26,  2.51it/s]\n",
      "Inference:  45%|████▍     | 53/119 [01:13<00:26,  2.52it/s]\n",
      "Inference:  45%|████▌     | 54/119 [01:13<00:25,  2.52it/s]\n",
      "Inference:  46%|████▌     | 55/119 [01:13<00:25,  2.53it/s]\n",
      "Inference:  47%|████▋     | 56/119 [01:14<00:24,  2.53it/s]\n",
      "Inference:  48%|████▊     | 57/119 [01:14<00:24,  2.53it/s]\n",
      "Inference:  49%|████▊     | 58/119 [01:15<00:32,  1.87it/s]\n",
      "Inference:  50%|████▉     | 59/119 [01:16<00:32,  1.87it/s]\n",
      "Inference:  50%|█████     | 60/119 [01:16<00:29,  1.99it/s]\n",
      "Inference:  51%|█████▏    | 61/119 [01:16<00:27,  2.09it/s]\n",
      "Inference:  52%|█████▏    | 62/119 [01:20<01:26,  1.52s/it]\n",
      "Inference:  53%|█████▎    | 63/119 [01:21<01:06,  1.20s/it]\n",
      "Inference:  54%|█████▍    | 64/119 [01:21<00:53,  1.04it/s]\n",
      "Inference:  55%|█████▍    | 65/119 [01:22<00:43,  1.25it/s]\n",
      "Inference:  55%|█████▌    | 66/119 [01:24<01:09,  1.31s/it]\n",
      "Inference:  56%|█████▋    | 67/119 [01:25<00:54,  1.05s/it]\n",
      "Inference:  57%|█████▋    | 68/119 [01:25<00:44,  1.16it/s]\n",
      "Inference:  58%|█████▊    | 69/119 [01:25<00:36,  1.36it/s]\n",
      "Inference:  59%|█████▉    | 70/119 [01:28<00:58,  1.20s/it]\n",
      "Inference:  60%|█████▉    | 71/119 [01:28<00:46,  1.04it/s]\n",
      "Inference:  61%|██████    | 72/119 [01:32<01:31,  1.94s/it]\n",
      "Inference:  61%|██████▏   | 73/119 [01:33<01:08,  1.48s/it]\n",
      "Inference:  62%|██████▏   | 74/119 [01:36<01:24,  1.87s/it]\n",
      "Inference:  63%|██████▎   | 75/119 [01:36<01:03,  1.44s/it]\n",
      "Inference:  64%|██████▍   | 76/119 [01:42<01:58,  2.75s/it]\n",
      "Inference:  65%|██████▍   | 77/119 [01:46<02:16,  3.24s/it]\n",
      "Inference:  66%|██████▌   | 78/119 [01:50<02:21,  3.45s/it]\n",
      "Inference:  66%|██████▋   | 79/119 [01:50<01:41,  2.53s/it]\n",
      "Inference:  67%|██████▋   | 80/119 [01:55<01:58,  3.04s/it]\n",
      "Inference:  68%|██████▊   | 81/119 [01:55<01:25,  2.25s/it]\n",
      "Inference:  69%|██████▉   | 82/119 [01:56<01:03,  1.70s/it]\n",
      "Inference:  70%|██████▉   | 83/119 [01:56<00:47,  1.31s/it]\n",
      "Inference:  71%|███████   | 84/119 [02:08<02:36,  4.47s/it]\n",
      "Inference:  71%|███████▏  | 85/119 [02:08<01:50,  3.26s/it]\n",
      "Inference:  72%|███████▏  | 86/119 [02:09<01:19,  2.41s/it]\n",
      "Inference:  73%|███████▎  | 87/119 [02:09<00:57,  1.81s/it]\n",
      "Inference:  74%|███████▍  | 88/119 [02:20<02:17,  4.42s/it]\n",
      "Inference:  75%|███████▍  | 89/119 [02:20<01:36,  3.21s/it]\n",
      "Inference:  76%|███████▌  | 90/119 [02:21<01:16,  2.63s/it]\n",
      "Inference:  76%|███████▋  | 91/119 [02:22<00:54,  1.96s/it]\n",
      "Inference:  77%|███████▋  | 92/119 [02:23<00:47,  1.78s/it]\n",
      "Inference:  78%|███████▊  | 93/119 [02:23<00:35,  1.37s/it]\n",
      "Inference:  79%|███████▉  | 94/119 [02:24<00:27,  1.09s/it]\n",
      "Inference:  80%|███████▉  | 95/119 [02:24<00:21,  1.11it/s]\n",
      "Inference:  81%|████████  | 96/119 [02:25<00:19,  1.20it/s]\n",
      "Inference:  82%|████████▏ | 97/119 [02:25<00:16,  1.36it/s]\n",
      "Inference:  82%|████████▏ | 98/119 [02:26<00:13,  1.54it/s]\n",
      "Inference:  83%|████████▎ | 99/119 [02:26<00:11,  1.70it/s]\n",
      "Inference:  84%|████████▍ | 100/119 [02:28<00:16,  1.16it/s]\n",
      "Inference:  85%|████████▍ | 101/119 [02:28<00:13,  1.34it/s]\n",
      "Inference:  86%|████████▌ | 102/119 [02:29<00:10,  1.55it/s]\n",
      "Inference:  87%|████████▋ | 103/119 [02:29<00:09,  1.72it/s]\n",
      "Inference:  87%|████████▋ | 104/119 [02:32<00:18,  1.20s/it]\n",
      "Inference:  88%|████████▊ | 105/119 [02:32<00:13,  1.03it/s]\n",
      "Inference:  89%|████████▉ | 106/119 [02:33<00:10,  1.24it/s]\n",
      "Inference:  90%|████████▉ | 107/119 [02:33<00:08,  1.45it/s]\n",
      "Inference:  91%|█████████ | 108/119 [02:35<00:11,  1.01s/it]\n",
      "Inference:  92%|█████████▏| 109/119 [02:36<00:10,  1.02s/it]\n",
      "Inference:  92%|█████████▏| 110/119 [02:36<00:07,  1.20it/s]\n",
      "Inference:  93%|█████████▎| 111/119 [02:37<00:05,  1.40it/s]\n",
      "Inference:  94%|█████████▍| 112/119 [02:39<00:07,  1.03s/it]\n",
      "Inference:  95%|█████████▍| 113/119 [02:39<00:05,  1.18it/s]\n",
      "Inference:  96%|█████████▌| 114/119 [02:39<00:03,  1.38it/s]\n",
      "Inference:  97%|█████████▋| 115/119 [02:41<00:03,  1.09it/s]\n",
      "Inference:  97%|█████████▋| 116/119 [02:42<00:03,  1.10s/it]\n",
      "Inference:  98%|█████████▊| 117/119 [02:45<00:03,  1.55s/it]\n",
      "Inference:  99%|█████████▉| 118/119 [02:45<00:01,  1.20s/it]\n",
      "Inference: 100%|██████████| 119/119 [02:48<00:00,  1.76s/it]\n",
      "Inference: 100%|██████████| 119/119 [02:49<00:00,  1.42s/it]\n",
      "all_predictions shape: (3, 3796)\n",
      "all_probabilities shape: (3, 3796, 2)\n",
      "Combination strategy is majority_vote. Computing the majority vote...\n",
      "Average probabilities: [[9.94710267e-01 5.28970547e-03]\n",
      " [9.99870777e-01 1.29133798e-04]\n",
      " [9.99723911e-01 2.76089617e-04]\n",
      " ...\n",
      " [5.54974237e-03 9.94450271e-01]\n",
      " [1.08321495e-01 8.91678512e-01]\n",
      " [8.57573748e-03 9.91424263e-01]]\n",
      "Results exported to: outputs/BestK3_224_epo50_bs32_lr1e-05_s42/2023-12-24_2131_VGG16_BN_Attention/ch1_majority_vote_val_BestK3_224_epo50_bs32_lr1e-05_s42_2023-12-24_2131_VGG16_BN_Attention.csv\n",
      "Figure(1500x600)\n",
      "Majority vote AUC: 0.93956\n",
      "Majority vote accuracy: 0.9399367755532139\n",
      "Majority vote kappa: 0.8797512796836449\n",
      "Target 0 - Precision: 0.92384, Recall: 0.96116, F-score: 0.94213, Sensitivity: 0.9611600207146557, Specificity: 0.9179624664879357, Support: 1931\n",
      "Target 1 - Precision: 0.95803, Recall: 0.91796, F-score: 0.93757, Sensitivity: 0.9179624664879357, Specificity: 0.9611600207146557, Support: 1865\n",
      "(   {   'accuracy': 0.9399367755532139,\n",
      "        'auc': 0.9395612436012956,\n",
      "        'fscore': [0.9421319796954315, 0.9375684556407449],\n",
      "        'kappa': 0.8797512796836449,\n",
      "        'precision': [0.9238427078148332, 0.9580302182428652],\n",
      "        'recall': [0.9611600207146557, 0.9179624664879357],\n",
      "        'sensitivity': [0.9611600207146557, 0.9179624664879357],\n",
      "        'specificity': [0.9179624664879357, 0.9611600207146557],\n",
      "        'support': [1931, 1865]},)\n"
     ]
    }
   ],
   "source": [
    "# Inferencing only the best 3 models from the baseline in the same folder\n",
    "# BEST 3 MODELS for challenge1!\n",
    "command = 'python ../inference.py --test_path \"../datasets/challenge1/val\" \\\n",
    "                    --experiment_name \"BestK3\" \\\n",
    "                    --network_name \"VGG16_BN_Attention\" \\\n",
    "                    --max_epochs \"50\" \\\n",
    "                    --base_lr \"0.00001\" \\\n",
    "                    --batch_size \"32\" \\\n",
    "                    --timeframe \"2023-12-24_2131\" \\\n",
    "                    --verbose \"2\" \\\n",
    "                    --ensemble \\\n",
    "                    --report'\n",
    "\n",
    "# run the function to excute the command\n",
    "_ = execute_cmd_realtime(command, log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excuting inference script...\n",
      "Namespace(test_path='../datasets/challenge1/test', output='outputs', experiment_name='BestK3', network_name='VGG16_BN_Attention', max_epochs=50, batch_size=32, base_lr=1e-05, img_size=224, seed=42, timeframe='2023-12-24_2131', verbose=2, multi=False, report=False, ensemble=True, combination_strategy='majority_vote', upscale_factor=8, gradcam=False)\n",
      "Constructed output path: outputs/BestK3_224_epo50_bs32_lr1e-05_s42/2023-12-24_2131_VGG16_BN_Attention. Searching for models...\n",
      "Found 3 models.\n",
      "Loading data with unknown class labels from ../datasets/challenge1/test path...\n",
      "Dataset labels: {'testX': -911, 'testY': -922} dictionary.\n",
      "Loading the data from ../datasets/challenge1/test\n",
      "Forcing n_classes to be based on the length of the labels dictionary...\n",
      "Before: 1\n",
      "After: 2\n",
      "Dataset length: 6340\n",
      "Using VGG16_BN_Attention with configurations: num_classes='2', normalize_attn='False'\n",
      "Using VGG16_BN_Attention with configurations: num_classes='2', normalize_attn='False'\n",
      "Using VGG16_BN_Attention with configurations: num_classes='2', normalize_attn='False'\n",
      "\n",
      "Inference:   0%|          | 0/199 [00:00<?, ?it/s]\n",
      "Inference:   1%|          | 1/199 [00:31<1:44:59, 31.81s/it]\n",
      "Inference:   1%|          | 2/199 [00:32<43:48, 13.35s/it]  \n",
      "Inference:   2%|▏         | 3/199 [00:32<24:23,  7.47s/it]\n",
      "Inference:   2%|▏         | 4/199 [00:33<15:16,  4.70s/it]\n",
      "Inference:   3%|▎         | 5/199 [00:33<10:17,  3.18s/it]\n",
      "Inference:   3%|▎         | 6/199 [00:34<07:16,  2.26s/it]\n",
      "Inference:   4%|▎         | 7/199 [00:34<05:23,  1.69s/it]\n",
      "Inference:   4%|▍         | 8/199 [00:35<04:08,  1.30s/it]\n",
      "Inference:   5%|▍         | 9/199 [00:35<03:18,  1.05s/it]\n",
      "Inference:   5%|▌         | 10/199 [00:36<02:44,  1.15it/s]\n",
      "Inference:   6%|▌         | 11/199 [00:36<02:19,  1.35it/s]\n",
      "Inference:   6%|▌         | 12/199 [00:36<02:01,  1.54it/s]\n",
      "Inference:   7%|▋         | 13/199 [00:37<01:49,  1.70it/s]\n",
      "Inference:   7%|▋         | 14/199 [00:37<01:40,  1.84it/s]\n",
      "Inference:   8%|▊         | 15/199 [00:38<01:34,  1.95it/s]\n",
      "Inference:   8%|▊         | 16/199 [00:38<01:29,  2.03it/s]\n",
      "Inference:   9%|▊         | 17/199 [00:39<01:26,  2.10it/s]\n",
      "Inference:   9%|▉         | 18/199 [00:39<01:22,  2.19it/s]\n",
      "Inference:  10%|▉         | 19/199 [00:40<01:20,  2.23it/s]\n",
      "Inference:  10%|█         | 20/199 [00:40<01:18,  2.28it/s]\n",
      "Inference:  11%|█         | 21/199 [00:40<01:16,  2.32it/s]\n",
      "Inference:  11%|█         | 22/199 [00:41<01:15,  2.36it/s]\n",
      "Inference:  12%|█▏        | 23/199 [00:41<01:13,  2.38it/s]\n",
      "Inference:  12%|█▏        | 24/199 [00:42<01:12,  2.41it/s]\n",
      "Inference:  13%|█▎        | 25/199 [00:42<01:11,  2.45it/s]\n",
      "Inference:  13%|█▎        | 26/199 [00:42<01:09,  2.48it/s]\n",
      "Inference:  14%|█▎        | 27/199 [00:43<01:09,  2.48it/s]\n",
      "Inference:  14%|█▍        | 28/199 [00:43<01:08,  2.48it/s]\n",
      "Inference:  15%|█▍        | 29/199 [00:44<01:08,  2.49it/s]\n",
      "Inference:  15%|█▌        | 30/199 [00:44<01:07,  2.50it/s]\n",
      "Inference:  16%|█▌        | 31/199 [00:44<01:07,  2.51it/s]\n",
      "Inference:  16%|█▌        | 32/199 [00:45<01:06,  2.50it/s]\n",
      "Inference:  17%|█▋        | 33/199 [00:45<01:06,  2.50it/s]\n",
      "Inference:  17%|█▋        | 34/199 [00:46<01:05,  2.51it/s]\n",
      "Inference:  18%|█▊        | 35/199 [00:46<01:05,  2.52it/s]\n",
      "Inference:  18%|█▊        | 36/199 [00:46<01:04,  2.53it/s]\n",
      "Inference:  19%|█▊        | 37/199 [00:47<01:04,  2.52it/s]\n",
      "Inference:  19%|█▉        | 38/199 [00:47<01:03,  2.52it/s]\n",
      "Inference:  20%|█▉        | 39/199 [00:48<01:03,  2.52it/s]\n",
      "Inference:  20%|██        | 40/199 [00:48<01:03,  2.52it/s]\n",
      "Inference:  21%|██        | 41/199 [00:48<01:02,  2.52it/s]\n",
      "Inference:  21%|██        | 42/199 [00:49<01:02,  2.52it/s]\n",
      "Inference:  22%|██▏       | 43/199 [00:49<01:01,  2.52it/s]\n",
      "Inference:  22%|██▏       | 44/199 [00:49<01:01,  2.53it/s]\n",
      "Inference:  23%|██▎       | 45/199 [00:50<01:00,  2.53it/s]\n",
      "Inference:  23%|██▎       | 46/199 [00:50<01:00,  2.53it/s]\n",
      "Inference:  24%|██▎       | 47/199 [00:51<00:59,  2.54it/s]\n",
      "Inference:  24%|██▍       | 48/199 [00:51<00:59,  2.53it/s]\n",
      "Inference:  25%|██▍       | 49/199 [00:51<00:59,  2.54it/s]\n",
      "Inference:  25%|██▌       | 50/199 [00:52<00:58,  2.54it/s]\n",
      "Inference:  26%|██▌       | 51/199 [00:52<00:58,  2.54it/s]\n",
      "Inference:  26%|██▌       | 52/199 [00:53<00:57,  2.54it/s]\n",
      "Inference:  27%|██▋       | 53/199 [00:53<00:57,  2.54it/s]\n",
      "Inference:  27%|██▋       | 54/199 [00:53<00:57,  2.54it/s]\n",
      "Inference:  28%|██▊       | 55/199 [00:54<00:56,  2.54it/s]\n",
      "Inference:  28%|██▊       | 56/199 [00:54<00:56,  2.54it/s]\n",
      "Inference:  29%|██▊       | 57/199 [00:55<00:55,  2.54it/s]\n",
      "Inference:  29%|██▉       | 58/199 [00:55<00:55,  2.54it/s]\n",
      "Inference:  30%|██▉       | 59/199 [00:55<00:55,  2.54it/s]\n",
      "Inference:  30%|███       | 60/199 [00:56<00:54,  2.55it/s]\n",
      "Inference:  31%|███       | 61/199 [00:56<00:54,  2.54it/s]\n",
      "Inference:  31%|███       | 62/199 [00:57<00:53,  2.54it/s]\n",
      "Inference:  32%|███▏      | 63/199 [00:57<00:53,  2.54it/s]\n",
      "Inference:  32%|███▏      | 64/199 [00:57<00:53,  2.54it/s]\n",
      "Inference:  33%|███▎      | 65/199 [00:58<00:52,  2.54it/s]\n",
      "Inference:  33%|███▎      | 66/199 [00:58<00:52,  2.53it/s]\n",
      "Inference:  34%|███▎      | 67/199 [00:59<00:52,  2.53it/s]\n",
      "Inference:  34%|███▍      | 68/199 [00:59<00:51,  2.54it/s]\n",
      "Inference:  35%|███▍      | 69/199 [00:59<00:51,  2.53it/s]\n",
      "Inference:  35%|███▌      | 70/199 [01:00<00:51,  2.53it/s]\n",
      "Inference:  36%|███▌      | 71/199 [01:00<00:50,  2.54it/s]\n",
      "Inference:  36%|███▌      | 72/199 [01:01<00:50,  2.54it/s]\n",
      "Inference:  37%|███▋      | 73/199 [01:01<00:49,  2.54it/s]\n",
      "Inference:  37%|███▋      | 74/199 [01:01<00:49,  2.53it/s]\n",
      "Inference:  38%|███▊      | 75/199 [01:02<00:48,  2.54it/s]\n",
      "Inference:  38%|███▊      | 76/199 [01:02<00:48,  2.53it/s]\n",
      "Inference:  39%|███▊      | 77/199 [01:02<00:48,  2.53it/s]\n",
      "Inference:  39%|███▉      | 78/199 [01:03<00:47,  2.53it/s]\n",
      "Inference:  40%|███▉      | 79/199 [01:03<00:47,  2.53it/s]\n",
      "Inference:  40%|████      | 80/199 [01:04<00:46,  2.54it/s]\n",
      "Inference:  41%|████      | 81/199 [01:04<00:46,  2.53it/s]\n",
      "Inference:  41%|████      | 82/199 [01:04<00:46,  2.53it/s]\n",
      "Inference:  42%|████▏     | 83/199 [01:05<00:45,  2.52it/s]\n",
      "Inference:  42%|████▏     | 84/199 [01:05<00:45,  2.53it/s]\n",
      "Inference:  43%|████▎     | 85/199 [01:06<00:45,  2.53it/s]\n",
      "Inference:  43%|████▎     | 86/199 [01:06<00:44,  2.53it/s]\n",
      "Inference:  44%|████▎     | 87/199 [01:06<00:44,  2.52it/s]\n",
      "Inference:  44%|████▍     | 88/199 [01:07<00:44,  2.52it/s]\n",
      "Inference:  45%|████▍     | 89/199 [01:07<00:43,  2.53it/s]\n",
      "Inference:  45%|████▌     | 90/199 [01:08<00:42,  2.53it/s]\n",
      "Inference:  46%|████▌     | 91/199 [01:08<00:42,  2.53it/s]\n",
      "Inference:  46%|████▌     | 92/199 [01:08<00:42,  2.53it/s]\n",
      "Inference:  47%|████▋     | 93/199 [01:09<00:41,  2.53it/s]\n",
      "Inference:  47%|████▋     | 94/199 [01:09<00:41,  2.52it/s]\n",
      "Inference:  48%|████▊     | 95/199 [01:10<00:41,  2.51it/s]\n",
      "Inference:  48%|████▊     | 96/199 [01:10<00:41,  2.51it/s]\n",
      "Inference:  49%|████▊     | 97/199 [01:10<00:40,  2.50it/s]\n",
      "Inference:  49%|████▉     | 98/199 [01:11<00:40,  2.51it/s]\n",
      "Inference:  50%|████▉     | 99/199 [01:11<00:39,  2.51it/s]\n",
      "Inference:  50%|█████     | 100/199 [01:12<00:39,  2.51it/s]\n",
      "Inference:  51%|█████     | 101/199 [01:12<00:39,  2.50it/s]\n",
      "Inference:  51%|█████▏    | 102/199 [01:12<00:38,  2.50it/s]\n",
      "Inference:  52%|█████▏    | 103/199 [01:13<00:38,  2.50it/s]\n",
      "Inference:  52%|█████▏    | 104/199 [01:13<00:37,  2.50it/s]\n",
      "Inference:  53%|█████▎    | 105/199 [01:14<00:37,  2.50it/s]\n",
      "Inference:  53%|█████▎    | 106/199 [01:14<00:37,  2.49it/s]\n",
      "Inference:  54%|█████▍    | 107/199 [01:14<00:36,  2.50it/s]\n",
      "Inference:  54%|█████▍    | 108/199 [01:15<00:36,  2.51it/s]\n",
      "Inference:  55%|█████▍    | 109/199 [01:15<00:35,  2.51it/s]\n",
      "Inference:  55%|█████▌    | 110/199 [01:16<00:35,  2.50it/s]\n",
      "Inference:  56%|█████▌    | 111/199 [01:16<00:35,  2.50it/s]\n",
      "Inference:  56%|█████▋    | 112/199 [01:16<00:34,  2.50it/s]\n",
      "Inference:  57%|█████▋    | 113/199 [01:17<00:34,  2.51it/s]\n",
      "Inference:  57%|█████▋    | 114/199 [01:17<00:33,  2.51it/s]\n",
      "Inference:  58%|█████▊    | 115/199 [01:18<00:33,  2.52it/s]\n",
      "Inference:  58%|█████▊    | 116/199 [01:18<00:32,  2.52it/s]\n",
      "Inference:  59%|█████▉    | 117/199 [01:18<00:32,  2.53it/s]\n",
      "Inference:  59%|█████▉    | 118/199 [01:19<00:32,  2.53it/s]\n",
      "Inference:  60%|█████▉    | 119/199 [01:19<00:31,  2.53it/s]\n",
      "Inference:  60%|██████    | 120/199 [01:20<00:31,  2.53it/s]\n",
      "Inference:  61%|██████    | 121/199 [01:20<00:30,  2.53it/s]\n",
      "Inference:  61%|██████▏   | 122/199 [01:20<00:30,  2.53it/s]\n",
      "Inference:  62%|██████▏   | 123/199 [01:21<00:30,  2.53it/s]\n",
      "Inference:  62%|██████▏   | 124/199 [01:21<00:29,  2.52it/s]\n",
      "Inference:  63%|██████▎   | 125/199 [01:22<00:29,  2.52it/s]\n",
      "Inference:  63%|██████▎   | 126/199 [01:22<00:29,  2.51it/s]\n",
      "Inference:  64%|██████▍   | 127/199 [01:22<00:28,  2.52it/s]\n",
      "Inference:  64%|██████▍   | 128/199 [01:23<00:28,  2.51it/s]\n",
      "Inference:  65%|██████▍   | 129/199 [01:23<00:27,  2.51it/s]\n",
      "Inference:  65%|██████▌   | 130/199 [01:24<00:27,  2.50it/s]\n",
      "Inference:  66%|██████▌   | 131/199 [01:24<00:27,  2.51it/s]\n",
      "Inference:  66%|██████▋   | 132/199 [01:24<00:26,  2.51it/s]\n",
      "Inference:  67%|██████▋   | 133/199 [01:25<00:26,  2.49it/s]\n",
      "Inference:  67%|██████▋   | 134/199 [01:25<00:26,  2.48it/s]\n",
      "Inference:  68%|██████▊   | 135/199 [01:26<00:25,  2.49it/s]\n",
      "Inference:  68%|██████▊   | 136/199 [01:26<00:25,  2.50it/s]\n",
      "Inference:  69%|██████▉   | 137/199 [01:26<00:24,  2.50it/s]\n",
      "Inference:  69%|██████▉   | 138/199 [01:27<00:24,  2.50it/s]\n",
      "Inference:  70%|██████▉   | 139/199 [01:27<00:24,  2.48it/s]\n",
      "Inference:  70%|███████   | 140/199 [01:28<00:23,  2.49it/s]\n",
      "Inference:  71%|███████   | 141/199 [01:28<00:23,  2.49it/s]\n",
      "Inference:  71%|███████▏  | 142/199 [01:28<00:22,  2.50it/s]\n",
      "Inference:  72%|███████▏  | 143/199 [01:29<00:22,  2.51it/s]\n",
      "Inference:  72%|███████▏  | 144/199 [01:29<00:21,  2.52it/s]\n",
      "Inference:  73%|███████▎  | 145/199 [01:30<00:21,  2.51it/s]\n",
      "Inference:  73%|███████▎  | 146/199 [01:30<00:21,  2.50it/s]\n",
      "Inference:  74%|███████▍  | 147/199 [01:30<00:20,  2.49it/s]\n",
      "Inference:  74%|███████▍  | 148/199 [01:31<00:20,  2.49it/s]\n",
      "Inference:  75%|███████▍  | 149/199 [01:31<00:20,  2.49it/s]\n",
      "Inference:  75%|███████▌  | 150/199 [01:32<00:19,  2.49it/s]\n",
      "Inference:  76%|███████▌  | 151/199 [01:32<00:19,  2.48it/s]\n",
      "Inference:  76%|███████▋  | 152/199 [01:32<00:18,  2.49it/s]\n",
      "Inference:  77%|███████▋  | 153/199 [01:33<00:18,  2.49it/s]\n",
      "Inference:  77%|███████▋  | 154/199 [01:33<00:18,  2.49it/s]\n",
      "Inference:  78%|███████▊  | 155/199 [01:34<00:17,  2.47it/s]\n",
      "Inference:  78%|███████▊  | 156/199 [01:34<00:17,  2.47it/s]\n",
      "Inference:  79%|███████▉  | 157/199 [01:34<00:17,  2.47it/s]\n",
      "Inference:  79%|███████▉  | 158/199 [01:35<00:16,  2.47it/s]\n",
      "Inference:  80%|███████▉  | 159/199 [01:35<00:16,  2.46it/s]\n",
      "Inference:  80%|████████  | 160/199 [01:36<00:15,  2.47it/s]\n",
      "Inference:  81%|████████  | 161/199 [01:36<00:15,  2.47it/s]\n",
      "Inference:  81%|████████▏ | 162/199 [01:36<00:14,  2.48it/s]\n",
      "Inference:  82%|████████▏ | 163/199 [01:37<00:14,  2.48it/s]\n",
      "Inference:  82%|████████▏ | 164/199 [01:37<00:14,  2.48it/s]\n",
      "Inference:  83%|████████▎ | 165/199 [01:38<00:13,  2.48it/s]\n",
      "Inference:  83%|████████▎ | 166/199 [01:38<00:13,  2.49it/s]\n",
      "Inference:  84%|████████▍ | 167/199 [01:38<00:12,  2.49it/s]\n",
      "Inference:  84%|████████▍ | 168/199 [01:39<00:12,  2.50it/s]\n",
      "Inference:  85%|████████▍ | 169/199 [01:39<00:11,  2.51it/s]\n",
      "Inference:  85%|████████▌ | 170/199 [01:40<00:11,  2.51it/s]\n",
      "Inference:  86%|████████▌ | 171/199 [01:40<00:11,  2.51it/s]\n",
      "Inference:  86%|████████▋ | 172/199 [01:40<00:10,  2.52it/s]\n",
      "Inference:  87%|████████▋ | 173/199 [01:41<00:10,  2.52it/s]\n",
      "Inference:  87%|████████▋ | 174/199 [01:41<00:09,  2.52it/s]\n",
      "Inference:  88%|████████▊ | 175/199 [01:42<00:09,  2.52it/s]\n",
      "Inference:  88%|████████▊ | 176/199 [01:42<00:09,  2.50it/s]\n",
      "Inference:  89%|████████▉ | 177/199 [01:42<00:08,  2.48it/s]\n",
      "Inference:  89%|████████▉ | 178/199 [01:43<00:08,  2.46it/s]\n",
      "Inference:  90%|████████▉ | 179/199 [01:44<00:10,  1.97it/s]\n",
      "Inference:  90%|█████████ | 180/199 [01:44<00:09,  2.09it/s]\n",
      "Inference:  91%|█████████ | 181/199 [01:44<00:08,  2.14it/s]\n",
      "Inference:  91%|█████████▏| 182/199 [01:45<00:07,  2.18it/s]\n",
      "Inference:  92%|█████████▏| 183/199 [01:45<00:07,  2.20it/s]\n",
      "Inference:  92%|█████████▏| 184/199 [01:46<00:06,  2.21it/s]\n",
      "Inference:  93%|█████████▎| 185/199 [01:46<00:06,  2.21it/s]\n",
      "Inference:  93%|█████████▎| 186/199 [01:47<00:05,  2.21it/s]\n",
      "Inference:  94%|█████████▍| 187/199 [01:47<00:05,  2.22it/s]\n",
      "Inference:  94%|█████████▍| 188/199 [01:48<00:04,  2.23it/s]\n",
      "Inference:  95%|█████████▍| 189/199 [01:48<00:04,  2.24it/s]\n",
      "Inference:  95%|█████████▌| 190/199 [01:48<00:03,  2.26it/s]\n",
      "Inference:  96%|█████████▌| 191/199 [01:49<00:03,  2.25it/s]\n",
      "Inference:  96%|█████████▋| 192/199 [01:49<00:03,  2.28it/s]\n",
      "Inference:  97%|█████████▋| 193/199 [01:50<00:02,  2.32it/s]\n",
      "Inference:  97%|█████████▋| 194/199 [01:50<00:02,  2.36it/s]\n",
      "Inference:  98%|█████████▊| 195/199 [01:51<00:01,  2.39it/s]\n",
      "Inference:  98%|█████████▊| 196/199 [01:51<00:01,  2.43it/s]\n",
      "Inference:  99%|█████████▉| 197/199 [01:51<00:00,  2.45it/s]\n",
      "Inference:  99%|█████████▉| 198/199 [01:52<00:00,  2.47it/s]\n",
      "Inference: 100%|██████████| 199/199 [01:52<00:00,  2.34it/s]\n",
      "Inference: 100%|██████████| 199/199 [01:52<00:00,  1.77it/s]\n",
      "all_predictions shape: (3, 6340)\n",
      "all_probabilities shape: (3, 6340, 2)\n",
      "Combination strategy is majority_vote. Computing the majority vote...\n",
      "Average probabilities: [[9.8122144e-01 1.8778516e-02]\n",
      " [9.9983495e-01 1.6509062e-04]\n",
      " [2.1365339e-01 7.8634661e-01]\n",
      " ...\n",
      " [1.8091114e-03 9.9819088e-01]\n",
      " [9.9986076e-01 1.3926937e-04]\n",
      " [2.6342348e-05 9.9997360e-01]]\n",
      "Results exported to: outputs/BestK3_224_epo50_bs32_lr1e-05_s42/2023-12-24_2131_VGG16_BN_Attention/ch1_majority_vote_test_BestK3_224_epo50_bs32_lr1e-05_s42_2023-12-24_2131_VGG16_BN_Attention.csv\n"
     ]
    }
   ],
   "source": [
    "# Inferencing only the best 3 models from the baseline in the same folder << on the test set >>\n",
    "# BEST 3 MODELS for challenge1 <<SUBMISSION>>\n",
    "command = 'python ../inference.py --test_path \"../datasets/challenge1/test\" \\\n",
    "                    --experiment_name \"BestK3\" \\\n",
    "                    --network_name \"VGG16_BN_Attention\" \\\n",
    "                    --max_epochs \"50\" \\\n",
    "                    --base_lr \"0.00001\" \\\n",
    "                    --batch_size \"32\" \\\n",
    "                    --timeframe \"2023-12-24_2131\" \\\n",
    "                    --verbose \"2\" \\\n",
    "                    --ensemble'\n",
    "\n",
    "# run the function to excute the command\n",
    "_ = execute_cmd_realtime(command, log=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
